{"docstore/metadata": {"1055cab1-3de0-40fe-90f0-2d9033c4158d": {"doc_hash": "80cc5cde4460520c159ae62d7bb3db4ae68e028fb629cc70c923874b8e4f6e96"}, "0cb393b1-4fa3-4add-a052-1e3ba8f37bdb": {"doc_hash": "4faaa1aff918e550b7dbd6f5d40d1fc3c838253086a4d08f2b0f13f53455e0d2"}, "76b4ee5b-951c-4c62-bf89-cccdf9305ab1": {"doc_hash": "d49a8fef037bcc2d196c8d204b54c61053671b0618716041c8aab08f30c599bc"}, "2882c793-8941-4b9f-a793-9bf9cb603102": {"doc_hash": "00ac49980a8d79d19962c3bf6f3c38231279acf809fae9aacc9cda7f022eff5f"}, "29c86582-726a-4daa-8e6e-e79d82075de6": {"doc_hash": "af956d3dbc7f533ae057b845e442a23d31d14ef4803a00912e8ca07b77a31c4d"}, "e8847db6-9b82-4bba-96b9-267d424fff7b": {"doc_hash": "9b385a9cdaafffbca871c11f468c39b617f514f236b33919bd6e0c3719036082"}, "8e1b8a2a-0337-4ede-8e83-20bc988a8891": {"doc_hash": "43c515e599fedf0e5a9ede95071192d053e5d0fb3aacecc3ecd8d9612390f9cf"}, "18c8e4c5-7896-422e-b175-c9118d020d01": {"doc_hash": "b6e1b5570a2de4f34e9870d271d50fa2765b8b189e357c1cd7e3f041b36cfee2"}, "b6d2dab4-ac8d-4825-a919-f0fc8828e199": {"doc_hash": "2bb79f9c17630ffb36267434abbed494234932ac3b46841dd5bcb1e69b516ba7"}, "4606b726-9a1e-4ef5-891a-13f972dce071": {"doc_hash": "96de4686adc567e462f818ac816d5f6797e5fa44539f35e7a7bc3259909f43ae"}, "72adc90f-c95b-45f4-a40d-7cebd2141e0b": {"doc_hash": "699f092bc7e563284b183268d540df8b78ec6ef1e4468a58f72ee7a7648050b7"}, "b1cb4d27-35eb-4e48-881c-de73f0c61abd": {"doc_hash": "af5ef1304cac919f130e5efee44985b2a78303265a1689e0a26e6748ce324726"}, "70b81647-b9f6-4947-84a1-8350567b6836": {"doc_hash": "2608f2884e4e2a8ae89603fdb9bf72c47377fd243d9543e1f1fe218fc4de9bc4"}, "632d3ac0-6d03-4732-9749-6bb66cbabef6": {"doc_hash": "c99ce49700354368f5abf3f01c4852f89d55fcb2ea74007014d7a9180fe71207"}, "fc4e5dd6-17dc-41ff-b944-0a5e44017832": {"doc_hash": "a67a2816852433a3c6388a569ba42a1de8bf9858cc949344374d1d561fe1c6cc"}, "15d19c7a-a447-4094-9e6e-ec680417ef0f": {"doc_hash": "017d9f7547e197a6d87d2a88fd81ae69c94b1ece65fe9b49c35dd72ec66a1822"}, "15b2b17a-5edb-4d24-b625-13942edb47a9": {"doc_hash": "9a3bf9924d57711de369fdbc3db5f33a51ee58c792c4d6270d6a76f57f25543a"}, "3b2250d0-b93c-49ce-9c98-ddf0a2e5f90c": {"doc_hash": "b63635a80f8e959e6e897b05b8ddf5415b23547696280b2a52b747edc2662a21"}, "6547b7de-10ba-4eb6-9257-7d27201f9301": {"doc_hash": "8769e0c8225f37781f07e7e2e4b6101d90cba79e497b9e7d7efa96a97173feef"}, "99bbc038-fd74-47bb-b0a2-3a3eed98385f": {"doc_hash": "3eec0222b295546accafd23451767b53a2f5fa0e06307a233f8018389043d321"}, "9614a124-f62a-43c7-afac-379c1cac8718": {"doc_hash": "998d840200c081354ff3eddc59fed4a45e65ad84e08fa4e0ec1048ba74fc1d05"}, "babf8ba1-22b6-42cd-86fa-c702119e7296": {"doc_hash": "d91b76aac863cba386e02574123393cce1344f634ecc60a1a9b6061299da2332"}, "ba0fd3fb-2846-4096-9fe7-09db24c6613b": {"doc_hash": "87395e1e9413f6bb062dbb186a3c68445d9cb49d8259819d319f103b42cdd638"}, "361141c9-e7b5-4045-9f0f-4c1c5c68b2cc": {"doc_hash": "60f51df9599a1020a57744941a4ea51b3702d453b1f18e24a742036fdae29b36"}, "d6edda22-194e-4dd8-82b9-86fdacddf479": {"doc_hash": "2354f282be33a0fff54aaa8fd0920e9bd78e8d65857cb861e1a8314c3a0b358d"}, "e7632259-1f52-4687-b941-fd17f76991b6": {"doc_hash": "5383290e585b9c2c699ce56b786b3ca531359f6f539211eaf8b6d57da64a8285"}, "837295da-79b3-4a37-8320-3e6aa6cb8289": {"doc_hash": "03b5e960e2d2dfa15be91952456ae9aa0df04d3d45eb31285ba711c1e4ed3ccc"}, "9bb3ac0c-a620-4cf4-89bc-18bc0f066e96": {"doc_hash": "4e4b3d2cab2f1b3e915c8dbe35fbdda30f5bf3b5ea98b13df7f24937a8d7478d"}, "7eaa85f0-b4f5-4e80-9b96-8789c9a1b4f4": {"doc_hash": "570186fe94ce17134fac42c76de48c5abe408b13151d60159fce2e47b6573091"}, "d7fc2ff5-c0ca-4190-be2d-cc2ac02565b8": {"doc_hash": "570145c9a7f007b775ca5b3c643b27ea3000685cbc3488283d92e3c0538b06ad"}, "7f024ff2-fa4a-4aba-a83c-cf63b7887cbf": {"doc_hash": "f4af56523c13f5415c2c05112bed4d18c5eac1d003c3313125703a333f7f22e9"}, "2f38a15f-ed77-41da-af3e-ae6b716e45d6": {"doc_hash": "74a686603f035e48ee8b52c7532ca66dfb520f8bcc3e51ce2148a767f2d88e3e"}, "8ae09ae3-d073-4a80-b873-a5903f3508ae": {"doc_hash": "d5dd10266bc7ac1e8aa3b9b4265b12465eb2489107227ace1fc6f2495fa8e1c8"}, "5a6684de-876e-471d-b60c-642d70173437": {"doc_hash": "c134febea70ac70728405819bad182f5f25c1fb6525020a6826ad33ca7217a3b"}, "ccd9de26-b535-4f35-a253-87772666276b": {"doc_hash": "e4121612a8948504789cc5d6e687dfde6ff93562fe869a299211ac5df4d7098d"}, "48bb859c-cf0c-47ed-8ea8-d188a9e6e485": {"doc_hash": "032f63753e39e5ee8e622ac9d8c2a58e896b4f2f4802cf2c6268569e5ce9fbba"}, "aa9b40b4-911f-4a5a-9cae-2e3862de69f1": {"doc_hash": "140fd8083ac707b2b81eafc2cce491d6a5ba26d7f9a40dcf0087249549c7ff2e"}, "210986f7-26f4-4da7-8fb2-6b1137877b85": {"doc_hash": "cb47865de7393029d8b280360aa8cbd1878ad7877c9536dbb2ba76b4e503c9f2"}, "c8db3186-7e1a-43ff-984d-eec665050d35": {"doc_hash": "b4edda1e607a81968637cec0872206298613b66a2990e915229288586fb15018"}, "a76c5fbf-6b0a-4cbe-9a52-ce8df9a8ff97": {"doc_hash": "c9a941cfaca2a578af51cb2b6995f5fc3b79f463533e4b05300a21e72a95c766"}, "e9b394d3-bdde-4611-a400-990cebc1d922": {"doc_hash": "997171c5ee91b4e6d13ebf25629cdb9c36f38f006c782b2d55269653ad95e2ad"}, "19ac6947-a140-473f-a316-b2007b0cbd08": {"doc_hash": "2cdc360d7961e40fa9e4958e4c0b59ab61d74a954e1ca5ff6b99fc896001d8d2"}, "5b3a24ea-b8a4-44d7-896a-6495ee0ef268": {"doc_hash": "5796392b7cc6fee22ab3ef0e4ca018fc9850e87dc68937a54fbea222c1dbd9d6"}, "c2b87e2d-229e-40c4-bbbb-7be1230bec1d": {"doc_hash": "7b5e100a03cc55e0bb62db776fdc46e44946762ddf4a2bff7578ff8ed112fb80"}, "d4591de8-c26f-4fa8-81e7-c6036f843743": {"doc_hash": "9469671dcfa863c583ae12276cb448fe5e0f56ac7d5ac9132a7450e819b2a407"}, "62b3829b-14f8-44ed-a8e3-89131dc6c30d": {"doc_hash": "977dd3c87327c09febb6c1a23b11ed3ac9d8c82e0435334349d6d7c237802828"}, "538b4779-1103-45b7-b8bc-0b1b5a9a8115": {"doc_hash": "734bbecd5a4c79faacb5f9d2133247ce6da18c774a58a5544199151c094602b5"}, "82b7897d-7334-4171-98ed-29352305c2a1": {"doc_hash": "bf98286659a252b784b480d2caa6d5792efee64198c22859b5e362a8380d3fb8"}, "e7ea49f3-3d57-4199-8bb6-001cb5e32e02": {"doc_hash": "83ef3198ac31f2ebda3c1b5cf610830989c5d6073b700cfed608d98c6e29e06f"}, "a8798fdd-4d95-4e5d-bee7-a12528710767": {"doc_hash": "4c9139d413714f5d003251014061cf393f63e4f3e4b381a26c458d3718ad89dc"}, "16728635-dfaf-485b-a202-083254e21728": {"doc_hash": "f1d9cce02cc26c091ff0e5691a6576fe70514952b62929801dcb6dde70a5c1bf"}, "2c75a539-cc0f-4b2e-a575-81c3d7ef8e47": {"doc_hash": "3b52cf0295e53583634459703c736f778866707abb4aec90aaae5c86adaf4093"}, "650ba54a-e415-456b-bdac-82b3b29b223d": {"doc_hash": "e818a8937b739e7aa8b2093048d697a3c590db15106043fea4964b88064e6564"}, "fa9973d9-6c6d-479a-a851-a2a9783eecdf": {"doc_hash": "0b462ec7295f846c41d3da9debc13a63518c85cf25cee128790bdc65c9df2bfa"}, "c9bf726c-dd98-430a-8ac5-e62efa48f608": {"doc_hash": "03ad3c54b28722470300cbebca8b01e97eb6b7197494cecf63f8c87816abfc3b"}, "1f35a55b-9669-4d1a-bce1-63fed7692545": {"doc_hash": "2cad66da3bd4b9b3129a9593fc1cbf1d5215ae0d858f719d85e66da11bd649e6"}, "0f1c7a88-cbb5-469c-b220-4d0ee4d341f1": {"doc_hash": "39f453e3d5e42f54076784d153d343aaa0dcf9db86a2fc522352c3f3726cd64b"}, "0b1afb59-43f0-4c49-b51d-71d4eab6c7f0": {"doc_hash": "26ffa3bdc06725de4fbf84143c8cd9f905091a89c565ce80aba43130dab5e696"}, "7cca6699-08af-490b-82f9-d6698b5922d7": {"doc_hash": "efc62733e9ddf055758626bd28670761fb92e1947e554ad73c8e7e3018da2c55"}, "3a027864-b685-4c01-8201-cddeccaa02c3": {"doc_hash": "39a424c78823af79a11bc2d6b7b2d12c6f3e0cb0379daef3c21769a396c9aa7a"}, "c5376c86-67b5-4e08-b6cc-4394797f0cfe": {"doc_hash": "1c32d6f23dc8d86f5df0e0e51b706ca87ce04761fc91d5670cb9678ab9a1b1da"}, "7d47bdef-ae9b-46e9-806e-f6cd221f9123": {"doc_hash": "b06f7920565a7cf16811e8daab190f1601c0bdeff2a4f411233720e3395e9c36"}, "090d5bf7-5c24-43e4-aa5b-12ae9c5cb4eb": {"doc_hash": "412f6a3017412bf9e51d702ecd65a97fa30b36a8ec4766c47dcdc0fdef12fb10"}, "31cf824d-caf8-4ab8-8cb4-f112e97917f3": {"doc_hash": "0dee8a9c2fbb99ad8776844964ff5d073b73297f60ab84dce1ca6f3032869fbd"}, "940ee1c9-c6d1-430a-aeb2-3e8f07321b6a": {"doc_hash": "337026c5ae1d7685bf860e6b06728d9ab54af28417ce1288a2c2bd3c33850313"}, "2efa351d-3719-4de0-8f4c-82cf333f0f4e": {"doc_hash": "1c9331e4f16ac3bcf6004451bef67038e6b2c64296d5a7f29ee159bb1458e62d"}, "bf07e478-238d-4f39-a0a7-3576c19b2c6e": {"doc_hash": "cfdc582b7dc1e9a141ac3ad958a8ad9f523480c973b0e2bedc6a0c80ec24bf67"}, "d312e8d8-f400-4be1-8479-145c93fd4eac": {"doc_hash": "76542bcac7b9c19e77c0eda6126da1cac5880be723f6998e24d9875aa626736a"}, "c20dc0d9-6268-42b9-9f3f-cda9176fedc1": {"doc_hash": "0d023172f2bfb2db60f114824827f242a3f1f902316d9d1a16cb2452496210d2"}, "9359c0a0-bb1b-4300-841d-c5011befab70": {"doc_hash": "ca47c767485bf054f3c20d8830113d2781d2676ab20fc7e806fc12eae883909e"}, "9f010ffb-3286-4b48-bd12-d308b15c4fe0": {"doc_hash": "2fd2413cd76cb66557ec0349555190032035b4d6de7969d0e923eb160f9f35d3"}, "e1d83966-80b2-413a-b755-eb25c3b2ac9b": {"doc_hash": "357c18ca9412eb14c8353e062b3b8b5c07aa1e4d1ef13df3f9d77abc0fec85e0"}, "3fdf4850-6dcb-4dd1-a0aa-29d56b223799": {"doc_hash": "5537dc9d732b4973c5fb4b914da3e965f32ddf9583893dfa2eb33f6476c258f9"}, "4d11d444-d350-46a4-a077-b2c5cca495c2": {"doc_hash": "f8e144a42e5fddf624b8e1b1da66c46f9cc55e598655a5d80dc5a00e49d3023a"}, "0e821136-d2a5-4739-87c7-85f0569d0248": {"doc_hash": "5ac1562075b835edd8729a6142da1d272392c2b5f6cdae40fabd0797b242f8e9"}, "c6356939-17c5-4d79-b5ed-5595f769c38d": {"doc_hash": "94049d3ac1b7cbba825a8600e18306b08abb081b6406e2b70362944087d899a3"}, "06463ff4-1428-466d-827b-32dba89abc5d": {"doc_hash": "3839d5f73794da3c1c40c7e70b1d2a879fb1cf11164c16e27cbdb0cab83786a8"}, "ff858135-bbde-49f4-8c8a-1b4ef8be8571": {"doc_hash": "b87ed439f6710682e81d4bb9ee8a46a89aa84fadd2c5b2c8f5b7cf7a1295fc6e"}, "2f43b949-148f-4471-8d7a-a579926f65a9": {"doc_hash": "645315ef0119091ae66f83deae67656a23d2dd3b663026b1c1b8f7a663428611"}, "a698474b-5e04-40e1-85a9-e96d6484439d": {"doc_hash": "f60ed213b4f9ba051eec793a5ef1712bb94fcb3f1c51f94b8c99627f51dc259b"}, "da8f3218-cf74-4160-9c1b-5d8203861969": {"doc_hash": "9d7447df42a42e9c99c7ef82f1f1cec669e03ab93c79166b9ad7ce6e767190ba"}, "43f00195-60dd-4633-9dca-76186edcb5ae": {"doc_hash": "7f4eeb157b985377dcb91e5987b0cdbcca9ac6fc65a6e9eaa2d4eaba5911b583"}, "f18a417d-ec4d-4851-8e98-61bf8fb3c057": {"doc_hash": "3c5f5670c61e42f016972cfd04f24b03c686030afd4087162a28de8a4de4a10c"}, "dafdc982-4db5-4582-af55-d929d003ddc6": {"doc_hash": "10ea7fec615577ea7d60218c9e3b85634e513763445bb8836526b9c6153683da"}, "7c75f5d2-2355-4287-8160-3cc09f95da25": {"doc_hash": "20d64a70a79eb4546fcf741ec45187b9ff66d02b2a3c328ff7ce610ea14df400"}, "17e3e098-7cf2-4a0a-abe8-6282aef059cf": {"doc_hash": "9413a948e283fa25b77e5ed302ae28500c8cff8bd083945441727db5b0af4dc2"}, "57e06875-98ac-470d-aa88-7af7053a1e78": {"doc_hash": "769bfe25043ae7868ded473d0cfb8f61e41fc02e63ab3b7bf0b70048b871616b"}, "8b259ffc-b866-4844-ba2b-f19cbf73809d": {"doc_hash": "1d5b255cdd64ca6c828dfb62b618f231465cb6197e868aeb59ba73f16aff26e4"}, "10b2b03f-3dc0-435e-84ea-3f27fa1e7f35": {"doc_hash": "91499743d44448771182e21257bc9257b5be34fdb0f38feb24067a82d84d154b"}, "821aeec8-6443-46c8-abda-67e5cdb47607": {"doc_hash": "9b4c376df22b53fccd981a237bbee834caea6933299cae9fb274b38e19ef617d"}, "764a9f6b-e887-4973-85fb-51fe02dc70fc": {"doc_hash": "6a506cc391b8580c07f7f45a0d08377f37c36d12c2bd851b2b42b2c89c937bd1"}, "db573aad-fc81-41a8-a25c-dd7fd401a41e": {"doc_hash": "2ea91142ee3a3eb62efafeccaec02bc8617c006d81fa9417562fdbf26c3120ce"}, "2ed98680-b4f8-4dbb-a474-bf07ef6b530a": {"doc_hash": "92e5f913bd0ba268b465ffee1e203b85151ebf5160852c0caee9d54b1a7fcc4a"}, "42e7f4ca-d857-45f7-8f1a-efb5cd790c1f": {"doc_hash": "4e153e0a09377d5aa2a2120f7b7ee52da9319043af1fa86a14109096a66d3c82"}, "5fca64ff-ee5e-4a7d-9c4f-93553f0e0053": {"doc_hash": "9f2833fdbe9fd251ca2c8c68798f69014139ee4182d669d7b2f033a9f32b59c7"}, "5ad41971-ff37-4829-bcb9-d6a25a8bd679": {"doc_hash": "5887f81a37d20916e0053b4e08ae166770ced17bd7c5fe3abdc3816a5909a8d7"}, "ba0d59dc-efd5-46d8-95bf-e9eea36b5838": {"doc_hash": "a9ee2d858a6d1c9de2e9c437fbe904868e2f0b32b1f4fc93cb30a575e637045d"}, "febbfc1e-6a8e-41a9-b548-424a43e0b1de": {"doc_hash": "7b5e2dbce9ed8695d2d850edd1b1e1280fa02d0eb18c75b17676b32b1c0a2eb7"}, "f8872a99-6a46-4616-9862-c143071ef0d3": {"doc_hash": "aa1b633f5eac9ae2495aa0b2b4f1d3603c29082d14b934f721b2aa58301a44c2"}, "0d78b2bd-2a61-4de7-8c99-3ea0b5c86d44": {"doc_hash": "2311a9b0f2c147d3529f8d252652d6237126ac4d23cbac3f1c349eee39ea883e"}, "498d7b76-5609-4ab6-9c8e-df3f6e43b806": {"doc_hash": "55cdca023ba786b5274fd16f9df85a4f9ea6ac0874b1c661615b11b26c5e7221"}, "b5e13dff-a8b0-4414-8680-cc1cab1924b9": {"doc_hash": "946b490449c4bd402713bffed928976ea628e2811d8653da380cbe40799c4986"}, "cf5a78b4-997f-4f57-9a23-b82b62d41cdc": {"doc_hash": "696b71dc515179083c29ff1692d09107a7c3e9f44631ce670b882ca8a6382891"}, "41048dd5-ad77-4e0e-9c0c-98107d098458": {"doc_hash": "410d7a13d4dfbabb5e50fdc08afa4b5933c4e021f67fcf09955465446edb44d2"}, "8d555154-769e-441d-abf1-3891e04ece7c": {"doc_hash": "e08f88ac9b9b9f4e750644f4334f929d12093a41ab7a5d7dfb7efa761ebc7e14"}, "5d3954f6-bdf5-43f6-8d0f-dc067211a638": {"doc_hash": "335407d0fbca436aac935ee96bea8d3bf25d15ce9cf0be7bb49e4901f0b0071e"}, "25de274a-2641-4859-ad7c-8ff593656e90": {"doc_hash": "0df108975609955f67070c963fa8bd0405b865c30aefd9a1df6213b6b7ce2298"}, "30b32d73-8ede-4207-b90e-486ae9a844c1": {"doc_hash": "7bb8989ad70c962cb32cfdf5621107f3cbf836a652d54dc6f37483a384d2f6e0"}, "0dcc16e3-f73e-4769-9008-ee8b71415b87": {"doc_hash": "6eb5308d6844a4a36b542b91eb4181b50e5bfab0feba078c9c14f898f1d71537"}, "66bae01c-709a-4d44-9404-3f9047f2a3a1": {"doc_hash": "e8b83554e241c3ddbf4851a2f9c5f36915da24a61d84b36bc41fa9832729ce8d"}, "0ba1aae8-c08b-416a-a089-e448cd0dac8e": {"doc_hash": "46555677e053827a6b0b1e0d04ddce7363907843360bb85fa903af7b85c47731"}, "857614ac-526c-4f59-a12d-6029525bc104": {"doc_hash": "238541530d7bebb189ba10c4696015575060ef8b9daf310dca33ce94921d3b5b"}, "51f23144-4921-4e93-9e46-73aeac749fb6": {"doc_hash": "768e59b33c4ac09bbcf138e686217780cccc8ef45bda4b87bdbef4b866451071"}, "5ac5bce2-022e-4dab-a6a8-b4071c6005b8": {"doc_hash": "d6466d88f139412655241cf88f885ebba1d8f8e63898120b77e0e47728f39dcb"}, "454f036c-11a4-417b-9da4-0cddd497e953": {"doc_hash": "7453b762d9c9676d04f12da6984528fdd2e656579873c8eae7e5296271653cef"}, "1687e99f-7724-4f24-9079-d30ffd2a5d2a": {"doc_hash": "7479a030a72310a33994e09da4940edcb5f5a96f449cb979567e954457fa6da3"}, "ac01eb7d-579b-4442-944e-d470cdaf74c3": {"doc_hash": "f749e9a87776222bb4f04bb0fd470ae3afb277f5b41a7c67bd2efd39cbc81a3d"}, "d8210e9a-9042-4e19-be93-2fc2df776b63": {"doc_hash": "d5377a4fe71e353dc7438f1bb556035f9be1971dc2a9e3b3dc934751b43ef45c"}, "b577be9d-89c2-4205-9feb-675d1fd64212": {"doc_hash": "d5221ba8e624ee4bdcb46f40ff1f550db4674475a2586614cd08ea08826dca18"}, "2b042c68-67cb-449f-a093-24242822580e": {"doc_hash": "69f535e3a8184a05bdb81ab86379f7c154be78a3ffb663dc952cc415364c36e4"}, "b1050cd5-7a1b-42ff-8e71-e5ef766fa427": {"doc_hash": "5e4ac1dc422aa0a74eaaf86628da944879a8c3bf58b7e9e347efd7eaa1dbf3ae"}, "e6ed634f-3ce9-4b0c-81d8-08a6587d0e09": {"doc_hash": "986bc9c9bbd2af9f8ef309bab6cc0a3e6bae74eef16552d401d71b1a7caab4ea"}, "4e38e080-5759-48d7-bb6d-0056fa1c23ba": {"doc_hash": "4797c2fea5ad7d5d0a256e13d8f61d00241511c963834758eac8373f7d88bcdd"}, "f5ae953c-eb66-46ce-82b4-3e00de3602af": {"doc_hash": "7593aeccf897cae6b994e7c69bf6133e8e5bcab055e5fd5d4a4b5e3d86e55d03"}, "4af756e0-789a-44a1-8e5b-64fe974f1dd6": {"doc_hash": "7e852f96c2d709be4fcb445fa4a63ceff89ae9f442ca07ee67155cc7fb6128d5"}, "10aca370-0630-4f8c-92fe-f972d434803f": {"doc_hash": "afeb9452f0e5f603386771866a77918d438a66f090f8011db7f6c0d56cada477"}, "6259eb95-dfa8-47d0-9403-64eaaea39db5": {"doc_hash": "ba40ae392ed40f2fb0194844e5525ddb9e5704077a2045ede50eb2a4ec9f4706"}, "e6f66dfc-2c2b-4745-8dfb-d9c00d88aec4": {"doc_hash": "549e1c7b2ec4008932404b12bceb3a517fc825e9cf76c1900d219e8a0f662e26"}, "bc49cc78-5026-4547-a553-7a48caf7e892": {"doc_hash": "e7a46ced57f08d87cb77f8a3c34a7d056a53fea73a8ae8bde5f00a750965d41f"}, "5ada9111-0098-48d9-ad24-91da4e16be51": {"doc_hash": "184afa2e9f3768a2c79038687e4888b3e63abcfe20702607f44eb5c1cd4e7b54"}, "f6c1500d-9301-4206-b926-33d4813eaf3c": {"doc_hash": "796260931b3f261d5147b19b102482d0a89fbaf13d9813a0a26918a42cf73968"}, "e655e4b7-40b9-4e3a-8cd7-7f870b921fde": {"doc_hash": "2f21dd3d6722d0a450751772a969e62170268017cb56bf1f4b42e60b46912c5b"}, "1fc9dd74-5621-477c-b253-e131e9531c88": {"doc_hash": "630023a6e4f131fdea7c54ffb6feffd33c3c5feaeb0bbab4608f8eda626b0f97"}, "ce6ae0e0-9ea9-44ec-b936-889d16a7b6e0": {"doc_hash": "c026eb757beb61f09959fa345c2cc7b8127c4faf5f75ce9c311cb63ebefbc9ff"}, "e035d4e2-8194-4f90-9fdf-430c37f109ec": {"doc_hash": "e8f615a450ed12324d17a28772de52b7c31f1a26d82b3b8824069f8f47869d86"}, "8b72022d-35f0-4864-82e2-e23ee93e45b0": {"doc_hash": "3a6f93d76eb5c34b9eaf673be9c4ac124e96450a7a8a3fb122f09c24549fc8b4"}, "2eabdcf0-f245-4cb0-a2fd-6c53a5374e93": {"doc_hash": "404f78042c72c68a0e7536bfe1715de0c6615d68479a14090b9ae8754cd33064"}, "25527a5f-1249-4765-a3e5-ccc1f86ba521": {"doc_hash": "6821676b8e0ff46fc36fed20b5d835717765c2d2bb09c18c02cab555df107050"}, "e76167d3-aabb-4ee5-820b-bac028ab042a": {"doc_hash": "b67b4b11613daba6152da428b61908233675a1f0df20028aae160918af8c4169"}, "77a31f89-215d-4d74-a6bc-365b27bc278a": {"doc_hash": "c188b35cf8821d11331b8279f144ac8923a9e0a886d59aafbc5df296e2254a45"}, "f4afdaaa-6044-45f9-b97e-be5d91f9246a": {"doc_hash": "35beeea0aadf723e966d3fa135d51d05233fb06a0aebe928b568408857d03402"}, "86b8a0c0-56e9-443e-990c-8c414c3e0e74": {"doc_hash": "cd299d1e514ec5e9e6b97c99beaa8cebff84babc76be7dc198286e640e04c5d9"}, "38bf3468-8b9b-4e88-a101-1b416ebad97e": {"doc_hash": "345c1eb01a37dd1cf4b7207d5ba20b2499dbdede59d880383bab261ad120f4bf"}, "d34affb4-f471-407d-b31d-03a4787b1aaf": {"doc_hash": "561cc2cc3d618cc043159c482341efa26219a6d41802fd6cec2f119d4e99c307"}, "9a3a8250-2296-4dd1-8e08-a032b86a9308": {"doc_hash": "d3181c76ef8fab87c4a6c1376b21a7490b8c65a79959613c12fb876a1505b6a8"}, "1c7fb51d-08e0-4d66-ba35-56b0cde4fdaf": {"doc_hash": "2398f205d68dc61dc90c9e28c1370dc866bbedb9a8be4ce9d997931b09536702"}, "1e46dfa7-2624-49bf-9626-0948ebdc29d7": {"doc_hash": "d72f41fe751b08c057adaf5ba1bb4c8a3b5ce1df9fb930c74e351c6b28962da0"}, "a69df4c0-ea51-4dcb-9a17-c69805fa9b6c": {"doc_hash": "ee21f5ec893353c1555510e256e3637c97c1725955c5f6e4893a62298572df98"}, "da41f435-b72a-4994-bce2-25541f68afd4": {"doc_hash": "cb3a54214ddf5a213e50cea67a6ff302870f99d65b6b304e3a00d2c2a40b6896"}, "496f15d6-052f-4ba9-83a4-5e05adc6378d": {"doc_hash": "1671f5d75313dfb75032931a43d920cc559103c0027d191bb1f08041d46ec8b0"}, "6788e0d2-1577-41df-9097-5ea46400bb47": {"doc_hash": "60e4405d9eca86ab7f3deba709afbf0e05732764ac95924f1b90729ef4e6e584"}, "df147337-9cbd-497d-9ea8-a25c43e7c130": {"doc_hash": "19daa3ac7f155e79d3472d104bfac884b5b50448372202b67689522cde717a3a"}, "0f198057-c119-444b-93c4-e2b61c0cb234": {"doc_hash": "cca1195795aa0275a0f7ff5577d2c49bf493ebf2fe909cf3d8a13d6630e5ebcf"}, "6a9a27d8-a5af-4a4f-914d-a061afab9820": {"doc_hash": "f7410c60093a013f1f59529e1ec2fc3d86a29209d0889dcd08ade5e3be99bb59"}, "9c041abd-493e-4417-92b5-460359648258": {"doc_hash": "b2df0a3373538402f2ae22aea65c283955c8e556f222a172615265608563e22a"}, "61fcfe35-589e-4020-8f85-87c972572faa": {"doc_hash": "d1924090e64b4457743c012ffd049c1325d11de19d335e9592dc364211a44bdd"}, "00b5ae46-3e4f-4aba-bd74-56efcf6b2e50": {"doc_hash": "5551ca37f2cd46d5f75e432e080bd029a7b12f616580f58ceb90ec2c428a9bf4"}, "25f52ac5-9a40-4017-8c34-1a7b10806aa5": {"doc_hash": "7c94df1881d9003b07fb1bc1bca1503daed9df21b63076bb29ca092b08abaed8"}, "d6ec7922-abe0-490f-89ce-86ec617ea33b": {"doc_hash": "c7dbef35ed37c3e1d9c235e568f2c068cae305bdec97edc037488c038db16cc7"}, "614dd2dd-d88c-4fce-b7ff-f651e20d5c92": {"doc_hash": "e606f00ac5717036074142bcb32c8af775ec591c9fdf3cf98b81213beddd8b51"}, "88fe5139-26cc-42bc-aca4-03e7b65c3255": {"doc_hash": "778239e547a151d6e1de8dd00ba628c45dbc2f9af3dfa90501ff9c19b7b70b85"}, "8ec08bba-5d16-41ed-bf0f-0ff69564fb47": {"doc_hash": "ced59ee7921863c612835cf79b29b3cfd7aa8d751272e37ba5b228ca2c6fbf74"}, "fc702246-b694-4660-8d45-870210082e27": {"doc_hash": "f8ba28ee90fb3feea55f6d0335b3a22e5b9fed13ec5215ca283f7555f861a765"}, "fd9ca423-c1c5-4b17-99f9-43a1a606bca7": {"doc_hash": "414263626be3eb80fb9c1eaaf3e5c3bcdb025a168704fd5cfdb59795f1f52993"}, "ec697b00-2b4c-4804-9915-18c4073da741": {"doc_hash": "1ad9cf578a38dacac778ea6fca287bf29e988e1749a312bb595808a994f22ae0"}, "e00fdc5c-618e-4d28-9990-da185dbb877d": {"doc_hash": "719f51fbcedfc0617bc67a83e64fb5f2abbb97c4a69a72e5f5022b1f9230e868"}, "bddfff1a-5f59-4d63-a934-9c14e018b1f8": {"doc_hash": "852f28bdb62e1450ff03a3ef2d50d8c577e22b315fdd0ce165f9ab44c4cc4c70"}, "d4f680cd-7823-48e7-9cb3-60cd57020ec8": {"doc_hash": "6548b85745735eca918566844dd89fe3084611922007efb979ab75db87561107"}, "912a671a-11fe-4618-99ea-99d7d12b6814": {"doc_hash": "094bd0eaaf3dbebd5fd7e3cd4bcdac9d02f503adb395b5fb550ed59f442d8044"}, "072331f2-0b5c-4e53-b6d9-6e83fc34a8d4": {"doc_hash": "71d02299aebdd3b73d3c7427209c80670f2deb797c52cebfbbf40cf7224259f1"}, "b1a72393-7d01-4758-a88e-b0ebc4165b97": {"doc_hash": "c599e47a8dc435526bb98509a78a2df85956b2be46ade3ad79d0038725d71032"}, "583cfe08-0496-4658-885b-9e781300a4fa": {"doc_hash": "3390dccca6434aad809d7e35763df7b138913046d203f793c5a91856412bfaa4"}, "4314dfb3-f9f2-470f-94b7-f18a71f9dc17": {"doc_hash": "e1683e8820b021954663324a629b5ce4a7767f5bdfe360286081092d2b44f025"}, "2e48c3e3-c09e-469f-9932-9c13c76d847e": {"doc_hash": "24fd7fa75b12f40df292ad7d69c40fc10852d06bfc591948fabb4aaa1ca4f5ca"}, "36f27ac3-e090-4c77-aecd-743c598043b5": {"doc_hash": "21567a7604925438c90c38ece2a3c57d9c7fadcaef404d1ed7447a929f5075c4"}, "36452ef8-c91e-44c1-a414-3aa45078be00": {"doc_hash": "e78dcdbf248a676e0cb8e082506394f8d245aaabc325c28ffec522f0d0d3a43d"}, "c8c42fa9-54df-479c-abe6-a43454fdc781": {"doc_hash": "41814ae73ed4dbe348a515a2bdefd2a81ff3d275a88992d8a8c067ed91d574f8"}, "fb2db519-a8ba-42a6-859d-28060be41a4c": {"doc_hash": "ff770e00fb2fbec35b487b4741a4f2cef84205c2b7cd2a3090fe39509321ab4d"}, "2e366c1b-2ab0-4c1a-a8e6-79b86100499b": {"doc_hash": "2fb2a149b0d90cb14461bc21557706676cba20326e0772963dca652e806de7c9"}, "b014570c-807c-4087-a1de-ad12c5853ae2": {"doc_hash": "fcac0397f6461e28ef6d1f40db5e451e01a6ef9cfd44c99f2d256818ea6bed27"}, "89e9ee3a-f52a-4c91-be53-186124424271": {"doc_hash": "fcb72edee3cb52cac4c9a774575706d29ac2da67b15899a9fc6d9cfeda21e01e"}, "2c2bb521-9736-4b75-8ef1-1caf5f928483": {"doc_hash": "3a7a0d8bb82784b7518e7708f4c68e066bc11b8e75e43f1f15c7c30464e7c008"}, "42a81c54-449f-4ae8-9606-7a5453b8e8c0": {"doc_hash": "4fbc09b71e3cf4f54eeedfe99d40842e8560e6a1aa65b241003e638bd9580b7d"}, "e644cf85-40d6-4555-a8ce-1a7555ccbcab": {"doc_hash": "f671b3d4f3bd1444e6f7fe02b4bb2579b3cef4654e213e3ba73b6e3074f084c2"}, "ab4f56f2-abc5-456b-ba51-c2e060295d05": {"doc_hash": "44d262a5a541458b785a2ef7a46279e9f30d19c3899ff6592acabf2bcd312e65"}, "983dff8f-8f64-4a3a-8c0a-0897b52e2f68": {"doc_hash": "fda5a333a105c3ef730defbe34533c932b27794baa8b5426200001e3e6a718e9"}, "52511555-1670-4f40-8690-0f1aa4a48d96": {"doc_hash": "88ea35f9d6f11c6ec81803a0cac4b910bfd901bd5ebcb255987bb792e7b7fd39"}, "1aadcf45-f101-4b2f-b81a-e019c1dffef5": {"doc_hash": "1515095f14f5bb7e533ea29bb099973f52004e99444ea87b648bcbf53c01dcaf"}, "bccd5b63-36a4-4c5c-90b4-2c5dee99db12": {"doc_hash": "e84d2ed9c3e7e93db22cbb59af2bce5dfddf2d578c3a6d882e33ef2a53ed949b"}, "75258f05-29d7-45e0-b1a4-71ccf39d5908": {"doc_hash": "6a35bfb923af9c5877079fb51eac49412c04713c1c8d59b9e97a5ff1df287190"}, "0c3b6d96-7e52-4a04-ad2b-f085d2791aff": {"doc_hash": "f9d5874da4cd3eb58ab3a5353e010ba020371dacd19bd5a03d6033d189ee780d"}, "7984fd7f-16a8-4a8f-9b56-611a78b0f025": {"doc_hash": "e345800368a30ff3ecd8ef10069eb68a2091734803a6a4930dc3331812b25786"}, "457bca46-30a6-48ab-85e3-8a92a227c9b8": {"doc_hash": "b9de7334b427914cb1fdca32fc097cdd5d3c36e6b2f538fa74e00dd0b2265d71"}, "5204de31-ae40-426a-9bff-9721945d5e71": {"doc_hash": "49f1e6435a0477ee68aa8a48be0196d7003afd4c97a3a3690b67fe4d56c7d917"}, "cacd28ea-beb3-4626-9509-a1e0f4534dd2": {"doc_hash": "432d789a7101a993a6e99030ffbaea85e626e4aedeeecac74aceeec8eaca1c40"}, "bc74650d-bc92-4280-bc32-be1930fc7eeb": {"doc_hash": "729d84084f74d3dde77340b2c41e4289726e3250e4addc49b2ba1e10433842e6"}, "2bb184bd-d85a-4720-885d-aa1158654ea1": {"doc_hash": "d5be37da17db6cf1735540e7ec26fbfdff07bfdda90635a81d73ad1ab52328b3"}, "ea6290d9-e146-4566-9beb-b77b3db2699b": {"doc_hash": "515cad551fc4a7f5d14b39f2ff8ff7dc1bcab986495b91f82ef07a899b1b6a0b"}, "768123eb-8a71-41b8-b233-99de00329cd1": {"doc_hash": "ef8decd5435f411411892efb2bd593dbac10c4f155ace6b5b03293f3807b7361"}, "36a9c1e3-6cb9-426c-bc35-39417706362a": {"doc_hash": "0556fbfbdaf49c737502995de2741a83ca991d32ff975106afd6c5c9b6dc92c9"}, "b163df89-06f2-4910-9f63-800a2f9ab160": {"doc_hash": "f0e22dad3c46200d2337591400371b955db31f89abcfb3c6869a8f893ea89398"}, "49233044-c547-4e66-861e-bdc3cfb4e920": {"doc_hash": "9d9b85daef24e4e5ed6f53277974752e310b064a91ffc80341d67ca7f94c7d5d"}, "d6cb4dba-90de-48fb-9fe2-d8b342b929ab": {"doc_hash": "ce9cc1aafb401dab34be4b4e15bf7b6a75566ec91b9ae14fb3b5e678f49c3d82"}, "849e745a-ea74-4757-b4d2-a9c1b89bf16b": {"doc_hash": "bc0cd2116cc5221a45ef0512437c1ffa33f2b2c5156ef01c82f847de5e1797b8"}, "ca8ac6f2-9a5a-492f-801f-2fdf43e94744": {"doc_hash": "bf0cf53685a42beded5ae0f5e20b05dc66ebbc7384341ea90b3bafb91285627e"}, "8365b330-c9f8-4a08-a2b8-c5c1d7a9782b": {"doc_hash": "657fdfd1a6dbade8c4696bc595296ce0fb716050627f330ba010eb28ff9f8f4a"}, "fb899527-b1d5-4bb0-bcd4-38aa69cefacb": {"doc_hash": "80c7727bb011cf3a32c225cec57122a0b46b1c263a54f97dcbbc0cbdc9cf0990"}, "d7ebe0a1-9913-4bd2-a19d-bccfa9a7bee0": {"doc_hash": "b89fdf5366847f2eb1ee3fc960e9b1f80a5bc9426936c71b5edbf5c3448d2fc9"}, "284f3ece-df66-457e-a513-b8d6e3c1f4bc": {"doc_hash": "8742affb9eac5822bdb2cb495bc565a0ee0a1b615c4ef81e3834054595331b2f"}, "6416c85f-ffcd-4f96-a539-25f849b78008": {"doc_hash": "de93dd864076b8edf60ba75e8e4f99a510f57e43790b09fc559995211ea3b2db"}, "c2e127d8-8993-41f5-b75c-ce3264419683": {"doc_hash": "ab031736951de6ea77237de9c9676a3223455566280c3bcd26a6738b72924a29"}, "61c7f514-183e-4bc7-af71-24af9d35c943": {"doc_hash": "0f37282a676cd99fade3965c85b581cfb522bf8929d18c85a617c7c15f26464b"}, "8a5f2dd0-e095-46b1-afe8-776c6f0812bc": {"doc_hash": "d00dd6951039b83c0f2593b510460bfa54aa3fa444214c7bb6266a948cd162f6"}, "6b024799-514a-4e3a-bb28-acf1778fde6a": {"doc_hash": "f114371d820eca48bc1898324741196272a3e91436f741c025f71b66367ff433"}, "3e193d12-fe7d-41ad-ad82-7fb0dd3fc54b": {"doc_hash": "400e1fc67bb5eda1c1438a621fce11694203704f7d306d621bc9afbf968dd5c6"}, "2f138a9c-3bbd-4417-8da9-e08eb1b37be8": {"doc_hash": "cf56d9bed9d1ced784a4e83bfc9309eeb316e87b61f1036a7c5a662e958d9a9c"}, "f493832e-5806-47f2-9f52-8d17afd636f4": {"doc_hash": "e6c6199f4d56defa583f849d60540d33c85a36e14ea761c2fcc6d79117ee520e"}, "d7cc455f-76a9-4086-a39c-b5db2f54de2f": {"doc_hash": "ce18ae67d35986daa8426e49c1e740526473c56a6d4e22d957172d340016d98c"}, "7f61124b-95d4-4f99-b2af-a4a49aaedfae": {"doc_hash": "4e9c73e195f6b0e1334786b85355ae039f2c6b7de493132a7ca71b1d934f9dff"}, "e3b6e21f-e9fa-4fc5-92cd-63c32c90ec09": {"doc_hash": "a8ece123bdcefdd694e5e77000a869a3993045f7b0ad837175f96cfd756e8495"}, "d7397418-8516-491a-ad0d-76777f097631": {"doc_hash": "474d19dc2e338f56ff326b0504b2ec9e18e8e7c60759304143cb2e43883f2bc4"}, "047995ca-9cde-42b7-804d-aa826b1efefd": {"doc_hash": "908ba170ab9d57fa91e5cda000a34e5172d25a79551303d11d399dcb96ac86c7"}, "22f5f460-7420-4451-9653-ea64cb0d5d19": {"doc_hash": "4d0011387ab2ceb0df5354afb2f0211364afc5b7e1ac7d2a365c8bcbb02443d4"}, "99d98673-e535-4466-a7f8-37cda0d1a0fe": {"doc_hash": "f5e9df4a39ad76667be6706f95d9536a843915aff01822d7777a22b98a6b79cc"}, "246abca3-db8f-4208-9502-f0ceb2f56a12": {"doc_hash": "15dcd23c24fe12cad7e86efd15681515161cc2675cc5109540d463367b198c72"}, "cd5a2c88-7179-417f-b5e5-1b6e9dee96d9": {"doc_hash": "dcaafae234fe5cc4292397a887f0c14447cd2226820ca6c67cf670f83ddf018b"}, "18c96326-0f03-4419-912c-87f624d99fde": {"doc_hash": "36b4c60cb1069f99669555cf8277ae36dd877a5e8c14ab7555b28cd00efca906"}, "73454c8b-1b43-41af-b161-2d7e7d8beed6": {"doc_hash": "4f17b908c0f83e18183034388992db46fcbe3fe49cac77cbe44e13038455a673"}, "6e71e1d7-d81b-4835-ad94-b0240c5f9fe9": {"doc_hash": "76f6a4e366f654edc47005941e5e4e4c77e47f7ece141216d7a3c1adf732ad3d"}, "febf3f02-8893-4448-90f3-7a68f7999775": {"doc_hash": "608e3c64031726ce97199ddd1965c92b15cd28133b69be7afc62828b89493796"}, "e1f49267-adbf-4ede-ba27-0a74e4b9c210": {"doc_hash": "5c77a4dc3fd735b1bce4eab789d5f7b6e0a93745522007f0be85b2bb090f308b"}, "453a427e-72ff-432b-b4f5-68093881c092": {"doc_hash": "8ac4ba3152dc9ec8d747346afa2cd9e60c86ad8a0f7df9d67c65f585a22cad36"}, "d2cc8df2-3670-4696-8d86-d69f3293281d": {"doc_hash": "3c04db5e86385354adebbf4fb0863b38bcb6bbdc0b49433b34531f9a27a92bc2"}, "35a1b625-9734-406a-ae4a-951a6de87ab2": {"doc_hash": "6713d692580fee1e627aa1a32913cdbb3e65ccb76ffc7da2fe07ec91cd6b9dc9"}, "9dab0728-a412-4241-beca-a82ebb3cc446": {"doc_hash": "c40d76a91450406659915b3fcfbfc3709d5ccceb52b6644fc1f7fca0d97444fb"}, "d8921085-6b8d-4b67-a87e-37fc52b10989": {"doc_hash": "23046fcc8571a08d6897549a9180523ac413c992111535f9a466739c64a70a61"}, "fa796ad6-7726-4a90-b5d0-60b224a2838e": {"doc_hash": "2ddf18c3f4a664ab0204a52edb8f265a009084a66029183aa520e7a1b570c8d8"}, "b884dda9-bf09-4013-960b-7862b8ae5c74": {"doc_hash": "4541070f003410491bc2a5cfcd39b7b057c848ba0b5fdbe4f227310ee2c4fc03"}, "e268c130-e65e-4609-b916-9f56798a1e83": {"doc_hash": "6cd9a9fd166a8d50b89415e30e1c9e021ebc4ddbabf7f2fd80a1a5bef8e5fc31"}, "4b9a6bc8-e3bd-4095-84e1-3ab38514a46b": {"doc_hash": "e95380bba5a12dbf2e57d5b0d8aef6ea75c1cb89ebe60a1e596e247bc111d702"}, "357b62b9-58aa-44ce-a8a1-ae8180769fa1": {"doc_hash": "a5fc24a5017cdb645287c5570b4d50fff31ce14380c415e14d45f37acaf22cb3"}, "b7914716-de6f-457f-91da-b922a2272305": {"doc_hash": "41ca1206e090adde28d150c611f024d53f2bc94180aef6ea9dca52bddaeda473"}, "67a5322c-4a2d-48e6-94d8-f2c688624584": {"doc_hash": "aaa5bb795010a2f2ba3b379a1c4aa014e253aeaecb6c77b54f10967d23dd87a7"}, "6847ac55-369e-418c-ae7d-dcf75d78c2f7": {"doc_hash": "8a211bdc95aa27acf22645376097f0284246ed226f2335b7169c36b0bc5b8a75"}, "99d9e258-987a-47df-8879-bc4b72625ddf": {"doc_hash": "4df047b60f4a4474af08e6b4e72f79f3d5982d22f8b7d4ce618b598094c58c8e"}, "df9a3a12-947a-49e5-913d-7e2d9ea6e28e": {"doc_hash": "c2de633713cc1f265870cee82a945cb74cb28cf6e6902dd6bedfc417cab410a2"}, "f9a54c65-7296-4e40-9553-8ee8ccf38b49": {"doc_hash": "126bb845c93d6b82b6d3adfac8f4983e443385afeac97e12e0295e79276e8f72"}, "9694409e-6b4e-40bc-a611-3599ede690f8": {"doc_hash": "384f8f332ad81d344af3c28b257dbdbbea4cfa84c466e530b9f962b1ba315165"}, "18ed28b5-ce82-42ac-bce2-dc65a344e4f8": {"doc_hash": "af22c98f944675e32b3eb61d652264ddf3a8a8360684508150f4b0c91156e498"}, "4b12f117-fa81-49ef-b348-e1da3aeb315b": {"doc_hash": "dbd74971bff7f946ddaecb81131a0f37de0cfd37fc90c2d1d5fcf9521514a242"}, "35e574da-f24f-478b-8567-ad8e4baa085c": {"doc_hash": "4aa5250c0b8cd1e4398f1c3c8fdba3562a9aa71989fc2a6bf47f029987c7223d"}, "3c81cc73-5a50-4e95-80ba-dccd463f7aeb": {"doc_hash": "c4bda79ce9cea7e2051074a7c2d53d81285a062ecf8a92cca59f62d9f7619ec0"}, "a0bef339-e289-46cd-8f4e-ca96e1de02f7": {"doc_hash": "ea10a8420ccaa7109adcd2c37962df10e87b44f5261cae098f3a5219d9e989c0"}, "bbaa441a-698b-4ac8-890d-e0466e60a464": {"doc_hash": "9c245316ad4fa197569263b0a5a43eaa39f490725e00d2d4ad08d8a61dd5f34d"}, "cd4a6ca4-1709-4825-a6fa-c758c556d77b": {"doc_hash": "6f5bcb23e19d4c892762d37012751b0155e96fd2bfa9d4de5b71c0ba85fb738c"}, "54b1bafa-53b1-426f-b6b1-78a162e7d845": {"doc_hash": "b4a79ec28ee08fdad7c40d8fb6b2c67fe65892703eb91e517ce289b567d25087"}, "b6fb25da-bf2d-4351-adcd-caff0a90155d": {"doc_hash": "cd9d6a7f45cdc7de1a9bf037ace85eaed023b7679fbe75655d5059ef5c53f890"}, "d3ca3c46-a434-4cb2-8e68-8cb883e61b84": {"doc_hash": "4768339c223d02e9fe77fd3f0253749683e1ec10e5190d91eea05e5cd8f4daff"}, "b5895300-5cd5-4c75-bf90-e2eae32f84de": {"doc_hash": "472f90119c40450dcb7d9da5d8f89203410ecd0d4f9989df9f1a39fa50084f04"}, "11702f2e-5e8b-485b-be42-53db1036b7b1": {"doc_hash": "b8bca58aa4d280ac645d1643bb70f808ee4fbdbef9d3140b6bb998ee516739d8"}, "499aba90-d4b4-47f0-897c-aa1f71a9978f": {"doc_hash": "899ac96db472700130bd27d07ab66c12ac7f178d3c00acfaca9750808db836ce"}, "c28b6add-4e73-403a-b634-b9da565c3eab": {"doc_hash": "6447d826bb8c5d366d28b78c5738e23c9d6c889473124d80157ebea6c3fc9f8c"}, "aebbb05d-18b5-46da-87f0-c1c876204941": {"doc_hash": "967cf76ffbded36b42db78b48d741fcb8d98f2f759d73e3adab6f798490b58ba"}, "84490578-42f7-4872-b8cc-531c8a05b3cd": {"doc_hash": "dff9cae3d731af6020546f40f369066447c02a959ca2bbe7ce453af0aa54d517"}, "9135660c-33fc-4c41-89d6-c0770e926a8d": {"doc_hash": "dd2634bbe812132905940e994fe73b017f6324431094e55c6a4315fbf608c4a0"}, "13917d88-9746-464b-83cf-ef2d8a6d7329": {"doc_hash": "4b92adfd24d94f09040464623d8e0019ca1b1d737d6e631d3666a321af720fbd"}, "5d35c0d6-749b-4884-b72e-d4491361bdee": {"doc_hash": "18e3c47813bd94a1953c9ad13d6b083e4b2b64cb551c7883e884a2ce51e29661"}, "8caf5b8e-4104-47e7-b7c6-f5440d0754c7": {"doc_hash": "5c87b6f5d8da6cf8a80c0d2f0b3e0b3df57b0e1fb9520c3d71ccd808d4ed408d"}, "2af97b67-8943-4176-aa52-2e3df6a2c556": {"doc_hash": "54faa4541e1ab7260161796bb03e9e199b55306abdbe6f831617e41a5f0529b8"}, "a0f7891e-9ea4-404b-bc07-5d8c866c8873": {"doc_hash": "aaf97f0b3c81eca3d1225c75baa754a4b5ec7b6d78b3c1cc65199d9cd8e9da3f"}, "6402bfef-3355-4af7-a591-982d2bd0007d": {"doc_hash": "8a6706b449610d5c01922706018005de07352efe18d02e02c30e50c214b5447e"}, "931a68da-aa5c-4b0d-b533-5149d64834f8": {"doc_hash": "750736f0e8f039c3154e529c8d0727c37f2ca33d2b5556619088893a74f5a0f1"}, "1cd95225-d3b7-4c59-832b-64eca57ee952": {"doc_hash": "e1904fece7d236c590872d5f4caf6f73f747fadcf1c6f015bb388819810234d6"}, "1eb2e04f-deea-4446-9334-586563527696": {"doc_hash": "af9043012b6dad5cf18c99aa042b02e0789e1627ac96c179d20b39f0b97aaad5"}, "d94e67d0-f728-415b-aaa8-e57619a5082f": {"doc_hash": "a0e7fdcd558a6919234bd2ac9ba466d6c6b3dce011df030857e77301faaab973"}, "d1cf3a3d-913c-46b6-848d-e7155b45274f": {"doc_hash": "53e2d0a5ad5f08db88d0509e7d3958893175802b3a3d70fb5f71b2030c9f4275"}, "432209b0-15f4-491e-8de3-92e3d817a4b4": {"doc_hash": "9c089d9ae8d6593381bacad5b000618cac5b42a0afe398772a618c7f40e0c68c"}, "cc7d7d5c-5413-4794-b9ed-dda78ef1bdc3": {"doc_hash": "037060e794338b9936c3272705969163c92c804155b5285c6b29c6e06d07f94f"}, "c868d01f-3e31-4e4f-bfa7-216b0def0ae4": {"doc_hash": "ac4d48713db74a54dbb1e68b935b52a9780ce88bf731e58b3e2904f7a335d3e6"}, "db7e7d16-dad4-48c3-af18-acceb0e970dc": {"doc_hash": "900cf9c1444aac5f75769c86b38b92426cc788444ea7715ab17161de2c01d750"}, "e0911cfb-c968-490c-adca-5902a1fc77d8": {"doc_hash": "cb6533a88a97637b47a900798946e4659866f3e77350dbb1e32ca25ba7a31f4f"}, "da98e5d9-4456-4aea-b743-90177405d840": {"doc_hash": "840ee51a0d1f726145dcdff90e81868475941fdda5e3380bdd61030d8f5b5c8e"}, "e6b22b50-9ee2-414a-b904-ba6d8e203ec2": {"doc_hash": "4fd162d2a5a3f5c65f63cfc45619a9847d701f5a611d9d376bda3135c511aef7"}, "01e52505-2dea-4319-a519-2f5ef4de6ecd": {"doc_hash": "3af6c925fde5cb4641c6eb23aede2f3807bca06bd9de968dd0cece42c8839b0b"}, "73adf633-431a-4834-838e-b0b831b93040": {"doc_hash": "60281c91cb99f3c7f197194592a623d6d23de5d7a70bcd8db7511e22fe510418"}, "dbb0b18a-d246-49f8-ae4a-ccf215e97be5": {"doc_hash": "73cc11b93aa232451e23f8bf4c4670efadb18004fa62c9f0b0eb327ad0e236ea"}, "15cb4107-2b9a-48c4-a94d-c6142df8c9c7": {"doc_hash": "68bc7de6fadf7a67f29d54fbfbad91b256dced662f5ef33d8502fd43d03282b1"}, "3d04c603-0322-45ca-851d-6668e6f5e76a": {"doc_hash": "c9ced6f9b299bb94db663ab25ee8f6a5ba9628a2aaf8f3a5bb548438de687551"}, "77412024-e9f2-495d-b308-2a259872b3c8": {"doc_hash": "53e2d266690355c5adc084298a663b45368dee39c4c29bac0921312a098b33ec"}, "1dbbbfda-1860-434a-8da1-0055df485e7b": {"doc_hash": "be9a966fb548fae043f03f012222d5c82b1e657abe6b1b7f711fe48d67d749fc"}, "b78dc95d-08de-4c07-abd8-d2c7dede22c0": {"doc_hash": "ca8238c9a19f5e80f7f4107c11fb4e531e0eb668e5c5ae2f2febb54c86d45cdf"}, "b22b1749-1cb4-42ee-bf35-7352660aee81": {"doc_hash": "9d344eb806fc4de41af814e98525e3371be56f937cbb2453650646ae0ea21af9"}, "31566a4e-4573-4055-824b-ba70dc65ef5e": {"doc_hash": "06652f43c8ac068d79a5cbeaffae4b6fd7901cb0c50ccf581b549b14a7d9189c"}, "4cd39dfd-644b-420e-9fa0-0116e032ee3f": {"doc_hash": "81f4d94b6899d759e1eaae941d71cd81d33171ef4fa83c073cc321f021a67d83"}, "a788d5fc-39b3-4bd1-a1f2-514e2a2a46e4": {"doc_hash": "0f49ee5c8d54bdf3d4e7994c941b48a589038189a482db607074719f756ad252"}, "0a10260f-78be-4219-9687-9290ca269631": {"doc_hash": "b47c1d6c747afa253083eee89159e984451a5b505a394bcca111bd620d95e1d7"}, "1b731b72-f980-4709-88e6-e6f12b0ebeec": {"doc_hash": "ba6f6b2a89c1b189584097d08ebccde442168f28603ae2b18da667ef8c43ff7a"}, "59e5af05-c95d-4f34-b605-14a9870a7512": {"doc_hash": "1f3e3d38ea07f69b0178c87e6c1638657ec2b097634831a1c795da32fc8569d5"}, "b6ffd4cf-0db4-4dc8-87e5-da0c6e17eb4e": {"doc_hash": "ec7a649b4f5e93f76fe4d0094b38c616386439cf1661d91ac85415a00601ca7b"}, "c55b5193-70ae-4700-8a97-9b507c524504": {"doc_hash": "c858a31df1a93b5fb0e24a815396db26329d0cab0931ed461df108e1fa4cd72f"}, "e7b8e214-0f3f-4003-b606-1204c9918a19": {"doc_hash": "a97b396b9b400b607d933fb7a462374ef3d26d5c52b4cb6d1f18372766dbdb88"}, "49efdd10-018e-4fac-b840-63e5b5a4d329": {"doc_hash": "679cf3775c8ea0cc0014a07ea00356331e6c80b4f4da1c5f3c9116b9c9800e1f"}, "b81240ec-12d8-4103-8614-6cb6cea0a065": {"doc_hash": "2ea9e987f0df51030bb014b5cf6d5629216234dfa7782030be7b09dbc549cb08"}, "0f431ba6-5ec3-4617-9866-00ac10b68bdd": {"doc_hash": "ac0b1d07f7e9db9fbc3b5a1a22ba20e13aee9fd5748c39291cc7adab0f96f673"}, "38cff964-089f-4afb-badb-822137d647ff": {"doc_hash": "8f26ef978beca7f59ac39c48d245d38b3276b4a1459d6ebcde76eda5ae08ef14"}, "b1bdf9f0-8ac4-4210-bd21-64d4f3da3da9": {"doc_hash": "66c51a17cecc3554c6b1260b853e7969c5c5fd43833cc9fabf85811823205a20"}, "1e678764-6328-4e6f-9960-fc433b8b2095": {"doc_hash": "be4d460bde7f3b7e06757f627e9923f271fc463d5efab8b789d1cb540bc6d78c"}, "ea0ddb09-5e45-4fa8-8380-6fc3f57f855c": {"doc_hash": "eccab61653bd117fd8572cd6eb78b28fd9dc55dd8323da18867b4b3d0abb75f2"}, "6f44f3b0-f413-4de6-b972-702b426c0b1e": {"doc_hash": "5f29d8a903b15c34c4a48d144cb473774d144ff28c89c4f310d646ad737fd120"}, "e470c461-f826-4ca4-8e2b-91f197579c06": {"doc_hash": "252bd0b2280dfe8a57ef22c32370acd03b087f50711da18fb0e6ddfb82a55664"}, "5309e019-436f-4e76-9efe-a5c5a25cbd0e": {"doc_hash": "44289f9567c7e4e59e4307d33c69cd08b01897eacb8c142c4a36e2974e137368"}, "6cc6387c-cd19-42c1-9e1f-e99a19e0bee9": {"doc_hash": "e0e6edda5e0b0b681808198cbcc7f61091b84054d97780ac0087eb6b40a3128f"}, "d63890c7-87a6-4190-b2be-adfd38fffd52": {"doc_hash": "f63613fdf31dbc8373daf1a0318c5a111ccf358f097b63d7ea2c2a22810b98ff"}, "8c5bfb2c-17bd-482f-a0db-c0c6c5e59c22": {"doc_hash": "3c49ec3494a0dcdd3d52160b448addc8406f0d534f9f0ebc5c2aff2b3a1e8558"}, "ecd73127-6cf6-46f9-97d1-cdfbeccd3fc9": {"doc_hash": "2f2f84ef8391bc2105a0b72dd00c87a73a2d03aaca06feb169595be31e75165e"}, "1374cc7a-e78d-4801-b627-1bdeff052265": {"doc_hash": "b45bdb3aa88fb8285c09bd09c1e2849497443740e2df441c45f7d05a5b4f2e5b"}, "d1b5f179-e496-461b-a21d-07bf0e9b291c": {"doc_hash": "93624efb199f2b3d5089014b7d10187dda675dbd6e665145c43048ebc6630e08"}, "e54f1bcc-9d27-4c7c-ac9b-de566f69c998": {"doc_hash": "0bb2fa14d59f0dffd7e2bf22f7e476a30a0c3a1f350a5d58e65dd04e7823df2a"}, "49367836-b72f-498e-a9f4-844def9b6335": {"doc_hash": "84924b1067129469321b2cb3157867fe5ba6c9b25fec9bd75c635947d37baeb4"}, "570520c9-950f-4948-b152-c5cb7c03af14": {"doc_hash": "6b496d94b615d6a367a9d4bc03fc6de6cca13824c67e3016d3d87aab485c3ce7"}, "ff2b767f-71d8-4b42-931f-b6bf3cabfdca": {"doc_hash": "865cf1b3420a3a44e7d2525e43a59f499a3a4d8a1dc8fe2eec691b701b1385ad"}, "9582983a-0b70-46f7-81f7-e80a40144a85": {"doc_hash": "62c7c967ed5cd4c62873f58506dff6698efb9366c2615955ab53fd4f6aa1e5fb"}, "a36618e2-03dd-41dd-939d-55c55b613729": {"doc_hash": "95373db054afc414dc28f52f9dc42c66c3e9b5d356c351d49834f5b2a4bc83ac"}, "327c53d4-15c6-4c30-87fa-d5ea733b93ad": {"doc_hash": "de7e45e00ac681c096b67f670659f62d6e4b6878a3a100e7986b94d297044786"}, "032e4ecc-9e25-43fb-a673-4d944e993375": {"doc_hash": "c4731c6f2f3af2068156acdd3236843639c67dd62e96397052c215d29333dca8"}, "182a1aee-6198-41fa-85e9-f124f8eeb483": {"doc_hash": "2b26d9cc191c4bf50fbaa316830edf9d9a44f5e54f925aeaa330bd04e861b9d0"}, "3ca4012d-5576-4cf1-94d2-40bbcf7d8a34": {"doc_hash": "14e53849d643db4b2b148165761c749b6a7a5458e179a03fe5bcf7ab30735910"}, "8bb4bcab-df22-484a-8714-44d1f2458714": {"doc_hash": "05518e99ec98cde9225e8aa37a8df0ef1c8e489b0be492c18d3d9e4b1f6c01a6"}, "f74019a3-4aa7-4bad-a044-fc1e1c028224": {"doc_hash": "3b67ad5dc14f0f7a818130a41d01b686e8d597a413918b91b71f4708234024f0"}, "58db01db-a401-437a-9989-24d7ec6882c3": {"doc_hash": "f43c40a79e8b1075c4062aba5c915670847166ec08ce4a44004793f6671bd1ba"}, "e561c16d-fc03-4932-a73c-9648d362537b": {"doc_hash": "5ff734c9fa251643775764b3e58321a691fa1f7afbcd2e29d0eb4029f2debc4e"}, "fd52834e-01e0-4394-821e-828524c37b01": {"doc_hash": "78eda9229049024a38f514f089cea3ceb4a41d79fdc481bf575020dfb857c171"}, "aca8caa3-94b5-4081-a010-94c3082db795": {"doc_hash": "33ebacb58b4e3bf1b513917d4e01a1fa4cc1eaa00a0e0bc4d076c5bb5be701e5"}, "28fb81f9-0196-4a98-97e6-f705938dd852": {"doc_hash": "cb058c35ee17daaca4b18ad72fd00531c523aa1118eece1d91baa5b1c213a68a"}, "4a160c16-e8b2-4d6d-917b-032d47c7637f": {"doc_hash": "c08b05a3e08a75dcea2605938465a6f18e9d90b4ea8fa6668fe07e14e45ad9e0"}, "8ebd34ea-8ea7-4d80-a8ec-df5ef2a9f831": {"doc_hash": "595465c789aff42c9e6c0fa34c804e4d1731b5bdd001d20bdd4d8ecbd3a7920c"}, "5c8aec44-f558-4e2e-a36a-9bc8c9f66662": {"doc_hash": "e2e3e5a3f66f80a6ba0e4e02e23beab6106d6557d44891d839d48dfc0fdc19b0"}, "74d3fbec-3350-441d-a0ca-21ae0adc6127": {"doc_hash": "612dbfa6a08ec87cef1a113190e321c6ad75472150b84b76f5e2843591282a49"}, "abd6883c-c573-4fc0-a395-4cdf8754b926": {"doc_hash": "f69f262f3269c152d861a3ad3426715f25f8248964a8efc32e469be3ca4fa084"}, "dcb92122-199e-4561-ad5b-eda9717edee6": {"doc_hash": "34942dafb7af3ee1ddd290e168cb1cc0ae7ed80b5656d15d3be291df34f8e985"}, "d2ee98bf-d5b7-4a47-a5d1-aad0a47aaf66": {"doc_hash": "b875e6fdaf3c90cfcaa217fcef86d86e76cae4084747dc48229a95e951a498b1"}, "565ace53-d45f-453a-980d-7c94b60086ac": {"doc_hash": "eb614b92163c68a62da4c599bc764b0f0e4a9f76688a3504b1c3f57350a1f78f"}, "a6eb447b-1b9c-44f0-9504-b2ba82a019c6": {"doc_hash": "514f81825a5a9f04586146b38293d15bad641fbcfa05d85ebd7ec7ee6d4636d0"}, "c7be0de5-97af-4039-9546-96d64af43239": {"doc_hash": "05309dc93cede4c4b1f3fcb9bf8e27fca41fde1b12173552363972c3f0702275"}, "eb846ad8-65cf-45c2-ad18-411e00398d9e": {"doc_hash": "d17228e44a07c2c1208cd73de2d09cb519046ae2f4cb2611aa8a261b3340a04c"}, "68a34bb1-8dc7-414a-9237-c93435a7a17d": {"doc_hash": "4221cceb7baf86aaaeb5e76dbf16c96808d58faea4da1024d3e2e9a6a44e7aad"}, "a9e10a71-1581-4121-8e75-e7653839a766": {"doc_hash": "a73ba87c84837487eb67e3f36d9ddf4194702ae7488f2cd33c89b4041244ce89"}, "6a67a70f-32ed-4ac4-ac56-ea799b7ea338": {"doc_hash": "79e458dedb35a6e44837be07ed2480204eddd9e66898464203b6e21b6793149e"}, "e4323b44-16c2-43de-b8b5-664de2dd767a": {"doc_hash": "d9e868953b7c580896f2c1c6c2520c5e31fac63a06039077eb8cfeab00a8df37"}, "7348dee9-51b1-4658-99d9-f3eee1141e83": {"doc_hash": "5ee06411e4434c46ed2e46040da9f748f086d3c00ad06924c3bb4aaafe6d6733"}, "a63beb90-a819-49bf-9de1-d855c827a2d6": {"doc_hash": "c3d1fda5f184330a6217b65ac7959060055837257f0482f360147320fb903dcb"}, "c6260607-7b54-4216-bc53-3f28e15172ee": {"doc_hash": "1b2ce561c48b2860a36249f8c172af8cf123d2adf31eb5077155d1846dd02e2a"}, "45758165-6462-4f92-afaa-29c2e4f9046b": {"doc_hash": "4877bf1ebdd839f907319da7887aff682f9a04b3952e616e58d757630bf164d4"}, "2e29fa28-b0e2-47d3-810d-b1d1984988c7": {"doc_hash": "cc9fc3f9a0cd6edfe65ab66ffbf1a6e660b753aec99c832f0c1300ba144d24dd"}, "334afe40-3d75-41ea-807f-6446a30d45d0": {"doc_hash": "977b5b6cfe78f56b54dab5be9c07bd4e3465d3f378b4bf2add4d25a4ae8e19e9"}, "4f2ed9aa-df2b-41eb-93c5-0a509ffb36d9": {"doc_hash": "3eb0b208021a22f505457e00e9e35847fbcb0f1b20ece138130421b3d8c3fed9"}, "a0abbe8d-8b8e-42d2-9c3d-55fe5fc2661c": {"doc_hash": "7b79a40f74034875c9abca22b162b3f65a1b0bfed2e2498fb09faef937a475c5"}, "ed424271-7919-4890-9d70-177e596695be": {"doc_hash": "80e6676543bfe16b9f89bc35534dd92edcf69ca6cf244fbf919d9c12f4d5f577"}, "4a37045f-4676-4056-bba8-f38fa91ff266": {"doc_hash": "7783a93d4554fce8aaf671f6b80c939d398ace97183772d26f503e84623d1eda"}, "cebd34c7-efd9-46ce-9113-de0aff878b3b": {"doc_hash": "460f907ca7b37c7e7293a47191dada1a12c44f5643617bcd052af59b6d2fdce6"}, "554f1a4e-a39e-480f-8467-974a431fb456": {"doc_hash": "c972d4676d3791aa4432f3b9d19bf622b32ea643ae8be97e21723285fbbc5d89"}, "4e3ff75c-242a-47cc-b939-c4e5a46d7ae0": {"doc_hash": "318e6dbcdad5e2a5f4c84c13e1bf556bdb1645c25e828187ed24088ef64b64a9"}, "3fac4e34-3fde-43c3-b8b1-466245ebb7a9": {"doc_hash": "d12bc2ee7979e8afd0875cd502c7fc39b23deb90c652c687fa16bbc281b1f12a"}, "527ef8fe-4bbb-4854-b8ec-ca36681de503": {"doc_hash": "509b5bbc82d81b451c082f1fb9c992dfad179b35a58121f5c95e0e7715fac847"}, "6b29b30d-5620-4500-b9a8-2620489a9cf0": {"doc_hash": "2a283ff5c14a977e4455c878749f55e30c3b3b64f2797d0f1fc2c9f6553d527b"}, "9ac36017-4571-4d76-9975-fa99df621ebd": {"doc_hash": "f9532c01727e7abeaa70146a09509d3d4b6d5be5105ce61cbf72906d8502cd93"}, "a55da908-a8af-46a4-bf19-c08e23e079c0": {"doc_hash": "a5f9ddcd445874eaa46632aecda6b91c59fa0103fab0563bc4de1d8d97563834"}, "769e9a4d-0b20-47b7-bbdb-b5ee36c6e8c1": {"doc_hash": "79fc9bf30894b1593f2d813c3941056d31133df4e8981406d928bcccf5e2a8e2"}, "4748651f-8211-4225-b0a1-48a705d5bf0a": {"doc_hash": "6d3d6c81e2733808c2d33f3779aeef2ea63f5f2ea9a9542bd1351a27f0c825ff"}, "ff01361e-8959-4346-a013-3929992273ac": {"doc_hash": "fb22ae52677b7d2dd48ad9f046fd2e0d44d8067297b0467d6f85cc4d99f60431"}, "de8ebf51-113e-4c7b-8ee7-3fe89735ae2d": {"doc_hash": "16eba53329998e89db6507cd12e3d439f14f1e03edf7364b941a7859c99991ae"}, "0d38d107-652f-421b-8c28-a0c67fca7a5a": {"doc_hash": "80d4597542dd11957aac3e8fd3a3c040d5d6b4d25670047c83e94e4153257c5c"}, "3efe6f9c-d557-441a-92e8-a3a31a5ea434": {"doc_hash": "633a2ac4f465b1035676c6311db13445d77b720561a868d1e9cfedbd5a665e01"}, "5569f031-2c26-46e0-a95b-3e00aaab0a97": {"doc_hash": "3351d6d5a5cc672dfc75ff6f73c8e682f75db1a77cf04a925ff37541055407ff"}, "e02c1741-9c35-4f8d-92ad-13922a1a40e3": {"doc_hash": "43b13d2291c9ea9b22b2f2b985a9684e8f03a885c566bc9415b503fac5e8b7c1"}, "5bc831aa-2322-4e1e-9d00-801c0a6bf809": {"doc_hash": "ea2c3b857056f0072f18c4c6c6a0a420ddff867c5ff592f52d641e3231769d89"}, "ec0e8fdd-6af3-4094-9534-825e94765638": {"doc_hash": "a0c5e0fa579c54376494e3fc3fcd72740a3d90c89f11854d35cc1dab8f27e3ad"}, "6cb540ae-9c33-4981-85a3-74bec71b2cf8": {"doc_hash": "bdf995d3e4c9375135a3ed7062b45636b74886ab74dad3ee3e9e9b3017f71e1d"}, "59dc4057-40b1-43f1-b6f6-2a3312d67d55": {"doc_hash": "1f46c82aa1563ff7f398e404c27d49623920ea57a7b613b3c09dcac7c9cf7e8e"}, "bb497585-9b09-40f1-8c5e-d33e7e35936c": {"doc_hash": "b2fa8691ed5c117813394e41ab094807f1a14f92144f29cc25b3926da20d034a"}, "80bbcdde-7957-45de-87a2-2a5d3c0a6281": {"doc_hash": "b79e50c1a21294bc431d5f24bc48ccfb4507b0627a3ba6fa9a058382484929ab"}, "ac683eb4-0b4c-470e-b7c1-d2fa51e8140b": {"doc_hash": "e137ed7aada2c0fafd497d3964ce55a23045221ebb413faf4568e76b9fef5193"}, "a2687c95-664d-43ab-9cfe-fc510f339ec6": {"doc_hash": "700dc86c4f90a27533dfdea52cc3a9b321b731cfb0a6ba585db84553dab6fbef"}, "1d65f319-62c9-4998-b159-2ef1c2c96e74": {"doc_hash": "8f140fa470874a993edef1918af41eb50f4a4118f700bdf4b3bd755ea2e116f5"}, "80f78307-bf53-4dba-91ed-33c9acadcd6c": {"doc_hash": "74e032d4edbd30d185ae9c055584d81a1571fe4b5c643f9aa467f3745eaaa4ac"}, "66f5930b-d1f6-4873-a952-f6c1d3b226c1": {"doc_hash": "a7e89cdb3aac0c3eb4c2dca6d32f7893f7ffb561b858ee4e6923aa9474daa682"}, "c99e10f3-0bcf-4352-8eb3-b87933ce315f": {"doc_hash": "5077de58f4af06a2f70e195bef28c8042a255fa0bde8b75257e4b204df1c7c30"}, "a8f94141-87fa-4630-ba17-4ff452bcd223": {"doc_hash": "61b905dbfe89ce536a43a17884e4475dd1480daf920af51ef4eecc979651a1f7"}, "3013bdca-a7e5-49d6-84a7-bc05c8a12589": {"doc_hash": "a3c7d3337cd859de4aef4da668d52910803ec4ed0c780e77c03fdb1f224e24b7"}, "2c8618b8-93d2-4610-9720-064b0c3f1464": {"doc_hash": "734cf6fa20b5e5c34209791e675b8ccafc3a949f4f82897f31ad3851e85ddea7"}, "66221f6c-1f53-40ec-87cc-92e89317da75": {"doc_hash": "a8d90dffbb42ab53426b5e365cdef678bf91024707d46f7f9fe355db44a5f600"}, "857787f7-6343-48f2-b530-0008b241bd78": {"doc_hash": "8688193ab8f7cf336693080d0273a4c391db0aec11a36241711972bdddfbdcd9"}, "82504d51-b83a-495b-a272-90ca096b323b": {"doc_hash": "3ab580a6539790959a6f4a687c7cd8d8a845c6b950b7827ed135e53c6c05f092"}, "a1be4f0e-4488-4b6f-af84-2f8c554b1019": {"doc_hash": "1cf4fd9e2257057fbfaa84e843be0e929064842620861ed9ed6f1af03f432311"}, "c1f48f0c-df73-4b0a-9962-b6976cfdbc73": {"doc_hash": "b5dcc7dc31431d6ee7d0fc09a3a69f102bdc934d0db61c725a2f08e34b3acc9b"}, "e3818040-c64a-4ab1-9c1b-4372f3ad15dc": {"doc_hash": "889a015e99ca5a411d43d6dd0f673cf208c95cd02d05c46e2d990c0d22aee20f"}, "26fe248a-9a34-4b4f-8a75-5b31899c4314": {"doc_hash": "72f93d4141e232ac89c83116617f10f77cf3e53c81b5c40f4656ec9c421c7edb"}, "fffc0b79-a704-41eb-8760-d15f63522300": {"doc_hash": "16f093ab0c994bd4d615161e50628e50f316c272e88fe6258e9002dfadd1a997"}, "6eb252d5-e95e-4085-ab80-83249ac71664": {"doc_hash": "16a13b1f2fb78cd01a95725c7d98b1000fc904b53cf1d6bd434fe43f886d019f"}, "2f788e98-c40f-4611-98f0-f5491d8c85b4": {"doc_hash": "c65dcd771d6b864db13c87c3efb3813c6f56d68f359033e68cac51169c094dbf"}, "85a5cd97-b020-47cc-9fa7-ca44e22229ca": {"doc_hash": "c4f397336c69c8e6877f3d47d5572be1afad6405680af2151a3bb312d160c3fe"}, "4ecb43a5-27a8-42af-bd05-87783e7635dd": {"doc_hash": "c664f8a07db3033c1f8449a1671ff2afb3b1aaeaba127f3c79355ed3f08824d5"}, "7d7ded6b-beb5-4c41-a0c8-26f0d2be74cf": {"doc_hash": "bc778917703f2a1a7e6a79a9918f8179c4001c6634497cd60b4f09c9d174bdba"}, "d4b88def-a5f6-49a2-b5eb-9f211d3327c6": {"doc_hash": "56d8c050632a102f9f0a7a5bbed56c782258194fac1abcee0586bffa7ea94542"}, "a4fe7ba1-b1cc-4b23-858b-9da8475b3cf5": {"doc_hash": "d1a68627adcdd0ea69179eda3f46f6c2421f555a23df9fc215944bc2e81d7f21"}, "75eb82a0-3dc9-4a16-b580-56f58c235a91": {"doc_hash": "e75a483f9ed6725eeb97c2e0b09ea8132eae1cf74bb947023b0470285be74934"}, "3a14a3c3-ba77-4fb7-84ac-200309c9b29e": {"doc_hash": "ba9bf7bbb95feab5a4d2098ef09c0ec65289a84fc81811838a9aea734555d74a"}, "a4628ac8-2033-4dd1-9085-1b5c927896c1": {"doc_hash": "85794deac14125a1c3708d69cb0ddcf5f2e78c61eb25d1cb0ef01b010c4886a3"}, "d1100a26-771a-414a-b9f6-d2c49fca3e42": {"doc_hash": "af911d112787e9bc65c9300b1ab8dc6a19467deced530605999cfadfd64dd0d5"}, "55e6e77b-61b0-4cdc-8151-2d72d2229418": {"doc_hash": "d0cb7919c48ab97155ebceb6bab36aa23e99d00d45f7389967fef2a7872ceda8"}, "747bf1c6-c3a2-4ac6-a486-e838151e32eb": {"doc_hash": "5f914df127cfb0c69a8c8bd0270dfa351e5d9b9e22d96a3ccbeaf24be06e24b9"}, "b6c48281-99f0-410f-b7e2-b94cca3d6594": {"doc_hash": "14b13803446a97bb28f41cfdc11a6bd630e41c381c3c4f4d800464bede781083"}, "57099382-0e90-41dc-8091-1826d4c87a99": {"doc_hash": "04840037a0907ba7cf4c09ac36a77e291ebc73ba843045bfb5f1feecdfd6b348"}, "3102d551-2716-4785-84af-4988f93b834a": {"doc_hash": "20b5a69fab2c5971e3e0ae6e207a31f8db09459cfd8d740e02513395f558164c"}, "61d9bf6b-0c7c-4d95-b245-a1b2122d03c0": {"doc_hash": "b3d6f0877b37986dae2499f7439d10003c26feed9906f89f88dd1af8fff9e3b4"}, "41524748-e290-4087-9098-c8d5b51f8e86": {"doc_hash": "f257b6060522eaacf9b0278260e87ef4b93e473fa3cc19902046c90ca0406050"}, "019f8739-0a8b-4024-bdcc-9c5459be863b": {"doc_hash": "72e067c143ce13d17be1794fcb2d22dd6da7c0bdeaf2c22da24641d2cd437572"}, "0b917cc6-6e32-4b6c-a304-8f95b98cacdc": {"doc_hash": "c885a43902137efb74553b2e3050531ba31f61e2475b112c8dd8955258e89d06"}, "7b8e263e-7f9f-4005-aced-fe66d49a8ed7": {"doc_hash": "9959062c44a2caaa7d227db3154f72cf374a473a274db04a4eb9cdaa219e1947"}, "09ae08a6-fb82-4723-8d92-82ee38374081": {"doc_hash": "90999a94658cbe42461ea8fb84c0e08dd50b682bce9ea12ad57c01208af68dbd"}, "65d0afab-5167-4ef0-8a9d-f8d8970a97ea": {"doc_hash": "51b8b393a2e7da5d183d6fc905c29a52df4c00bbc5500eca59db8947b10f762a"}, "aa686e92-a2e5-4dea-9447-49e5a3f6f1f3": {"doc_hash": "fd47b37c0f22d6b910ed982289ab18ba83bad9feea154f4bbc95c1bf2178a637"}, "d1fbd355-b68a-4644-aacf-c912bfb58210": {"doc_hash": "f0b2b1b115146bfa40ebef5c70555ff7214c0fb634a0043e6d639c32fd513555"}, "7102958b-9325-40c1-8f4b-7d35edaee533": {"doc_hash": "228932dea1a15d07ff599ac1085c57f18b93269af8aefd2cb8c15b99b935cd68"}, "79187b5e-608c-4163-a542-2453672f13e7": {"doc_hash": "2592ddd0d98816e3f9acc00cffbccd2b550e43ba20195152ba5e5d86cc96b5b3"}, "ff4e3f29-eaf3-4d29-a3bb-899d5f111fc3": {"doc_hash": "d8d87c1d6a6114f6e8b71ac24a3881cc7903cfd287b339db600de314b64bb6d0"}, "4e750904-ad0f-4c78-b5ee-8394526be24f": {"doc_hash": "e8d14d6fdbbaa61f350a6c16585b124214b2e3756526b7d5edfafb557e0bd9d4"}, "e2460752-3287-4b9a-8f61-b64e9b92fd42": {"doc_hash": "18ebf0543d7ad656cdd17c66094ad01ca901881d0b18e0d34dfd0b38b7bc0da6"}, "40a89f9b-a773-4015-8ad6-af2b18bbea1a": {"doc_hash": "9b427b81a715e7ebe2f0ff51719792d83399376e963cef47068ab776a60343aa"}, "e67ddf3f-0f2a-4f22-92b4-6f721015835f": {"doc_hash": "d323f3fc223bfd04f631c79812c7ca200279683a8ae48d74c0669369d711c3ae"}, "232fd370-97e9-4d09-aa4e-fe39d2d88d41": {"doc_hash": "75b67bfe4d77446da921730542852aa60cadab506a5c5b07cc42bfbddbb5a5aa"}, "26c70035-6b5a-44ac-ac8d-30dcb30f884a": {"doc_hash": "66a455a0867fc4b92e901797cfbf32c74206a07a3df93ce926a7cefc6b43295d"}, "499cf0a2-3303-44ff-b6ce-1667ce65aa52": {"doc_hash": "45586ab5b6c7aee9370d0b190afb05ab87c5cd2d377515ad2b06cafd5a31b143"}, "ed629947-36db-4485-89ee-f141022e7968": {"doc_hash": "e0f0a6863a9d7488e31aa90b85e2027dabba99889474c5c8a0f2158abedc0d78"}, "3ac5cbf5-8f3e-41b3-8ff0-c5484db6cec5": {"doc_hash": "c0ed32ef106746cc3439c075118a9be6bd0f30153d0056c6d54dccc807838477"}, "3135567f-fe28-44ca-b871-7e8af3e77c05": {"doc_hash": "b3dbec6d23f9f100e90bf8d2e4a3e43f86fe98e5c34f1bb5aa322f13648eba62"}, "bb70bd7f-7277-4420-b40b-4ed2f350e643": {"doc_hash": "3372121f49f87ae72312499cd4921d91ea732cada31ff9a0952c690cb024f51c"}, "63490de5-d4d5-45b4-8436-445d7b841129": {"doc_hash": "af06c4292165c6d6dcaae2dd1f88ab235cb47b51e97f10bb7d9981cb16481c60"}, "43442a2a-ca31-472d-8223-47d7666217cb": {"doc_hash": "99a36429b194ccc59ac6fb2d165ed5567296d37efa7cfe46bdc644488a639828"}, "b0237b78-e6d4-482b-b782-e958e5d1f622": {"doc_hash": "113967e0b4030a7ae09738d22b0799bb24a642862ee05447bdbca1a4e1cfe885"}, "95ed55f1-f696-4e2a-8fee-c8b8937400fd": {"doc_hash": "b82bb1ff6830da32812afe61a662afae0a747302afdf206e5b62c7bdc428e47a"}, "a98ebeb8-d33f-40ab-a775-e01a9e60b6cf": {"doc_hash": "6d711185df0036847fd2e1756313accb79455827d2a697ae6e89d3d5f538773f"}, "1019b346-d906-448c-bb1e-4ed44f2fece0": {"doc_hash": "ba232faf12fc5091e8a14fb366ec020358ed10da48ce2731d541af4a49e28d2e"}, "f0b91540-4d28-4514-9378-5f06bb147d45": {"doc_hash": "b92235c7111003f88acb15ee6f3833dd156cb562d8741ad345a9f7d4be63d555"}, "9f3f8ee8-4573-4efc-afcd-60a2480a5946": {"doc_hash": "9e3316843514b597bd6b3eae232944c6ac368c517ea623e13048c821ea70fa54"}, "91513ded-e7e2-4276-a455-ca96b52382a7": {"doc_hash": "bf480597db8c612fbdc42647cd0348fa4b23986740c1a64363f5921a8bbadc96"}, "6ab8118a-f1d2-4004-a9aa-700ec1a3f720": {"doc_hash": "3868b36a6ec0a14ac0ab167dfb2051fbb378684879b0fdbd153230e3a648a066"}, "2f3c182b-ecaa-4c53-8f1b-180d87b96b60": {"doc_hash": "1895b052f0e3be4a58f790dd0a5acd0e9a652f6e9a59bb1607df74a5ec883983"}, "097c4c55-d972-4c83-8c65-b10cc113ce3e": {"doc_hash": "eb8f5c1a56f14800d1b94c0d27c56de16abeafb87a6fa79dd38006b736f81b2d"}, "87930f5d-ffff-41a9-9466-9604183dff0b": {"doc_hash": "ecaaf57de5d1ef5249e3b2bee28f44d033ff3cc6f7df198c5d0ebaade869330e"}, "70fc0b80-effb-40ce-a772-a2fc92f2ff41": {"doc_hash": "8ed16401b8ede5591c2136e5f30f58b1e853a6a509811b9f60e734d62a15ecb3"}, "4a2cb916-2943-42f9-8001-23509b21a3f8": {"doc_hash": "f2189d2b4ad5b031555067f63f9fcba6da93bf6f0c0a5a6aeca6e2fa0e36b03d"}, "853bc384-6435-4a44-9bd5-3ccd09d61817": {"doc_hash": "7ac4e2b4cad6cd6326b4fb494fc8f1a81f2daaa50581c50ba9d209248032559f"}, "37993fdf-3d0e-440c-809c-6de8afaa142b": {"doc_hash": "eb297febcdb71078573f33e9402611b891d3f367d095578890c42790d39347d2"}, "36565ad5-8026-4eb5-8257-6b26d7f8ca0d": {"doc_hash": "4fc5028b83d89cb9d2ade354a2a7a3e1f486205f97ce451287a022c091ee6bcf"}, "b967fd86-cc0a-47f2-a128-ff533bff7c9c": {"doc_hash": "02b799d66c4f0afdc2be4bb76fdf6d24369e78009571ba08276c310e3337a51f"}, "a787aeed-3d0f-49a7-a8c4-c76bfddbbe38": {"doc_hash": "16f7f6cd27e9fe05c51a26febce705ec00dc0dfebe9c18eca947c5e63c22c272"}, "caf67602-181d-4975-85ae-57f6d7316635": {"doc_hash": "5261cc06ce7713a7eebaf6a57d07aaf27946addecd534f2737ac4223a8f42449"}, "5aff0cc5-bf6f-45d5-8dac-a2cc16e2e011": {"doc_hash": "0e4fa4a14e07d94188c724398f37a4bf9258ea3d834c1d39c59fb8d4a79de258"}, "7ce586d9-5182-475b-ae18-37870ea75fe6": {"doc_hash": "cc50107a5c04a715eb4979cfef7c2a83cd1dd2e3a36230e61cf168902a8d8636"}, "1a9a02fd-75d8-473e-89f6-24c26f4bfeea": {"doc_hash": "cb15ace979b9e132a5fa2174bc9ad5766ad52f4ba8a5d64f00135bcce5cadf76"}, "8b9a67d7-e2c0-4853-9b30-4a0cf16a682b": {"doc_hash": "1954f266ed61d8c94f09e369347b1eb304d33cd4e667e9b8ba38423d7cf3bc87"}, "61bd7d6e-2568-4363-b252-72ec2a5ccc50": {"doc_hash": "e6975ef34ba66fc004cf717bdad476447caae199029b776cd461651e54d8a961"}, "cba3c393-97ed-485e-bc1b-405a1f6529a1": {"doc_hash": "79302d91c417eb873687c46e2f2fcf26b9b4da10fe8a12d64eadc367023fa0ed"}, "dd08245f-a602-4b5f-8bbc-8c6868d74684": {"doc_hash": "dd61438d9ebf10f435da7608895b77be6a7dab27a34c3fba0506f39ae2754ace"}, "9b4d510c-465c-4aa7-8ab2-1338342cac7c": {"doc_hash": "5ce3c055e42e5cd4c4f5735dc8af3375cc89f85c3fd4e3ea8a81d7be63cf432c"}, "9c8faed4-72c6-4fa0-8e29-3cd39ea646b5": {"doc_hash": "716035b788f648326673ea5f2f70696a139eb9cbf7ab49e84667d58cb13f4a66"}, "ec815257-65da-43a7-8ff1-2ca25a11859d": {"doc_hash": "4b38590ea831084a77dfca14a5ab67985757a4425355c3128b5777c9b035b0d4"}, "ddd0d686-8d51-4943-927c-a877647e69bb": {"doc_hash": "94f85638f158f47fc2c057167c14e8d7406c8c340f2262369eff527d9932ccdb"}, "1ed0302b-f918-4c02-a8f3-e85e286b2a10": {"doc_hash": "1b1115ecee66678b43a299a6a72810f6695234b870e24b08e84e4fd3486e4f56"}, "f44ef2f0-abb1-4330-8bc8-e07bae79fa48": {"doc_hash": "187f1c07f721c32d6afbed5e159c90024bc8df6dd7d17efde77d68f0b03648e2"}, "96f9a3f8-d908-44bd-b7e6-88cbecd4ddd1": {"doc_hash": "6b08c88b1bc33dd20964b0a8a2b403e2de6bebd3668ce9ca820dfd2480539a7e"}, "705726c1-b46e-46ff-aefe-67f5ed4e4687": {"doc_hash": "a381465727ed722c78b1996a403614eb8d1e95342655e70fe48bab88ddd58757"}, "d64a9582-efae-4b98-9733-55093dded487": {"doc_hash": "8ea594c710fc82b81f84e078fd79513285cf0186c348abc5d8a66dc054cc4f83"}, "bfa8c08f-6930-474e-9015-782caee22249": {"doc_hash": "e066179866c115ab2ffc2aeb42ec526e5df89062e6369aad6484be2f3f60f8ff"}, "5769e258-8f9a-47cf-b14d-6e09f936d966": {"doc_hash": "05f290952fa1600fa2f6c71e78b2b0970131f637e1626fc6cbd1b92fff93c9ef"}, "79b8419a-ced7-4cdc-9be9-73f00bc35e28": {"doc_hash": "8b1175444790d31d6aba171148149dff6b7a7095f43a26f75d0c91ca7c5b19cf"}, "07772b93-e5c0-4b0b-881f-3f009f97283d": {"doc_hash": "5ef8f94d38774d075360211d0467c2c1bebb3c935c497d0c1f99d9318430e670"}, "acc83c0b-fb30-4f73-9e34-96fd0d8b13f4": {"doc_hash": "4ad1d94a79fb0882359dba95a8520b8d9d3b6afa1a721d0a26dca5833aff215d"}, "d13efa88-add7-4300-bac7-9a56006a4252": {"doc_hash": "a56c5a257904f58110bd1b3ad61e3251a324ee62c884e6bfc90ef2f0069cb48a"}, "725d2cec-08dd-4ac3-9578-69e0ebb6face": {"doc_hash": "9e64c72321991dee2366ef6d20e582e114dec40a33e27cae0216e8ddc138b693"}, "bdaeeccd-42b2-4757-8853-928c43e9cea8": {"doc_hash": "0337877fe81cd66a4b0701c3924618b7212598affdfb2ec586b10d40ddf32545"}, "aeea95e3-efd0-4470-8eb1-63c997b1b1f0": {"doc_hash": "7278a84e81c4193be844812b7c67cedefa818d86e37720597357cc55150e6d0e"}, "2edfd473-006d-40b2-8363-ff2f2a97e0a2": {"doc_hash": "62bfc24218b6838952c0d8760305cdff5fd77de2b22e74f077f840f8b32c1764"}, "879611b6-20b8-44f3-9b61-5a916fe8fe7d": {"doc_hash": "c586cb39f74f8e12a6b3992d2ed771a851e817b9018e9c1dc56c4daf21bbad52"}, "db786f4d-abb2-4b95-bc75-580445707589": {"doc_hash": "def20050659421dac23be68624763e534d742d0ad7a00be2cadfa95a7971991f"}, "1c98eefc-6e16-48c0-8b7e-922f5fd85982": {"doc_hash": "b23f3500640e4401a75aedc11d3664e66489273585ea2c0a878bf027289202f9"}, "13911268-47df-427f-a664-a4152a93f002": {"doc_hash": "32220c4fb62e9e453a733d2f646b5cbfa3b133b04607c73682366a55ddb5f718"}, "11ab501b-8b90-4ef7-b488-65a39ba08944": {"doc_hash": "8a7cfbe0d6cb3d19404d0e78039cf53ddb1374ee2f9b9aab7363476c78bce43f"}, "58fffb2b-02fd-4529-ba71-9abc38e20808": {"doc_hash": "73ed61816cbd5586d209fe08e8ac2d69af482c72441acfec548aae5cb72a6825"}, "b73b90bc-47a6-48ec-b832-04ecb57e3035": {"doc_hash": "b7607df4eae79c9abed340d0b10d9848ef4e71e451dd20c2731d4fe5b3bb2169"}, "2d705883-ec5d-41bc-90fc-62f01d59ee9c": {"doc_hash": "8075e7938a9af8382ac6a02979944ed65b3db920c8a63a509187a88ebc160aec"}, "5ab02fa1-6a86-4def-a89b-28775226dca2": {"doc_hash": "1c4e915901deab792e7f3f6116df6ad584d7c86b51549ec67b55ae1745367e80"}, "54c18693-9d61-472c-b4aa-a2a2b9603ce9": {"doc_hash": "c12fbb45b519c8d122edfb97728d0fe71fa0320c6c13dd2a6e427368db2bce7c"}, "aee9432e-a670-489f-93a3-54efce08279c": {"doc_hash": "374a134046d38afdcf78f1197d01cfd9a74176d57ca6c762f786aa21d2815581"}, "58c749ac-5f89-4265-b05d-aa26c9473a05": {"doc_hash": "2525da008f305cde5be778904dcb2797ec71a7bdf3a841b638a941bef1a6c852"}, "224b1cf7-2c74-4358-84a8-c16d8d730a4b": {"doc_hash": "cde4ac7d7e33de574a9bf4d341c8753473df63611fabf2798908d0c1ec1d0f54"}, "e758bd70-2e60-43d7-8b42-2aa4c9e14530": {"doc_hash": "0e1b6f208b7f5ab6ce71f2263232c6c05bea25d856531547b4b0f60be0faef98"}, "c0644d39-0c18-4a19-b2c0-c8e3f6f1efe3": {"doc_hash": "e994e422795ce975e453a63e1e32a5a3d1965e744c088676de6315b5c16025c0"}, "fd289f34-a684-4ff6-9e09-cbcf600c64e8": {"doc_hash": "0914ce0d7186c8a83f94f799e4cef063d07fcb7941c1b162215085467c97a091"}, "2b4ddbce-1b3f-4aa6-8da5-01aa3b3b1b30": {"doc_hash": "5c39f9f2391b2b298b5b02145d2f43b45a96734473120be7a484201d56b31cd8"}, "a3621a50-4f14-4b2f-9dfd-a8367464268f": {"doc_hash": "3f8047b35fca2f0ef7e1ba2b06c60e75037aae182b18f428ee88638532874714"}, "43aee3c9-3962-487f-9f6e-06a284bdf3bd": {"doc_hash": "3acf05a2364698e56386c9ca40f8a0f028df9ef754629c57fa59024f42be24f2"}, "b83c0836-b1be-4c8a-ac1c-4895bd232512": {"doc_hash": "eb65a649ed36802083083ce0e7790da723dd064df70ee1c8049fe2d5a3946232"}, "d8e883b9-bcd4-4baa-8788-30af6c449733": {"doc_hash": "c9550562be57cf9ef21c8c4cc94b81b6cc470a5292a10d403e03f6b462f5a43e"}, "ab01a622-1b36-45bb-ba82-b37574fadbb9": {"doc_hash": "13b337183d48e12278276493adf684be9fabbcea13481a90c5a4e35aa52d5a0b"}, "06c96390-be53-495c-a17f-f2acf2bfbd34": {"doc_hash": "172375d382ea89417139cb89a56ce69e407e8f82fce2d57123da6bd8f29842a4"}, "f57247b5-94f3-45d3-954f-7a59a1560f4f": {"doc_hash": "d1dda9c2be41c977cee3208d2caa64cd8ed458691db646c39b5323744a44f8da"}, "af5e8c6f-b6ac-4c81-a9b9-54cb02fe11ae": {"doc_hash": "3b5f6a963275151095b8e123b51cb4eb94090a38e6915f2cc1b7542d51b174c3"}, "83d4b30a-adce-4fc6-85cf-34d210c9230a": {"doc_hash": "2652daabc55494dceccb039e0348598816ed27380a64eb04d5ee60dc5ac3c47d"}, "12ee014f-85c4-4c9c-a9c4-18da3ea16d61": {"doc_hash": "c7178e0fc9a84f6347cfdeca56e53649fef37f785ed89416bac85045952d3c77"}, "b69cbae6-8140-4bc4-9089-398fd958e121": {"doc_hash": "d3294e068efc0022d242205acba43cffe918d99d0366c29110a46cf20a2cf700"}, "83c3fcd5-9850-4b78-993a-a3e061f19050": {"doc_hash": "65dc8f7f832202b99bd4cc71aa6bfe05627b89af15bcc7510a4f77bea0fced91"}, "3dc29ed1-9840-4420-b3c0-39ba77ef7235": {"doc_hash": "97b06bbd693afd870b0bfb563a7d4fc06a366e34332e003f3ff8b09b76dae867"}, "293c9f39-6d54-47af-bc82-6ec6971ea22b": {"doc_hash": "bb7397501324ecb49d267af7cfe6ff88d0fa5d43445820c1c8c6f6266301c51a"}, "ca53f78d-67f4-4b8e-8989-2198f976eb9d": {"doc_hash": "01b7287ea1c34f13772c2149c5bf33f0cb247e77dbc00bd6053926e9d7c8dfd4"}, "810a64d9-ae89-492b-b557-50fe5aa83fd6": {"doc_hash": "200a753d35fea3d2b47a246452ff7cf05621592c9c3b9606ca323c8816db99ab"}, "b1a3d09d-7f61-43a1-a48f-144bb06bdd8f": {"doc_hash": "8d0b3e5be2dd311e4a75493aac2d10b3cdb3983adcc99f921088e6a38ecbb5f2"}, "96087410-9849-4f72-8629-4ef72bc5c1e1": {"doc_hash": "8fac94732cca26a5c1311f4182cfaf74bc582f52ad5e319a6401d5852b7f3cc3"}, "7552719f-1bdf-4882-b906-175e91b5dc2a": {"doc_hash": "d4e4f137a508b11fa5614774281d18f828fd3eff9096e7ccf6861586b3cf699c"}, "7ffbbf99-1a6c-4a03-9db1-ce5cceed28d0": {"doc_hash": "0ec01c52b0df75db7317ce211d9227d0debe2ab070cc23228ce032a9c84102d7"}, "34073912-15a5-4449-b99f-962cb946543b": {"doc_hash": "9e029142c11e2257ca95a8a4b52321a3ebdf7d7b4b7f1ea7a5b8579bfa942323"}, "b9e250dd-292b-4442-947f-91f6ad08247c": {"doc_hash": "08ad4a0a9f0ad52edaa9b78c5a569b079bafbe9fec3abbf85d44cb4fb1aee6df"}, "aa94825f-15ad-41b6-a30f-9eb1a12bf424": {"doc_hash": "1331d55dd16a06be2fc96dfce92df6d9f5352b7f4248a81fd6dbebd70330c838"}, "37c08ea8-0354-49af-9c64-31af245ae7cd": {"doc_hash": "0b48312f45a600da50b3853bf3072d7bf010cc50870d5b775d320fd4f1ad83d6"}, "d9d9fc7d-e9fa-4375-971f-0231221eb43c": {"doc_hash": "8b928e0f1da877dbb5505096c516073b7afd12734c0aa6f0e14177fe0a5b166b"}, "52facd60-fe99-40f8-8034-c40a65c341a9": {"doc_hash": "56e653bf76ad63ea148fddff3c13a5158079bc9b06ad9170bfee0521023dd61f"}, "fb5dd54f-abad-406f-8d9f-153771956b6b": {"doc_hash": "09314c729b6f5d4b8570601797db38061e5deebb32770f4a408b88ab7db34741"}, "65f524b4-e9de-448c-b4a4-a3be98145e66": {"doc_hash": "ef7711bd2c538bebe5dcc43b3eebd86d3e02ce45aa213cdff9cb1d3232132ee3"}, "977106f8-727c-4748-892c-213923909f57": {"doc_hash": "4a9c6a8a7d9f378da67cce8dca94f6dc305e0ac539ce95a9ec42baad0cb3ef16"}, "da311f91-b9bb-4133-94e7-39b6e3511b10": {"doc_hash": "5907b11ff9da2db1763c06db2351f1a2c98d52ec0852c452b73692b2df25196f"}, "93ea7b12-d2a6-47d0-b1d5-5b4d97d3cca8": {"doc_hash": "2542feaec99a1aab981a213357bb7c910db9579f25a2d0d503adadc6abe77752"}, "5cc88e99-7b3d-4d03-84c2-88c198def688": {"doc_hash": "2a79e3fc89eba102a8c4d630cf12f2238f2d6ee70db05ed2d4fd6be883361b39"}, "f17ab070-3c88-417c-a6ba-6e604aff0ce2": {"doc_hash": "5db4e6aa9d1a8d7c1420e987c3ff317d705263d0e6e62079948bb9abc4cddf47"}, "42de9950-141b-4acb-ac12-187aa82acf1a": {"doc_hash": "e178277dcd78391563440649cb306a1a107c906089ee32690570ba0cada1ae0a"}, "2855f849-2e4d-41a9-8cf9-ce4b25f5e58a": {"doc_hash": "b2c6038923f3f80469f17ef73717cde32a45dc8df5aa4c6fb7859a330115f986"}, "9ac47593-6fef-44e6-ad2b-997207af7b11": {"doc_hash": "9095b41d92ce3b228c8b487d66b905024fd3b6d5aac0e4b35b4bf31283e49fed"}, "5379b944-75b7-4cee-a16a-a3a7768ddf78": {"doc_hash": "35969a70435ef95c30c4ea9497e0ec0e98fb821d8b848a541fa8d9a7d65d38cd"}, "8150a85f-cdbb-4127-bde8-73809ad09d55": {"doc_hash": "4c92e980b9f1da6978fa80e2cdd2b51477bd43e5344aab7dbeb167713b5165f2"}, "546a9877-3fca-4fce-a5d1-14e50833f3d8": {"doc_hash": "ef514857c1d238d92fbfdc0a7a88076cc2807e0bb63cae3c17f3c74105f70552"}, "8035cfab-d7cc-46ca-8c4a-4ca03e504cf0": {"doc_hash": "e91c420c25ec585f6a769faea945f876abc8275cbdae39c28c9615c77d202ddc"}, "58bd6b46-9b48-4c1b-acd2-6472658690e2": {"doc_hash": "2fbe175eddf9be6c13ed435ec4da0a9c4b3211e66d4c1316ac3600d6b833aac4"}, "5d5ce0d9-e984-441c-8167-8282e95d5e2f": {"doc_hash": "f13ea9d3b5fc36da9a04f7684a6ccfcb26d95f4a2c8e9b570474c43775777919"}, "73027aea-92a0-48dc-8a43-a7f43f4cdee0": {"doc_hash": "ef32387e2453b96a89388ab1ea13638f7dc5943cd717c81c27ee7136a5f9ba43"}, "28b9ae88-7301-4b5f-b8b6-5858df9741bc": {"doc_hash": "00e6372d9aefd70cac07ab0d643331f438d8a75786340785a5b819c6c4b7c505"}, "6a2e8f49-772b-4996-8d0d-74f5d4be0e6c": {"doc_hash": "3847ddf0f6aeb9ae91a3e3cabddadc7df3236c43de4f4babe662d2be68a53970"}, "2ca09b75-8377-44b2-9372-eea5c90acb9d": {"doc_hash": "536aa957c7d5aeeec24f4f9e69d8283715b46556a5a3e647d3bc79ea0e473e17"}, "35ef44bc-dc35-4418-9829-fa3f6a5fc549": {"doc_hash": "f79a4677eb3ec247d215cdea4b9b6d9ff2788916abc24bc9da44367d4f748c3e"}, "bff1a03a-19ad-4fae-afaf-2a1b11dcbf49": {"doc_hash": "f0dcccfc2b6a027cfa6f9ced7cd934ed87e8e23d8da569dbcc338f0bb437bc3f"}, "323fc648-9ebe-47bc-b648-8f3df328c56b": {"doc_hash": "1c9179f69a923e83ec96d726bb075f3b886041084a5b826c15dd5646140df700"}, "2493c2df-f507-4f46-b70a-54c5d755c6fa": {"doc_hash": "20dd929aa4f1be3eddc0e62da5731e9f843396daf133a92ebfd95b3036f2aaaa"}, "854f53d1-c4ac-41b9-941f-180ae8043834": {"doc_hash": "f8e63bf519f95052be8df78c62d7a2541f27f9dff7a5f2aab801453c0f0a5941"}, "fcd17d77-40cb-4645-9d43-4918cb849541": {"doc_hash": "c2861b98853c38e42204317955d12b2dcbe089dfecfa8d400822b5ed5a104c25"}, "84c577c0-2e54-4a12-85de-209d926e6f95": {"doc_hash": "75ced02d2e8818030b52b39c20451fb014aad8515faa36e621c3d5c4c3adb410"}, "de347875-96f0-4c32-b409-fffccc8030be": {"doc_hash": "6f94401cff2cf173cb1e73e884b3c2b5d94e16f64b4afa9b136ef402f685fa97"}, "3c13166c-38bb-498c-b53a-f1c8810f8af0": {"doc_hash": "c75e54195c5a37a1fc66e2507abe13b21fa00cd77a0b00dbdcf9e31f4d06c7c6"}, "2482d4f9-8ad6-472d-a213-8d68a89f885d": {"doc_hash": "6476203209ebe273d73ab97968cbe61cb5ebd4f1b6a69e0417a1210711a2b1ef"}, "89eb3d87-ac56-431b-b75f-9aeca027d6ae": {"doc_hash": "75e103a545ec637fb2fd80518b896a9d0449d9d8e0cfc4371b1a6f28cd4d2838"}, "637b611b-b03f-4f80-9391-ec00994a37b8": {"doc_hash": "86d8ae920da2701a69849759e452172ae296c7432bdefd1f4227a7f08aee35d2"}, "1d455d44-1b34-4212-ac12-58a445925308": {"doc_hash": "f3b58af822369cc442142cf27b91aeede9181d9959054b92dddd87539e3863b3"}, "dd07c690-c09e-49f5-ad46-edd2e4cd2943": {"doc_hash": "33e0cc46d116dfe00bd41da779286cba2ed14ddcb69014e2737eb4bfea937074"}, "0911ce70-34eb-407c-aa4f-b186e41d3f5b": {"doc_hash": "a809613e01b8fad3ccf785ba8938fa1347d0801ca1bb85ab1502fe11458dbe3a"}, "e027dbc5-ed3b-470f-aefe-f6a918faf2b4": {"doc_hash": "48d30fdf568a60f5f829991a67f893f52bc20a465398d817f17523ccc79cbd61"}, "2160186c-61ff-4912-9b65-251463254afc": {"doc_hash": "4dc5b0874aa8033ea4d8849cdfc1957f4ec96daef5efe18d41a701e1d390f1ce"}, "8aa6590c-6151-4c7b-907a-8e0373f1f4be": {"doc_hash": "6fd097118ea721087224407147e678640f2660b5d906111c9aef296f9d0fe43b"}, "41cc0792-64bf-490d-a157-954263cc541b": {"doc_hash": "3f79eb1128237ff2a4552658e777eac58be5697d26da639db3d0c6146b47f1ef"}, "db978b68-622e-4395-9885-0a866cfef8e2": {"doc_hash": "699790b126de71c8e5e84cc50d93f616ce8a871a279079567cbccce5eb9ee46f"}, "453755f7-26aa-499c-8cca-6f61a56b2f92": {"doc_hash": "63da0fc323947ee62342905821c65b611291cfc21496e1931b845e56e15e3d0c"}, "6990dd6f-b33b-41a3-b119-a4b8ca5fd2e4": {"doc_hash": "2e0a2d450c200b461f799e4c01902993fdeaf9237e13b3f1c04e55b5d9893467"}, "c7583283-f082-4d4c-bd6a-bfe98cfb8a73": {"doc_hash": "9e2ed8be8949318de03a802f38eede83afd31cdead6561408758db6f8aecf377"}, "f275161f-bc83-403f-8390-e22680af1b28": {"doc_hash": "f79893bcc7ed7497373d85a25efadb8df4c376b6abc42a460f92ca9ab7ad3c28"}, "4aa12a2d-cef0-460d-8953-41eba24148e0": {"doc_hash": "28a14c8622fe58d16db32fdc7f862fe203506893dc559db2d831e31e398beda4"}, "4e27d59b-30b1-4b00-9c22-4151a49597d9": {"doc_hash": "1fef9136011718048f9cc6113930fbcaea1660bcc0c77b91fb7dd35e3094e7a8"}, "953d01b9-5f72-4431-a5f1-f10536815276": {"doc_hash": "032a894b0a2019c34b62d6b7b5dd79030a9bc20db1066e235f499f6378b4d603"}, "f2e88415-33e1-4f02-8b99-36513b3f5ac7": {"doc_hash": "045a6520f6acb25205ca8fac9584175ce75f4f56ac0ff5ff50c3a1c1814bedec"}, "97373fee-517c-4ec0-b8fd-50b4316d1c57": {"doc_hash": "9ba6b03874b57d27fa408de27933a2841a15a102ebb0d73011cd6acecdea2b8c"}, "9913c17d-8de0-4118-a98b-b1ffe920f72b": {"doc_hash": "de727a1d6de64a90480c96f710e29300a91a04790656ac163323b08ceb82a163"}, "20cd6ccd-576c-44fd-89ee-226d415c79ec": {"doc_hash": "266c29cb6acc239059d35ee9ed79ab546feeb4fd3e3398ebdae1265077e48203"}, "9ddc1033-a2a4-4283-80f6-c7e44e8731f4": {"doc_hash": "27f3d0ab45d788598ca67a970908aa145b77495cac2b332e2285cf8c79a5d5d9"}, "b435372f-c394-497b-9214-6f061d9317da": {"doc_hash": "cbc2b61f033c4950a85c40a8c18c2cf367863ff013b4f528bac9cd0648095e83"}, "332c016a-8ec4-479d-b000-5f469ad4ef3d": {"doc_hash": "514a42d395e4d61aaece02293b0c641f1c1461bfc0a1c559cc8a410023e40bf9"}, "04d8fc09-3631-43b1-b706-867639fe4120": {"doc_hash": "71ccd7ee0f3b10e561351287e51e367aa64c8a403cc69603a0470a9580e91be4"}, "299e83cf-8f50-441e-8eef-0da70b8dad58": {"doc_hash": "66fdbdccb9fd3c98bda3c1487ec261b2937b3aa1e925f59077d029f01e633a21"}, "509c349c-f793-463a-a46c-f368578bc3db": {"doc_hash": "49a2cf516b978025962388cdfdd572672da24b0e47beca122ffafce5018c37fb"}, "a928a780-075e-4ce1-930c-dce30ef6fe3b": {"doc_hash": "12dd2149f24dc8e6c30bcae64f8d843b17dbc2a9262f1134b7f7246ffd966bf9"}, "42c1e297-610c-4db4-8ce9-60104aa68a1e": {"doc_hash": "51e90acf1af95b3a9b7c33af4a86c284694adc8aea6d15bd36c9ee7e75fb3e2e"}, "e4c8e3ce-b4e8-4a3a-a380-6cbc0e34eb8d": {"doc_hash": "45aee66e7513449b468f96f28a4ae5e7ae7b73409da3c49eea11274d415d4172"}, "6052adcc-6ff7-45b1-a42f-3b47355c6810": {"doc_hash": "bd6335e36e0d8d1d0b319c1b23abc0d238be66dd62bffe2d4d5a5154b4b0d46f"}, "3134e8c7-1b91-433f-a477-0db9e3644e25": {"doc_hash": "c15a791467b6eea09e62a63e7ef650cdeef4a30880115eb160a6541725944464"}, "9202f5c4-9382-4d33-80a6-ccf5da4411cd": {"doc_hash": "63a3c59c8ceb195e9f3ec3ffa71110bf9bd9f0c01ae4a8d7e8ed9346791746c1"}, "0c43243d-f759-4795-92c4-3cf0246fd358": {"doc_hash": "7ae1ac7b521e06ef6f2dedac05ef51a343eada35cbde63b987754059f6def71c"}, "19200d45-8bc6-42b0-950f-fccd948360ac": {"doc_hash": "9f3fd18d513f6aa6337a8d6d7460997d9dda2d0c162f35d73c8a0ecec1990511"}, "1a067d15-eebf-4d59-9323-55007e5c502c": {"doc_hash": "ccee096c172d671eb8fe1d396dd1979703509d357198240842e990c3d3939eea"}, "ae3ffe52-600a-4399-86b3-02cd815d3336": {"doc_hash": "9ee90b61f84c8f50fd01b760b539627008f8e2ad23e1d8a3707a9f2fc8968ca6"}, "67d0adea-ff04-48c1-8cf4-76ec3b030028": {"doc_hash": "4d7f60b9ea5d7e6648df8f59911ab15f5ba27c0293d5e9299e7af1b5a917a0b9"}, "bf69b4f3-91e7-44ed-8b4d-55b2023937f4": {"doc_hash": "f7b68f62191fa8006253b1b607311d2925eb34ff73f5d0bb2cc28fa54e218ac7"}, "fcb03a3f-9786-49ee-93f4-8fbbb8c66181": {"doc_hash": "d3256b67d650cdf2f44664bde78313086a154e4a0b1e522075f986184dda0b46"}, "ae2afd6b-44b8-4dcf-9f3a-99bcb0ac56f4": {"doc_hash": "eb1d9f908d6b84c5961fb543f966463b9fee2b3eb822f0cb24456ffda841fdd1"}, "19d876f7-2614-429f-8be8-84e8fcdb50c4": {"doc_hash": "c3fdb31bc85ab75256d56ee0d38edf309888fae9fce46aa89b327a13c0190d5d"}, "099bce85-e026-4d3e-b3f3-764cdc21a390": {"doc_hash": "83c2583c647317b1c0623705dc6ceffd6afb287a3fdf4d1cc250d2d0fa435d02"}, "490a8118-f499-4804-b36a-9bb506b3b402": {"doc_hash": "837ec16835a9c01c08455fbeb31afb92a3493a0d6da76d571ff3a2dd43c329e6"}, "fad79c2d-fb76-4eca-9ef5-81aaf6c13b04": {"doc_hash": "66bce0fc5651427caa826d5a9cb61a5f6dce8548458ebb110f4d7093c0f57770"}, "7f8344a7-4298-487b-ac2f-59ae3945ac33": {"doc_hash": "3785bdef0e29eb7c826456d5e626723a39c3cf07356d37e7129ac8a3656a0783"}, "16939e12-56fc-4441-ba42-494b2cacefd7": {"doc_hash": "7bbbe2291108503c995382ca9e96da05ded8a34cc74e03aad058f1cb0cfdba8b"}, "8ec4454a-e6ba-4ca0-ba68-bfab0357f10f": {"doc_hash": "de4c8af3583f0c622af4b64f80f74e0fc90b7531771fb2c6ad22b9a7f1c35be8"}, "a193671e-2f5c-405e-a5b1-1faab6eb9a0c": {"doc_hash": "9545f307e282d01ff6029f1993c48f0c8df241dcd052fd2d66baa09de4fcf472"}, "c5046fbb-3a9e-4d15-9b17-2e3225ecb568": {"doc_hash": "be83870deac0e716da4d6054560155745790356a6040d4cedd2e38c554adc337"}, "21521fe2-da41-4839-9a82-1593543eb214": {"doc_hash": "5158c1ea09d2e9958f38a2631cbe614c206c4762ba4d2f0f5d729a021127523b"}, "634df08c-edb8-4537-9cc1-1fb9462f0add": {"doc_hash": "62a8e16bf946c8c50bf99ecebf7c2dbc5088ed2e62e61d9f17696709104c333e"}, "11d4e906-d585-47d1-a947-e4975e8f6b16": {"doc_hash": "989501a220326ff01c0628e800ca0b1de01ea3e05b835e59626ef2bd011e9b63"}, "76507da0-fca8-4e0d-b866-bc56be8d7a7e": {"doc_hash": "5c666d8b886291471848cdc63e46220545dc3e430674ac3cfa6a893745a44c98"}, "b356994e-7652-4f58-b58d-77f9454cd1bc": {"doc_hash": "8935225be6a48e9fed5507ccce5e969db953e71e86ff4a7f3e84994f03b9b739"}, "f609026a-cf8b-4940-95f6-f4fc30ced2df": {"doc_hash": "836aed02ef6e064ea55eb892a3cdb6d7ee0cd0d87447b31fec1fc6c5e7def50e"}, "2f8edf0c-c84d-4b18-ad63-93cb445bf8e2": {"doc_hash": "ae756e336a18534a3e3cbf1d87358b6275e484a005dd86d8e6b6844d8aa2bccf"}, "d60364fb-b1fd-4419-9594-ef3829c610a2": {"doc_hash": "ef2fa5e53814a459ebf3bc052a8d77e28def3131004b71c7a8b09ac377bf1bc3"}, "066a00d7-1f9a-46c7-ba9c-98546729adce": {"doc_hash": "1c0a1d99ccf75c70c467b5701a440058efcaca26f14cd7c49fab843371dbbae0"}, "3b9fbd32-4764-42a4-a26c-5e01e1049f1d": {"doc_hash": "48ffaaf3db96602ef57fd2d30dfca8b6a46212a463fa55c4e04151cf8ca02697"}, "423ba13c-29a7-4cf2-90a0-760eee24a4d6": {"doc_hash": "78fbf5958b13262d95d6cbfe53852f9f0c28737490aa72de0c8521b548592fea"}, "d1d2f24f-ef17-408b-9835-d7a4d81891d2": {"doc_hash": "68622f74db8df8c7ea99d87daf3c56cf0274d322731720bd8257e59f0f554fdc"}, "d51515f7-f737-475d-a6d2-a0225b27bc67": {"doc_hash": "bc4e52e732b847e2aa00e89266e5d06856d1360d2db1541b3dd59f8670405005"}, "08d5950e-0ca0-47dc-8fb4-e28f865ca8ca": {"doc_hash": "e44b02b75982ce48d851cf9f32e5bc22d6dbbe581048be86b6bf7065c534fa00"}, "d698099a-3bc4-4b0b-a98e-699e4be54bb2": {"doc_hash": "d79fbec53cd73229d54b9df3d67c29a9f7d2f193c5f98f6d8bdb55763c111d02"}, "f76b83eb-0cfb-4514-a7db-761be15d00fc": {"doc_hash": "3c6aef14356cfb56c687a87f93f32da3803911df88e14300a299d319e5026e14"}, "5657481b-8fd5-4bc9-be1f-ce813f9429e4": {"doc_hash": "17ac1e9ec956d7928ecb46f2056fb67c66211df61cf952fe6e7e387c67fd0766"}, "2e4cb92a-4cb5-4a70-a423-8df0e76b64ca": {"doc_hash": "e959c4a9793a00ef78e515a3792bae090ae4b2d4a54f3df0ce5fa7a3633fb78a"}, "749a9622-920c-4930-ad12-993d11205de3": {"doc_hash": "4ff280230d688db96715abf6b81322e07f395f417fc23d8b32e90d39b23642c8"}, "cf3c703d-b532-4295-a0c7-ba98a207f835": {"doc_hash": "9cae8105dd300edca2eedc05c46af2eb8b092638010663a187e91ab58698c3c4"}, "15766b8a-3298-4022-9df9-9c245d98097b": {"doc_hash": "dc0d5c34f5dbec88addbf50054261b8d5f2aae0db41d5c82fa0f9fecdb9a4e3b"}, "e74bec38-64f3-46f6-9792-f8c8216d37e1": {"doc_hash": "82437f789a3a2fbfb3201fa9266fd65d51ba3cfb8c8c8170252e29def677f3c3"}, "026df233-c40e-46d9-b93f-1720a4e6eb88": {"doc_hash": "63c6631948cb3f770673d7e466ad27c7b0605d79f083683d3b7386f747d757f4"}, "7ee00712-165d-4f15-8c96-e58ce2254ff1": {"doc_hash": "3704fb0e722bd9a4c5df30cec04308f192f2a1b9b688faf63054bd3a5495895b"}, "706c75e1-2e2f-40d0-b375-fe191221057a": {"doc_hash": "d4bba03189e9a81d2b6f21997c7c524f9423934b7115537c416ad6b14cbe3a6f"}, "8a63abcc-54f5-46b7-a54c-fc7462cc0141": {"doc_hash": "9ca824041a8a0ee1071c7758c4029424da2a568ed9816d466b08941764a62b20"}, "764e66b4-ff42-4dce-8313-38dc8d2f41b0": {"doc_hash": "ec02737a836f69fe2becb79784ffe4b13f79a82173e088cdb6f832e1c4ee4ec7"}, "6f0b5503-9bf5-4524-828e-6c049759dfa7": {"doc_hash": "7badc9bb876d7c595093750c2b6dcc97ab9b8adadc734a62fbb31a718240a132"}, "66350227-7841-460c-bf9a-3596b667258e": {"doc_hash": "f490b6b86ac15180607f84d4a961583e63458f47589e3b93009c04513cccbfed"}, "bb83d2c0-00bd-468b-bd96-e3a731a50e41": {"doc_hash": "5dd08047312a7a05942ea9eb9b67119169a7cec747bae182ddb6062c4334fb2e"}, "3aed12bb-9fd8-4276-8a02-4db208c5bd94": {"doc_hash": "055eaa2a75bc4cb704dbfe172af6c1c507a7ed4db0331f31d3eefbc1634f439f"}, "112ba11c-f7b2-4a40-8206-7e8463b28dc1": {"doc_hash": "296360405dd57669df770ff360da6df2ea6935b5c4be10dc03d2d23cd5da3cb8"}, "faa52826-1c42-41f2-9d7d-faa4e0c19b71": {"doc_hash": "3b9006856808bc17a95e41444df2e74d40a023f4a5faf3d7bed4f4621ad892ed"}, "1693c946-6be2-4716-b335-1c9a5cb80e4f": {"doc_hash": "2e3237c05c4a432fe6588a63c72e46d94c0b4ae9155aed4cf190bfdc54e64a68"}, "635b2631-1876-4fe9-a823-cc5ce0b096e6": {"doc_hash": "00719f142646a8f4da78e8770464db548dfb606560ec95b784a81045056d7dc7"}, "35d4ad19-15f9-4c69-9551-c01eeb37fdbb": {"doc_hash": "21706b8d82bccc61dc41b3584c6ddcdf67d4d0bf4e57dbbf98dab10ea75a568b"}, "5a0f14f6-f792-4435-a78d-15a5e85ac1b7": {"doc_hash": "7cbf416b2b463d5870e3f1bc087d9c8a44ca0cb527c9928038bc7e89692a1335"}, "b4f73cb7-7466-44a9-8ca1-ffbe416926eb": {"doc_hash": "753d8242410a5a91d84f96d7440cb6335cadeb8b79985093c3fd6e9e3868e7df"}, "e7bf8485-5b53-46bb-9b5f-fc09587c3b8b": {"doc_hash": "b6544f0c4cbeb469a4aff689699b25699cb731c1fab99edea3d8a799ff38baab"}, "b89fe7ae-a5c1-4bc4-91cc-132ba9dcb317": {"doc_hash": "79536085dc11dd87ec941215e7d5864f70a72413f05ab5131624856c8105b3bb"}, "fe1e7fac-e836-4fb2-9506-d5079828cc47": {"doc_hash": "7f05ec9f4fd31a4b9fb5e7b03c53496c67c5a177c8cff03430f61a75db7925f4"}, "951930e0-3b29-4168-88e2-f3c100f4e5f4": {"doc_hash": "5f19e2aa8d5fb495a126a28f1893214cfb6859436f7817b2c5a884c953140b44"}, "f5600451-6172-43dd-8206-9243ff7f2e65": {"doc_hash": "45610f9cac532db23252009063409442be45884de1e614e93e17105085c1250e"}, "c6fc990a-1c9b-4839-8d1b-27e02a547763": {"doc_hash": "b2280eb588bb4e4549713917be3c5d69399a229c8c3bedf23af6eb8f942c2b99"}, "fbb399c0-cc79-4ee9-94a5-cb70a850ad3d": {"doc_hash": "b1059f935ad1ce5e0a5586922954b0c0b3226748a0a3c457646bc9424705a18c"}, "675421be-3819-4745-ab9a-78351f6128b0": {"doc_hash": "a517bcbcd667557382a49b5d29c5aa6ea3b61d31ecddea0f01d8bab77c2a2d0b"}, "22a1b7ca-e5c0-4a86-bdfb-c4b7b374cd7f": {"doc_hash": "d656f20116cd5fe6bda839f3246c68e115efe9a9739498141913422b4bd5386f"}, "d4e06117-e29f-467b-a081-de34e576e7db": {"doc_hash": "5c6fffd2491f755491218b1c68f41979f6cf910803ab32db8f0b12d04c683d71"}, "12a2905f-959c-4839-8d4b-82391a6e3750": {"doc_hash": "863d46f9fba25b8f456e277f2bb3d167b0b60309340a22df6f7dc2a3edd33e4c"}, "47408614-d40b-439c-bf8d-d615016e2772": {"doc_hash": "f08967429f7c50efea1543ebacc8143121e186f5466241c62a498ebb5dd9b7a7"}, "1c624b9d-0446-4a7f-bc28-da411251f932": {"doc_hash": "4e4e7b31667f5bc0685e4e79fedaf9d78f5395f0364db82bbbceaa3870e50aee"}, "b11a3125-28a6-4c48-a28a-a6b4722df724": {"doc_hash": "6e24ee07b9365e73779362bdc63e1a549b60849abe964db67af8e65d148b4fcb"}, "37b6de1e-f780-418a-b19e-dddfdcd52e7f": {"doc_hash": "fd44134e2711d248d4b3ee11b211af80197d1064ba87870c9b7b58b90d2dbb18"}, "0af9cfe6-f629-496b-bdb0-d7c140d1c85c": {"doc_hash": "fb6d883eca5124ffd4033a48df952755a2029f6e30ee695261e7b92e15d47625"}, "6717935b-83b1-4324-a332-766ee976b1d7": {"doc_hash": "0bb9027791a55bf22381270752dc92c7a9d4305884759cbf431b46a7c13c14cd"}, "552c7007-8afa-4540-8ec4-d5aa60eb0047": {"doc_hash": "0e7fcdce549ea200a231adb9ef22064b4689a720e25a9e8efe5eaed4b0e97788"}, "425e6bdd-1295-4efc-9693-ec034da485d5": {"doc_hash": "8ef71e8e7debc2317cb5d05db2ca13f9e9e406f88c3f6c0ecb36dfe252796e31"}, "f1384f71-be0c-4adf-b32d-5a7346a8915c": {"doc_hash": "09a9ab00c694067796cbe6cbf69667b086bd10e554d9d8dee9cc5bbdb5c1b5ff"}, "4a2a5849-9d5b-4ed2-ae8b-5eec3d1a802c": {"doc_hash": "df75a72e36385e0aa1bd09f6726d0b6097d34f032c8ac116b5d5ab903ae335b7"}, "d9a8b7f7-5217-4452-a853-62c282430388": {"doc_hash": "2a6286985386bdb586103367e1f055341350b73d85341ca1d04ecfa9e6c39a3a"}, "d5d8803b-a0cb-4d11-9a97-2df8fdce2573": {"doc_hash": "955969b3b77b82270456759117d537f2cfcc5ff41a95ad8be36d2f46ce59975a"}, "58d8100f-b2df-439e-ab75-a30af24329a7": {"doc_hash": "cf0f6bb33298a1589db016ea45bd18be826222e1dba937e9198108a663c377d2"}, "2bc7c8b3-82d1-4b74-b9f8-81bcddbe8c40": {"doc_hash": "179994e2c25725388ba1e7499e60fed7538218727efba2eaef62b186b12165e0"}, "b55945bb-264b-4bd4-8198-6fd2eba8b3e8": {"doc_hash": "ddbc398cc00054efd7fcf271d05c6700d858aa60a4a8e4a53cebe1300c4152a0"}, "2a197dae-5788-409a-85f9-c26d2d3aafbb": {"doc_hash": "683f9992e6cd0d7990af74007e5e60075f7fa1105653d1977988f816866e674f"}, "23361655-cf42-4f62-866b-660a347e8711": {"doc_hash": "6d06eb0bc2e1d4c8c18e382f1d4c135df99634712b7f2e8e6d93b498ff975286"}, "94ea69bc-9fb4-4780-90bf-4d79aafe64e0": {"doc_hash": "a1b2f001d686a719bb111fa939cfbf096a3e91a170efc4325f6032fa9e2d3bee"}, "49dddca3-5a05-42f6-8b7c-298e84574cd1": {"doc_hash": "c0c4a762315f4a12c4da3076de0222f96ea8cf84e8b949c9c0f5459836afe47b"}, "938c7cad-1c17-4615-b516-37113c379bcb": {"doc_hash": "9af8e8fb413f34271cd7fc514d0f44492123029a8316cc4d960679137cb9bb18"}, "65f887ed-e7d7-44cd-99c2-fcda28e11f29": {"doc_hash": "f1bad15710ee522ad5900d70cf5d06d448658d97a8697c3da63fc771493a6942"}, "7cf91735-c48d-4107-8803-4add5255b869": {"doc_hash": "33066dee997f84da4a2ba38a57438c44c2d1da370cd2b1d92b8f7f1442e39e0e"}, "a0aa7e02-5291-4ded-bacc-0bb0c0420ffb": {"doc_hash": "9bb5333a5063d2c7c29ac9b64d83b78f7691529d4e78aed27773de7e39543604"}, "e817642e-0a8c-4cb5-9c1d-ea6f53d3e864": {"doc_hash": "6c0c06edfaef9b2ac0cf363f32502429c1858df0600597fb31e7c187a610a7d3"}, "d02e7dbb-a300-4530-9e2d-da62fd570631": {"doc_hash": "c3084c11778ad9a8d388ce58b3683d22a2f31bd8c82484559f3bfadd5bd74b5c"}, "1db597a3-1654-4147-92e3-7a4867f13e89": {"doc_hash": "b8a923e05449cbc80fdca55771bc11ccaa4637537c0595f46ef5fec763119e8f"}, "3eab9b70-fe02-4933-ab0a-8be2b8d34bfd": {"doc_hash": "30adb22c3010a7dfebba9880e62972584e05617c65cf3cebe66f0229faa17df6"}, "ac611dfb-3cad-4a7c-9390-3774f3f0bc7e": {"doc_hash": "f8cbb53c7c4b97a5adb50060f9f14b274a10a41dbe97f3d746f9897a386b7e55"}, "5f5a2809-2f98-473a-8e50-280e0c31cd98": {"doc_hash": "3881457964f6b56059a0d440600b6d97be09d9484bf59148ffea011bb18b5b7c"}, "3f0241d2-4bcd-4957-9a72-37304efc89d7": {"doc_hash": "3750fb292727e223f06d6f4b9711b97e3e1c2af6aee8200abc0a3335c53e6627"}, "849eef0b-c2b7-4c25-8c77-7cbad09ea253": {"doc_hash": "4fa46a31a1ecf888d1efd6d9412fafaa5703f58b9bd6454d1000a130af9ee564"}, "45cdc8fb-233b-4fca-9bf5-cf6dada9ca99": {"doc_hash": "8a6d72ef5fc15f4e8b0e20561195f3711c6e2b846c93dc45c087832da402826e"}, "867713ac-988a-4213-886b-116fddadccbf": {"doc_hash": "b2b8c6df77d6bec8b84163c87ecbcb2472eb93b35e39645f91d825cba2bedbbb"}, "4ce82fef-382a-4ae1-9508-7d359838429b": {"doc_hash": "9ef0e56c69ffbbccb8b6e50d871c3422d3881fa62d990c33fc430f781751f925"}, "3ee8390d-b4a1-48c4-9f88-15ebaa4e209e": {"doc_hash": "fba8d1b0996e278c5f8acd5962079a24513986c261a20244c4954b22a4b88689"}, "da05f072-ba87-42c8-9f5d-30fa9a97e347": {"doc_hash": "8624306b53f793f129a7a32657aa79208f745333cba9fa33685bf16a635e6f4d"}, "a8b8c19b-382a-4762-a808-cacb9d8e0e46": {"doc_hash": "231e944ed1c13fc7e525c58729444a691ca8e36e6d0a0bcac431065df102d100"}, "1c097be0-c362-4948-a985-ce4722b74ac1": {"doc_hash": "ace76adca162410dc99fd42653d584614f821676de213589f93e672517d077bf"}, "4bc6c501-037a-4978-9f40-01330752c35f": {"doc_hash": "2eae3eb953de82aa3f0e88b6cc032def4a77641211f45661837ceca4815cf01f"}, "41bd9b9a-e3e1-4a1b-a0ac-7de912c26555": {"doc_hash": "40bfffc5a51dbe2b55732f346068e68bde0d1e46dd85abb48b833d1b7f62c975"}, "da0c6e3c-c875-4770-9b0c-ac33eb48a994": {"doc_hash": "be91f47826f4824e22ee323491f3e4b5134a6d63599c666ce434ae1013a07de2"}, "006c351f-4d17-4a7a-ba15-53d74145587e": {"doc_hash": "eb72d5bf68423098bed100c9d4c905c7386e30600a076bdc6f8f473e6d32b983"}, "ce302011-ea0e-4aac-9044-67703edac036": {"doc_hash": "0c98461172171043235e54f68009342dc24eada6bb365c7b6fa042b65edf28ae"}, "14034c9c-3c49-484d-a612-9fd3d4b19a84": {"doc_hash": "86647a9090c8b2007e9d8cdd0cfc199b79318c236ebcd610a3f4291869539c47"}, "94d775a2-73be-46c1-b15d-c53d7f14e686": {"doc_hash": "5ef718af4bc881d27a8891a0d98abb2915f8054ea19df83521111c554ffc9973"}, "ca8d2549-51b5-48ef-aa2c-584cb3f2e7af": {"doc_hash": "b5a630c0718129d0c678cdc49477e8847efc2329058f3b86997acaee4e96d4fa"}, "e740c590-c233-44ec-a3b2-15e56d0a7974": {"doc_hash": "a86a320ab3e088ad7f52e6e4e9d1d096bf761fede821ca46d1b49517c701715e"}, "2f96ea1d-df89-4345-9626-0b69f3d894d0": {"doc_hash": "cea9c13616a2bdbc2795e03129e0eca98b4b99789b97bfa4c7c403ae5421f82c"}, "3465da41-ac3e-4605-90ad-08609dfecc54": {"doc_hash": "0d5b6fd631c6ae0a0ca6b23a3e195a8f5f655e83dd5a7ee4b4146549fb91faab"}, "d2ca7a75-2731-40e7-95ed-37761509be0c": {"doc_hash": "4cace9990aec366a188335913a91a5cb6d793227d43e702912d55c55125cf68d"}, "75adfeb4-7053-4522-b1e3-01b71b7864c1": {"doc_hash": "a8f2c2143b89d0d9b538c5aa920699927bf8cfe4dc5c695d6e737581190392be"}, "49094575-b561-4013-ad25-973ec0330a0a": {"doc_hash": "70d20d3b3f5726c55cbb7b0e809e98735b40b046fc3ba65f7aa3930d5629a62d"}, "acfa5488-ed43-4658-bdbe-a1cf66df7d9b": {"doc_hash": "e761ae2d14bc048c62c60ccc027366fd93b4d4b4e9cf50d4c43d9561f9745139"}, "65411d11-aa0a-4ca3-9dce-6290f875780e": {"doc_hash": "b6cbca692e2b3999cbfa7464ce985c238aeb61fda3ccea26eff8e40bd7eb3b61"}, "f3bd6321-354e-460f-9c44-aedb4c7d8eec": {"doc_hash": "f1fa84cadfa4ef7549bd86d28a9d8b221c985b4beb1c23308f75d2f1ec2a87a8"}, "f611d14a-8ccb-4592-b449-4915ff7a903f": {"doc_hash": "3ce8074ef05dad4c265a093cdaa9ae77a4ddb42b73f9dce0848b39fddf50d478"}, "1c779ef8-e622-43ae-ab05-8a5ee97aa1cb": {"doc_hash": "26980ebf49901793d4dc7a38ac598832f67eb73b94e8ac05986c4ff0489ff3f7"}, "4fe23b2e-6b35-4860-8d21-99385f08f73f": {"doc_hash": "d20edb0d23f5c17b7f0d03f20e44a41c3de62a29c4dd4259d72a1577a96d4b95"}, "f4fe7fa4-7991-42a2-bfa4-c0c840620002": {"doc_hash": "26a2ed7f4ed4eaf236b3363dc9c387ec083fc6bba764192fe66d0bf3787ea125"}, "419a09ed-8c0a-458d-83f7-d616fd7fd378": {"doc_hash": "1aac0f265424d0dd42ea6910de65effe80c94c909616f7ddadf48e8f898ce9d4"}, "9be2a220-1ea5-431f-b3b9-1d8768354e09": {"doc_hash": "0ae5b3735dcf4bbc22e25e40dbdcfd3ba42909dec2f019e4bfb9c431adfd608d"}, "d6db9eac-2e2f-433d-a1a2-aab4456c7702": {"doc_hash": "b2d50e9d9d79d5851f946b1c8f5b2cfbc168a46905bc7290ad4a53dbd906ee06"}, "4947b4fd-eef4-4527-87fb-f6216660ef9e": {"doc_hash": "fdab60261ad7a92bbde4fb130e7674c555d0d22f397557796d231cced24e04a6"}, "c1ac35dc-e744-48d4-99b1-e15fe2eb2b2b": {"doc_hash": "3f7380d6cc3c93a19c30b6087fc52428578a2328722afc8c81d0f20cfc09076f"}, "e04481bf-705c-4bbf-9bd7-a21d9db126bb": {"doc_hash": "48266319e42514308801d292800fae83e73af5ab1012510d973c04eb674b198a"}, "7db99afb-4a36-4ba7-8645-d0b26e9ea86a": {"doc_hash": "ac5d09238af4d5262ac4ec112520737ee5200c020b06d508cd0979b8629efbac"}, "43030402-104b-4b6b-9922-fc04306332d8": {"doc_hash": "5bd9685abc7279bed35a06dda8ade129065856c2fc97ce4cda15d8155c0db7cd"}, "3ec56ac8-fbc6-4a4a-b16b-e7e5d4a0af87": {"doc_hash": "47a26758df00ff9578e6ac090d9451c15fb98ce9a532ea735023c74404490451"}, "ed4e0f49-ef51-4c83-8c86-6d60b8dc81e6": {"doc_hash": "c3ec2eb476a497631ee156a1fb2354e9e78ad736573d6367d71fd0d47cc30838"}, "db739bdd-96b2-44f2-90ed-ab44d2b177da": {"doc_hash": "bc04da8bb8aef603d511ba3d26f0851492bc40c682f82d5113050ff8f3d7980b"}, "6253098d-23e5-469c-8864-a80f547a9c2e": {"doc_hash": "d4b690d1206e9cd8a9b7fbeeec8f952bca463543942fffa23452c838efc47eb3"}, "0a6ddb55-2c90-4763-9d49-cc259a2a5aac": {"doc_hash": "f74edfdd39a0de9e326db87ac66158a8780a898608fab57a0e7535ad71f64486"}, "d549d3bf-ac3f-45a1-8e84-6d3e17cea0bb": {"doc_hash": "a89ddc212669f54b0cf0c032db3c90133f59af14f71798c5405e4955de0e58dc"}, "65b56197-393e-4d6f-a4f4-a95fe3f8054b": {"doc_hash": "42add97ec53c4af48fc038977603f969dd2234ef9b17f0d69d25dcfbb99e873c"}, "0704ec82-dd9d-4475-bfc2-d8c760d8c7f1": {"doc_hash": "3b4cf34d97c091fcab67941c327d1a2534730f509fadb33164bbd5a8dfb0f649"}, "31d4c388-bbe8-4bc2-bd60-10ed6c3a934d": {"doc_hash": "1eb40b25c3192a253c2ac375f46343bbd96e02ca694d81471eab7e89b8fda2f7"}, "866cb3a8-b37b-4511-9e51-6cf018461fad": {"doc_hash": "fb646f013ebc0ef2ca7c4138065aed059227f7fbab2fd7e5a56b3198a613e02f"}, "dfcf074c-7e32-42b5-a0a9-ad2028f486a2": {"doc_hash": "1afb6ccfbebcca7820264a51d4f35c765627fcdf707025272f96d0dd444d14a7"}, "503e268c-d523-44c1-aabc-e63da374754e": {"doc_hash": "9c43fe228ca8d7966c45c79cd828c9019a7560381ef65044ec9732a5330b6e6b"}, "4077461b-f287-48d2-bb79-8afb97915f45": {"doc_hash": "02978fca17d2e41de1b6e1228238f50e7045883e4adf7e6b4d62633c0a3fe381"}, "303a2888-9f58-4433-a6d0-75f9a5a3c7e4": {"doc_hash": "7a444cba5ec23c6b907b1130b70fa787180fb9905084442fe788f93e778854b3"}, "863b2bcd-a573-44f0-b222-dbf493fea942": {"doc_hash": "7ae2fba56f3e1fa3b8739690369bd8b6165b42a5589074b43a605f764f12281f"}, "c3473cf6-b761-4ea4-91d8-d17ad08b6f45": {"doc_hash": "f4945096549c351298845d03a1db268c2bf1ef29b339327d640a36c9beb3772b"}, "cd7d2a43-f9e0-4d69-b7f6-cd9f96eaf9a6": {"doc_hash": "a31c475b619535ca90d2b890e044bd0e87cbd6a87092a684d1912986d094f7e7"}, "e353f117-93bb-4029-a9a0-32e620df4146": {"doc_hash": "82cd17883aea4eceb7de6ac8fa7e2b6753f09974b1d6c084cc185e6ba9e594a6"}, "c247cee0-02b6-47ae-905e-342b98d6915c": {"doc_hash": "4e9b73c2e4654d92c44b4acb0d6c726ff8032e908f94b7d75fbc505a26dfc36e"}, "2abad730-9c71-4820-b774-819fdc23548f": {"doc_hash": "2ea1ac9e72f79a88359ef7eebce77ac116203afb3d72f65a47bbac3a9dfc5b7d"}, "93173e0a-b205-4d75-b5a0-bac84604e7ea": {"doc_hash": "166085a4055c271682bb577a88ddeede51ed7f16239e9fcb3ba5b99066560eab"}, "c1814021-75e4-48f0-bc68-c2bd30930482": {"doc_hash": "d945f89224163f6a64cc8079dd184205de079de7f1ebf72dcb342aa05b92c28b"}, "c5d6f6da-a902-42de-a038-ab7d91dc437a": {"doc_hash": "d595dfcc7f8cadafcc9028455fb92709fb86e0f30df49e0db4c80315b7ca44af"}, "09218358-23df-4ae9-8aeb-3d543942ec9f": {"doc_hash": "2495f7293f899335876a487c8050708fdb3983343b2d7d22de42978c52cd5eb8"}, "ab820acd-18bd-4912-a2a5-a20299e213cd": {"doc_hash": "9b0a2a7ae99a7f7b04cfdedba7b497d5da9a6561bbb2ca663e3a8592e1c8fd1a"}, "73d22555-4e99-4e66-87a8-9b98ef6d761f": {"doc_hash": "adcf2c10650ba24895d853e30e5ab7bc02665f12cec56c2590513bcc1645c3ac"}, "f754b4d5-cfc5-4423-b343-dd2b3e115f7f": {"doc_hash": "5dbadff477ebed15489c67400c4327b52629979cf4a543269639a0a9bc156c45"}, "f5e2a8b9-9d7d-4b95-a25c-eb5cee17d274": {"doc_hash": "e2efc559afce72f25edb70459040016ade8de447291b665183e5250dcaff7efd"}, "40b22f2a-b2e1-4bbc-b8cd-201976d3362b": {"doc_hash": "c107dbedacec1c6791b946474b199ed00a29c327d4998a18b5b3e7314ccdec0f"}, "67f998e2-fbc6-415a-b844-846d76725cb6": {"doc_hash": "e52784dc22eac793faf2b89d91f693753a895fe871b331b9fc6818d17c55cc9b"}, "00dcaa36-b41e-4b15-ab57-ff02b18a2594": {"doc_hash": "fa3dd9b2454567b418266ec39f1caf2d46e63b2e737aec8aee4771d808c2f6e3"}, "11944dd5-fa5d-44e3-b988-58f724312d1a": {"doc_hash": "428ad5eaf20ed1dad7a71bc5159a1c8248e3720cdd564b79bc48e080b1cab9fa"}, "a72b0fc9-6f28-40a5-adcb-6c6457635267": {"doc_hash": "32472cd8e5cd4dcf8f310b11e1a92a1aad7a5a501723b5a66e0b43f5866ae8e3"}, "b40fccb6-19aa-4ed0-9769-023837188635": {"doc_hash": "2a468293582c678e98463dcefa73bbcb5247c29f6a289a317b07d07d45d0eeaf"}, "498f43fe-e516-430b-921f-f220a4bca135": {"doc_hash": "81309e62f0132b0908a4bcc1c6652b5f4ded3a4c5286ff1ee0e415b13a416ce0"}, "5bb20df2-8c98-4fcc-91ca-14c25d9e1254": {"doc_hash": "afb0d303877758b43787f161d910f2f8a34d1bb9142cbcc60830b8ea8e9a1b7e"}, "ea0233c7-f6a0-4969-8a38-3de709801e21": {"doc_hash": "9e6831e23dad7d4303c25c86d5576c19137d3ef8e52983ddc662b117f76a9e18"}, "fe6d9ee0-4f0b-4e6b-ba7e-f8b421f70ba1": {"doc_hash": "f3f5459e9b01f7292a1a5328e81eefc7dcb0a508e5518bc2ce0195a6d0faf633"}, "84bce283-64b9-4711-b47e-8a483514a7a9": {"doc_hash": "e5c8c800d78c1ae48ad404cd90c6eb5c38cf56b64aa6ea42ace559f84c889cd3"}, "3dd800bf-1697-423b-af73-bcf226c96649": {"doc_hash": "518e032c0ccda57ab7e92a7a3fc0d181fb20f9fb27c896e6bb9c5de8f8354ec9"}, "8877f80b-a1f6-4fed-894a-c8b2082898d7": {"doc_hash": "01c518af0538694221940f705e67ce5ac91279bd514d2624f2497572f34ccc1c"}, "434f312b-f8a3-449c-9cac-29b1cd1dacfd": {"doc_hash": "7590d972141cb68c5641a1e5d944ace8528ba99ef49b280f5fd4a7262534b7be"}, "e1ebea8b-cb1f-46bb-9efe-5411510df6f3": {"doc_hash": "269c72fa00109ad5e2759d59259a068259e4bc048b7daabfeba5f2df8cfb422f"}, "a498bf8f-fc93-46cf-9a59-e4e462273221": {"doc_hash": "a4e39867661d64a833265fc075507a48e60e96a19143957f36eddaad50b97265"}, "8eb0b328-a36f-43bf-a1e8-9553048e7105": {"doc_hash": "a02fea202bfde232632cc4172ffff1b06f58b43cc80a57efcf2c6c402725613d"}, "f9734b26-5554-4247-8603-cd66954275de": {"doc_hash": "19fba9e245c3e304903e508af1ae6ee963f3759a7fb9f20852b0a142c738c886"}, "71158a50-fcd1-4ac5-8056-0298f0a66f88": {"doc_hash": "51ef1d5647e02167c6b172ca455f5be619c3e4cf640ef7c4747f19dbdbf6c5a1"}, "8a7f3c50-63f3-4ed4-9928-34859934bb94": {"doc_hash": "b08dc05452aaed93f80ef9a615ede0af7786d7bcf3d889a5eef31f47f753bd89"}, "8611bba9-39ec-460b-b6ef-4d34003024dc": {"doc_hash": "d064f58702f949b536c44ff45269cbd9c6fe69cff6782fd794644036b250f926"}, "fdcd0ccd-aa6b-499d-bbd0-18295092af4a": {"doc_hash": "2b1d3ce99253ddf6ead034a0d87af7ff6f7040afa0c646ad5f0e5154921c7c6a"}, "85fb3d01-ca41-4156-8d9d-8a11e98b0ecb": {"doc_hash": "2cfd6f79330c945a47a4ad60c5cd3a426a6ac8ee21b0a5451a2a76e579b70b75"}, "dc869f38-7e85-4ea9-940a-d67f7288e491": {"doc_hash": "dcd1358a4705b9e0f4881fd62fe6a9b33de8b8672237406eb793c93ec47ab9c3"}, "471ae22a-39ee-4f3e-8990-79cdb10cb0d2": {"doc_hash": "53f5ac18c4bb9bfbca4101ed9acc0a9f6c869c34a25b3eda2a2b1c6d5fffe27c"}, "4e6147a6-8446-4e20-a7a6-395667d3847c": {"doc_hash": "d05e32bab4f9782967ec1392c4f30fabb5f7b6a4be394c79547ccb999a8ee8a4"}, "12dbd2e0-bd6a-4678-9455-24b430b4a4b1": {"doc_hash": "8b94919e6db137f10ad975f9446a14159e2b688521f05e344aefcdf25f6bdd5d"}, "500f4b48-da17-4a63-a7ee-37bacbcda968": {"doc_hash": "c3a5ca5a47ad571d1c3133d808c7e2d21eaed80aeb7501a8f452fb147b9490bb"}, "1fe0db50-fe6f-459d-a8d7-eb8d77f775fa": {"doc_hash": "7b9c11f4617050c2ff058c115256b37d8eae2e078328c5eb25ba674cb563fc46"}, "08c2b015-4b23-470e-9e2e-8432121c910c": {"doc_hash": "d9e2f850c8a9e68e3092f20aeb5c6040368a03a461e4cf9b3022f4d880311929"}, "0f3ea944-b933-43bd-a972-60faca64ac6b": {"doc_hash": "77f58a6cc83c23ee9bdb7dd65973ea25b0c346214d49a9cecb5ceec5a857e5ee"}, "b1a5e353-fb42-4039-9815-9ed3f5a9f91d": {"doc_hash": "be7cf4111d4adfe037dfcd0c44bbc20c2266f41c73ff39d8322a311595835bd6"}, "8faa3c2f-4fd1-41a1-8db5-716aad00c402": {"doc_hash": "704bd4820927f26d5d47a95d04305f6abb7d74f20038f86ba4debe7e15e6317c"}, "6fa3618d-a757-42ed-b3c2-ef687e91db76": {"doc_hash": "167fc81d0d00d7a0f69198f2671ce8f7203d39a1530a86ffa5efd85fc2014407"}, "d2dcfd9b-20d2-45dc-9442-480d1e9a40f6": {"doc_hash": "78b3a6744f08e59e2961705572b02c4f33796dd5d861b502ec300a886d44e95e"}, "482cb469-8738-46cd-9b26-e7ad65c66bed": {"doc_hash": "610229de352f8c83828ac55a3d6b3aef8a6fb4a844af9a473f0fa91a93fdefb3"}, "25654a24-78bb-4c4e-b01c-e22f34789b33": {"doc_hash": "ca9c13d4fdcc444c5dcf952f1d60b266d858c860d39b43227dfa67cce28d9ffc"}, "03f3bc74-0219-4450-bfe4-7c07236a1542": {"doc_hash": "0895dba48e557c15a14a0d84248e023d75555f3fc1ddf7b35eb7455c3e137d65"}, "25cff5b1-1fa3-4392-97bf-894e6890b526": {"doc_hash": "11e60f7797b8a8ee2140d7d537da49e65a0b4df70147db6ec48e2c4bb52e1f8b"}, "075b5552-9573-47dd-b334-c2c1577b3307": {"doc_hash": "abc5629fcdde401cf2f69b1f116780b5316405909cd9a13932fec00f5b4da63c"}, "bc864984-d54c-4ecf-a519-71ce4f74f090": {"doc_hash": "e6dcbe909fd63c47f4e3e27f36d902a4dc679d5bb18f7662fff4d6d98d0cefbc"}, "e02cbaf4-3a74-4e47-a3da-393e48cfe8f1": {"doc_hash": "b2ecf86486b6935853aede2b980a4b9b323f7a74cc8f5a140778bdef5b5c72de"}, "05a7174f-b169-4b6f-8e76-67bd0a33b5ca": {"doc_hash": "b5c0e9b702fe4258663ff221ad982b697b5519099d358828562be162cf752019"}, "8ae730a8-361a-4e03-b526-5fa922bcd689": {"doc_hash": "d69e8a78ab1d0ad32b759e5afb3d4f8f455b87a95cf2cfef3d5468e1b387cbbc"}, "76f9c77e-d394-44e7-b38b-f16c68225de3": {"doc_hash": "31b21ee498066b4c58f9739f78050c77632ce3289a2ed935aea128694652e60a"}, "f08f39a5-0668-4ac3-baa7-0e939ac22cec": {"doc_hash": "d4140f76e6478556db0fbc88cdd3c116d29dda2dd87dc81012cfecd9a7ee5f2d"}, "f747a74f-7a6b-46e5-9b86-5a8c1155accf": {"doc_hash": "d6c24dcbf84e7410c881ef57d1d70beefe516a0065056ed198a4990c94d6b8e8"}, "dcf5c681-296b-4d0d-94be-68053ccfc642": {"doc_hash": "cd6eb9438e95d1e7d48f0f2a23dcba5a916538f28ee88e90bd26a15b8cbec470"}, "57056ed8-fca9-4d6c-8390-23166faa0760": {"doc_hash": "db22ec3594898562302a849914cb14d3ced01023fd4debd07724395425fffe59"}, "61354d97-eab6-401e-bb8f-04c7386c5c29": {"doc_hash": "663a7e2233263d10a093e834d54566cadd90e86d753d60b5c2022a900b8ba813"}, "2442d659-21e0-4c92-91ea-227170c8c722": {"doc_hash": "3651974b3c3e539e4b6ef0d8dc9e897f2528bca292adc26bb0693a9305255cde"}, "aeabb0df-04d8-4039-8591-cb17ae8b5851": {"doc_hash": "7bcd81dd3e71d85567803311adcf3946c80135b4818bfee624e5231630a2f1a3"}, "e50c0160-f7fa-40ae-a1b0-82f366fcfa65": {"doc_hash": "fc7fa7b76212c089434f47647f4c3f47de49c4efdb2f62805881e49852e2a0ec"}, "4e25f31a-bcaf-4869-b5d0-fb6eeed3f609": {"doc_hash": "af746a862bcfe4dae4d65f2b8bef02ce091660bf4d1b68a36effd8615ea1104d"}, "e167a74d-a2c6-44d3-92db-347d485b0067": {"doc_hash": "08120dacfa57053cbb170e7bac8e454c7d62ce7f1463cf4afebfd520f2306c7e"}, "78759b27-e84d-4385-91d6-fc02f0e562ab": {"doc_hash": "2b72c499c16b42a1e4568304503a9a445a39cf3da196509c753f87d11e34e0c6"}, "62cd556e-e921-4e66-b323-71d73b39d752": {"doc_hash": "e0d12f266bbdcdef1abcce217b1c6640a50c6800946de1d2a0d06ec42b83d7ed"}, "4e526249-4874-4c6a-a424-0ac86e55c3e9": {"doc_hash": "6f988e14dd0d004dddcd6a9a6e981c58c07269360f4544c11ba58049e3e6cecc"}, "ede2e8b9-23b1-420e-baf6-afab6682a3fd": {"doc_hash": "f38dd3af5e16e1cd8eb1f18f9bae223845f9216d5ef3144b086c25da51fb3c91"}, "de6351e0-b9b6-4fba-8bad-8c5bafafe7a3": {"doc_hash": "340ff0be24113eacae9306e1d983ff55f3ce6312e300f926a555ddc8fba3e5bd"}, "f9ac0031-1183-429a-9ab7-f7aeeefd7335": {"doc_hash": "bf137e9df881a0139b2047c13f2494e75aa9cc944a41466eee8ade8b4f6a9964"}, "a3a0f720-ca75-4c68-9015-b3ebe58ec7bd": {"doc_hash": "e71dc2d3dbcbc5531026c6b65b0ff3af5b9f17ca13e1dae7ca9ff67dc91c1ce8"}, "374f3c4b-3055-4a5f-b1b3-b0e2828169cc": {"doc_hash": "647bedaf9bad95e567476fd37e50b3bbc9afd2913f05b55dd337e36af36339b2"}, "2d9bda5f-a5af-4f90-8e41-ee8baf9c0fce": {"doc_hash": "99045476a21df2031cb131e6512e54fd3650b9837bcc87f0ea492f8b903f45a1"}, "501912db-1da0-4b69-b3c0-8204f2272b91": {"doc_hash": "be9dbbb0f8e39f5681302da7411e9a8bd56508741a44c1168a1033c6a3999a5b"}, "c35662d5-4619-42fa-911b-6b9a7efa61d8": {"doc_hash": "718892968b6fb894be89ff02666dcfa92a520d6783ffa7c73908ed95fb16c816"}, "69873c8a-50a0-4dde-80a6-81c31a86ceba": {"doc_hash": "785bcf464a46b60eda929caddfb82e6a2f7d9ac4d89dbdbaec3ff37aafd1ecae"}, "e99ea25d-0f86-4d10-bf3a-b3bfde792d53": {"doc_hash": "a8295c1778d68486e3d89c2f4d01aa74d6aa95f0d96452743118ce06c7e1da1a"}, "61c0fb7d-e00e-42b4-9b42-00ba59656909": {"doc_hash": "a822e5ea6edc02fcd67d0c84cf153504f450d2f55043e254a86649605cb389db"}, "9b7a38ec-314b-4a36-b2f0-34f61f077cd9": {"doc_hash": "b6a8788e55b711f7a907a4bdd6c0ba260f9b84a8ce400656e380456c8628912b"}, "5fd3d459-3cb7-4a37-887f-24b3655c941f": {"doc_hash": "7bded3281f0b8588f4a56059818e5e26ae1fb86d7c2fd558ed93c64171c006fa"}, "e804e772-93ae-4bef-8543-095c1308ecf9": {"doc_hash": "41bf701bf6b65d075d0070a691c8e4ee3a7488603f94393edbd64de00f7f22a8"}, "0f86f60c-e3bd-4bc8-ba07-b253894009f3": {"doc_hash": "5336817547c8816f8755bfa1b1593824c46fe82472f3a75a86ad4ed29100e166"}, "9748daf9-5e34-4e49-bb00-d2d9846475a7": {"doc_hash": "331ced2152468c0a773f3c0a3dac60a6ae0ef45863a42507d9192df7e8b2b817"}, "8fcad5c1-ca7c-4974-90c9-81b7d00ac872": {"doc_hash": "fc6ed9e0cc5d9538779e09c7c676e6fcb651a639778e48046cb40be16fa76da8"}, "9501fbb8-6fdc-4811-8fb1-00a70841f79e": {"doc_hash": "84ecc5ec8f47cf04928f43c3cba57ee818e0e23317ae4d1900692a96fc7e3391"}, "4d7dac46-ed9a-4fb8-bf50-dbe8498a5a0b": {"doc_hash": "b6a5dbc61ea5e510e3a7d2fc55e67b309f1b1b7d0589464fb626523f603ec1cb"}, "5f05dd94-549a-412b-b345-044a86f73acb": {"doc_hash": "159ba792133f756e1fd8c93ba6e7142b8ce0187145b3d3f713ca04c82e4acf50"}, "c4219c03-66a7-458f-b05b-6137ada7713b": {"doc_hash": "c65a719fcf07b5b95172298553ec73ee1c17bee1807c356893c413937ba47475"}, "71d14e2e-9eed-48c5-9a6c-a1ee87faf124": {"doc_hash": "bb38b31dc24fcfa9e0d9b3f731f0198932934fb9161b5007801a7ca6a3b0b702"}, "bf74a7d7-a4ee-4f6c-9b96-2a99c7f933f6": {"doc_hash": "f8cadd019bd1ab34ce1d450ccc9445878eef3fde3a31eccec6bcedaed952791a"}, "fc524ffb-6643-456e-a3ce-da9defa2b51c": {"doc_hash": "ffe465bec5222b97904006d59df6e9d25071ad2e4163f81d081e02a719e0c887"}, "6112b130-97de-479f-a591-cad320bdb332": {"doc_hash": "6b7f3781a5747bff52bf9ab17920275f88126faf3142b69e32d932cfd1e6b071"}, "de1fe382-3a35-441d-91c0-1f3ead489f21": {"doc_hash": "db496ea81e00569cc21518ced8979df989367a1355d0dc2e408fb3019e8aa26a"}, "f5165019-a891-4a31-85d3-824f68533eb9": {"doc_hash": "72a900d90fc2d24e457a8706db82fca4ae303e87bca2eb1d714139c42e347862"}, "cddfd9d5-f1ef-43e6-8cc7-4bb21f4d2d81": {"doc_hash": "2e4cffbc8ff8a9bd232ac207b358c14bfeb8dd92c2cdc89a932c5ea81c4ff592"}, "881e6be6-f8b3-498e-a977-e5cc27879c35": {"doc_hash": "e1a02baf2bed8e8c0b0000e4ca4c5966d73a9608c466a832ab28b331554c7d96"}, "487f46c1-e72e-457d-b89b-6f51f231071a": {"doc_hash": "3ac1a24180ab273ace0f852f916ef475d9e00319d942498aed4a25b884c1993c"}, "eb0140fb-3068-4780-8010-4c8afc3938d6": {"doc_hash": "6dd798eb66bf84ec70fc5b378f14ec99ae15bd032839cceff939ac2a17e9238f"}, "b2dfe512-d151-4b39-b0ea-92be8970464e": {"doc_hash": "0e10baad524db2edbd67bee0a3f3a87927d2f3f7ef25fe5ad86eef79c6fae882"}, "e0e63502-7f30-4614-8536-d3c58f97fc4c": {"doc_hash": "081b8941009c9ebdd76f3855442fb221fe431c35d53b3dd1682bd7e1b151dbf4"}, "19e28945-f05a-4405-8b64-989217737940": {"doc_hash": "5fd7c2c43deec2f80f582bf526f697beb3f081012ee821902494561e79129da7"}, "90c81b4b-4258-4229-83d4-bbde0370722d": {"doc_hash": "258f4fa34c549c3fbef99dfdcf653ade6f17197d60e97877a0bf271419f4d1ce"}, "2740fd29-d190-422d-9f73-7eb625649d25": {"doc_hash": "c9938b1fc838acd79f14f51ba5b92c071e247ef07fb4477b5eb83c8b9a575750"}, "1841f743-8a20-49a9-b10a-f5acd89775ce": {"doc_hash": "99808ff2a5227638a2fbae1d30e72567d2b2489dc272439ddf938af63a9be283"}, "66c2e118-111a-4834-8015-e93879f9adfb": {"doc_hash": "d01a3f0a12c102051896e871c520583f5b024d9acc0d8bd93cf61f5fd10163c8"}, "82bffdbd-d832-40b0-8b80-1720befb4cd6": {"doc_hash": "80b61a670e45572d9fbe55873d28a1d794b4fb6f1a6f1370d9ed649d128125da"}, "7a8d7a00-4781-462d-a8dd-f3b22e4c8070": {"doc_hash": "347fded493f019ebddc7867d2801b48c045ac12c30d0261c32aa872f0431d06c"}, "180b6bb5-650a-44fb-9942-ca0e269a7209": {"doc_hash": "e7c89bb81a1d599320f52cbd37fc7d05e6240ed9ef4b64ad646f39c59511ad69"}, "f15e40f8-ac19-4f7d-ae34-3fe8d741f353": {"doc_hash": "2036cc5685e6655d2e6e32e02a4410659ad63f05b883e9761d26ab58e57c211a"}, "7e6b40c5-b572-4bb4-b0f5-1d1450726f88": {"doc_hash": "b71739297edf21ef3a8d5ff37a401be476cd1a3f2ac6fa9d27bd6764efe56c1c"}, "606c713f-2b55-424c-a12c-bdec48369f93": {"doc_hash": "13dacd45075734127b2eb518be12f24a88a5fb4775c7ad239492c76d3ede212a"}, "6da35135-2d29-418a-9915-ba76596b0184": {"doc_hash": "aeda9b329026711a1c1e4f8c78b720f68534c3f146bb0aacbea4632287bbd91c"}, "652ddc05-6ae1-474c-9ab0-0a34fdc41798": {"doc_hash": "84a77df49763988134c9b0bffb5430b24f736d6fb3ef5bb9fb175ba575431de4"}, "dfdca133-c495-4853-afcb-ae76d10560b4": {"doc_hash": "2522ffcdee609f67b6ceb7520628cea1d0c672ebb82c9bfd570931e81fbe39f7"}, "6ef00ac4-be9e-4560-94dc-c0f059986828": {"doc_hash": "cb075bb3d2bd9de739b023a3487972d893b57c0417edc4af40af4d8aff6d9cf2"}, "0323f4d5-e5ff-4f07-a733-97ca8f5587e1": {"doc_hash": "d2ba3a9380960093480fb0ebc586038050b7c099d73e6286c7c1a83896dd06f9"}, "96c02a1c-8c50-405b-a59a-fead0ef2f85f": {"doc_hash": "2bc03001f31b15c32e52c8050d36cebfa5ec94023cec2083d8d5fc6bb8fe4fa2"}, "bd8d06d9-57fd-4124-95e2-00bc15eb87fb": {"doc_hash": "a867cfeeacbe1ca39eaff388e75d616074c7f10aed8900675f2d37efad8736dc"}, "d918ce06-130c-4f27-bcf5-eb9438e7783f": {"doc_hash": "c7211316604d7d1d2b55268a6820f0411dd9ff95e6367dfaa8b0068a6ecb4c45"}, "25a1cd45-cf98-4029-a208-34e8e873cba8": {"doc_hash": "dc69d6875dff1a6f6d44ece01adf8661934c1eb3cab9215f14aad9eb1c7a174d"}, "d07b97f8-de65-4617-936d-e8e49fecad27": {"doc_hash": "d1af5738d65dc025ab28d8e8a680e4163cce611648d5d431e4237c4383d6ed55"}, "9bf88343-040d-40ce-b3a5-a26e12a83f0d": {"doc_hash": "e54ed11dd2738252fc5209c9ed6aecb3c9460286f3287096bcf87a6d8e620cb4"}, "27a08d37-f5c3-4f75-98a2-f9b088600912": {"doc_hash": "18bfe7dded33d18fc795a871006e913636899f7ced42c8ff76979d51afadd8ef"}, "8c1c17c1-a651-4f44-af98-24b8f8b3eaba": {"doc_hash": "ecdd9e2a1e10c7dc9600c00d3bee8aca1ade722e79edb7b5e2ecf497a35b8284"}, "0e99c074-85df-4b0b-aa60-7cf8b7563037": {"doc_hash": "c46028e8418d85bc23bdfbf9c316ef04a7de0fbe184a1bfdf30a5e22ac0cdf56"}, "8fe6ea00-4b37-4016-a3b3-d5d33758bb58": {"doc_hash": "66beaa995b9019b1238735761785fb717e3ef59ab2467c8fc6795db4784b42bd"}, "b514d198-1adc-46fa-b510-4ce177ed5285": {"doc_hash": "d57ca0ba5a7bd32dcdf6c647b3eea9c13c4fe9d87bdf2209919f67fc510cbf48"}, "b21de841-0ca2-4c0c-bcb7-499d8c3f59e2": {"doc_hash": "e9e8446380b24ea674f64e0d03fc87b02dd151f12b3eb2cd25c97332ce583a26"}, "a9564b8f-602c-439c-a34b-d1a68328cf98": {"doc_hash": "b04d33dc59476fe4586f63b201a798c35ce75d6ff1e4fae9893e7379a4b62c3c"}, "44dbd0d3-627a-40c9-8eec-8d867cc87aba": {"doc_hash": "82dc51301cb5a13c9a82ba4d6f2a7230b471cb8a19323b44c0a59e92565b1fbc"}, "ca639341-cfa1-4ad6-9a7c-ede9950e46c6": {"doc_hash": "a6d94ffa7c2d4225928c51db793cd4c09aaec2743d407a5e087a49c8be0565a8"}, "fbc27a12-f526-4efe-94af-e825f8c29333": {"doc_hash": "f6447480d55bfa4e8f3d2ae1e0af4cd5b65a0b704b6e99b37f0ccd67f7738f14"}, "5b6365a0-9a0e-423c-89df-5bf0ae10728b": {"doc_hash": "6d2cb45713cfaf89036467aca3b22a3c3c60cd8735214e8ac61d0243ebff01f7"}, "16b9dee1-83f2-4077-b0c2-c105b5bc1089": {"doc_hash": "3b922652cf522235df33df6ed788fbb6a8e7f944f69b13ce0dee491d9739d159"}, "b0aa9b53-05a7-4e82-b2fa-e483014b4584": {"doc_hash": "30517150c5d7129cc03dd3b2621110e596f44e04c53d8c4ee9aa37bc3ba2b40b"}, "08697dc2-a7cd-4496-8e7d-c8f20224ca25": {"doc_hash": "d0a0d6b91a6b0462ff45e5cd304d9dda44395daa38d502944e0ae2379a14f930"}, "6cacc18f-9059-4dce-b72e-532d10024dda": {"doc_hash": "6173a2ec8b6dcb56a12f8d147762519aa8de636cfc5f0ccf74a55427e9147eac"}, "25e4d2b9-ee8d-4154-ad29-90ece83bf9f6": {"doc_hash": "db2c0f2474c1ac86a2374d627447012e856632be02c6219f9416009410f02717"}, "593d8f1e-9941-4dc9-886b-0eb9f2efe722": {"doc_hash": "d756674f63324d67bb886919b5ad8a0f68057b2f16b3629c23f029a8d359d2cb"}, "c1e78ff3-2b09-4b18-b428-614d19edb7c6": {"doc_hash": "27ed20cab14353c3c5bce10628f6266c2efe9055c242db5385b9d02baeb9904f"}, "c585a92a-13ce-4d60-a974-f4345ab5224e": {"doc_hash": "3bfa12bca6ce3a601eb39c4b46f6963e22b395d774d77da318e555d355aa855a"}, "1560dae4-3c1f-41ac-98a5-59587b8248d7": {"doc_hash": "0bcc51410aab2a6ce1780acb3828a8dacc77b93b8bf9586f99999206350a93f3"}, "1d8bffc0-70c5-4588-998b-7d76637ccb23": {"doc_hash": "b50b6cb929df938a1a85c9d201801806c52ad957cf149dfc7f66b9413f621a4d"}, "65bc225b-5c4a-4331-b7f0-fe48cb9bb13c": {"doc_hash": "54deb889d7fdca21044e67d2d8d2ab75d41de14d6404b03fb75ea98626831bef"}, "107e1562-7713-449e-84dd-fc3b40cb96e3": {"doc_hash": "3307c65e248249bf2af004471836f23825f205f25452710e6623999f0fde77ea"}, "67db3404-3718-4854-a347-f3da51c473ca": {"doc_hash": "b1c43b2f94ea46973dc904342d0db6f2740293f8860879b301477a86a060f8b5"}, "cbcc793c-7a18-4bf7-b7a4-62be1fefcbd4": {"doc_hash": "3f11f8b37f13dd193c71e7ca8fc3b7d164e4a13aecfc59a793a24f4de8e26dca"}, "7bf8a7c6-8046-4f4a-8850-c41f9a04a11e": {"doc_hash": "11b8b814b96b6f6e2db57dfed5fab6f7c8c510d419cb406b9198424f45ffb7ef"}, "8b5128bc-04b2-475d-b054-5c200a69628f": {"doc_hash": "3fa306767fc5f8f4ba21b632b0c40d9b8990b530cda97b7437ec42a5a3890765"}, "08326ecb-8555-47d4-8f1b-4d2743157c08": {"doc_hash": "04f027ee1eef207fca140e805c5c9a5564eac8eb39c59a4a2029ab6f3979016d"}, "854b1789-6709-42db-a512-74ef59dc1c0a": {"doc_hash": "31f003572b4972bba29c776148c68bd2df2974d59b706f3b4aea35b37e7b769f"}, "0e2763f5-8282-48c8-bdb5-c6858d809ef8": {"doc_hash": "4659b369234871be0654aecf0ca294817e080802047e97116178ca7e0d45f268"}, "9c6ac038-0c4f-4f96-9761-a7521cb18726": {"doc_hash": "1332cb7d625bd7c4d4ea65eb3eb237c4a9669fbc003847d5707aea2f2d69a940"}, "18d7b87e-2110-4bf2-80e8-47ac8e602f47": {"doc_hash": "2a8e326d2030f2e78b68cb2859f39b5c07a7d9d93d7479d450244fca86270bed"}, "f14bf528-b3b1-4135-b175-1100d96baedd": {"doc_hash": "5f6d9072cd7b63535a6def61c9ccff1227f9cd46720914785231a1ca0bf16c8a"}, "1cb0578c-0020-4679-9804-36abb1bab365": {"doc_hash": "057b4b293f8cc220e39567d683f7aa721d00f759f909801ac2cd25c83a93a652"}, "e940afb5-1b99-4fec-b375-13e230e8fc17": {"doc_hash": "f55c3be793ee153050bede144714d2ae9f7afc3a1c1382a66bc32c21a4803eaa"}, "4990288f-9a75-4a29-95ad-7ff392f458ec": {"doc_hash": "12843f3a7741e8105048edc68a2d990ed8a15c5030c644ab9f27dbeb0a54293f"}, "617fb5da-93b0-4a73-8d01-5d4df1e5b623": {"doc_hash": "c8cb01c4e844f0a590aeae07631292bca2c52b66d6f01aa2edd63be164f0846d"}, "48408684-a559-49a0-84af-e9ab56a5c002": {"doc_hash": "80cc5cde4460520c159ae62d7bb3db4ae68e028fb629cc70c923874b8e4f6e96"}, "9f96c364-aefb-46cb-8764-485843f9da81": {"doc_hash": "4faaa1aff918e550b7dbd6f5d40d1fc3c838253086a4d08f2b0f13f53455e0d2"}, "6f521b0a-82c0-4d68-8eca-aee142e3abdd": {"doc_hash": "d49a8fef037bcc2d196c8d204b54c61053671b0618716041c8aab08f30c599bc"}, "5b3695ac-9465-48f0-8563-c1dfe5f58101": {"doc_hash": "00ac49980a8d79d19962c3bf6f3c38231279acf809fae9aacc9cda7f022eff5f"}, "fcfc89f8-3c8e-45c1-bbb4-90d3957f0aa6": {"doc_hash": "af956d3dbc7f533ae057b845e442a23d31d14ef4803a00912e8ca07b77a31c4d"}, "23c391c7-bd9d-4de5-9275-aa80ad842755": {"doc_hash": "9b385a9cdaafffbca871c11f468c39b617f514f236b33919bd6e0c3719036082"}, "42adff5f-096d-4099-8fc1-0f326a3a81ee": {"doc_hash": "43c515e599fedf0e5a9ede95071192d053e5d0fb3aacecc3ecd8d9612390f9cf"}, "c4ed7c14-03d0-4bcc-8f77-eab06f2f0933": {"doc_hash": "b6e1b5570a2de4f34e9870d271d50fa2765b8b189e357c1cd7e3f041b36cfee2"}, "88548818-645f-44ec-bb73-3ce8757b329a": {"doc_hash": "2bb79f9c17630ffb36267434abbed494234932ac3b46841dd5bcb1e69b516ba7"}, "1b631852-6931-45e1-b1a8-5056c7225314": {"doc_hash": "96de4686adc567e462f818ac816d5f6797e5fa44539f35e7a7bc3259909f43ae"}, "84f892ba-86cc-4722-b4c5-d8cd1b0e6fe9": {"doc_hash": "699f092bc7e563284b183268d540df8b78ec6ef1e4468a58f72ee7a7648050b7"}, "9b452be2-62c9-4ceb-b684-bea4dd154485": {"doc_hash": "af5ef1304cac919f130e5efee44985b2a78303265a1689e0a26e6748ce324726"}, "3465dd95-f4ed-4030-8a97-e5c2785ab8ef": {"doc_hash": "2608f2884e4e2a8ae89603fdb9bf72c47377fd243d9543e1f1fe218fc4de9bc4"}, "e222dcae-300e-4b6b-bd46-961a92811dc4": {"doc_hash": "c99ce49700354368f5abf3f01c4852f89d55fcb2ea74007014d7a9180fe71207"}, "327d31c7-2dbc-4034-a918-1ba6000a3e71": {"doc_hash": "a67a2816852433a3c6388a569ba42a1de8bf9858cc949344374d1d561fe1c6cc"}, "4bcea138-4ea5-47ca-a138-f990ab7ca50c": {"doc_hash": "017d9f7547e197a6d87d2a88fd81ae69c94b1ece65fe9b49c35dd72ec66a1822"}, "394ba390-88e3-4b01-b16c-03f51c5ac493": {"doc_hash": "9a3bf9924d57711de369fdbc3db5f33a51ee58c792c4d6270d6a76f57f25543a"}, "12e706e5-3d10-4846-bb2f-d701de452a60": {"doc_hash": "b63635a80f8e959e6e897b05b8ddf5415b23547696280b2a52b747edc2662a21"}, "4eb89310-240b-47b5-b5ea-10d87bc1ab85": {"doc_hash": "8769e0c8225f37781f07e7e2e4b6101d90cba79e497b9e7d7efa96a97173feef"}, "6257cdce-4127-42fe-a04d-d2623ea1c107": {"doc_hash": "3eec0222b295546accafd23451767b53a2f5fa0e06307a233f8018389043d321"}, "bc4e0317-9860-4a4a-8c48-a2f9901b5ad5": {"doc_hash": "998d840200c081354ff3eddc59fed4a45e65ad84e08fa4e0ec1048ba74fc1d05"}, "b74a91ba-d4c7-42f0-b003-63584c4ef701": {"doc_hash": "d91b76aac863cba386e02574123393cce1344f634ecc60a1a9b6061299da2332"}, "6f7f3332-c5a2-445a-98d4-836b45758eca": {"doc_hash": "87395e1e9413f6bb062dbb186a3c68445d9cb49d8259819d319f103b42cdd638"}, "d2100c3b-2002-4c87-953a-48e0c9a4c1ba": {"doc_hash": "60f51df9599a1020a57744941a4ea51b3702d453b1f18e24a742036fdae29b36"}, "98b8b684-e16c-47d3-84e8-bab3d0e7c19c": {"doc_hash": "2354f282be33a0fff54aaa8fd0920e9bd78e8d65857cb861e1a8314c3a0b358d"}, "c0191bac-3de7-4d6d-87d1-d521169c6125": {"doc_hash": "5383290e585b9c2c699ce56b786b3ca531359f6f539211eaf8b6d57da64a8285"}, "384c421d-a650-402a-a59b-358614d5939a": {"doc_hash": "03b5e960e2d2dfa15be91952456ae9aa0df04d3d45eb31285ba711c1e4ed3ccc"}, "46d2a782-7f34-4aef-98fc-ff743ec222fe": {"doc_hash": "4e4b3d2cab2f1b3e915c8dbe35fbdda30f5bf3b5ea98b13df7f24937a8d7478d"}, "90dc78a7-b6be-44ba-845c-ca21caa823b6": {"doc_hash": "570186fe94ce17134fac42c76de48c5abe408b13151d60159fce2e47b6573091"}, "cf2bbd9d-e687-4783-b0aa-c88bc6397371": {"doc_hash": "570145c9a7f007b775ca5b3c643b27ea3000685cbc3488283d92e3c0538b06ad"}, "8ba5a3b1-4da3-4c53-ac08-91495941a71f": {"doc_hash": "f4af56523c13f5415c2c05112bed4d18c5eac1d003c3313125703a333f7f22e9"}, "a75e2298-df88-4941-8d34-0691ad651bc0": {"doc_hash": "74a686603f035e48ee8b52c7532ca66dfb520f8bcc3e51ce2148a767f2d88e3e"}, "f2fd141d-38b6-484f-960f-94ddf10c2f56": {"doc_hash": "d5dd10266bc7ac1e8aa3b9b4265b12465eb2489107227ace1fc6f2495fa8e1c8"}, "73488434-4930-4218-839d-c4a34182cdc2": {"doc_hash": "c134febea70ac70728405819bad182f5f25c1fb6525020a6826ad33ca7217a3b"}, "2d8ea8f5-b845-4068-9492-6ed19a23799c": {"doc_hash": "e4121612a8948504789cc5d6e687dfde6ff93562fe869a299211ac5df4d7098d"}, "fc9ad232-734b-41ed-b8b8-bd5bfdabf6d5": {"doc_hash": "032f63753e39e5ee8e622ac9d8c2a58e896b4f2f4802cf2c6268569e5ce9fbba"}, "badfca3b-6f23-4830-b7c3-274068dae3bc": {"doc_hash": "140fd8083ac707b2b81eafc2cce491d6a5ba26d7f9a40dcf0087249549c7ff2e"}, "9a1fdf7f-80fc-4698-a3c3-8d89fcc46a16": {"doc_hash": "cb47865de7393029d8b280360aa8cbd1878ad7877c9536dbb2ba76b4e503c9f2"}, "a26314d9-c4f7-4629-8720-c58d38fbab5f": {"doc_hash": "b4edda1e607a81968637cec0872206298613b66a2990e915229288586fb15018"}, "58a7d488-2645-4d12-9cf0-c9cd7475e999": {"doc_hash": "c9a941cfaca2a578af51cb2b6995f5fc3b79f463533e4b05300a21e72a95c766"}, "46b254de-3187-4f58-bcf3-6642f5c6aa04": {"doc_hash": "997171c5ee91b4e6d13ebf25629cdb9c36f38f006c782b2d55269653ad95e2ad"}, "e9a2baed-a16e-4158-b29c-c1019e425caf": {"doc_hash": "2cdc360d7961e40fa9e4958e4c0b59ab61d74a954e1ca5ff6b99fc896001d8d2"}, "7472e930-1480-4122-a4ff-327104fe4e92": {"doc_hash": "5796392b7cc6fee22ab3ef0e4ca018fc9850e87dc68937a54fbea222c1dbd9d6"}, "6eaf9f2d-1e5d-40d8-8280-3b79317f95ec": {"doc_hash": "7b5e100a03cc55e0bb62db776fdc46e44946762ddf4a2bff7578ff8ed112fb80"}, "e78e34d3-d4dc-47ca-b2ad-b15847c4e259": {"doc_hash": "9469671dcfa863c583ae12276cb448fe5e0f56ac7d5ac9132a7450e819b2a407"}, "ee2f7c6b-a025-4c13-9f86-ac5703ad0cee": {"doc_hash": "977dd3c87327c09febb6c1a23b11ed3ac9d8c82e0435334349d6d7c237802828"}, "5c611cb5-2b6a-4db5-96df-c1f1a34a56e8": {"doc_hash": "734bbecd5a4c79faacb5f9d2133247ce6da18c774a58a5544199151c094602b5"}, "06d61e52-6e86-4ac2-846a-4ed07a13593a": {"doc_hash": "bf98286659a252b784b480d2caa6d5792efee64198c22859b5e362a8380d3fb8"}, "73478bc4-1c2f-43d7-8ab6-51438cb824fd": {"doc_hash": "83ef3198ac31f2ebda3c1b5cf610830989c5d6073b700cfed608d98c6e29e06f"}, "434c4fce-ac6a-41bd-bd39-968e0c944ad1": {"doc_hash": "4c9139d413714f5d003251014061cf393f63e4f3e4b381a26c458d3718ad89dc"}, "dc1e515b-990c-4a75-9582-ec2bcdde3102": {"doc_hash": "f1d9cce02cc26c091ff0e5691a6576fe70514952b62929801dcb6dde70a5c1bf"}, "49fc0429-b09a-4c50-aa4f-3b0ab0276b36": {"doc_hash": "3b52cf0295e53583634459703c736f778866707abb4aec90aaae5c86adaf4093"}, "91d535ba-4e10-47e5-a233-2e359af83f7c": {"doc_hash": "e818a8937b739e7aa8b2093048d697a3c590db15106043fea4964b88064e6564"}, "7a30e3cb-cf53-4443-ba9d-922a08c22b2c": {"doc_hash": "0b462ec7295f846c41d3da9debc13a63518c85cf25cee128790bdc65c9df2bfa"}, "62a5a01a-f88f-4f0b-8c6a-c0d5a437c99c": {"doc_hash": "03ad3c54b28722470300cbebca8b01e97eb6b7197494cecf63f8c87816abfc3b"}, "5aa4957e-d08e-4a1a-bb66-7a1235faaecb": {"doc_hash": "2cad66da3bd4b9b3129a9593fc1cbf1d5215ae0d858f719d85e66da11bd649e6"}, "133f19a2-2277-4de2-97b6-9ebd272df02f": {"doc_hash": "39f453e3d5e42f54076784d153d343aaa0dcf9db86a2fc522352c3f3726cd64b"}, "413b2e84-bee2-4bdc-a817-1bb494debf9f": {"doc_hash": "26ffa3bdc06725de4fbf84143c8cd9f905091a89c565ce80aba43130dab5e696"}, "73aba02f-d110-49a3-a165-58191e42cf60": {"doc_hash": "efc62733e9ddf055758626bd28670761fb92e1947e554ad73c8e7e3018da2c55"}, "1d450dd1-4cd9-4887-9bbe-59b23e03cc7e": {"doc_hash": "39a424c78823af79a11bc2d6b7b2d12c6f3e0cb0379daef3c21769a396c9aa7a"}, "fd044a4f-fb88-48e2-af67-23ef5759798d": {"doc_hash": "1c32d6f23dc8d86f5df0e0e51b706ca87ce04761fc91d5670cb9678ab9a1b1da"}, "b4b52a8b-9f03-43f4-afef-051c965fe819": {"doc_hash": "b06f7920565a7cf16811e8daab190f1601c0bdeff2a4f411233720e3395e9c36"}, "97265181-2202-428f-915c-58e8d8e7985c": {"doc_hash": "412f6a3017412bf9e51d702ecd65a97fa30b36a8ec4766c47dcdc0fdef12fb10"}, "655925b4-fcb0-4054-bbe6-fa15a63be5ae": {"doc_hash": "0dee8a9c2fbb99ad8776844964ff5d073b73297f60ab84dce1ca6f3032869fbd"}, "d3629797-ef26-4310-a593-baa9553ea709": {"doc_hash": "337026c5ae1d7685bf860e6b06728d9ab54af28417ce1288a2c2bd3c33850313"}, "5a1d8454-b571-4741-9e20-d8db17748d56": {"doc_hash": "1c9331e4f16ac3bcf6004451bef67038e6b2c64296d5a7f29ee159bb1458e62d"}, "89206f4e-1f3d-4560-b86f-e7919533ec1f": {"doc_hash": "cfdc582b7dc1e9a141ac3ad958a8ad9f523480c973b0e2bedc6a0c80ec24bf67"}, "46024538-2902-48c2-be0c-7e605af14d68": {"doc_hash": "76542bcac7b9c19e77c0eda6126da1cac5880be723f6998e24d9875aa626736a"}, "3a86a7bf-5060-45d6-a2e7-567a2cf6a70e": {"doc_hash": "0d023172f2bfb2db60f114824827f242a3f1f902316d9d1a16cb2452496210d2"}, "849cdc2c-92a1-447e-92f5-811d90aa05d7": {"doc_hash": "ca47c767485bf054f3c20d8830113d2781d2676ab20fc7e806fc12eae883909e"}, "ca5b1d49-385e-4f85-ade1-0f15900a63eb": {"doc_hash": "2fd2413cd76cb66557ec0349555190032035b4d6de7969d0e923eb160f9f35d3"}, "890e256d-faa2-45a0-9afd-8d14090aca03": {"doc_hash": "357c18ca9412eb14c8353e062b3b8b5c07aa1e4d1ef13df3f9d77abc0fec85e0"}, "ef7d5c7b-70b4-4bc6-b7f0-5b8170f64593": {"doc_hash": "5537dc9d732b4973c5fb4b914da3e965f32ddf9583893dfa2eb33f6476c258f9"}, "704d61e8-16ec-4b8d-bd50-0f41c875f7d3": {"doc_hash": "f8e144a42e5fddf624b8e1b1da66c46f9cc55e598655a5d80dc5a00e49d3023a"}, "ad2cd4b7-686e-46c6-96c5-278508bb4e27": {"doc_hash": "5ac1562075b835edd8729a6142da1d272392c2b5f6cdae40fabd0797b242f8e9"}, "145bf9ea-bd38-4be9-8529-426120ee7e55": {"doc_hash": "94049d3ac1b7cbba825a8600e18306b08abb081b6406e2b70362944087d899a3"}, "1ccf5faa-e80a-49ad-a9db-dbd35603a999": {"doc_hash": "3839d5f73794da3c1c40c7e70b1d2a879fb1cf11164c16e27cbdb0cab83786a8"}, "9b15b938-07d6-4ad0-9663-c79169d40ba9": {"doc_hash": "b87ed439f6710682e81d4bb9ee8a46a89aa84fadd2c5b2c8f5b7cf7a1295fc6e"}, "9a62de42-46f5-4058-8608-d340f10d81d0": {"doc_hash": "645315ef0119091ae66f83deae67656a23d2dd3b663026b1c1b8f7a663428611"}, "42644151-95f5-4e6f-8ed3-ad52c00de26a": {"doc_hash": "f60ed213b4f9ba051eec793a5ef1712bb94fcb3f1c51f94b8c99627f51dc259b"}, "52b692c9-0491-4525-86bc-540affb584fa": {"doc_hash": "9d7447df42a42e9c99c7ef82f1f1cec669e03ab93c79166b9ad7ce6e767190ba"}, "a5da3c12-cefd-4820-9843-095e4b3f9174": {"doc_hash": "7f4eeb157b985377dcb91e5987b0cdbcca9ac6fc65a6e9eaa2d4eaba5911b583"}, "4c320d49-b781-44a0-bbd9-fb081f4766cd": {"doc_hash": "3c5f5670c61e42f016972cfd04f24b03c686030afd4087162a28de8a4de4a10c"}, "56b5413a-3aad-4e3b-8ef3-b0aed325dc2a": {"doc_hash": "10ea7fec615577ea7d60218c9e3b85634e513763445bb8836526b9c6153683da"}, "90f9b884-5c4c-4259-8bb2-2328115cd409": {"doc_hash": "20d64a70a79eb4546fcf741ec45187b9ff66d02b2a3c328ff7ce610ea14df400"}, "cc5d295c-481e-4981-a523-21bfc9e5fa72": {"doc_hash": "9413a948e283fa25b77e5ed302ae28500c8cff8bd083945441727db5b0af4dc2"}, "7b488069-ffd0-4979-8b3e-d6936284158c": {"doc_hash": "769bfe25043ae7868ded473d0cfb8f61e41fc02e63ab3b7bf0b70048b871616b"}, "e876464b-a92d-4655-a04e-0d795a6a5198": {"doc_hash": "1d5b255cdd64ca6c828dfb62b618f231465cb6197e868aeb59ba73f16aff26e4"}, "61da4309-2e75-423c-8f33-bd30fad41a1d": {"doc_hash": "91499743d44448771182e21257bc9257b5be34fdb0f38feb24067a82d84d154b"}, "27fd9ba2-9cc7-4831-b38e-d522e8e27d40": {"doc_hash": "9b4c376df22b53fccd981a237bbee834caea6933299cae9fb274b38e19ef617d"}, "d4d61a44-08e1-4f51-8ebe-d4193a502470": {"doc_hash": "6a506cc391b8580c07f7f45a0d08377f37c36d12c2bd851b2b42b2c89c937bd1"}, "11a87556-3692-425e-869c-7964c56a4c4a": {"doc_hash": "2ea91142ee3a3eb62efafeccaec02bc8617c006d81fa9417562fdbf26c3120ce"}, "01a4611c-8d60-4ce3-bc67-92061393b259": {"doc_hash": "92e5f913bd0ba268b465ffee1e203b85151ebf5160852c0caee9d54b1a7fcc4a"}, "56f8ae87-3588-4b30-a2a8-ae43836c7c97": {"doc_hash": "4e153e0a09377d5aa2a2120f7b7ee52da9319043af1fa86a14109096a66d3c82"}, "4543d55b-ecab-49e4-976b-47068e153f4e": {"doc_hash": "9f2833fdbe9fd251ca2c8c68798f69014139ee4182d669d7b2f033a9f32b59c7"}, "b854ca3a-6214-4037-a03d-98a5eb372199": {"doc_hash": "5887f81a37d20916e0053b4e08ae166770ced17bd7c5fe3abdc3816a5909a8d7"}, "a951a192-737f-428f-91e3-4da8fecb8207": {"doc_hash": "a9ee2d858a6d1c9de2e9c437fbe904868e2f0b32b1f4fc93cb30a575e637045d"}, "c1adedd3-3dd3-4dd0-9810-ed322bab345d": {"doc_hash": "7b5e2dbce9ed8695d2d850edd1b1e1280fa02d0eb18c75b17676b32b1c0a2eb7"}, "8ae4d3c8-cf5c-4b02-bcb4-a2da2ded5ccb": {"doc_hash": "aa1b633f5eac9ae2495aa0b2b4f1d3603c29082d14b934f721b2aa58301a44c2"}, "49eba7cf-fa70-4c19-b746-2e76da424040": {"doc_hash": "2311a9b0f2c147d3529f8d252652d6237126ac4d23cbac3f1c349eee39ea883e"}, "da1fc032-6a10-4ba5-8703-38e0e434fcb8": {"doc_hash": "55cdca023ba786b5274fd16f9df85a4f9ea6ac0874b1c661615b11b26c5e7221"}, "df6e6f8c-5a8d-40ab-a844-7bd97febe3ca": {"doc_hash": "946b490449c4bd402713bffed928976ea628e2811d8653da380cbe40799c4986"}, "bf25cf1a-001b-4fd5-8c2e-3d3a880c0f0b": {"doc_hash": "696b71dc515179083c29ff1692d09107a7c3e9f44631ce670b882ca8a6382891"}, "75ce63b5-a8c1-4833-b03b-7749d2f6446e": {"doc_hash": "410d7a13d4dfbabb5e50fdc08afa4b5933c4e021f67fcf09955465446edb44d2"}, "94ef656c-001b-4622-9ef4-f1f3112ce30a": {"doc_hash": "e08f88ac9b9b9f4e750644f4334f929d12093a41ab7a5d7dfb7efa761ebc7e14"}, "276b7a87-5c77-490c-88c5-662ab77c7739": {"doc_hash": "335407d0fbca436aac935ee96bea8d3bf25d15ce9cf0be7bb49e4901f0b0071e"}, "f5d7a1e7-7d0d-4003-8fdc-dfde908e7eaa": {"doc_hash": "0df108975609955f67070c963fa8bd0405b865c30aefd9a1df6213b6b7ce2298"}, "047015f3-bbb7-4810-82d2-00182ca2bb4e": {"doc_hash": "7bb8989ad70c962cb32cfdf5621107f3cbf836a652d54dc6f37483a384d2f6e0"}, "fd7d7be9-3312-4811-bfea-33a94c3efea3": {"doc_hash": "6eb5308d6844a4a36b542b91eb4181b50e5bfab0feba078c9c14f898f1d71537"}, "da16f4c3-0f7f-4561-b8d6-4c1ca5dba149": {"doc_hash": "e8b83554e241c3ddbf4851a2f9c5f36915da24a61d84b36bc41fa9832729ce8d"}, "9001d674-842a-4670-91bb-2dd8d45a0284": {"doc_hash": "46555677e053827a6b0b1e0d04ddce7363907843360bb85fa903af7b85c47731"}, "601760b6-cab2-4438-9ebd-c5db34c64eeb": {"doc_hash": "238541530d7bebb189ba10c4696015575060ef8b9daf310dca33ce94921d3b5b"}, "bb64ea57-bd9d-49c4-8f02-12c2e8d6747e": {"doc_hash": "768e59b33c4ac09bbcf138e686217780cccc8ef45bda4b87bdbef4b866451071"}, "59a04634-8fa5-4ef0-85d1-4188055bc5e2": {"doc_hash": "d6466d88f139412655241cf88f885ebba1d8f8e63898120b77e0e47728f39dcb"}, "cfbd397a-82e7-45a6-87d2-e91e88259d51": {"doc_hash": "7453b762d9c9676d04f12da6984528fdd2e656579873c8eae7e5296271653cef"}, "cf087e60-596b-457d-ae74-e17036c49961": {"doc_hash": "7479a030a72310a33994e09da4940edcb5f5a96f449cb979567e954457fa6da3"}, "e053c873-b43e-4b4e-8506-b8786504f608": {"doc_hash": "f749e9a87776222bb4f04bb0fd470ae3afb277f5b41a7c67bd2efd39cbc81a3d"}, "5d533c52-3b66-47da-bf53-43cd16ea65dd": {"doc_hash": "d5377a4fe71e353dc7438f1bb556035f9be1971dc2a9e3b3dc934751b43ef45c"}, "4afbbc40-ac79-4467-b845-a96a319782c5": {"doc_hash": "d5221ba8e624ee4bdcb46f40ff1f550db4674475a2586614cd08ea08826dca18"}, "3ebaa7d7-81f8-4273-82c7-b2f975c3b027": {"doc_hash": "69f535e3a8184a05bdb81ab86379f7c154be78a3ffb663dc952cc415364c36e4"}, "42d91795-6991-4ed1-b71a-fddfb5162f53": {"doc_hash": "5e4ac1dc422aa0a74eaaf86628da944879a8c3bf58b7e9e347efd7eaa1dbf3ae"}, "8ef22460-9569-4e31-a62f-57039b3ab45f": {"doc_hash": "986bc9c9bbd2af9f8ef309bab6cc0a3e6bae74eef16552d401d71b1a7caab4ea"}, "9ac4f0cd-4510-4838-97d0-1825a73b455f": {"doc_hash": "4797c2fea5ad7d5d0a256e13d8f61d00241511c963834758eac8373f7d88bcdd"}, "099c0fde-afc9-4757-b452-98bd77c8ee24": {"doc_hash": "7593aeccf897cae6b994e7c69bf6133e8e5bcab055e5fd5d4a4b5e3d86e55d03"}, "d3a0e19d-b350-4df0-b41c-2da3d94f9102": {"doc_hash": "7e852f96c2d709be4fcb445fa4a63ceff89ae9f442ca07ee67155cc7fb6128d5"}, "1e34e8c3-1add-41b2-87aa-7cc98e47191c": {"doc_hash": "afeb9452f0e5f603386771866a77918d438a66f090f8011db7f6c0d56cada477"}, "95cac827-53ca-4e9d-b9e8-e39a41290010": {"doc_hash": "ba40ae392ed40f2fb0194844e5525ddb9e5704077a2045ede50eb2a4ec9f4706"}, "485f11b9-7bdd-49a4-8c0d-a6de84f1b298": {"doc_hash": "549e1c7b2ec4008932404b12bceb3a517fc825e9cf76c1900d219e8a0f662e26"}, "d9ec12a4-5aab-46e7-bbd0-2fb793bbdf1e": {"doc_hash": "e7a46ced57f08d87cb77f8a3c34a7d056a53fea73a8ae8bde5f00a750965d41f"}, "a3a83ad9-c0e5-41c9-85c2-2ce8da7a35a6": {"doc_hash": "184afa2e9f3768a2c79038687e4888b3e63abcfe20702607f44eb5c1cd4e7b54"}, "e8adb925-4bbe-499b-848e-3aaa84bdc0f6": {"doc_hash": "796260931b3f261d5147b19b102482d0a89fbaf13d9813a0a26918a42cf73968"}, "88186046-2f14-4193-801f-62c1610a0831": {"doc_hash": "2f21dd3d6722d0a450751772a969e62170268017cb56bf1f4b42e60b46912c5b"}, "9c1c62de-0914-48fd-8a74-5322d395a967": {"doc_hash": "630023a6e4f131fdea7c54ffb6feffd33c3c5feaeb0bbab4608f8eda626b0f97"}, "e7d15af7-f384-44d7-a6af-63138b0acb64": {"doc_hash": "c026eb757beb61f09959fa345c2cc7b8127c4faf5f75ce9c311cb63ebefbc9ff"}, "4252ff8b-69c8-498a-8fd2-00cedc96d2c2": {"doc_hash": "e8f615a450ed12324d17a28772de52b7c31f1a26d82b3b8824069f8f47869d86"}, "b0bd8c6a-5162-4f13-b824-e9c9b3e04435": {"doc_hash": "3a6f93d76eb5c34b9eaf673be9c4ac124e96450a7a8a3fb122f09c24549fc8b4"}, "2e0a495a-e4d8-4d5d-8e28-a394f2674e23": {"doc_hash": "404f78042c72c68a0e7536bfe1715de0c6615d68479a14090b9ae8754cd33064"}, "895db094-7bc9-41ab-b9a5-7df9ebe2ef86": {"doc_hash": "6821676b8e0ff46fc36fed20b5d835717765c2d2bb09c18c02cab555df107050"}, "a652d009-6e8e-4c35-b04f-c2f609e05270": {"doc_hash": "b67b4b11613daba6152da428b61908233675a1f0df20028aae160918af8c4169"}, "8e1a7291-61b8-41fd-b9f0-c596dca14cfa": {"doc_hash": "c188b35cf8821d11331b8279f144ac8923a9e0a886d59aafbc5df296e2254a45"}, "ebe07a89-1b27-4c43-8de5-c2ced123c616": {"doc_hash": "35beeea0aadf723e966d3fa135d51d05233fb06a0aebe928b568408857d03402"}, "8c832c06-b34d-4d8a-ae08-47c80f6b3338": {"doc_hash": "cd299d1e514ec5e9e6b97c99beaa8cebff84babc76be7dc198286e640e04c5d9"}, "1f0aa7b4-fd65-4088-ad29-72d20ef68132": {"doc_hash": "345c1eb01a37dd1cf4b7207d5ba20b2499dbdede59d880383bab261ad120f4bf"}, "e6af6716-5c31-468b-80e3-1654459b527a": {"doc_hash": "561cc2cc3d618cc043159c482341efa26219a6d41802fd6cec2f119d4e99c307"}, "0481642f-3849-44f8-8eb2-592e12506acd": {"doc_hash": "d3181c76ef8fab87c4a6c1376b21a7490b8c65a79959613c12fb876a1505b6a8"}, "9a62d6f7-34ee-40b5-ba4e-cd5e8399dba8": {"doc_hash": "2398f205d68dc61dc90c9e28c1370dc866bbedb9a8be4ce9d997931b09536702"}, "3f10434d-6d77-4b4d-9aa9-eb4c88694ddf": {"doc_hash": "d72f41fe751b08c057adaf5ba1bb4c8a3b5ce1df9fb930c74e351c6b28962da0"}, "8d958897-0bad-40dd-a1e8-1210016a3a9c": {"doc_hash": "ee21f5ec893353c1555510e256e3637c97c1725955c5f6e4893a62298572df98"}, "47247f16-8589-49f1-9959-602e9f9fc179": {"doc_hash": "cb3a54214ddf5a213e50cea67a6ff302870f99d65b6b304e3a00d2c2a40b6896"}, "95a57764-0915-4b4f-9824-2b9f570903a5": {"doc_hash": "1671f5d75313dfb75032931a43d920cc559103c0027d191bb1f08041d46ec8b0"}, "a4261f44-e4cd-46b8-b24d-dd8ef8bc60bf": {"doc_hash": "60e4405d9eca86ab7f3deba709afbf0e05732764ac95924f1b90729ef4e6e584"}, "6ea95163-09e6-484e-a46d-2734fc121709": {"doc_hash": "19daa3ac7f155e79d3472d104bfac884b5b50448372202b67689522cde717a3a"}, "00434ed3-00ad-44f1-858a-11542574fb52": {"doc_hash": "cca1195795aa0275a0f7ff5577d2c49bf493ebf2fe909cf3d8a13d6630e5ebcf"}, "9d88c518-b8b3-4883-b501-4a0644aec170": {"doc_hash": "f7410c60093a013f1f59529e1ec2fc3d86a29209d0889dcd08ade5e3be99bb59"}, "8e0f801f-634c-4ba3-8014-8e13fcac0f9c": {"doc_hash": "b2df0a3373538402f2ae22aea65c283955c8e556f222a172615265608563e22a"}, "1bfdd6d3-8edf-433c-b36d-a10b6fa38249": {"doc_hash": "d1924090e64b4457743c012ffd049c1325d11de19d335e9592dc364211a44bdd"}, "3b610170-ef75-4aad-9d59-185865c4af1b": {"doc_hash": "5551ca37f2cd46d5f75e432e080bd029a7b12f616580f58ceb90ec2c428a9bf4"}, "c286eb77-ddb8-41f3-a9cb-1e629d0f58c1": {"doc_hash": "7c94df1881d9003b07fb1bc1bca1503daed9df21b63076bb29ca092b08abaed8"}, "1de42d96-edcb-4b76-b656-759556741c2d": {"doc_hash": "c7dbef35ed37c3e1d9c235e568f2c068cae305bdec97edc037488c038db16cc7"}, "77e21318-de82-4aad-8e66-b8f3eda13674": {"doc_hash": "e606f00ac5717036074142bcb32c8af775ec591c9fdf3cf98b81213beddd8b51"}, "3815c333-bf82-48ec-a322-bd701e852689": {"doc_hash": "778239e547a151d6e1de8dd00ba628c45dbc2f9af3dfa90501ff9c19b7b70b85"}, "36614cf7-3135-4930-8386-4c1b311fa7d3": {"doc_hash": "ced59ee7921863c612835cf79b29b3cfd7aa8d751272e37ba5b228ca2c6fbf74"}, "0d7e9987-a2e3-40d7-bb22-c67dc07e3d2a": {"doc_hash": "f8ba28ee90fb3feea55f6d0335b3a22e5b9fed13ec5215ca283f7555f861a765"}, "49467157-d072-4769-a7f0-88a20209fa62": {"doc_hash": "414263626be3eb80fb9c1eaaf3e5c3bcdb025a168704fd5cfdb59795f1f52993"}, "005829e2-dc17-460d-8384-923caa055421": {"doc_hash": "1ad9cf578a38dacac778ea6fca287bf29e988e1749a312bb595808a994f22ae0"}, "b5e2eb9c-6674-47f8-ba37-ccf4360865c0": {"doc_hash": "719f51fbcedfc0617bc67a83e64fb5f2abbb97c4a69a72e5f5022b1f9230e868"}, "21035f52-4491-4b4b-a068-5bdcefff2532": {"doc_hash": "852f28bdb62e1450ff03a3ef2d50d8c577e22b315fdd0ce165f9ab44c4cc4c70"}, "c62f6a66-ac2b-4a4d-a1e6-e52b4bf73e50": {"doc_hash": "6548b85745735eca918566844dd89fe3084611922007efb979ab75db87561107"}, "7d12f870-885d-4f1a-85c1-79df89e787c2": {"doc_hash": "094bd0eaaf3dbebd5fd7e3cd4bcdac9d02f503adb395b5fb550ed59f442d8044"}, "0d29e8ef-8703-46a9-8e56-31bce62649c3": {"doc_hash": "71d02299aebdd3b73d3c7427209c80670f2deb797c52cebfbbf40cf7224259f1"}, "cd00d081-72da-4fba-80b4-2187ea581aea": {"doc_hash": "c599e47a8dc435526bb98509a78a2df85956b2be46ade3ad79d0038725d71032"}, "fa73bef8-f1dd-47d8-90c2-e4c2b904649f": {"doc_hash": "3390dccca6434aad809d7e35763df7b138913046d203f793c5a91856412bfaa4"}, "b0745ae3-d77e-4239-8458-db638932f8e9": {"doc_hash": "e1683e8820b021954663324a629b5ce4a7767f5bdfe360286081092d2b44f025"}, "5b59a6b6-c876-4fed-b14b-2a08ad755686": {"doc_hash": "24fd7fa75b12f40df292ad7d69c40fc10852d06bfc591948fabb4aaa1ca4f5ca"}, "059c7af9-2d3d-4e7b-aa49-12758431e88d": {"doc_hash": "21567a7604925438c90c38ece2a3c57d9c7fadcaef404d1ed7447a929f5075c4"}, "a74bc16d-db74-45cc-8dd7-0e2e1146e34a": {"doc_hash": "e78dcdbf248a676e0cb8e082506394f8d245aaabc325c28ffec522f0d0d3a43d"}, "05e96bc0-9cab-407d-9fa0-22545bb7631e": {"doc_hash": "41814ae73ed4dbe348a515a2bdefd2a81ff3d275a88992d8a8c067ed91d574f8"}, "7bf03655-62db-4115-b539-4b32dee0480f": {"doc_hash": "ff770e00fb2fbec35b487b4741a4f2cef84205c2b7cd2a3090fe39509321ab4d"}, "43f7fbc8-ee6c-47f7-8431-261b9bf73d71": {"doc_hash": "2fb2a149b0d90cb14461bc21557706676cba20326e0772963dca652e806de7c9"}, "92b2a89b-c831-4d28-a426-2020333bedff": {"doc_hash": "fcac0397f6461e28ef6d1f40db5e451e01a6ef9cfd44c99f2d256818ea6bed27"}, "573e6b23-1ec1-4382-aab8-97105ecb392b": {"doc_hash": "fcb72edee3cb52cac4c9a774575706d29ac2da67b15899a9fc6d9cfeda21e01e"}, "99f98855-6912-4860-92f1-e9ced9713b1b": {"doc_hash": "3a7a0d8bb82784b7518e7708f4c68e066bc11b8e75e43f1f15c7c30464e7c008"}, "b03af0db-db8a-45f1-955b-b50405bc530c": {"doc_hash": "4fbc09b71e3cf4f54eeedfe99d40842e8560e6a1aa65b241003e638bd9580b7d"}, "a6ddbe78-8c66-4b99-8f26-f147ceb9360b": {"doc_hash": "f671b3d4f3bd1444e6f7fe02b4bb2579b3cef4654e213e3ba73b6e3074f084c2"}, "273d6719-1355-4b83-947b-26128dc77d67": {"doc_hash": "44d262a5a541458b785a2ef7a46279e9f30d19c3899ff6592acabf2bcd312e65"}, "ca097ea6-c6a6-44d8-8898-79a471e99efd": {"doc_hash": "fda5a333a105c3ef730defbe34533c932b27794baa8b5426200001e3e6a718e9"}, "75deb755-9a66-4614-81b0-51dea63714c6": {"doc_hash": "88ea35f9d6f11c6ec81803a0cac4b910bfd901bd5ebcb255987bb792e7b7fd39"}, "4296237c-de48-42f1-9d56-131b5e5069fe": {"doc_hash": "1515095f14f5bb7e533ea29bb099973f52004e99444ea87b648bcbf53c01dcaf"}, "51cc7534-84e4-496a-8c2a-e1d9e5734e9c": {"doc_hash": "e84d2ed9c3e7e93db22cbb59af2bce5dfddf2d578c3a6d882e33ef2a53ed949b"}, "363ff23e-6f93-4a30-9e49-5550ef79b0ee": {"doc_hash": "6a35bfb923af9c5877079fb51eac49412c04713c1c8d59b9e97a5ff1df287190"}, "e6076e74-e729-40a7-b572-23481fec1f20": {"doc_hash": "f9d5874da4cd3eb58ab3a5353e010ba020371dacd19bd5a03d6033d189ee780d"}, "957adf60-7664-4594-95e6-be32fb2fab6f": {"doc_hash": "e345800368a30ff3ecd8ef10069eb68a2091734803a6a4930dc3331812b25786"}, "1a334e0c-3c4e-461f-8fba-fabb92bd9b35": {"doc_hash": "b9de7334b427914cb1fdca32fc097cdd5d3c36e6b2f538fa74e00dd0b2265d71"}, "f35676ad-b0f1-4f1c-ac64-79084cdd0e3a": {"doc_hash": "49f1e6435a0477ee68aa8a48be0196d7003afd4c97a3a3690b67fe4d56c7d917"}, "bd31b1a6-96e1-4d8e-b2c7-f8ba1d5391ad": {"doc_hash": "432d789a7101a993a6e99030ffbaea85e626e4aedeeecac74aceeec8eaca1c40"}, "20cd8e76-b65b-4706-9b60-3b15ab0e48d8": {"doc_hash": "729d84084f74d3dde77340b2c41e4289726e3250e4addc49b2ba1e10433842e6"}, "1c882041-a8fc-4a35-8799-55d08a4e3c4b": {"doc_hash": "d5be37da17db6cf1735540e7ec26fbfdff07bfdda90635a81d73ad1ab52328b3"}, "a67effab-4441-4753-ab89-733a6c1b3c2c": {"doc_hash": "515cad551fc4a7f5d14b39f2ff8ff7dc1bcab986495b91f82ef07a899b1b6a0b"}, "70f33f55-233a-47fa-9690-072457f46a9b": {"doc_hash": "ef8decd5435f411411892efb2bd593dbac10c4f155ace6b5b03293f3807b7361"}, "c2d64453-8fbe-4c45-9774-fd3d5fe76de9": {"doc_hash": "0556fbfbdaf49c737502995de2741a83ca991d32ff975106afd6c5c9b6dc92c9"}, "253fd818-3eb4-4122-b8c6-85a22cc23498": {"doc_hash": "f0e22dad3c46200d2337591400371b955db31f89abcfb3c6869a8f893ea89398"}, "be234742-fa94-496f-b6fc-7b4a6d29a44b": {"doc_hash": "9d9b85daef24e4e5ed6f53277974752e310b064a91ffc80341d67ca7f94c7d5d"}, "7b3067e7-0ba9-4a9f-8493-5e670de80bd1": {"doc_hash": "ce9cc1aafb401dab34be4b4e15bf7b6a75566ec91b9ae14fb3b5e678f49c3d82"}, "d66095f0-2e6f-410e-8af8-2f0521639be2": {"doc_hash": "bc0cd2116cc5221a45ef0512437c1ffa33f2b2c5156ef01c82f847de5e1797b8"}, "817c9c4d-02f7-460e-81d6-f453ae0cad65": {"doc_hash": "bf0cf53685a42beded5ae0f5e20b05dc66ebbc7384341ea90b3bafb91285627e"}, "0d3df119-995e-4cfe-b023-6e1b6da8cc5f": {"doc_hash": "657fdfd1a6dbade8c4696bc595296ce0fb716050627f330ba010eb28ff9f8f4a"}, "2b1d89a6-3bc6-4062-bc75-68232a5ad87f": {"doc_hash": "80c7727bb011cf3a32c225cec57122a0b46b1c263a54f97dcbbc0cbdc9cf0990"}, "a69ce5c7-3d27-42ea-a9f2-cc97879321b2": {"doc_hash": "b89fdf5366847f2eb1ee3fc960e9b1f80a5bc9426936c71b5edbf5c3448d2fc9"}, "d08bdf9b-2458-4520-8fd4-96b5f367b9dc": {"doc_hash": "8742affb9eac5822bdb2cb495bc565a0ee0a1b615c4ef81e3834054595331b2f"}, "c68b3f8f-4541-4dc0-b3d2-805d624b6274": {"doc_hash": "de93dd864076b8edf60ba75e8e4f99a510f57e43790b09fc559995211ea3b2db"}, "1ba8e81a-5d85-4f1e-a256-f8ab38a494f5": {"doc_hash": "ab031736951de6ea77237de9c9676a3223455566280c3bcd26a6738b72924a29"}, "6805b77a-278e-499e-b483-c21227b59e5d": {"doc_hash": "0f37282a676cd99fade3965c85b581cfb522bf8929d18c85a617c7c15f26464b"}, "346eac7f-1350-4934-a76b-95cdbf3b1d3d": {"doc_hash": "d00dd6951039b83c0f2593b510460bfa54aa3fa444214c7bb6266a948cd162f6"}, "324695a1-07b2-4d4f-9581-cfcf72d1b4fb": {"doc_hash": "f114371d820eca48bc1898324741196272a3e91436f741c025f71b66367ff433"}, "a4c1db42-664b-46cb-908f-c69ad36b525e": {"doc_hash": "400e1fc67bb5eda1c1438a621fce11694203704f7d306d621bc9afbf968dd5c6"}, "a3dd14a6-f8c2-492d-8e2d-5f15e71095f1": {"doc_hash": "cf56d9bed9d1ced784a4e83bfc9309eeb316e87b61f1036a7c5a662e958d9a9c"}, "aeabc1a8-cbfd-4060-8276-f5ac6a65bdb2": {"doc_hash": "e6c6199f4d56defa583f849d60540d33c85a36e14ea761c2fcc6d79117ee520e"}, "fce5b89a-7f81-4f6f-bb87-21fcde963285": {"doc_hash": "ce18ae67d35986daa8426e49c1e740526473c56a6d4e22d957172d340016d98c"}, "fe533649-7236-4575-b4eb-37d837a45005": {"doc_hash": "4e9c73e195f6b0e1334786b85355ae039f2c6b7de493132a7ca71b1d934f9dff"}, "40c48541-8379-4d7c-96db-254470a923bb": {"doc_hash": "a8ece123bdcefdd694e5e77000a869a3993045f7b0ad837175f96cfd756e8495"}, "07cc4278-ad98-45cb-880f-969e75a9ccfa": {"doc_hash": "474d19dc2e338f56ff326b0504b2ec9e18e8e7c60759304143cb2e43883f2bc4"}, "6ab38410-4630-4994-8c0d-ed56a8813a60": {"doc_hash": "908ba170ab9d57fa91e5cda000a34e5172d25a79551303d11d399dcb96ac86c7"}, "47824ebc-41f3-4338-893c-9039cec34da3": {"doc_hash": "4d0011387ab2ceb0df5354afb2f0211364afc5b7e1ac7d2a365c8bcbb02443d4"}, "cf13279b-6823-45e5-be38-0e84a5a242cc": {"doc_hash": "f5e9df4a39ad76667be6706f95d9536a843915aff01822d7777a22b98a6b79cc"}, "dae5d9a2-ff2b-4095-9b9d-74611c78fd48": {"doc_hash": "15dcd23c24fe12cad7e86efd15681515161cc2675cc5109540d463367b198c72"}, "97d09484-4b26-4261-96a2-82e5320385c2": {"doc_hash": "dcaafae234fe5cc4292397a887f0c14447cd2226820ca6c67cf670f83ddf018b"}, "4c8ac1bc-2d1f-47cb-868e-c1f49156a661": {"doc_hash": "36b4c60cb1069f99669555cf8277ae36dd877a5e8c14ab7555b28cd00efca906"}, "53d87b73-c72b-4b9c-a714-531b0b338c1e": {"doc_hash": "4f17b908c0f83e18183034388992db46fcbe3fe49cac77cbe44e13038455a673"}, "751b6f78-ddd6-4bd2-ae75-ac7f0e7f8ecc": {"doc_hash": "76f6a4e366f654edc47005941e5e4e4c77e47f7ece141216d7a3c1adf732ad3d"}, "d40a95d7-7a4d-4cd8-84ad-15292b2a6bce": {"doc_hash": "608e3c64031726ce97199ddd1965c92b15cd28133b69be7afc62828b89493796"}, "fbdce1af-d079-47bf-8f69-e7bd81f0ec80": {"doc_hash": "5c77a4dc3fd735b1bce4eab789d5f7b6e0a93745522007f0be85b2bb090f308b"}, "2760f4fc-33e0-4a06-863b-068adce24da4": {"doc_hash": "8ac4ba3152dc9ec8d747346afa2cd9e60c86ad8a0f7df9d67c65f585a22cad36"}, "54be066c-a795-4ae0-a82a-89d3a528c4e8": {"doc_hash": "3c04db5e86385354adebbf4fb0863b38bcb6bbdc0b49433b34531f9a27a92bc2"}, "d6f5b857-d818-40ee-9dd2-3140f27f005e": {"doc_hash": "6713d692580fee1e627aa1a32913cdbb3e65ccb76ffc7da2fe07ec91cd6b9dc9"}, "18a3a66b-e8b3-4518-ad72-9ead47fd4ddc": {"doc_hash": "c40d76a91450406659915b3fcfbfc3709d5ccceb52b6644fc1f7fca0d97444fb"}, "bb7812db-1568-4fe8-9a2f-c215eb666b53": {"doc_hash": "23046fcc8571a08d6897549a9180523ac413c992111535f9a466739c64a70a61"}, "bb49b041-d3ec-4e2b-804d-ba5e639b9e02": {"doc_hash": "2ddf18c3f4a664ab0204a52edb8f265a009084a66029183aa520e7a1b570c8d8"}, "e7e4d2d5-be2c-4c58-9aee-3bbc9e602d70": {"doc_hash": "4541070f003410491bc2a5cfcd39b7b057c848ba0b5fdbe4f227310ee2c4fc03"}, "3c16b5bd-3435-419b-8905-fda941c1e035": {"doc_hash": "6cd9a9fd166a8d50b89415e30e1c9e021ebc4ddbabf7f2fd80a1a5bef8e5fc31"}, "60b0dddc-6e5e-41de-ae6e-395aa8624452": {"doc_hash": "e95380bba5a12dbf2e57d5b0d8aef6ea75c1cb89ebe60a1e596e247bc111d702"}, "c7239741-f23f-44d4-b398-563137108b93": {"doc_hash": "a5fc24a5017cdb645287c5570b4d50fff31ce14380c415e14d45f37acaf22cb3"}, "7caa0d96-ed0e-4ad6-b8dd-9cb816d96d8e": {"doc_hash": "41ca1206e090adde28d150c611f024d53f2bc94180aef6ea9dca52bddaeda473"}, "db81b2d5-1eb0-4608-b907-2ec4ca837353": {"doc_hash": "aaa5bb795010a2f2ba3b379a1c4aa014e253aeaecb6c77b54f10967d23dd87a7"}, "77c38ce9-cd84-4f0b-ad4c-0d81c62224e8": {"doc_hash": "8a211bdc95aa27acf22645376097f0284246ed226f2335b7169c36b0bc5b8a75"}, "4fb8d204-4613-4669-847b-d907cbc0d958": {"doc_hash": "4df047b60f4a4474af08e6b4e72f79f3d5982d22f8b7d4ce618b598094c58c8e"}, "8e005cb3-2ab1-4f10-b2d4-c2832730fb91": {"doc_hash": "c2de633713cc1f265870cee82a945cb74cb28cf6e6902dd6bedfc417cab410a2"}, "40b31ffa-a2db-495a-810e-6de7a42d74f4": {"doc_hash": "126bb845c93d6b82b6d3adfac8f4983e443385afeac97e12e0295e79276e8f72"}, "5040c277-1bc3-491b-9439-34de1c277722": {"doc_hash": "384f8f332ad81d344af3c28b257dbdbbea4cfa84c466e530b9f962b1ba315165"}, "44173407-ed7a-4c00-b19d-435a1da17ce6": {"doc_hash": "af22c98f944675e32b3eb61d652264ddf3a8a8360684508150f4b0c91156e498"}, "4872ce10-7924-4819-b8a4-51d0f4d227ef": {"doc_hash": "dbd74971bff7f946ddaecb81131a0f37de0cfd37fc90c2d1d5fcf9521514a242"}, "cb44dd25-dbf3-4e59-aff1-e99f493df7d8": {"doc_hash": "4aa5250c0b8cd1e4398f1c3c8fdba3562a9aa71989fc2a6bf47f029987c7223d"}, "9b8f31ab-4d81-4c9a-8390-3470ad7c35bc": {"doc_hash": "c4bda79ce9cea7e2051074a7c2d53d81285a062ecf8a92cca59f62d9f7619ec0"}, "6e82a88b-42da-4ac7-ac69-3b88b9b03639": {"doc_hash": "ea10a8420ccaa7109adcd2c37962df10e87b44f5261cae098f3a5219d9e989c0"}, "ce91d630-2192-47ea-93bc-ef8762671e24": {"doc_hash": "9c245316ad4fa197569263b0a5a43eaa39f490725e00d2d4ad08d8a61dd5f34d"}, "24b67a22-fa47-467b-968f-eff0e9326b69": {"doc_hash": "6f5bcb23e19d4c892762d37012751b0155e96fd2bfa9d4de5b71c0ba85fb738c"}, "e74a262e-b527-475a-b425-7f2bf053045a": {"doc_hash": "b4a79ec28ee08fdad7c40d8fb6b2c67fe65892703eb91e517ce289b567d25087"}, "6bfedf5e-d97b-4485-9997-9003f9fd3fc9": {"doc_hash": "cd9d6a7f45cdc7de1a9bf037ace85eaed023b7679fbe75655d5059ef5c53f890"}, "b542b99b-cbad-4c8e-8dd2-bbe6aa250dff": {"doc_hash": "4768339c223d02e9fe77fd3f0253749683e1ec10e5190d91eea05e5cd8f4daff"}, "fe891f37-2aa4-447d-bc1e-fa400f57d707": {"doc_hash": "472f90119c40450dcb7d9da5d8f89203410ecd0d4f9989df9f1a39fa50084f04"}, "9447130e-1fd4-4f47-a259-68c364460863": {"doc_hash": "b8bca58aa4d280ac645d1643bb70f808ee4fbdbef9d3140b6bb998ee516739d8"}, "f7f940be-22d9-4af0-bcd7-a39c94009003": {"doc_hash": "899ac96db472700130bd27d07ab66c12ac7f178d3c00acfaca9750808db836ce"}, "3805fbaf-9e0a-44c6-b113-84690771616c": {"doc_hash": "6447d826bb8c5d366d28b78c5738e23c9d6c889473124d80157ebea6c3fc9f8c"}, "ff389065-88f5-4f16-ae68-a97c20e9ddf3": {"doc_hash": "967cf76ffbded36b42db78b48d741fcb8d98f2f759d73e3adab6f798490b58ba"}, "50fd5f36-b74f-45a0-a322-ce8c6d924094": {"doc_hash": "dff9cae3d731af6020546f40f369066447c02a959ca2bbe7ce453af0aa54d517"}, "d254ab76-27dc-4207-ad29-4d1191e92e77": {"doc_hash": "dd2634bbe812132905940e994fe73b017f6324431094e55c6a4315fbf608c4a0"}, "5ccac207-cbe8-44e9-91bc-d43eaf85aefc": {"doc_hash": "4b92adfd24d94f09040464623d8e0019ca1b1d737d6e631d3666a321af720fbd"}, "6c7463d2-3f10-4b15-8fa5-be58bc68f73c": {"doc_hash": "18e3c47813bd94a1953c9ad13d6b083e4b2b64cb551c7883e884a2ce51e29661"}, "73ddd92d-c486-4cb5-bcb1-1aa09fe4c348": {"doc_hash": "5c87b6f5d8da6cf8a80c0d2f0b3e0b3df57b0e1fb9520c3d71ccd808d4ed408d"}, "bef9d1a0-9e79-4fb8-afa5-56ea8786e0a6": {"doc_hash": "54faa4541e1ab7260161796bb03e9e199b55306abdbe6f831617e41a5f0529b8"}, "29f3208b-60e1-43e3-8854-91a225ef8e83": {"doc_hash": "aaf97f0b3c81eca3d1225c75baa754a4b5ec7b6d78b3c1cc65199d9cd8e9da3f"}, "57ceb1cf-a5ca-4610-9d08-734e828a2f79": {"doc_hash": "8a6706b449610d5c01922706018005de07352efe18d02e02c30e50c214b5447e"}, "17a96da8-542b-4714-bd4b-960bacb895d3": {"doc_hash": "750736f0e8f039c3154e529c8d0727c37f2ca33d2b5556619088893a74f5a0f1"}, "34351da4-2377-43b9-aa9e-3e9291e9d836": {"doc_hash": "e1904fece7d236c590872d5f4caf6f73f747fadcf1c6f015bb388819810234d6"}, "6dcfbce0-7ff5-4fa8-baba-bb44d28f5de5": {"doc_hash": "af9043012b6dad5cf18c99aa042b02e0789e1627ac96c179d20b39f0b97aaad5"}, "045547f4-52d3-4b41-aaaa-18bde8aa8871": {"doc_hash": "a0e7fdcd558a6919234bd2ac9ba466d6c6b3dce011df030857e77301faaab973"}, "1e0608d2-0744-496f-8b9a-472890556b52": {"doc_hash": "53e2d0a5ad5f08db88d0509e7d3958893175802b3a3d70fb5f71b2030c9f4275"}, "aec881a5-658e-4fbf-b3a8-bae19f1a1b4a": {"doc_hash": "9c089d9ae8d6593381bacad5b000618cac5b42a0afe398772a618c7f40e0c68c"}, "bb7ff2b2-0e88-494e-84bf-8382886ba499": {"doc_hash": "037060e794338b9936c3272705969163c92c804155b5285c6b29c6e06d07f94f"}, "e29ccfda-4f98-46ae-a990-6842e70fcbeb": {"doc_hash": "ac4d48713db74a54dbb1e68b935b52a9780ce88bf731e58b3e2904f7a335d3e6"}, "8645c399-f4ff-4ab5-b61b-2d2c312b517d": {"doc_hash": "900cf9c1444aac5f75769c86b38b92426cc788444ea7715ab17161de2c01d750"}, "d841d29b-5244-4809-9a9a-c2defff22dfc": {"doc_hash": "cb6533a88a97637b47a900798946e4659866f3e77350dbb1e32ca25ba7a31f4f"}, "01dc2481-3feb-4e7f-84fa-1e46688fc63a": {"doc_hash": "840ee51a0d1f726145dcdff90e81868475941fdda5e3380bdd61030d8f5b5c8e"}, "d4884c0c-ee04-4dc6-9d01-57f901518ac2": {"doc_hash": "4fd162d2a5a3f5c65f63cfc45619a9847d701f5a611d9d376bda3135c511aef7"}, "ff5b03d4-c1ec-463f-a7af-04f0514c102a": {"doc_hash": "3af6c925fde5cb4641c6eb23aede2f3807bca06bd9de968dd0cece42c8839b0b"}, "ef69dd37-6b04-4878-828d-757f6a7ce9c5": {"doc_hash": "60281c91cb99f3c7f197194592a623d6d23de5d7a70bcd8db7511e22fe510418"}, "c3d06f35-73bf-46fb-9f60-3d9cfe0f150b": {"doc_hash": "73cc11b93aa232451e23f8bf4c4670efadb18004fa62c9f0b0eb327ad0e236ea"}, "4a0f0463-3e8d-4415-a718-abdc15b46812": {"doc_hash": "68bc7de6fadf7a67f29d54fbfbad91b256dced662f5ef33d8502fd43d03282b1"}, "dd61db79-5663-42a1-bbfe-d5937c5ba494": {"doc_hash": "c9ced6f9b299bb94db663ab25ee8f6a5ba9628a2aaf8f3a5bb548438de687551"}, "c5390049-ec4d-4af0-8a2f-70823e25974a": {"doc_hash": "53e2d266690355c5adc084298a663b45368dee39c4c29bac0921312a098b33ec"}, "f787c4c4-ded4-4cf2-b8a1-25ac1be41c50": {"doc_hash": "be9a966fb548fae043f03f012222d5c82b1e657abe6b1b7f711fe48d67d749fc"}, "b828da60-ac94-43cb-99f8-226e1d029b9c": {"doc_hash": "ca8238c9a19f5e80f7f4107c11fb4e531e0eb668e5c5ae2f2febb54c86d45cdf"}, "de216f62-6959-4f50-bd36-09d359106cfd": {"doc_hash": "9d344eb806fc4de41af814e98525e3371be56f937cbb2453650646ae0ea21af9"}, "2777637a-840a-47da-ad94-b6e4bf219e4d": {"doc_hash": "06652f43c8ac068d79a5cbeaffae4b6fd7901cb0c50ccf581b549b14a7d9189c"}, "1c9934a7-c713-4e3b-9214-a9247c72fff1": {"doc_hash": "81f4d94b6899d759e1eaae941d71cd81d33171ef4fa83c073cc321f021a67d83"}, "ab3b88ef-de2e-47c6-9d87-c479121dfb76": {"doc_hash": "0f49ee5c8d54bdf3d4e7994c941b48a589038189a482db607074719f756ad252"}, "c9a04133-9102-4c7e-bed8-0ddbbcdd2f5e": {"doc_hash": "b47c1d6c747afa253083eee89159e984451a5b505a394bcca111bd620d95e1d7"}, "35a487e0-6605-436e-b0d7-3fc5852d2c46": {"doc_hash": "ba6f6b2a89c1b189584097d08ebccde442168f28603ae2b18da667ef8c43ff7a"}, "74820e9c-3430-41bf-8f2f-e4208cb51c7b": {"doc_hash": "1f3e3d38ea07f69b0178c87e6c1638657ec2b097634831a1c795da32fc8569d5"}, "05a9f93f-8788-43e2-aebf-ee032e90f9bc": {"doc_hash": "ec7a649b4f5e93f76fe4d0094b38c616386439cf1661d91ac85415a00601ca7b"}, "c93f14c6-6d02-4c1f-8ca7-ff19d0a1f56b": {"doc_hash": "c858a31df1a93b5fb0e24a815396db26329d0cab0931ed461df108e1fa4cd72f"}, "62a8324f-549e-45bb-acf2-fc2ec2ef0e54": {"doc_hash": "a97b396b9b400b607d933fb7a462374ef3d26d5c52b4cb6d1f18372766dbdb88"}, "ec16935f-b39a-419e-b676-af793741891a": {"doc_hash": "679cf3775c8ea0cc0014a07ea00356331e6c80b4f4da1c5f3c9116b9c9800e1f"}, "9e15c98e-1e73-4f96-a994-ef55e37faa7e": {"doc_hash": "2ea9e987f0df51030bb014b5cf6d5629216234dfa7782030be7b09dbc549cb08"}, "a1c73952-c972-46e5-b5e2-dea429571bcb": {"doc_hash": "ac0b1d07f7e9db9fbc3b5a1a22ba20e13aee9fd5748c39291cc7adab0f96f673"}, "49ae2e3d-9f83-4c27-912c-38732e78bec7": {"doc_hash": "8f26ef978beca7f59ac39c48d245d38b3276b4a1459d6ebcde76eda5ae08ef14"}, "3aab36d4-bc51-4ac7-b76f-2ff9edd6fdc2": {"doc_hash": "66c51a17cecc3554c6b1260b853e7969c5c5fd43833cc9fabf85811823205a20"}, "b6b374c3-17ef-4cef-9cb9-4c6e01ce34d3": {"doc_hash": "be4d460bde7f3b7e06757f627e9923f271fc463d5efab8b789d1cb540bc6d78c"}, "fa0e15f6-28a9-4342-81a8-65544201741d": {"doc_hash": "eccab61653bd117fd8572cd6eb78b28fd9dc55dd8323da18867b4b3d0abb75f2"}, "bd454f9b-bfac-4218-bd8e-898e03fad768": {"doc_hash": "5f29d8a903b15c34c4a48d144cb473774d144ff28c89c4f310d646ad737fd120"}, "b91ec09b-d992-4aab-8104-8f5065a933ea": {"doc_hash": "252bd0b2280dfe8a57ef22c32370acd03b087f50711da18fb0e6ddfb82a55664"}, "f886f97d-f083-4e84-bde9-64477065ae5b": {"doc_hash": "44289f9567c7e4e59e4307d33c69cd08b01897eacb8c142c4a36e2974e137368"}, "304f26b9-576e-4b14-8d4e-8bcc76ee5ca3": {"doc_hash": "e0e6edda5e0b0b681808198cbcc7f61091b84054d97780ac0087eb6b40a3128f"}, "1f1a3deb-710b-4115-bf92-402d61a8b003": {"doc_hash": "f63613fdf31dbc8373daf1a0318c5a111ccf358f097b63d7ea2c2a22810b98ff"}, "728147cb-e064-4bc2-bbf8-f2cba6bf9754": {"doc_hash": "3c49ec3494a0dcdd3d52160b448addc8406f0d534f9f0ebc5c2aff2b3a1e8558"}, "ca648513-08e8-47bc-aa8e-cf6dc33d6dec": {"doc_hash": "2f2f84ef8391bc2105a0b72dd00c87a73a2d03aaca06feb169595be31e75165e"}, "19483242-0cf3-4c30-a0d8-80c2e5e8cf1d": {"doc_hash": "b45bdb3aa88fb8285c09bd09c1e2849497443740e2df441c45f7d05a5b4f2e5b"}, "747f48f9-5159-49df-91b4-246cf1246c21": {"doc_hash": "93624efb199f2b3d5089014b7d10187dda675dbd6e665145c43048ebc6630e08"}, "cff5bf1a-dad0-4fc0-942c-55966011b554": {"doc_hash": "0bb2fa14d59f0dffd7e2bf22f7e476a30a0c3a1f350a5d58e65dd04e7823df2a"}, "6c8070d8-57c5-4224-90e3-b8edcca6bd27": {"doc_hash": "84924b1067129469321b2cb3157867fe5ba6c9b25fec9bd75c635947d37baeb4"}, "b5f1b2ec-8f05-4ea3-af4e-1285d267d9a3": {"doc_hash": "6b496d94b615d6a367a9d4bc03fc6de6cca13824c67e3016d3d87aab485c3ce7"}, "0b870b43-3fcc-47c8-9f50-8f4d0cf9b091": {"doc_hash": "6bd3bc774db283f24c97359a8f70dbb0bf2c23c8ca3d6997bdf017ae27980942"}, "3e8791f6-8b8b-441f-a335-323452ea6e8b": {"doc_hash": "26895df23cae5b0f0f484159b8c95a56955c3b6a1c0dd51cfb6cb94f3c899f69"}, "738a9260-71d4-469d-8980-7b588e2b03bf": {"doc_hash": "62c7c967ed5cd4c62873f58506dff6698efb9366c2615955ab53fd4f6aa1e5fb"}, "1f591369-ea64-457c-bc7b-104ff1e40ccb": {"doc_hash": "95373db054afc414dc28f52f9dc42c66c3e9b5d356c351d49834f5b2a4bc83ac"}, "81969284-a34d-443d-ba47-6abbf3e45265": {"doc_hash": "de7e45e00ac681c096b67f670659f62d6e4b6878a3a100e7986b94d297044786"}, "02121a17-09a1-4166-aafa-49979286b613": {"doc_hash": "c4731c6f2f3af2068156acdd3236843639c67dd62e96397052c215d29333dca8"}, "c6789ab8-71c6-4d07-9b01-c1d5c34da506": {"doc_hash": "2b26d9cc191c4bf50fbaa316830edf9d9a44f5e54f925aeaa330bd04e861b9d0"}, "d10128ae-5640-4ec7-b9e6-06ed18550f05": {"doc_hash": "14e53849d643db4b2b148165761c749b6a7a5458e179a03fe5bcf7ab30735910"}, "369ac8bf-355a-4d6d-8a49-3d28bb7c1918": {"doc_hash": "05518e99ec98cde9225e8aa37a8df0ef1c8e489b0be492c18d3d9e4b1f6c01a6"}, "a53e1d1c-b021-48e0-9376-400bde1e9d27": {"doc_hash": "3b67ad5dc14f0f7a818130a41d01b686e8d597a413918b91b71f4708234024f0"}, "edc46c87-dd07-4fdf-8a93-c3215a39742a": {"doc_hash": "f43c40a79e8b1075c4062aba5c915670847166ec08ce4a44004793f6671bd1ba"}, "77610945-a8b7-477d-857a-1bee8e30e18c": {"doc_hash": "5ff734c9fa251643775764b3e58321a691fa1f7afbcd2e29d0eb4029f2debc4e"}, "72a10eb7-53c6-491d-b7a0-20ec29a7fede": {"doc_hash": "78eda9229049024a38f514f089cea3ceb4a41d79fdc481bf575020dfb857c171"}, "2f24674a-9d84-4578-a438-fa11060fc2dd": {"doc_hash": "33ebacb58b4e3bf1b513917d4e01a1fa4cc1eaa00a0e0bc4d076c5bb5be701e5"}, "79039ba9-b3fe-40ad-9cd9-1eca75851992": {"doc_hash": "cb058c35ee17daaca4b18ad72fd00531c523aa1118eece1d91baa5b1c213a68a"}, "90ec7b2d-2dfa-4edb-836a-fc25c9726e7d": {"doc_hash": "c08b05a3e08a75dcea2605938465a6f18e9d90b4ea8fa6668fe07e14e45ad9e0"}, "ec8f9ae3-d7a3-4382-a1ae-a339bd5c4c76": {"doc_hash": "595465c789aff42c9e6c0fa34c804e4d1731b5bdd001d20bdd4d8ecbd3a7920c"}, "836e8d7b-02a3-4cbe-9d13-62848c5d4242": {"doc_hash": "e2e3e5a3f66f80a6ba0e4e02e23beab6106d6557d44891d839d48dfc0fdc19b0"}, "339cd940-60fe-419e-b2c7-4c62de0a1ce8": {"doc_hash": "612dbfa6a08ec87cef1a113190e321c6ad75472150b84b76f5e2843591282a49"}, "d85ba796-3d21-42ef-9e90-553ff0bfa055": {"doc_hash": "f69f262f3269c152d861a3ad3426715f25f8248964a8efc32e469be3ca4fa084"}, "b3d36e08-c5b2-4e70-b063-79cc3e6fcc96": {"doc_hash": "34942dafb7af3ee1ddd290e168cb1cc0ae7ed80b5656d15d3be291df34f8e985"}, "b023170f-8bb9-4433-a9ae-3c33ba2b1d21": {"doc_hash": "b875e6fdaf3c90cfcaa217fcef86d86e76cae4084747dc48229a95e951a498b1"}, "4fb366d2-0df5-49c1-b9fb-21f51c040cd7": {"doc_hash": "eb614b92163c68a62da4c599bc764b0f0e4a9f76688a3504b1c3f57350a1f78f"}, "87b4f30f-387e-4b49-aa9b-4dbdb23906ca": {"doc_hash": "514f81825a5a9f04586146b38293d15bad641fbcfa05d85ebd7ec7ee6d4636d0"}, "08d1a41a-9330-49a3-be95-1dc1d02f9a0b": {"doc_hash": "05309dc93cede4c4b1f3fcb9bf8e27fca41fde1b12173552363972c3f0702275"}, "f3914009-8f15-4d65-a1b9-b49f2e29445c": {"doc_hash": "d17228e44a07c2c1208cd73de2d09cb519046ae2f4cb2611aa8a261b3340a04c"}, "6f02c832-6607-49be-a7c8-2eb3c745eef0": {"doc_hash": "4221cceb7baf86aaaeb5e76dbf16c96808d58faea4da1024d3e2e9a6a44e7aad"}, "f4f7e0f9-19c4-4b98-ab26-5966659d8915": {"doc_hash": "a73ba87c84837487eb67e3f36d9ddf4194702ae7488f2cd33c89b4041244ce89"}, "798322db-f167-43fe-b474-e5dd9cb15d09": {"doc_hash": "79e458dedb35a6e44837be07ed2480204eddd9e66898464203b6e21b6793149e"}, "c81184ad-6949-49ec-adab-006f837a5725": {"doc_hash": "d9e868953b7c580896f2c1c6c2520c5e31fac63a06039077eb8cfeab00a8df37"}, "a36db39b-9dd9-445f-b91c-56794d81ac4d": {"doc_hash": "5ee06411e4434c46ed2e46040da9f748f086d3c00ad06924c3bb4aaafe6d6733"}, "b7a3e8dc-2f15-4f7a-a7f4-b61b5f1c17ed": {"doc_hash": "c3d1fda5f184330a6217b65ac7959060055837257f0482f360147320fb903dcb"}, "27cf3b8d-f30f-4141-aad0-362eed165343": {"doc_hash": "1b2ce561c48b2860a36249f8c172af8cf123d2adf31eb5077155d1846dd02e2a"}, "834b91d0-dcc9-4ba5-b5e8-0aa082ba0a9d": {"doc_hash": "4877bf1ebdd839f907319da7887aff682f9a04b3952e616e58d757630bf164d4"}, "20c243ac-ab44-4fc3-bd52-49acdeb1d9b2": {"doc_hash": "cc9fc3f9a0cd6edfe65ab66ffbf1a6e660b753aec99c832f0c1300ba144d24dd"}, "804c76bf-9b90-42ed-8e68-191fa43dca8e": {"doc_hash": "977b5b6cfe78f56b54dab5be9c07bd4e3465d3f378b4bf2add4d25a4ae8e19e9"}, "cfe299c9-5624-4e91-a938-0b2203a548d8": {"doc_hash": "3eb0b208021a22f505457e00e9e35847fbcb0f1b20ece138130421b3d8c3fed9"}, "8109a3a5-5a97-465b-84a7-67683d1f7ccb": {"doc_hash": "7b79a40f74034875c9abca22b162b3f65a1b0bfed2e2498fb09faef937a475c5"}, "48aeba71-0f34-4f50-9865-2d7f45a8f181": {"doc_hash": "3ce2d76593d0c7267c82bdd57f0073adc24e1abc012eb4da69aeb42551e23953"}, "ff303e4d-efff-433d-9ee7-7ccceda8c86d": {"doc_hash": "eea842b73e42f6edaedcd62231b5c99b601bd4cd957f93be44be4a4e41257f6f"}, "4029cdd6-c3d7-4eb5-8cec-06b6b0b978c1": {"doc_hash": "7783a93d4554fce8aaf671f6b80c939d398ace97183772d26f503e84623d1eda"}, "9a95c5e0-6889-434a-ab98-ca4d5cd5ea87": {"doc_hash": "460f907ca7b37c7e7293a47191dada1a12c44f5643617bcd052af59b6d2fdce6"}, "c42a2352-8e3c-4ac1-927b-057509bc77da": {"doc_hash": "c972d4676d3791aa4432f3b9d19bf622b32ea643ae8be97e21723285fbbc5d89"}, "9fb91a98-3258-49c5-ae92-4f72b6414193": {"doc_hash": "318e6dbcdad5e2a5f4c84c13e1bf556bdb1645c25e828187ed24088ef64b64a9"}, "8c33af57-21fe-4fe8-9814-a45e7fcea357": {"doc_hash": "d12bc2ee7979e8afd0875cd502c7fc39b23deb90c652c687fa16bbc281b1f12a"}, "d26dd00f-fd60-4ccb-860a-0607158d041b": {"doc_hash": "509b5bbc82d81b451c082f1fb9c992dfad179b35a58121f5c95e0e7715fac847"}, "140aa4e0-32b5-4b8c-84d1-4e4bc41d86ad": {"doc_hash": "2a283ff5c14a977e4455c878749f55e30c3b3b64f2797d0f1fc2c9f6553d527b"}, "9fd90ec3-c241-45aa-b88a-26931e284fc7": {"doc_hash": "f9532c01727e7abeaa70146a09509d3d4b6d5be5105ce61cbf72906d8502cd93"}, "8bf698ba-071e-4ad9-aeb3-de011b9d5d13": {"doc_hash": "a5f9ddcd445874eaa46632aecda6b91c59fa0103fab0563bc4de1d8d97563834"}, "27e724ac-b044-4b8b-a905-ef2937e00550": {"doc_hash": "79fc9bf30894b1593f2d813c3941056d31133df4e8981406d928bcccf5e2a8e2"}, "356f2fab-15b9-4d7e-a8c9-153da9d32d87": {"doc_hash": "6d3d6c81e2733808c2d33f3779aeef2ea63f5f2ea9a9542bd1351a27f0c825ff"}, "a0d51a9e-9114-4db1-9e1f-e742876f1a17": {"doc_hash": "fb22ae52677b7d2dd48ad9f046fd2e0d44d8067297b0467d6f85cc4d99f60431"}, "0e1dfe27-7a14-424a-b01c-1321e655ce6b": {"doc_hash": "16eba53329998e89db6507cd12e3d439f14f1e03edf7364b941a7859c99991ae"}, "6609a223-082c-4970-a208-8a9250179ee0": {"doc_hash": "80d4597542dd11957aac3e8fd3a3c040d5d6b4d25670047c83e94e4153257c5c"}, "dcea1d42-c3de-4f4f-98b8-2a2f842c9f52": {"doc_hash": "633a2ac4f465b1035676c6311db13445d77b720561a868d1e9cfedbd5a665e01"}, "f1b25289-9af7-4af5-b24b-50d5ac05b685": {"doc_hash": "3351d6d5a5cc672dfc75ff6f73c8e682f75db1a77cf04a925ff37541055407ff"}, "434e059a-f17e-478b-b560-00694e83463f": {"doc_hash": "43b13d2291c9ea9b22b2f2b985a9684e8f03a885c566bc9415b503fac5e8b7c1"}, "d0a4dd62-059f-4541-92ce-29ba3e4311ef": {"doc_hash": "ea2c3b857056f0072f18c4c6c6a0a420ddff867c5ff592f52d641e3231769d89"}, "f51de19b-575f-4626-9f66-0e20a638cbfb": {"doc_hash": "a0c5e0fa579c54376494e3fc3fcd72740a3d90c89f11854d35cc1dab8f27e3ad"}, "0c1ca8ce-c338-4cce-9e0a-8150ff3a2f01": {"doc_hash": "bdf995d3e4c9375135a3ed7062b45636b74886ab74dad3ee3e9e9b3017f71e1d"}, "82f4c9ca-2a59-44c7-9945-df77f8b8336e": {"doc_hash": "1f46c82aa1563ff7f398e404c27d49623920ea57a7b613b3c09dcac7c9cf7e8e"}, "68138da9-34cf-4657-9686-26bb6f8da903": {"doc_hash": "b2fa8691ed5c117813394e41ab094807f1a14f92144f29cc25b3926da20d034a"}, "7b01b1a6-4428-4a29-a978-13f225885eee": {"doc_hash": "b79e50c1a21294bc431d5f24bc48ccfb4507b0627a3ba6fa9a058382484929ab"}, "29580fa6-f4ab-46a4-a8d9-b12e4efb5b82": {"doc_hash": "e137ed7aada2c0fafd497d3964ce55a23045221ebb413faf4568e76b9fef5193"}, "1dbda34e-2b4e-4a99-995d-4386a82ba93d": {"doc_hash": "700dc86c4f90a27533dfdea52cc3a9b321b731cfb0a6ba585db84553dab6fbef"}, "531f9723-7220-47c2-8a02-6797c16d1e16": {"doc_hash": "8f140fa470874a993edef1918af41eb50f4a4118f700bdf4b3bd755ea2e116f5"}, "7f26319e-1d75-4581-9d6c-3eec050cfcb4": {"doc_hash": "74e032d4edbd30d185ae9c055584d81a1571fe4b5c643f9aa467f3745eaaa4ac"}, "7c362ae0-c47d-4ae9-b1b2-08062fdfefba": {"doc_hash": "a7e89cdb3aac0c3eb4c2dca6d32f7893f7ffb561b858ee4e6923aa9474daa682"}, "8f013150-1e5e-440c-a645-43b5e11a3298": {"doc_hash": "5077de58f4af06a2f70e195bef28c8042a255fa0bde8b75257e4b204df1c7c30"}, "28559435-68b5-47b2-afa6-ca173764b907": {"doc_hash": "61b905dbfe89ce536a43a17884e4475dd1480daf920af51ef4eecc979651a1f7"}, "17802436-49b7-41b8-9f80-f00ba7bc3af7": {"doc_hash": "a3c7d3337cd859de4aef4da668d52910803ec4ed0c780e77c03fdb1f224e24b7"}, "bd272091-0078-4a35-8e66-e9aae344c400": {"doc_hash": "734cf6fa20b5e5c34209791e675b8ccafc3a949f4f82897f31ad3851e85ddea7"}, "576d8cc0-e40e-45fd-90fa-1a1b3e686e53": {"doc_hash": "a8d90dffbb42ab53426b5e365cdef678bf91024707d46f7f9fe355db44a5f600"}, "2398eec9-672e-448f-af57-a48c470ef7b3": {"doc_hash": "8688193ab8f7cf336693080d0273a4c391db0aec11a36241711972bdddfbdcd9"}, "15a0707f-8121-4d61-b430-e9f26ddf0e79": {"doc_hash": "3ab580a6539790959a6f4a687c7cd8d8a845c6b950b7827ed135e53c6c05f092"}, "6fa67f41-dc9b-4c0f-b291-a3975563b4e8": {"doc_hash": "1cf4fd9e2257057fbfaa84e843be0e929064842620861ed9ed6f1af03f432311"}, "3a1a651e-86af-488e-93f9-a1b3711ccda7": {"doc_hash": "b5dcc7dc31431d6ee7d0fc09a3a69f102bdc934d0db61c725a2f08e34b3acc9b"}, "8fca5be4-6a79-4db7-a13f-9a21335b3a85": {"doc_hash": "889a015e99ca5a411d43d6dd0f673cf208c95cd02d05c46e2d990c0d22aee20f"}, "4759422d-360e-45c7-a73f-4b44fea06d24": {"doc_hash": "72f93d4141e232ac89c83116617f10f77cf3e53c81b5c40f4656ec9c421c7edb"}, "32bf1bb9-8f70-4dac-b084-8b86b57985b0": {"doc_hash": "16f093ab0c994bd4d615161e50628e50f316c272e88fe6258e9002dfadd1a997"}, "a98c25d9-0bff-494e-b96f-56b010620a1d": {"doc_hash": "16a13b1f2fb78cd01a95725c7d98b1000fc904b53cf1d6bd434fe43f886d019f"}, "d6f7f8f3-9056-4f23-ad50-e7d7b69cc02c": {"doc_hash": "d4073455a2d733d12808c993f179652a0ac3a4cab43d05e8b6ce1a0d24073864"}, "c1541ff4-69cb-40d7-ade5-283b065c0e0c": {"doc_hash": "1534e48538e01c52f211639d659441ef84bf213cd66391680da19a2d42581aea"}, "4135503a-1baf-4f7c-b608-6f76e482cc8e": {"doc_hash": "449b9bf412649486deabd249470417ec6f43779e8ab47f83018d6a2dd26f814f"}, "eb8a7af5-8359-49eb-afb5-3b05ef2582ce": {"doc_hash": "293961ec5e2ade6f4e2009710f9e01ce83edd2a72c929b9d5632c35770797400"}, "d14bdb64-557f-4198-945f-fb39462f38d7": {"doc_hash": "c664f8a07db3033c1f8449a1671ff2afb3b1aaeaba127f3c79355ed3f08824d5"}, "c8cf0cd9-8acf-4532-9b4d-3dff91007429": {"doc_hash": "bc778917703f2a1a7e6a79a9918f8179c4001c6634497cd60b4f09c9d174bdba"}, "d1db909f-71e4-4826-b372-588b5e9f4d92": {"doc_hash": "56d8c050632a102f9f0a7a5bbed56c782258194fac1abcee0586bffa7ea94542"}, "a32a0a79-2582-46c4-b801-68360e2d6b51": {"doc_hash": "d1a68627adcdd0ea69179eda3f46f6c2421f555a23df9fc215944bc2e81d7f21"}, "55d12e1f-24ce-408e-810a-e6f8a0da9662": {"doc_hash": "e75a483f9ed6725eeb97c2e0b09ea8132eae1cf74bb947023b0470285be74934"}, "87ec1bf3-84bc-4e63-8f29-d777dbc13667": {"doc_hash": "ba9bf7bbb95feab5a4d2098ef09c0ec65289a84fc81811838a9aea734555d74a"}, "43a32980-d40f-4633-af3c-23e32de66f34": {"doc_hash": "85794deac14125a1c3708d69cb0ddcf5f2e78c61eb25d1cb0ef01b010c4886a3"}, "77386cfd-d52e-4340-96e4-ee73f8a478b5": {"doc_hash": "af911d112787e9bc65c9300b1ab8dc6a19467deced530605999cfadfd64dd0d5"}, "0911a4be-7086-4ee3-8572-8ba976afb873": {"doc_hash": "d0cb7919c48ab97155ebceb6bab36aa23e99d00d45f7389967fef2a7872ceda8"}, "3c9075f0-bf15-4c4b-ac6e-50a8f1981aac": {"doc_hash": "c3ac55e9fea46988804a36b7cc9ac86a54594bc48197749b2d0067e5dfcfe51a"}, "c323df0f-6e74-4428-ac57-bea94f8b5fff": {"doc_hash": "74f9605ba969bb3e1b4dc9875c58d457e3b6c49df3dabf635fb2eb2e1f1a392a"}, "50791452-b4ec-486f-9cea-1fc4639111b8": {"doc_hash": "14b13803446a97bb28f41cfdc11a6bd630e41c381c3c4f4d800464bede781083"}, "fd9724e3-16a4-4cbf-a8b3-616efb0d21df": {"doc_hash": "04840037a0907ba7cf4c09ac36a77e291ebc73ba843045bfb5f1feecdfd6b348"}, "f92e5a04-cf62-42c0-ad84-fb32ffc32b43": {"doc_hash": "20b5a69fab2c5971e3e0ae6e207a31f8db09459cfd8d740e02513395f558164c"}, "0de00b3e-d14f-458f-b754-487c205aeda2": {"doc_hash": "b3d6f0877b37986dae2499f7439d10003c26feed9906f89f88dd1af8fff9e3b4"}, "28031fae-3eb5-4247-8da3-6c9d6638db02": {"doc_hash": "f257b6060522eaacf9b0278260e87ef4b93e473fa3cc19902046c90ca0406050"}, "bb0aeb52-a3ba-4c5d-84f1-8a2a0a6b2b85": {"doc_hash": "72e067c143ce13d17be1794fcb2d22dd6da7c0bdeaf2c22da24641d2cd437572"}, "795816c6-66f9-46a4-a29f-19aff2eaff92": {"doc_hash": "c885a43902137efb74553b2e3050531ba31f61e2475b112c8dd8955258e89d06"}, "df6da787-8c73-474c-885e-5624268d9b88": {"doc_hash": "9959062c44a2caaa7d227db3154f72cf374a473a274db04a4eb9cdaa219e1947"}, "718d9f37-ef65-4900-bc0d-1ce3a2507751": {"doc_hash": "90999a94658cbe42461ea8fb84c0e08dd50b682bce9ea12ad57c01208af68dbd"}, "7384abe3-ee42-4537-b1dd-d06db1cce554": {"doc_hash": "51b8b393a2e7da5d183d6fc905c29a52df4c00bbc5500eca59db8947b10f762a"}, "ea572e80-afeb-4076-9a1f-e434151edd2b": {"doc_hash": "fd47b37c0f22d6b910ed982289ab18ba83bad9feea154f4bbc95c1bf2178a637"}, "e4aa2d95-894b-4ee8-8147-e8f29a8fb1b4": {"doc_hash": "f0b2b1b115146bfa40ebef5c70555ff7214c0fb634a0043e6d639c32fd513555"}, "ffb8821c-361b-4e5d-b592-6c4d183b9d1b": {"doc_hash": "228932dea1a15d07ff599ac1085c57f18b93269af8aefd2cb8c15b99b935cd68"}, "da246d65-9a3e-4c2b-a4a5-88e1728a2217": {"doc_hash": "2592ddd0d98816e3f9acc00cffbccd2b550e43ba20195152ba5e5d86cc96b5b3"}, "896dc42a-5387-4e77-8e5d-b66c0ba82e4b": {"doc_hash": "d8d87c1d6a6114f6e8b71ac24a3881cc7903cfd287b339db600de314b64bb6d0"}, "b8b3705d-9b39-42cd-8ea3-834d366d83e4": {"doc_hash": "e8d14d6fdbbaa61f350a6c16585b124214b2e3756526b7d5edfafb557e0bd9d4"}, "f7bc1b83-a8c1-40e3-9f0b-b92b2b76b49d": {"doc_hash": "18ebf0543d7ad656cdd17c66094ad01ca901881d0b18e0d34dfd0b38b7bc0da6"}, "1e4907b4-eca0-48cb-b0d4-45a951e9225b": {"doc_hash": "9b427b81a715e7ebe2f0ff51719792d83399376e963cef47068ab776a60343aa"}, "e534d45f-c7b8-420b-bc79-48073101a833": {"doc_hash": "d323f3fc223bfd04f631c79812c7ca200279683a8ae48d74c0669369d711c3ae"}, "5d15c07f-13ed-47b6-86e7-b88054e3b197": {"doc_hash": "75b67bfe4d77446da921730542852aa60cadab506a5c5b07cc42bfbddbb5a5aa"}, "5e0e88c0-d99c-4644-b2a5-34d037b16c4b": {"doc_hash": "66a455a0867fc4b92e901797cfbf32c74206a07a3df93ce926a7cefc6b43295d"}, "3f166149-b782-43ca-9c69-4cacd3f0837e": {"doc_hash": "45586ab5b6c7aee9370d0b190afb05ab87c5cd2d377515ad2b06cafd5a31b143"}, "03d0512f-3378-400a-9646-3d60083f2cf4": {"doc_hash": "e0f0a6863a9d7488e31aa90b85e2027dabba99889474c5c8a0f2158abedc0d78"}, "3fce0be2-52ec-4ea9-be7b-1561002de646": {"doc_hash": "c0ed32ef106746cc3439c075118a9be6bd0f30153d0056c6d54dccc807838477"}, "a868ade9-4954-4cc9-b71d-5f25e92a55fc": {"doc_hash": "b3dbec6d23f9f100e90bf8d2e4a3e43f86fe98e5c34f1bb5aa322f13648eba62"}, "e6c2ffb2-51f2-447c-815e-96b576dd9a33": {"doc_hash": "3372121f49f87ae72312499cd4921d91ea732cada31ff9a0952c690cb024f51c"}, "65e23da8-fb6e-4fbe-acbd-ad013430c4c6": {"doc_hash": "af06c4292165c6d6dcaae2dd1f88ab235cb47b51e97f10bb7d9981cb16481c60"}, "62f76dbd-c7f5-4538-9942-aec36c595963": {"doc_hash": "99a36429b194ccc59ac6fb2d165ed5567296d37efa7cfe46bdc644488a639828"}, "e932fa8b-5677-466d-a3a7-7a917295b4b7": {"doc_hash": "113967e0b4030a7ae09738d22b0799bb24a642862ee05447bdbca1a4e1cfe885"}, "03d69c1f-1d2d-40e5-99a4-cf97fa7b0ee8": {"doc_hash": "b82bb1ff6830da32812afe61a662afae0a747302afdf206e5b62c7bdc428e47a"}, "54f45e69-96da-4ee8-a859-3fb273385438": {"doc_hash": "6d711185df0036847fd2e1756313accb79455827d2a697ae6e89d3d5f538773f"}, "57d51f92-a15e-4cc9-bc17-9de862fe9279": {"doc_hash": "ba232faf12fc5091e8a14fb366ec020358ed10da48ce2731d541af4a49e28d2e"}, "f241386f-0176-41df-9d80-2b44b6acd227": {"doc_hash": "b92235c7111003f88acb15ee6f3833dd156cb562d8741ad345a9f7d4be63d555"}, "e69bf53b-b373-4038-b0bf-796e908443f6": {"doc_hash": "9e3316843514b597bd6b3eae232944c6ac368c517ea623e13048c821ea70fa54"}, "41bd75d8-75f4-4e3a-8513-a46942cdba68": {"doc_hash": "bf480597db8c612fbdc42647cd0348fa4b23986740c1a64363f5921a8bbadc96"}, "b8b06100-019e-48a2-b757-be825b7e07de": {"doc_hash": "3868b36a6ec0a14ac0ab167dfb2051fbb378684879b0fdbd153230e3a648a066"}, "75934dfa-1f6d-4b33-8916-7a60b2069777": {"doc_hash": "1895b052f0e3be4a58f790dd0a5acd0e9a652f6e9a59bb1607df74a5ec883983"}, "d1529401-4370-4de9-a9bb-1a7200a77f35": {"doc_hash": "eb8f5c1a56f14800d1b94c0d27c56de16abeafb87a6fa79dd38006b736f81b2d"}, "d53fafec-e911-46b8-87eb-7046839b86bd": {"doc_hash": "ecaaf57de5d1ef5249e3b2bee28f44d033ff3cc6f7df198c5d0ebaade869330e"}, "4446c0fd-8188-49e8-8479-8d6c80863842": {"doc_hash": "8ed16401b8ede5591c2136e5f30f58b1e853a6a509811b9f60e734d62a15ecb3"}, "d3a353bc-94e8-4c76-9aa2-976e19d3c363": {"doc_hash": "f2189d2b4ad5b031555067f63f9fcba6da93bf6f0c0a5a6aeca6e2fa0e36b03d"}, "1f9d783b-9248-42d7-9c43-a7dd30fb99ed": {"doc_hash": "7ac4e2b4cad6cd6326b4fb494fc8f1a81f2daaa50581c50ba9d209248032559f"}, "c483594a-08ea-4117-8c3d-e3eb0de19f57": {"doc_hash": "eb297febcdb71078573f33e9402611b891d3f367d095578890c42790d39347d2"}, "3f0af890-0c41-4deb-baa9-101ce86687ba": {"doc_hash": "4fc5028b83d89cb9d2ade354a2a7a3e1f486205f97ce451287a022c091ee6bcf"}, "7366fd00-8b8b-47a7-b47b-977ac1527a43": {"doc_hash": "02b799d66c4f0afdc2be4bb76fdf6d24369e78009571ba08276c310e3337a51f"}, "23de6620-8de3-4b8b-b419-77d926829fc3": {"doc_hash": "16f7f6cd27e9fe05c51a26febce705ec00dc0dfebe9c18eca947c5e63c22c272"}, "c9a68b45-2f9e-462d-ba66-b20d47a0f9e9": {"doc_hash": "5261cc06ce7713a7eebaf6a57d07aaf27946addecd534f2737ac4223a8f42449"}, "5dba078c-e733-48d5-9e76-c035cb0f9103": {"doc_hash": "0e4fa4a14e07d94188c724398f37a4bf9258ea3d834c1d39c59fb8d4a79de258"}, "2fda79e1-dc38-4312-961e-82df15af96d1": {"doc_hash": "cc50107a5c04a715eb4979cfef7c2a83cd1dd2e3a36230e61cf168902a8d8636"}, "60b1ea8f-aae4-4c98-8038-e1cad00adff8": {"doc_hash": "cb15ace979b9e132a5fa2174bc9ad5766ad52f4ba8a5d64f00135bcce5cadf76"}, "6a1fbc99-97ef-4f12-95f6-b20460a8a5df": {"doc_hash": "1954f266ed61d8c94f09e369347b1eb304d33cd4e667e9b8ba38423d7cf3bc87"}, "15473392-b4f4-4f4f-be3f-6836ff55968f": {"doc_hash": "e6975ef34ba66fc004cf717bdad476447caae199029b776cd461651e54d8a961"}, "3672b6b7-e060-480b-8361-7c9ab6b3d7a5": {"doc_hash": "79302d91c417eb873687c46e2f2fcf26b9b4da10fe8a12d64eadc367023fa0ed"}, "0c01c99a-4c9c-40a1-bc16-0ebac457785a": {"doc_hash": "dd61438d9ebf10f435da7608895b77be6a7dab27a34c3fba0506f39ae2754ace"}, "f39337d5-aae2-47ff-b422-d96496e290e7": {"doc_hash": "5ce3c055e42e5cd4c4f5735dc8af3375cc89f85c3fd4e3ea8a81d7be63cf432c"}, "43b9cf79-b0ab-4894-a630-178a09c586ef": {"doc_hash": "716035b788f648326673ea5f2f70696a139eb9cbf7ab49e84667d58cb13f4a66"}, "1ae59746-d0a6-4597-bb2b-c54e3a9a72d7": {"doc_hash": "4b38590ea831084a77dfca14a5ab67985757a4425355c3128b5777c9b035b0d4"}, "54d24904-1db7-4510-ac35-6a777d9ab8e1": {"doc_hash": "94f85638f158f47fc2c057167c14e8d7406c8c340f2262369eff527d9932ccdb"}, "7de6e759-de29-48d6-a428-1b6e79f0ca4e": {"doc_hash": "1b1115ecee66678b43a299a6a72810f6695234b870e24b08e84e4fd3486e4f56"}, "7f9c1356-c276-4be5-81db-ef63584267bb": {"doc_hash": "187f1c07f721c32d6afbed5e159c90024bc8df6dd7d17efde77d68f0b03648e2"}, "fd568aab-842b-41b6-ada3-1182e60a77e9": {"doc_hash": "6b08c88b1bc33dd20964b0a8a2b403e2de6bebd3668ce9ca820dfd2480539a7e"}, "383797b2-155e-46a4-8db8-a8c2566cc8ca": {"doc_hash": "a381465727ed722c78b1996a403614eb8d1e95342655e70fe48bab88ddd58757"}, "83fb0024-42a7-4e06-8a54-4abbc8be700e": {"doc_hash": "8ea594c710fc82b81f84e078fd79513285cf0186c348abc5d8a66dc054cc4f83"}, "5373a23b-42c8-49c8-94b1-6adc6bb67caf": {"doc_hash": "e066179866c115ab2ffc2aeb42ec526e5df89062e6369aad6484be2f3f60f8ff"}, "8ac09f96-fab6-405a-8b6f-5581fe9c7713": {"doc_hash": "05f290952fa1600fa2f6c71e78b2b0970131f637e1626fc6cbd1b92fff93c9ef"}, "e80b5fbd-ad7a-4bb9-9c98-e467b81b3dbf": {"doc_hash": "8b1175444790d31d6aba171148149dff6b7a7095f43a26f75d0c91ca7c5b19cf"}, "303c6456-f637-441a-80ee-1ec54d2be014": {"doc_hash": "5ef8f94d38774d075360211d0467c2c1bebb3c935c497d0c1f99d9318430e670"}, "7ac2ee76-da4d-4842-be82-e77c61f7d369": {"doc_hash": "4ad1d94a79fb0882359dba95a8520b8d9d3b6afa1a721d0a26dca5833aff215d"}, "6bef7bff-8dc3-437f-b283-cbaefc1cb7f3": {"doc_hash": "a56c5a257904f58110bd1b3ad61e3251a324ee62c884e6bfc90ef2f0069cb48a"}, "ddff8166-e0ca-4edc-bcd1-3f53457b4377": {"doc_hash": "9e64c72321991dee2366ef6d20e582e114dec40a33e27cae0216e8ddc138b693"}, "a2f37b49-48c0-40a9-95ac-c1f179c8dbfe": {"doc_hash": "0337877fe81cd66a4b0701c3924618b7212598affdfb2ec586b10d40ddf32545"}, "b720cabe-b491-49f1-a2da-2a756e4d5363": {"doc_hash": "7278a84e81c4193be844812b7c67cedefa818d86e37720597357cc55150e6d0e"}, "01b85149-2bec-48c3-8d9c-04b18de185f2": {"doc_hash": "62bfc24218b6838952c0d8760305cdff5fd77de2b22e74f077f840f8b32c1764"}, "2c542e3d-20f7-4e1f-9ce9-fe0f93ec312e": {"doc_hash": "c586cb39f74f8e12a6b3992d2ed771a851e817b9018e9c1dc56c4daf21bbad52"}, "cb524e71-195a-4383-9e45-76db28a34e41": {"doc_hash": "def20050659421dac23be68624763e534d742d0ad7a00be2cadfa95a7971991f"}, "d6cfd8dc-02af-4ed4-a276-8c60752e3b3d": {"doc_hash": "b23f3500640e4401a75aedc11d3664e66489273585ea2c0a878bf027289202f9"}, "aa08c70f-f2ae-449a-b18a-047b6ea39109": {"doc_hash": "32220c4fb62e9e453a733d2f646b5cbfa3b133b04607c73682366a55ddb5f718"}, "65ffb4a8-088d-4783-957d-90df6add4cb2": {"doc_hash": "8a7cfbe0d6cb3d19404d0e78039cf53ddb1374ee2f9b9aab7363476c78bce43f"}, "640d7a25-0eee-41bc-be68-5764b1ae0618": {"doc_hash": "73ed61816cbd5586d209fe08e8ac2d69af482c72441acfec548aae5cb72a6825"}, "168f34c4-67a1-4099-9ee7-b6df32b205ed": {"doc_hash": "b7607df4eae79c9abed340d0b10d9848ef4e71e451dd20c2731d4fe5b3bb2169"}, "9653f3c0-ed3a-463d-b0e3-6b5d7ffa9f16": {"doc_hash": "8075e7938a9af8382ac6a02979944ed65b3db920c8a63a509187a88ebc160aec"}, "c9e6cb81-6b56-4aac-846b-b998afd66609": {"doc_hash": "1c4e915901deab792e7f3f6116df6ad584d7c86b51549ec67b55ae1745367e80"}, "ce11222d-7569-4797-9871-2ce7de3e78f0": {"doc_hash": "c12fbb45b519c8d122edfb97728d0fe71fa0320c6c13dd2a6e427368db2bce7c"}, "8063fde7-bace-4648-b543-c05e60c6ec55": {"doc_hash": "374a134046d38afdcf78f1197d01cfd9a74176d57ca6c762f786aa21d2815581"}, "322f7966-0d2d-427b-8a75-2eea9363af12": {"doc_hash": "2525da008f305cde5be778904dcb2797ec71a7bdf3a841b638a941bef1a6c852"}, "38843e45-e339-4d63-8fd4-e528a1d1dece": {"doc_hash": "cde4ac7d7e33de574a9bf4d341c8753473df63611fabf2798908d0c1ec1d0f54"}, "19e45eb1-0ee6-4e79-855a-44de8cb57bd4": {"doc_hash": "0e1b6f208b7f5ab6ce71f2263232c6c05bea25d856531547b4b0f60be0faef98"}, "a98fa7dd-0582-4c08-a929-948ec13c72d8": {"doc_hash": "e994e422795ce975e453a63e1e32a5a3d1965e744c088676de6315b5c16025c0"}, "558187ce-9729-4c0d-ad2a-d5d0afbc3ff5": {"doc_hash": "0914ce0d7186c8a83f94f799e4cef063d07fcb7941c1b162215085467c97a091"}, "19c47ad2-f1e5-49f6-a010-c8619bc9a10c": {"doc_hash": "5c39f9f2391b2b298b5b02145d2f43b45a96734473120be7a484201d56b31cd8"}, "06ef845b-2125-44a8-b638-0a153b27cecb": {"doc_hash": "3f8047b35fca2f0ef7e1ba2b06c60e75037aae182b18f428ee88638532874714"}, "69c0ace7-157d-47c7-b265-9fa529625fe9": {"doc_hash": "3acf05a2364698e56386c9ca40f8a0f028df9ef754629c57fa59024f42be24f2"}, "f9c5dfd8-0104-4b58-a51b-5a6c8fa536b6": {"doc_hash": "eb65a649ed36802083083ce0e7790da723dd064df70ee1c8049fe2d5a3946232"}, "5a86d1ac-bb03-444e-b44b-424a427266b1": {"doc_hash": "c9550562be57cf9ef21c8c4cc94b81b6cc470a5292a10d403e03f6b462f5a43e"}, "656ea19e-ef35-489f-a7e1-2185a8f9c9d1": {"doc_hash": "13b337183d48e12278276493adf684be9fabbcea13481a90c5a4e35aa52d5a0b"}, "cc13321b-1313-4321-955d-f851313abd97": {"doc_hash": "172375d382ea89417139cb89a56ce69e407e8f82fce2d57123da6bd8f29842a4"}, "8b4335e7-0d2d-42d9-a3ae-29cd0db702b1": {"doc_hash": "d1dda9c2be41c977cee3208d2caa64cd8ed458691db646c39b5323744a44f8da"}, "e086310c-8fca-4357-87fc-ca5dd92632cb": {"doc_hash": "3b5f6a963275151095b8e123b51cb4eb94090a38e6915f2cc1b7542d51b174c3"}, "94303b51-eeb1-4faa-910d-a39e0b6e1a10": {"doc_hash": "2652daabc55494dceccb039e0348598816ed27380a64eb04d5ee60dc5ac3c47d"}, "b23307d0-d8f8-4de3-a63a-64ebd4f74b53": {"doc_hash": "c7178e0fc9a84f6347cfdeca56e53649fef37f785ed89416bac85045952d3c77"}, "db50e996-fd33-48d9-a8fd-868c0930a951": {"doc_hash": "d3294e068efc0022d242205acba43cffe918d99d0366c29110a46cf20a2cf700"}, "277262d6-954e-4d59-89e8-42db709bf7ee": {"doc_hash": "65dc8f7f832202b99bd4cc71aa6bfe05627b89af15bcc7510a4f77bea0fced91"}, "24e2200b-0739-44c6-b5c3-a1abc372d2ad": {"doc_hash": "97b06bbd693afd870b0bfb563a7d4fc06a366e34332e003f3ff8b09b76dae867"}, "53a31e01-4bb1-4bac-9fe4-4e37937fd42c": {"doc_hash": "bb7397501324ecb49d267af7cfe6ff88d0fa5d43445820c1c8c6f6266301c51a"}, "eb10a1ed-71a2-4272-802d-167e73e5a5a7": {"doc_hash": "01b7287ea1c34f13772c2149c5bf33f0cb247e77dbc00bd6053926e9d7c8dfd4"}, "f25d84b5-38e7-4e61-a735-18ecbcde6705": {"doc_hash": "200a753d35fea3d2b47a246452ff7cf05621592c9c3b9606ca323c8816db99ab"}, "58e07487-86e0-464b-b08e-0cc352b155b9": {"doc_hash": "8d0b3e5be2dd311e4a75493aac2d10b3cdb3983adcc99f921088e6a38ecbb5f2"}, "40ce3c2f-15b1-4296-90a8-a631873f0fea": {"doc_hash": "8fac94732cca26a5c1311f4182cfaf74bc582f52ad5e319a6401d5852b7f3cc3"}, "ce03c5a2-5705-4921-8f98-e3840492d771": {"doc_hash": "d4e4f137a508b11fa5614774281d18f828fd3eff9096e7ccf6861586b3cf699c"}, "8914572b-205b-4e5c-9285-359e84b71e83": {"doc_hash": "0ec01c52b0df75db7317ce211d9227d0debe2ab070cc23228ce032a9c84102d7"}, "e41bb151-c0b1-45df-838e-b301832076c5": {"doc_hash": "9e029142c11e2257ca95a8a4b52321a3ebdf7d7b4b7f1ea7a5b8579bfa942323"}, "e3fa7a21-5804-4d45-a11e-69b230b6df6e": {"doc_hash": "08ad4a0a9f0ad52edaa9b78c5a569b079bafbe9fec3abbf85d44cb4fb1aee6df"}, "c3925161-bb50-4016-94e9-b2df40f4d73f": {"doc_hash": "1331d55dd16a06be2fc96dfce92df6d9f5352b7f4248a81fd6dbebd70330c838"}, "41ed23fc-e714-4583-8c1f-0386593884e2": {"doc_hash": "0b48312f45a600da50b3853bf3072d7bf010cc50870d5b775d320fd4f1ad83d6"}, "af8ebad4-f39e-4ea8-8ee1-5a9d2620993b": {"doc_hash": "8b928e0f1da877dbb5505096c516073b7afd12734c0aa6f0e14177fe0a5b166b"}, "e31b450b-0bcc-42c7-84c8-ef42e0628fa7": {"doc_hash": "56e653bf76ad63ea148fddff3c13a5158079bc9b06ad9170bfee0521023dd61f"}, "6311aa3d-a68f-4770-a253-c82a4ab2209d": {"doc_hash": "09314c729b6f5d4b8570601797db38061e5deebb32770f4a408b88ab7db34741"}, "931660bc-80c1-4d58-ad5c-8aea7742f154": {"doc_hash": "ef7711bd2c538bebe5dcc43b3eebd86d3e02ce45aa213cdff9cb1d3232132ee3"}, "d2f2ea19-763f-4f16-9864-ca01c7b5a980": {"doc_hash": "4a9c6a8a7d9f378da67cce8dca94f6dc305e0ac539ce95a9ec42baad0cb3ef16"}, "dce78927-d728-43ae-8aa4-45eda30502cf": {"doc_hash": "5907b11ff9da2db1763c06db2351f1a2c98d52ec0852c452b73692b2df25196f"}, "c02bdba5-bc15-4bad-aa9a-0405b98f10c8": {"doc_hash": "2542feaec99a1aab981a213357bb7c910db9579f25a2d0d503adadc6abe77752"}, "0e9ba824-9a02-4233-8eb6-defa156ebd6e": {"doc_hash": "2a79e3fc89eba102a8c4d630cf12f2238f2d6ee70db05ed2d4fd6be883361b39"}, "b92104ef-e713-4d00-840a-52ee3303a62e": {"doc_hash": "133219e1bfe55ffb8427c2b6223e5f96644066829edb9ef31079ed4a2b8e87a6"}, "bfecf4c9-0a1f-4a65-85a5-d96e8b520f7e": {"doc_hash": "aee46c7eb72c3494501338290ceaade8c8a3b79c4299c27460fa1eae2cbe6a7b"}, "e5f8e08f-6da0-4faf-beda-07a6a09b3b7c": {"doc_hash": "e178277dcd78391563440649cb306a1a107c906089ee32690570ba0cada1ae0a"}, "2ca21c5e-68ff-43f3-8ad1-d2fd664a4410": {"doc_hash": "b2c6038923f3f80469f17ef73717cde32a45dc8df5aa4c6fb7859a330115f986"}, "6fd60630-ec63-429a-ae1d-c56b07f140b8": {"doc_hash": "9095b41d92ce3b228c8b487d66b905024fd3b6d5aac0e4b35b4bf31283e49fed"}, "9d00581f-57bf-46d5-ae23-64b494eaed50": {"doc_hash": "35969a70435ef95c30c4ea9497e0ec0e98fb821d8b848a541fa8d9a7d65d38cd"}, "e585e45f-ea96-4cc7-8e67-6c519728c3b2": {"doc_hash": "4c92e980b9f1da6978fa80e2cdd2b51477bd43e5344aab7dbeb167713b5165f2"}, "8ebd7d56-3f00-4afa-9e47-85dcb2417b5d": {"doc_hash": "ef514857c1d238d92fbfdc0a7a88076cc2807e0bb63cae3c17f3c74105f70552"}, "fb6a1471-e28d-42de-bf7a-f97522aa4179": {"doc_hash": "e91c420c25ec585f6a769faea945f876abc8275cbdae39c28c9615c77d202ddc"}, "7689f001-6397-464e-835b-b052a0682eb5": {"doc_hash": "2fbe175eddf9be6c13ed435ec4da0a9c4b3211e66d4c1316ac3600d6b833aac4"}, "2d63168d-6b7c-444a-8591-79839a9973c7": {"doc_hash": "f13ea9d3b5fc36da9a04f7684a6ccfcb26d95f4a2c8e9b570474c43775777919"}, "182074ce-2b1d-4565-8074-df6c51091fe0": {"doc_hash": "ef32387e2453b96a89388ab1ea13638f7dc5943cd717c81c27ee7136a5f9ba43"}, "782c106b-e93f-45da-ae1c-97cbbd2d352e": {"doc_hash": "00e6372d9aefd70cac07ab0d643331f438d8a75786340785a5b819c6c4b7c505"}, "70f2979e-0af1-444e-86e7-9b92f90833ef": {"doc_hash": "3847ddf0f6aeb9ae91a3e3cabddadc7df3236c43de4f4babe662d2be68a53970"}, "685da344-9e72-4fed-86ee-198573f34a27": {"doc_hash": "536aa957c7d5aeeec24f4f9e69d8283715b46556a5a3e647d3bc79ea0e473e17"}, "74811923-5cf7-4369-bbe1-2354fa68a064": {"doc_hash": "f79a4677eb3ec247d215cdea4b9b6d9ff2788916abc24bc9da44367d4f748c3e"}, "badc67df-81c3-4aff-a5fe-e101ecb89e68": {"doc_hash": "f0dcccfc2b6a027cfa6f9ced7cd934ed87e8e23d8da569dbcc338f0bb437bc3f"}, "5fc42715-0af8-4b7a-9a61-e3327402d5c7": {"doc_hash": "1c9179f69a923e83ec96d726bb075f3b886041084a5b826c15dd5646140df700"}, "fb79c043-e399-4c8a-890e-2805cb99283f": {"doc_hash": "20dd929aa4f1be3eddc0e62da5731e9f843396daf133a92ebfd95b3036f2aaaa"}, "6c47e8d0-e22e-4ca7-aa77-33d53d85a4ab": {"doc_hash": "f8e63bf519f95052be8df78c62d7a2541f27f9dff7a5f2aab801453c0f0a5941"}, "42780557-7e7a-4ee3-bd26-8fd7b118bcae": {"doc_hash": "c2861b98853c38e42204317955d12b2dcbe089dfecfa8d400822b5ed5a104c25"}, "01a8024a-8e6d-45c7-a7c4-d25dda5fe63c": {"doc_hash": "75ced02d2e8818030b52b39c20451fb014aad8515faa36e621c3d5c4c3adb410"}, "80957618-a76d-4a4b-b7e3-d9eef427a02a": {"doc_hash": "6f94401cff2cf173cb1e73e884b3c2b5d94e16f64b4afa9b136ef402f685fa97"}, "880d7c98-e9d4-494f-a5b9-3c83478a397f": {"doc_hash": "c75e54195c5a37a1fc66e2507abe13b21fa00cd77a0b00dbdcf9e31f4d06c7c6"}, "bc967d8d-72a9-424d-ac46-97a7bf856925": {"doc_hash": "6476203209ebe273d73ab97968cbe61cb5ebd4f1b6a69e0417a1210711a2b1ef"}, "fd038975-d881-47b5-952e-f18bfa904934": {"doc_hash": "75e103a545ec637fb2fd80518b896a9d0449d9d8e0cfc4371b1a6f28cd4d2838"}, "f3433c19-3cfa-4568-aac5-2d33dd962551": {"doc_hash": "86d8ae920da2701a69849759e452172ae296c7432bdefd1f4227a7f08aee35d2"}, "2c6583ac-fad2-446a-9a01-d970ab7b35f3": {"doc_hash": "f3b58af822369cc442142cf27b91aeede9181d9959054b92dddd87539e3863b3"}, "9aaf6dec-7310-4665-aaa4-6f03c204dedf": {"doc_hash": "33e0cc46d116dfe00bd41da779286cba2ed14ddcb69014e2737eb4bfea937074"}, "f9e3a8a5-305d-42ac-aac7-30356e286636": {"doc_hash": "a809613e01b8fad3ccf785ba8938fa1347d0801ca1bb85ab1502fe11458dbe3a"}, "3d4a3e8b-4492-469a-990d-261b7651690b": {"doc_hash": "48d30fdf568a60f5f829991a67f893f52bc20a465398d817f17523ccc79cbd61"}, "eb77ae05-3d59-40f7-9040-722e6d740909": {"doc_hash": "4dc5b0874aa8033ea4d8849cdfc1957f4ec96daef5efe18d41a701e1d390f1ce"}, "3c7344ee-13aa-4b65-a9d0-cbcaabb120b5": {"doc_hash": "6fd097118ea721087224407147e678640f2660b5d906111c9aef296f9d0fe43b"}, "c6f43c0f-71bc-4e43-8553-64a56b2ffc74": {"doc_hash": "3f79eb1128237ff2a4552658e777eac58be5697d26da639db3d0c6146b47f1ef"}, "10907192-7b46-438e-9a2e-cc1a540d78f4": {"doc_hash": "699790b126de71c8e5e84cc50d93f616ce8a871a279079567cbccce5eb9ee46f"}, "7388b28f-2e70-4a83-a4f2-75fe5a5a769d": {"doc_hash": "63da0fc323947ee62342905821c65b611291cfc21496e1931b845e56e15e3d0c"}, "4a3d1087-cf83-42c2-be7b-99f4be07949d": {"doc_hash": "2e0a2d450c200b461f799e4c01902993fdeaf9237e13b3f1c04e55b5d9893467"}, "48701dc8-35ca-463f-bdfa-cdcaeaf98dc4": {"doc_hash": "9e2ed8be8949318de03a802f38eede83afd31cdead6561408758db6f8aecf377"}, "a87c9eca-a29f-4d18-a6fe-e47981d0bc57": {"doc_hash": "f79893bcc7ed7497373d85a25efadb8df4c376b6abc42a460f92ca9ab7ad3c28"}, "4c4a03f2-c630-4290-82f1-e24428ddaa6e": {"doc_hash": "28a14c8622fe58d16db32fdc7f862fe203506893dc559db2d831e31e398beda4"}, "27a26eac-3b1e-4805-b232-e7e18c8e87e8": {"doc_hash": "1fef9136011718048f9cc6113930fbcaea1660bcc0c77b91fb7dd35e3094e7a8"}, "7383412b-59aa-4959-b006-f30133170303": {"doc_hash": "032a894b0a2019c34b62d6b7b5dd79030a9bc20db1066e235f499f6378b4d603"}, "c4ade4d3-3f2b-4e8d-ab7f-c2904dbdee35": {"doc_hash": "045a6520f6acb25205ca8fac9584175ce75f4f56ac0ff5ff50c3a1c1814bedec"}, "bbe04038-cae5-41a7-916c-f286f666d0b3": {"doc_hash": "9ba6b03874b57d27fa408de27933a2841a15a102ebb0d73011cd6acecdea2b8c"}, "4689ffd2-ce0e-466f-86da-22b8284b6130": {"doc_hash": "de727a1d6de64a90480c96f710e29300a91a04790656ac163323b08ceb82a163"}, "9fd5a20e-b11c-4c4e-b4f8-cf1f48668498": {"doc_hash": "266c29cb6acc239059d35ee9ed79ab546feeb4fd3e3398ebdae1265077e48203"}, "e77e9a4f-a121-425f-99b8-a8b3990348ac": {"doc_hash": "27f3d0ab45d788598ca67a970908aa145b77495cac2b332e2285cf8c79a5d5d9"}, "321137d0-12b1-4f5b-9a6b-5374ca7eb51a": {"doc_hash": "cbc2b61f033c4950a85c40a8c18c2cf367863ff013b4f528bac9cd0648095e83"}, "692d6fce-e751-4840-837f-deda1fb88ce8": {"doc_hash": "c1e2c71dbd758916019de7323c52fb7514aa02811e0c9b1ef2687476b39a29b3"}, "8a549541-6190-4c20-9c6d-60529186fd44": {"doc_hash": "c06a524c8a10e3e8d0849841a927d37fe7aeb9fd2a695e3cb7a9dbd7f671e10a"}, "570c332f-974a-4a9f-b83c-076f0903802b": {"doc_hash": "4f97efc9869077a1010e39e694edf17e3ddf5fd1e87278c287282511d10b1e3f"}, "a7ac41e1-777d-414a-b05b-473ace63fcd7": {"doc_hash": "71ccd7ee0f3b10e561351287e51e367aa64c8a403cc69603a0470a9580e91be4"}, "f4a1ed1f-2fe5-44ae-bb92-0cda14799793": {"doc_hash": "66fdbdccb9fd3c98bda3c1487ec261b2937b3aa1e925f59077d029f01e633a21"}, "a6c6a51e-108a-4da7-b7da-9f1c09e20e16": {"doc_hash": "49a2cf516b978025962388cdfdd572672da24b0e47beca122ffafce5018c37fb"}, "f8f2d3af-cfd0-4a3e-b985-2a2c561f9d95": {"doc_hash": "12dd2149f24dc8e6c30bcae64f8d843b17dbc2a9262f1134b7f7246ffd966bf9"}, "a4760bd8-cc29-4b3d-8c0c-f002b86c24f8": {"doc_hash": "51e90acf1af95b3a9b7c33af4a86c284694adc8aea6d15bd36c9ee7e75fb3e2e"}, "e02b6e93-b012-4466-bece-2edfd493235f": {"doc_hash": "45aee66e7513449b468f96f28a4ae5e7ae7b73409da3c49eea11274d415d4172"}, "ec3e1332-847c-4661-b304-8758242fe868": {"doc_hash": "bd6335e36e0d8d1d0b319c1b23abc0d238be66dd62bffe2d4d5a5154b4b0d46f"}, "c9a7a47e-ef38-4c07-bc1a-f99a040ded96": {"doc_hash": "c15a791467b6eea09e62a63e7ef650cdeef4a30880115eb160a6541725944464"}, "b4b7480c-472a-4674-ab75-e02c859593e7": {"doc_hash": "63a3c59c8ceb195e9f3ec3ffa71110bf9bd9f0c01ae4a8d7e8ed9346791746c1"}, "9cd169d3-0bdd-464a-b62f-421fee763c74": {"doc_hash": "7ae1ac7b521e06ef6f2dedac05ef51a343eada35cbde63b987754059f6def71c"}, "5fcff00f-a6ce-493b-8295-7f3714e66941": {"doc_hash": "9f3fd18d513f6aa6337a8d6d7460997d9dda2d0c162f35d73c8a0ecec1990511"}, "13f4993c-4f7c-487c-82aa-f0436b0628d9": {"doc_hash": "ccee096c172d671eb8fe1d396dd1979703509d357198240842e990c3d3939eea"}, "101989c5-5d47-42c9-b8e5-bae826260e1d": {"doc_hash": "9ee90b61f84c8f50fd01b760b539627008f8e2ad23e1d8a3707a9f2fc8968ca6"}, "ef073839-8e76-4cd9-9d9d-ae92b71b6487": {"doc_hash": "4d7f60b9ea5d7e6648df8f59911ab15f5ba27c0293d5e9299e7af1b5a917a0b9"}, "fa8aa981-7e24-43f2-945b-934d03eca0dc": {"doc_hash": "f7b68f62191fa8006253b1b607311d2925eb34ff73f5d0bb2cc28fa54e218ac7"}, "fa1ea493-82e1-45f7-b3a2-65fba75c8af7": {"doc_hash": "d3256b67d650cdf2f44664bde78313086a154e4a0b1e522075f986184dda0b46"}, "f30dd88c-4740-455e-bf42-9d10855aeca3": {"doc_hash": "eb1d9f908d6b84c5961fb543f966463b9fee2b3eb822f0cb24456ffda841fdd1"}, "70190edb-2116-4383-93e7-9dee271d1caa": {"doc_hash": "c3fdb31bc85ab75256d56ee0d38edf309888fae9fce46aa89b327a13c0190d5d"}, "e819e555-dbf3-4ef3-b6df-d90c42860b4d": {"doc_hash": "83c2583c647317b1c0623705dc6ceffd6afb287a3fdf4d1cc250d2d0fa435d02"}, "94c78c48-d0fd-4c0c-b078-03462eaad417": {"doc_hash": "837ec16835a9c01c08455fbeb31afb92a3493a0d6da76d571ff3a2dd43c329e6"}, "fcabbc94-0638-4fbc-92c6-110688243cba": {"doc_hash": "66bce0fc5651427caa826d5a9cb61a5f6dce8548458ebb110f4d7093c0f57770"}, "dcae9e6b-0ed3-4548-8eaf-24513f19c727": {"doc_hash": "3785bdef0e29eb7c826456d5e626723a39c3cf07356d37e7129ac8a3656a0783"}, "3504329c-9f11-406c-83b7-c3ddee4e1072": {"doc_hash": "7bbbe2291108503c995382ca9e96da05ded8a34cc74e03aad058f1cb0cfdba8b"}, "b82fc84b-8857-4212-9195-0f7f05d0bdf9": {"doc_hash": "de4c8af3583f0c622af4b64f80f74e0fc90b7531771fb2c6ad22b9a7f1c35be8"}, "897a9dac-42be-4d8b-b48c-f1d1c80ea3d4": {"doc_hash": "9545f307e282d01ff6029f1993c48f0c8df241dcd052fd2d66baa09de4fcf472"}, "8cd78a98-f208-486e-a6d3-48e1e3fb5f12": {"doc_hash": "be83870deac0e716da4d6054560155745790356a6040d4cedd2e38c554adc337"}, "349b78f4-c963-4a4d-b842-aec9a42c2850": {"doc_hash": "5158c1ea09d2e9958f38a2631cbe614c206c4762ba4d2f0f5d729a021127523b"}, "dac194fb-3182-4124-a288-137cea9fb16d": {"doc_hash": "62a8e16bf946c8c50bf99ecebf7c2dbc5088ed2e62e61d9f17696709104c333e"}, "120086cd-1c64-4e43-9151-6a3ad4f79a14": {"doc_hash": "989501a220326ff01c0628e800ca0b1de01ea3e05b835e59626ef2bd011e9b63"}, "e58aa6a7-5c07-40b1-a908-d6ce35fa482b": {"doc_hash": "5c666d8b886291471848cdc63e46220545dc3e430674ac3cfa6a893745a44c98"}, "53123884-ca99-41d3-81d1-00199854e400": {"doc_hash": "8935225be6a48e9fed5507ccce5e969db953e71e86ff4a7f3e84994f03b9b739"}, "1deb7187-cbf7-4c19-86ea-05ac5a280499": {"doc_hash": "836aed02ef6e064ea55eb892a3cdb6d7ee0cd0d87447b31fec1fc6c5e7def50e"}, "04dac2bf-2c67-4630-9686-2fd2e22e99d9": {"doc_hash": "ae756e336a18534a3e3cbf1d87358b6275e484a005dd86d8e6b6844d8aa2bccf"}, "e9effa83-8bc3-440c-89fd-1e5d457a1c72": {"doc_hash": "ef2fa5e53814a459ebf3bc052a8d77e28def3131004b71c7a8b09ac377bf1bc3"}, "e115307f-96e2-43ff-97a6-da4eb80f183d": {"doc_hash": "1c0a1d99ccf75c70c467b5701a440058efcaca26f14cd7c49fab843371dbbae0"}, "bc377baa-1bc0-497a-acd8-41f16802449b": {"doc_hash": "48ffaaf3db96602ef57fd2d30dfca8b6a46212a463fa55c4e04151cf8ca02697"}, "c1451c18-209c-4870-9a17-c6f4a2d8bc98": {"doc_hash": "78fbf5958b13262d95d6cbfe53852f9f0c28737490aa72de0c8521b548592fea"}, "d19a91c1-72e9-4496-a78d-644e1b90c0e5": {"doc_hash": "68622f74db8df8c7ea99d87daf3c56cf0274d322731720bd8257e59f0f554fdc"}, "55a0e89d-7acd-476e-994b-61737a941e42": {"doc_hash": "bc4e52e732b847e2aa00e89266e5d06856d1360d2db1541b3dd59f8670405005"}, "41a919fc-eb92-474b-bc76-27329632ba03": {"doc_hash": "e44b02b75982ce48d851cf9f32e5bc22d6dbbe581048be86b6bf7065c534fa00"}, "b6f80684-ea9c-463a-9fa1-071882eff338": {"doc_hash": "d79fbec53cd73229d54b9df3d67c29a9f7d2f193c5f98f6d8bdb55763c111d02"}, "8dbd0a0b-edd3-46c6-823e-30aceec79a12": {"doc_hash": "3c6aef14356cfb56c687a87f93f32da3803911df88e14300a299d319e5026e14"}, "63d0e4bf-059e-48f2-bbf9-c878a46d0981": {"doc_hash": "17ac1e9ec956d7928ecb46f2056fb67c66211df61cf952fe6e7e387c67fd0766"}, "bef5acd1-6ec6-45e5-9c85-3234f73f9dd9": {"doc_hash": "e959c4a9793a00ef78e515a3792bae090ae4b2d4a54f3df0ce5fa7a3633fb78a"}, "a8d33be9-a4a2-476d-b1ad-ed3d700006f1": {"doc_hash": "4ff280230d688db96715abf6b81322e07f395f417fc23d8b32e90d39b23642c8"}, "8c59078a-b43a-4309-b7e2-8d2f06e4f05d": {"doc_hash": "9cae8105dd300edca2eedc05c46af2eb8b092638010663a187e91ab58698c3c4"}, "11c3a327-bec8-434f-9ae5-b46e48f1606b": {"doc_hash": "dc0d5c34f5dbec88addbf50054261b8d5f2aae0db41d5c82fa0f9fecdb9a4e3b"}, "e068f964-17db-4aa1-995d-7338b3e547c5": {"doc_hash": "82437f789a3a2fbfb3201fa9266fd65d51ba3cfb8c8c8170252e29def677f3c3"}, "9df54351-f55e-4e43-a8bf-8c2313051034": {"doc_hash": "63c6631948cb3f770673d7e466ad27c7b0605d79f083683d3b7386f747d757f4"}, "3e94ab66-0311-4fe3-b91e-8404af858e38": {"doc_hash": "3704fb0e722bd9a4c5df30cec04308f192f2a1b9b688faf63054bd3a5495895b"}, "88674dbf-c39c-49cb-a616-6afe413e5587": {"doc_hash": "d4bba03189e9a81d2b6f21997c7c524f9423934b7115537c416ad6b14cbe3a6f"}, "76893ab9-a9e6-4af5-9e42-6eabe753aa01": {"doc_hash": "9ca824041a8a0ee1071c7758c4029424da2a568ed9816d466b08941764a62b20"}, "ae5d25bd-0605-4843-98a6-ca9013b9925f": {"doc_hash": "ec02737a836f69fe2becb79784ffe4b13f79a82173e088cdb6f832e1c4ee4ec7"}, "91bedafe-a40c-4019-bc5e-9dbfcd66dd27": {"doc_hash": "7badc9bb876d7c595093750c2b6dcc97ab9b8adadc734a62fbb31a718240a132"}, "5e66b07d-6008-409e-930d-cc35efb3605c": {"doc_hash": "f490b6b86ac15180607f84d4a961583e63458f47589e3b93009c04513cccbfed"}, "ae338825-0a2f-474b-a717-484fbead0c3a": {"doc_hash": "5dd08047312a7a05942ea9eb9b67119169a7cec747bae182ddb6062c4334fb2e"}, "6561232f-7876-48d7-8209-493dd45ae370": {"doc_hash": "055eaa2a75bc4cb704dbfe172af6c1c507a7ed4db0331f31d3eefbc1634f439f"}, "632fd1f9-cf7d-4a93-acd8-9d0ea1a17fda": {"doc_hash": "296360405dd57669df770ff360da6df2ea6935b5c4be10dc03d2d23cd5da3cb8"}, "15a579e7-91be-4656-b233-8ac3fc6e7c5e": {"doc_hash": "3b9006856808bc17a95e41444df2e74d40a023f4a5faf3d7bed4f4621ad892ed"}, "d2373422-89c2-4817-a41f-9588f51255d0": {"doc_hash": "2e3237c05c4a432fe6588a63c72e46d94c0b4ae9155aed4cf190bfdc54e64a68"}, "02d8df6d-89ed-4208-907d-3f0a0b7185e0": {"doc_hash": "00719f142646a8f4da78e8770464db548dfb606560ec95b784a81045056d7dc7"}, "43e47fcc-df6a-4160-b759-f62d56b4d5ae": {"doc_hash": "21706b8d82bccc61dc41b3584c6ddcdf67d4d0bf4e57dbbf98dab10ea75a568b"}, "244d31db-68e1-4c87-a2e6-1810caecc69e": {"doc_hash": "7cbf416b2b463d5870e3f1bc087d9c8a44ca0cb527c9928038bc7e89692a1335"}, "ffb509fd-7854-40d4-88f1-6b41a92fd959": {"doc_hash": "753d8242410a5a91d84f96d7440cb6335cadeb8b79985093c3fd6e9e3868e7df"}, "eb1d1413-1c83-474d-994b-6614897c79dc": {"doc_hash": "b6544f0c4cbeb469a4aff689699b25699cb731c1fab99edea3d8a799ff38baab"}, "9d93aa42-ffad-4c4e-b041-16c167e14473": {"doc_hash": "79536085dc11dd87ec941215e7d5864f70a72413f05ab5131624856c8105b3bb"}, "8df0183b-93e9-4c8f-925e-5f73d9b977e0": {"doc_hash": "7f05ec9f4fd31a4b9fb5e7b03c53496c67c5a177c8cff03430f61a75db7925f4"}, "f98b5ac4-b242-4fa3-a2c4-e2bc91b7da2a": {"doc_hash": "5f19e2aa8d5fb495a126a28f1893214cfb6859436f7817b2c5a884c953140b44"}, "56775cb9-9a91-4485-a765-cfdae11ea738": {"doc_hash": "45610f9cac532db23252009063409442be45884de1e614e93e17105085c1250e"}, "32165c7a-5ec6-4de9-8f6f-b4cdcb23b94f": {"doc_hash": "b2280eb588bb4e4549713917be3c5d69399a229c8c3bedf23af6eb8f942c2b99"}, "8cc65232-5d32-4a63-97e4-dd64fc2cbba8": {"doc_hash": "b1059f935ad1ce5e0a5586922954b0c0b3226748a0a3c457646bc9424705a18c"}, "45596f74-d86c-4a46-9994-0a0e527075f5": {"doc_hash": "a517bcbcd667557382a49b5d29c5aa6ea3b61d31ecddea0f01d8bab77c2a2d0b"}, "70456fce-874a-49c3-8261-7d869bc00ee5": {"doc_hash": "d656f20116cd5fe6bda839f3246c68e115efe9a9739498141913422b4bd5386f"}, "7cfe2105-6b8d-4829-b1d5-475a53b165b9": {"doc_hash": "5c6fffd2491f755491218b1c68f41979f6cf910803ab32db8f0b12d04c683d71"}, "cb207bec-2c1d-4bac-a875-dbdb79f90efc": {"doc_hash": "863d46f9fba25b8f456e277f2bb3d167b0b60309340a22df6f7dc2a3edd33e4c"}, "571dc5f3-f6b8-404e-9c99-0fccb55763c1": {"doc_hash": "f08967429f7c50efea1543ebacc8143121e186f5466241c62a498ebb5dd9b7a7"}, "99125867-af15-4e4b-9ab2-49c26c29ce32": {"doc_hash": "4e4e7b31667f5bc0685e4e79fedaf9d78f5395f0364db82bbbceaa3870e50aee"}, "e3f64ee8-7afd-4355-99be-68defb5c86b6": {"doc_hash": "6e24ee07b9365e73779362bdc63e1a549b60849abe964db67af8e65d148b4fcb"}, "20c6c5c7-c1b3-4898-9b01-1b59855d8073": {"doc_hash": "fd44134e2711d248d4b3ee11b211af80197d1064ba87870c9b7b58b90d2dbb18"}, "fde6e150-9d5a-4042-9433-2425a22f6612": {"doc_hash": "fb6d883eca5124ffd4033a48df952755a2029f6e30ee695261e7b92e15d47625"}, "4325e93f-f4ee-4f59-986a-5de587fbb32d": {"doc_hash": "0bb9027791a55bf22381270752dc92c7a9d4305884759cbf431b46a7c13c14cd"}, "70b2b2af-1712-4347-a379-cb0484a82525": {"doc_hash": "0e7fcdce549ea200a231adb9ef22064b4689a720e25a9e8efe5eaed4b0e97788"}, "95a21f24-d67c-49e5-93f2-7b2258b2a07a": {"doc_hash": "8ef71e8e7debc2317cb5d05db2ca13f9e9e406f88c3f6c0ecb36dfe252796e31"}, "c3054673-a6b7-4b1a-b5ef-5ac306bdc39d": {"doc_hash": "09a9ab00c694067796cbe6cbf69667b086bd10e554d9d8dee9cc5bbdb5c1b5ff"}, "a4c0c55d-26ca-4382-bbdb-310d709e2a24": {"doc_hash": "df75a72e36385e0aa1bd09f6726d0b6097d34f032c8ac116b5d5ab903ae335b7"}, "046cabda-68d2-4356-8a2b-6f75027a8c35": {"doc_hash": "2a6286985386bdb586103367e1f055341350b73d85341ca1d04ecfa9e6c39a3a"}, "2e38bf80-4328-465e-930b-0dffc8ad0efe": {"doc_hash": "955969b3b77b82270456759117d537f2cfcc5ff41a95ad8be36d2f46ce59975a"}, "df937357-6cf1-4c23-ab7d-1e20fc5bb765": {"doc_hash": "cf0f6bb33298a1589db016ea45bd18be826222e1dba937e9198108a663c377d2"}, "61f898a3-3505-47f7-aefe-722bd418354c": {"doc_hash": "179994e2c25725388ba1e7499e60fed7538218727efba2eaef62b186b12165e0"}, "04c8f721-86f3-4074-9d1d-4aa5674924ac": {"doc_hash": "ddbc398cc00054efd7fcf271d05c6700d858aa60a4a8e4a53cebe1300c4152a0"}, "8b1f4c30-d72c-4900-b65c-0273b0279177": {"doc_hash": "683f9992e6cd0d7990af74007e5e60075f7fa1105653d1977988f816866e674f"}, "066dd50f-da66-4adf-b597-7858c3232b2c": {"doc_hash": "6d06eb0bc2e1d4c8c18e382f1d4c135df99634712b7f2e8e6d93b498ff975286"}, "3b0fcdde-5394-490f-aefa-6c7fb24d1bc2": {"doc_hash": "a1b2f001d686a719bb111fa939cfbf096a3e91a170efc4325f6032fa9e2d3bee"}, "331cf6f8-f379-41b8-8309-2ab814ae8ac8": {"doc_hash": "c0c4a762315f4a12c4da3076de0222f96ea8cf84e8b949c9c0f5459836afe47b"}, "180e7636-d28b-4af9-bcbe-a1d13992400a": {"doc_hash": "9af8e8fb413f34271cd7fc514d0f44492123029a8316cc4d960679137cb9bb18"}, "e61c1878-d98b-4ebd-9772-c0529ce2dd8a": {"doc_hash": "f1bad15710ee522ad5900d70cf5d06d448658d97a8697c3da63fc771493a6942"}, "be6940e2-ba9d-4119-aace-40c2cfd19240": {"doc_hash": "33066dee997f84da4a2ba38a57438c44c2d1da370cd2b1d92b8f7f1442e39e0e"}, "05ae72b0-ed40-4e0a-94ba-d6cb9b4e84ba": {"doc_hash": "9bb5333a5063d2c7c29ac9b64d83b78f7691529d4e78aed27773de7e39543604"}, "a3fe2f9d-23bc-4b6a-98ad-4e4bc85aafee": {"doc_hash": "6c0c06edfaef9b2ac0cf363f32502429c1858df0600597fb31e7c187a610a7d3"}, "ac5a12b6-e7e4-4751-bd4a-42adf9cdd960": {"doc_hash": "c3084c11778ad9a8d388ce58b3683d22a2f31bd8c82484559f3bfadd5bd74b5c"}, "ba86eb15-39e8-46de-a52c-a5f61605c75b": {"doc_hash": "b8a923e05449cbc80fdca55771bc11ccaa4637537c0595f46ef5fec763119e8f"}, "fe0f92f3-61fc-4dc1-866c-a4103b4bd1de": {"doc_hash": "30adb22c3010a7dfebba9880e62972584e05617c65cf3cebe66f0229faa17df6"}, "08e834fe-8e94-47e1-b8d7-0f657fe2e0b6": {"doc_hash": "f8cbb53c7c4b97a5adb50060f9f14b274a10a41dbe97f3d746f9897a386b7e55"}, "2f5fb929-b1c2-46ef-bad1-d8f73f4ea6ae": {"doc_hash": "3881457964f6b56059a0d440600b6d97be09d9484bf59148ffea011bb18b5b7c"}, "7ed51720-b57c-4450-be27-f9e6d02a3159": {"doc_hash": "3750fb292727e223f06d6f4b9711b97e3e1c2af6aee8200abc0a3335c53e6627"}, "779cd096-cb94-4c2e-b77b-55a48dfbb162": {"doc_hash": "4fa46a31a1ecf888d1efd6d9412fafaa5703f58b9bd6454d1000a130af9ee564"}, "94018cd7-33e0-42da-8feb-395b1cb83aae": {"doc_hash": "8a6d72ef5fc15f4e8b0e20561195f3711c6e2b846c93dc45c087832da402826e"}, "58a56288-3abe-4112-b787-c20bf2e77407": {"doc_hash": "b2b8c6df77d6bec8b84163c87ecbcb2472eb93b35e39645f91d825cba2bedbbb"}, "d888f7d4-24bf-4b41-bf12-849a09e0ffb6": {"doc_hash": "9ef0e56c69ffbbccb8b6e50d871c3422d3881fa62d990c33fc430f781751f925"}, "1c32d2d2-a102-4e57-9a3d-e5bc8fca82d1": {"doc_hash": "fba8d1b0996e278c5f8acd5962079a24513986c261a20244c4954b22a4b88689"}, "e7c0957c-321f-4cbd-a91b-cb7e692c3874": {"doc_hash": "8624306b53f793f129a7a32657aa79208f745333cba9fa33685bf16a635e6f4d"}, "361606aa-1713-4489-b56d-5285d1c27657": {"doc_hash": "231e944ed1c13fc7e525c58729444a691ca8e36e6d0a0bcac431065df102d100"}, "a63104b6-0e48-4923-a63f-1addaf3ca9cf": {"doc_hash": "ace76adca162410dc99fd42653d584614f821676de213589f93e672517d077bf"}, "0ed7352f-f67c-4486-ae62-a431450d5bdf": {"doc_hash": "2eae3eb953de82aa3f0e88b6cc032def4a77641211f45661837ceca4815cf01f"}, "94d60388-c035-4160-83f5-6954ce104677": {"doc_hash": "40bfffc5a51dbe2b55732f346068e68bde0d1e46dd85abb48b833d1b7f62c975"}, "417849c6-6071-459d-b333-1e0dabb002c2": {"doc_hash": "be91f47826f4824e22ee323491f3e4b5134a6d63599c666ce434ae1013a07de2"}, "315db3c9-3770-4b9c-b9a5-e0960820f2e2": {"doc_hash": "eb72d5bf68423098bed100c9d4c905c7386e30600a076bdc6f8f473e6d32b983"}, "0bd98659-5e9d-4acf-8449-76d03659f49f": {"doc_hash": "0c98461172171043235e54f68009342dc24eada6bb365c7b6fa042b65edf28ae"}, "85671103-136c-4829-a6ed-047bf9c5cef7": {"doc_hash": "86647a9090c8b2007e9d8cdd0cfc199b79318c236ebcd610a3f4291869539c47"}, "3e96e818-54b5-45f1-abbf-dbe284c9d3c4": {"doc_hash": "5ef718af4bc881d27a8891a0d98abb2915f8054ea19df83521111c554ffc9973"}, "5b57012d-16ae-4703-8d1f-33797dcc6c24": {"doc_hash": "b5a630c0718129d0c678cdc49477e8847efc2329058f3b86997acaee4e96d4fa"}, "72db3bb3-a494-402e-884c-9d3149ce5141": {"doc_hash": "a86a320ab3e088ad7f52e6e4e9d1d096bf761fede821ca46d1b49517c701715e"}, "e0f8dd35-9d54-44c0-9b49-96d51aec6707": {"doc_hash": "cea9c13616a2bdbc2795e03129e0eca98b4b99789b97bfa4c7c403ae5421f82c"}, "113aeaf7-a055-4606-997e-1f445cb3eae1": {"doc_hash": "0d5b6fd631c6ae0a0ca6b23a3e195a8f5f655e83dd5a7ee4b4146549fb91faab"}, "74ffd9a6-73b5-4627-a211-b5b309351d1c": {"doc_hash": "4cace9990aec366a188335913a91a5cb6d793227d43e702912d55c55125cf68d"}, "b2af3b2d-d93e-4473-be74-d54fa1bcd703": {"doc_hash": "a8f2c2143b89d0d9b538c5aa920699927bf8cfe4dc5c695d6e737581190392be"}, "f48d65d8-1c5d-4e61-ad55-05d173dad989": {"doc_hash": "70d20d3b3f5726c55cbb7b0e809e98735b40b046fc3ba65f7aa3930d5629a62d"}, "7b323e31-7a2e-45de-80d8-5f2094542b59": {"doc_hash": "e761ae2d14bc048c62c60ccc027366fd93b4d4b4e9cf50d4c43d9561f9745139"}, "9b73e692-0940-4775-b2fe-59fab7521895": {"doc_hash": "b6cbca692e2b3999cbfa7464ce985c238aeb61fda3ccea26eff8e40bd7eb3b61"}, "32b208e7-d5a5-4108-bfae-ff251648cafd": {"doc_hash": "f1fa84cadfa4ef7549bd86d28a9d8b221c985b4beb1c23308f75d2f1ec2a87a8"}, "9b244cca-6c48-4263-8db8-0664b66b0c1b": {"doc_hash": "3ce8074ef05dad4c265a093cdaa9ae77a4ddb42b73f9dce0848b39fddf50d478"}, "25d69c77-9650-4202-81fb-1773ea2bb043": {"doc_hash": "26980ebf49901793d4dc7a38ac598832f67eb73b94e8ac05986c4ff0489ff3f7"}, "1cdd62fc-fa0a-41eb-a95f-1b8b5f199934": {"doc_hash": "d20edb0d23f5c17b7f0d03f20e44a41c3de62a29c4dd4259d72a1577a96d4b95"}, "154d101d-f3d0-44cb-bdeb-541bf45ad455": {"doc_hash": "26a2ed7f4ed4eaf236b3363dc9c387ec083fc6bba764192fe66d0bf3787ea125"}, "0222f807-3aa1-4b6c-a24e-4d4ac6877556": {"doc_hash": "1aac0f265424d0dd42ea6910de65effe80c94c909616f7ddadf48e8f898ce9d4"}, "0c89e2e2-545b-4398-b16c-9e0d1247f8d9": {"doc_hash": "0ae5b3735dcf4bbc22e25e40dbdcfd3ba42909dec2f019e4bfb9c431adfd608d"}, "90c51afa-1fb6-4bb1-93af-904c97a505ff": {"doc_hash": "b2d50e9d9d79d5851f946b1c8f5b2cfbc168a46905bc7290ad4a53dbd906ee06"}, "901c04f6-05a9-4087-aafa-6d8508e13ebd": {"doc_hash": "fdab60261ad7a92bbde4fb130e7674c555d0d22f397557796d231cced24e04a6"}, "c52e9a6a-74ce-44a4-bd42-367e0d5be239": {"doc_hash": "3f7380d6cc3c93a19c30b6087fc52428578a2328722afc8c81d0f20cfc09076f"}, "f13c919f-ff6a-4d74-9ecf-1132a47d4282": {"doc_hash": "48266319e42514308801d292800fae83e73af5ab1012510d973c04eb674b198a"}, "7aa6bc14-c7f1-4fa5-ab2e-a3635d549fa8": {"doc_hash": "ac5d09238af4d5262ac4ec112520737ee5200c020b06d508cd0979b8629efbac"}, "4e77d0aa-c908-479e-b0e6-aeb072188df0": {"doc_hash": "5bd9685abc7279bed35a06dda8ade129065856c2fc97ce4cda15d8155c0db7cd"}, "b697a4c6-bdfe-4623-bbd8-75b54ca71517": {"doc_hash": "47a26758df00ff9578e6ac090d9451c15fb98ce9a532ea735023c74404490451"}, "6f412e81-1f46-4200-8eb0-1af4b28cdbba": {"doc_hash": "c3ec2eb476a497631ee156a1fb2354e9e78ad736573d6367d71fd0d47cc30838"}, "f9a0291d-3501-476f-ad1c-22f14ae9fb9c": {"doc_hash": "bc04da8bb8aef603d511ba3d26f0851492bc40c682f82d5113050ff8f3d7980b"}, "7e08609c-80e0-41b1-806a-3e52b1562344": {"doc_hash": "d4b690d1206e9cd8a9b7fbeeec8f952bca463543942fffa23452c838efc47eb3"}, "4c3776b5-ee4c-402f-aba7-71874bece099": {"doc_hash": "f74edfdd39a0de9e326db87ac66158a8780a898608fab57a0e7535ad71f64486"}, "73b42b33-9509-4c87-80fe-48948b430738": {"doc_hash": "a89ddc212669f54b0cf0c032db3c90133f59af14f71798c5405e4955de0e58dc"}, "4659fa20-1455-4a24-a6e0-8e2089721696": {"doc_hash": "42add97ec53c4af48fc038977603f969dd2234ef9b17f0d69d25dcfbb99e873c"}, "a18ca057-d03a-4958-9661-9c4041de861e": {"doc_hash": "3b4cf34d97c091fcab67941c327d1a2534730f509fadb33164bbd5a8dfb0f649"}, "a7ca5fee-0582-4e4a-99d9-d423af12be95": {"doc_hash": "1eb40b25c3192a253c2ac375f46343bbd96e02ca694d81471eab7e89b8fda2f7"}, "3472e04c-a05a-421d-ba58-dffc4bbb0d78": {"doc_hash": "fb646f013ebc0ef2ca7c4138065aed059227f7fbab2fd7e5a56b3198a613e02f"}, "37dd03c3-47b0-4189-af7b-eefceac8e947": {"doc_hash": "1afb6ccfbebcca7820264a51d4f35c765627fcdf707025272f96d0dd444d14a7"}, "4e3c3e71-2216-4e46-a310-a2a425c2839a": {"doc_hash": "9c43fe228ca8d7966c45c79cd828c9019a7560381ef65044ec9732a5330b6e6b"}, "e54a2b40-ca83-465a-9256-c30746d157d3": {"doc_hash": "02978fca17d2e41de1b6e1228238f50e7045883e4adf7e6b4d62633c0a3fe381"}, "a2900eb4-d0be-4a22-804b-79eaee783be5": {"doc_hash": "7a444cba5ec23c6b907b1130b70fa787180fb9905084442fe788f93e778854b3"}, "f753a8db-e056-458e-be3c-f95c3e4306cb": {"doc_hash": "7ae2fba56f3e1fa3b8739690369bd8b6165b42a5589074b43a605f764f12281f"}, "45edf86d-776f-4c15-a56d-9fab04adc046": {"doc_hash": "f4945096549c351298845d03a1db268c2bf1ef29b339327d640a36c9beb3772b"}, "1c733f74-dbbd-4cbe-8890-8fefb5eb9adc": {"doc_hash": "a31c475b619535ca90d2b890e044bd0e87cbd6a87092a684d1912986d094f7e7"}, "651bb172-6715-486c-a170-f215d4de72ca": {"doc_hash": "82cd17883aea4eceb7de6ac8fa7e2b6753f09974b1d6c084cc185e6ba9e594a6"}, "40d35dc9-d9c3-4975-8b0a-7bd7daae3b4e": {"doc_hash": "4e9b73c2e4654d92c44b4acb0d6c726ff8032e908f94b7d75fbc505a26dfc36e"}, "ad195f0c-e603-4a5b-93d3-37bd6c81afef": {"doc_hash": "2ea1ac9e72f79a88359ef7eebce77ac116203afb3d72f65a47bbac3a9dfc5b7d"}, "c0a78c56-41da-417e-bed8-694a2948df90": {"doc_hash": "166085a4055c271682bb577a88ddeede51ed7f16239e9fcb3ba5b99066560eab"}, "7568404e-7c21-4f77-9a30-6c446080308e": {"doc_hash": "d945f89224163f6a64cc8079dd184205de079de7f1ebf72dcb342aa05b92c28b"}, "55177e0f-2164-4617-8a6e-520c63f7dd48": {"doc_hash": "d595dfcc7f8cadafcc9028455fb92709fb86e0f30df49e0db4c80315b7ca44af"}, "0dc3a88c-c314-4277-b5cd-486ab8b71110": {"doc_hash": "2495f7293f899335876a487c8050708fdb3983343b2d7d22de42978c52cd5eb8"}, "984a3c16-f732-40e9-928f-d7552e54ec20": {"doc_hash": "9b0a2a7ae99a7f7b04cfdedba7b497d5da9a6561bbb2ca663e3a8592e1c8fd1a"}, "41b5f004-6fc0-4de8-a337-57090114b000": {"doc_hash": "adcf2c10650ba24895d853e30e5ab7bc02665f12cec56c2590513bcc1645c3ac"}, "f0d54a8e-f08c-4ca0-88e7-d9c82d4d2bc1": {"doc_hash": "5dbadff477ebed15489c67400c4327b52629979cf4a543269639a0a9bc156c45"}, "4bc8c3b3-5f84-4fe4-86aa-5eadc27832ea": {"doc_hash": "e2efc559afce72f25edb70459040016ade8de447291b665183e5250dcaff7efd"}, "fa1d5db5-c4f5-43ec-b936-92b8e9c7752a": {"doc_hash": "c107dbedacec1c6791b946474b199ed00a29c327d4998a18b5b3e7314ccdec0f"}, "85f672b6-0a8c-4ce9-8490-ea311f17ddb5": {"doc_hash": "e52784dc22eac793faf2b89d91f693753a895fe871b331b9fc6818d17c55cc9b"}, "c527ea3b-8a08-4c25-9e82-053f85f64fe0": {"doc_hash": "d489eac6b45f387cc5a777f0b9eecab4f2fd2c35e6dd723b19f046c4d5acea9c"}, "aab4a435-1f5e-4d16-9a48-a1d09227d2a9": {"doc_hash": "eb017b8a1cf4686103db0086b5b839064f0c5cd12f1756fd558b50cd8af457a9"}, "7609dc0c-5228-437d-b533-ea5de7edf12a": {"doc_hash": "428ad5eaf20ed1dad7a71bc5159a1c8248e3720cdd564b79bc48e080b1cab9fa"}, "b7505f6a-f2ab-4742-851b-6e9130cd8cd5": {"doc_hash": "32472cd8e5cd4dcf8f310b11e1a92a1aad7a5a501723b5a66e0b43f5866ae8e3"}, "2844b63b-9431-4a3a-81f1-8d29b25495df": {"doc_hash": "2a468293582c678e98463dcefa73bbcb5247c29f6a289a317b07d07d45d0eeaf"}, "dbbd8e66-facf-4807-a645-263efdff6462": {"doc_hash": "81309e62f0132b0908a4bcc1c6652b5f4ded3a4c5286ff1ee0e415b13a416ce0"}, "aab9ab3d-9841-408e-9257-680a81fae8c6": {"doc_hash": "afb0d303877758b43787f161d910f2f8a34d1bb9142cbcc60830b8ea8e9a1b7e"}, "e8a222f3-e1d5-4cb0-a90a-5cafff2932f9": {"doc_hash": "9e6831e23dad7d4303c25c86d5576c19137d3ef8e52983ddc662b117f76a9e18"}, "18d18cd7-b1af-408b-8cb8-bcc9d16cad52": {"doc_hash": "f3f5459e9b01f7292a1a5328e81eefc7dcb0a508e5518bc2ce0195a6d0faf633"}, "337573b8-eb9b-49b3-8c4f-6a9062f14fdd": {"doc_hash": "e5c8c800d78c1ae48ad404cd90c6eb5c38cf56b64aa6ea42ace559f84c889cd3"}, "fd928c51-48b4-4355-bdb2-e134c90349b0": {"doc_hash": "518e032c0ccda57ab7e92a7a3fc0d181fb20f9fb27c896e6bb9c5de8f8354ec9"}, "807bf418-8695-4f2d-ab0c-3aec705b11ae": {"doc_hash": "01c518af0538694221940f705e67ce5ac91279bd514d2624f2497572f34ccc1c"}, "da7cdcd9-373e-4065-a663-3496d4dd9d08": {"doc_hash": "7590d972141cb68c5641a1e5d944ace8528ba99ef49b280f5fd4a7262534b7be"}, "9d6c8f93-f858-4c0b-84db-f1245c83c18b": {"doc_hash": "269c72fa00109ad5e2759d59259a068259e4bc048b7daabfeba5f2df8cfb422f"}, "bfd71d47-9022-49f4-bb9f-5fc1c150641e": {"doc_hash": "a4e39867661d64a833265fc075507a48e60e96a19143957f36eddaad50b97265"}, "75ab2bf1-a216-4168-8961-1275c31b1162": {"doc_hash": "a02fea202bfde232632cc4172ffff1b06f58b43cc80a57efcf2c6c402725613d"}, "c1e5b5ea-3695-4d1d-98b6-f0eb6765c84c": {"doc_hash": "19fba9e245c3e304903e508af1ae6ee963f3759a7fb9f20852b0a142c738c886"}, "4c8e04b9-b476-4ef7-8431-46e54244f8de": {"doc_hash": "51ef1d5647e02167c6b172ca455f5be619c3e4cf640ef7c4747f19dbdbf6c5a1"}, "aca903d7-7a60-421f-a56c-e9d5b056fbb6": {"doc_hash": "b08dc05452aaed93f80ef9a615ede0af7786d7bcf3d889a5eef31f47f753bd89"}, "ac9a4381-79c9-4434-b7c2-b50b81e7f11f": {"doc_hash": "d064f58702f949b536c44ff45269cbd9c6fe69cff6782fd794644036b250f926"}, "bd86a9c7-a2f3-498a-82bc-c323271d3d39": {"doc_hash": "2b1d3ce99253ddf6ead034a0d87af7ff6f7040afa0c646ad5f0e5154921c7c6a"}, "6804bb6e-2a8c-4db9-b10d-ced299655fe5": {"doc_hash": "2cfd6f79330c945a47a4ad60c5cd3a426a6ac8ee21b0a5451a2a76e579b70b75"}, "17981f9d-35ff-4299-94ad-4fe65db58d04": {"doc_hash": "dcd1358a4705b9e0f4881fd62fe6a9b33de8b8672237406eb793c93ec47ab9c3"}, "ea624d00-b60f-4e8c-8128-997996b781b5": {"doc_hash": "53f5ac18c4bb9bfbca4101ed9acc0a9f6c869c34a25b3eda2a2b1c6d5fffe27c"}, "93bc5df9-d52a-4496-8064-41969f751d2c": {"doc_hash": "d05e32bab4f9782967ec1392c4f30fabb5f7b6a4be394c79547ccb999a8ee8a4"}, "fc0b1b56-06d4-4d94-8a55-90e48d0de69d": {"doc_hash": "8b94919e6db137f10ad975f9446a14159e2b688521f05e344aefcdf25f6bdd5d"}, "b22f537f-ea44-4e7f-bc31-b6bce9f7e89b": {"doc_hash": "c3a5ca5a47ad571d1c3133d808c7e2d21eaed80aeb7501a8f452fb147b9490bb"}, "edaf2361-3251-4533-bcdb-d5372a2b1e83": {"doc_hash": "7b9c11f4617050c2ff058c115256b37d8eae2e078328c5eb25ba674cb563fc46"}, "3f612755-36ff-4fb4-8251-f518832cafb7": {"doc_hash": "d9e2f850c8a9e68e3092f20aeb5c6040368a03a461e4cf9b3022f4d880311929"}, "26886055-1272-404f-86cf-43b0a7c8fb9f": {"doc_hash": "77f58a6cc83c23ee9bdb7dd65973ea25b0c346214d49a9cecb5ceec5a857e5ee"}, "e97a197b-33a9-4148-bf5e-a64690ce6f73": {"doc_hash": "be7cf4111d4adfe037dfcd0c44bbc20c2266f41c73ff39d8322a311595835bd6"}, "681e643d-69a5-440a-b889-4e0b278e7a16": {"doc_hash": "704bd4820927f26d5d47a95d04305f6abb7d74f20038f86ba4debe7e15e6317c"}, "f9fb1eb8-6fb5-48b1-875b-edef37e28451": {"doc_hash": "167fc81d0d00d7a0f69198f2671ce8f7203d39a1530a86ffa5efd85fc2014407"}, "814a6b8b-bb00-4c6b-8ecc-d3aaa5ebe9bd": {"doc_hash": "78b3a6744f08e59e2961705572b02c4f33796dd5d861b502ec300a886d44e95e"}, "5a36ffa5-2364-48b1-a318-d05e7ff4b80a": {"doc_hash": "610229de352f8c83828ac55a3d6b3aef8a6fb4a844af9a473f0fa91a93fdefb3"}, "95b57879-58d4-40c8-92c9-4ff3d9aac971": {"doc_hash": "ca9c13d4fdcc444c5dcf952f1d60b266d858c860d39b43227dfa67cce28d9ffc"}, "5ea55572-9ace-4e57-8122-3618ad87ce1b": {"doc_hash": "0895dba48e557c15a14a0d84248e023d75555f3fc1ddf7b35eb7455c3e137d65"}, "48065c45-d81a-43d0-a2a4-77a5c1840b39": {"doc_hash": "11e60f7797b8a8ee2140d7d537da49e65a0b4df70147db6ec48e2c4bb52e1f8b"}, "7f974e98-5d74-486e-8c28-253332114f72": {"doc_hash": "abc5629fcdde401cf2f69b1f116780b5316405909cd9a13932fec00f5b4da63c"}, "a18b9e57-86fb-408b-91bc-ced7c514871a": {"doc_hash": "e6dcbe909fd63c47f4e3e27f36d902a4dc679d5bb18f7662fff4d6d98d0cefbc"}, "98da43f3-872e-4d7e-9003-33320020571b": {"doc_hash": "b2ecf86486b6935853aede2b980a4b9b323f7a74cc8f5a140778bdef5b5c72de"}, "3ed1b11c-494a-4b15-aad7-a0d00d623b18": {"doc_hash": "b5c0e9b702fe4258663ff221ad982b697b5519099d358828562be162cf752019"}, "076130c7-3a70-44a8-99a3-3626c990a964": {"doc_hash": "d69e8a78ab1d0ad32b759e5afb3d4f8f455b87a95cf2cfef3d5468e1b387cbbc"}, "a679f071-1377-490a-a369-e5249eb29995": {"doc_hash": "31b21ee498066b4c58f9739f78050c77632ce3289a2ed935aea128694652e60a"}, "071bd54c-1843-4eaf-8f29-f03b350d1fcb": {"doc_hash": "d4140f76e6478556db0fbc88cdd3c116d29dda2dd87dc81012cfecd9a7ee5f2d"}, "affc46bc-a6cd-4d1b-b07d-4da9af6c9576": {"doc_hash": "d6c24dcbf84e7410c881ef57d1d70beefe516a0065056ed198a4990c94d6b8e8"}, "dd338691-43f4-4ea2-9327-98a13f024efc": {"doc_hash": "cd6eb9438e95d1e7d48f0f2a23dcba5a916538f28ee88e90bd26a15b8cbec470"}, "40711827-2ac4-4bef-bc6e-8f634f086b02": {"doc_hash": "db22ec3594898562302a849914cb14d3ced01023fd4debd07724395425fffe59"}, "405109e0-dbf8-4f95-9514-8a68221fe332": {"doc_hash": "663a7e2233263d10a093e834d54566cadd90e86d753d60b5c2022a900b8ba813"}, "0a12e305-b689-4399-8823-f8d7b6780a06": {"doc_hash": "3651974b3c3e539e4b6ef0d8dc9e897f2528bca292adc26bb0693a9305255cde"}, "5f5a1e72-e813-455f-a8e7-701d96a13a83": {"doc_hash": "7bcd81dd3e71d85567803311adcf3946c80135b4818bfee624e5231630a2f1a3"}, "83410c06-7b57-47f1-8752-3f65b886cfaf": {"doc_hash": "fc7fa7b76212c089434f47647f4c3f47de49c4efdb2f62805881e49852e2a0ec"}, "15da190f-77d8-40fe-a107-550a480c11c5": {"doc_hash": "af746a862bcfe4dae4d65f2b8bef02ce091660bf4d1b68a36effd8615ea1104d"}, "3be11605-7bf7-46a5-85f3-77e090b3955a": {"doc_hash": "08120dacfa57053cbb170e7bac8e454c7d62ce7f1463cf4afebfd520f2306c7e"}, "88f70560-ffdf-4d22-9a82-834977b85306": {"doc_hash": "2b72c499c16b42a1e4568304503a9a445a39cf3da196509c753f87d11e34e0c6"}, "2ac42a22-4ef0-4714-a110-9afefc25d03b": {"doc_hash": "e0d12f266bbdcdef1abcce217b1c6640a50c6800946de1d2a0d06ec42b83d7ed"}, "cb8ec7af-859b-4146-8fb4-1a5e94c27830": {"doc_hash": "6f988e14dd0d004dddcd6a9a6e981c58c07269360f4544c11ba58049e3e6cecc"}, "dd07ac46-671b-43e9-b591-1a177189c7b3": {"doc_hash": "f38dd3af5e16e1cd8eb1f18f9bae223845f9216d5ef3144b086c25da51fb3c91"}, "aeb0251d-ffde-4d17-8b1b-f523ec078c19": {"doc_hash": "340ff0be24113eacae9306e1d983ff55f3ce6312e300f926a555ddc8fba3e5bd"}, "bfbf9b8b-cbb2-4538-96d8-2cb969b1bf91": {"doc_hash": "bf137e9df881a0139b2047c13f2494e75aa9cc944a41466eee8ade8b4f6a9964"}, "9a8252b4-6a41-4612-ad7f-fefa06d4c477": {"doc_hash": "e71dc2d3dbcbc5531026c6b65b0ff3af5b9f17ca13e1dae7ca9ff67dc91c1ce8"}, "7aa6bf04-da3c-4880-9509-9f992502290e": {"doc_hash": "647bedaf9bad95e567476fd37e50b3bbc9afd2913f05b55dd337e36af36339b2"}, "ce3363c6-7184-4c5f-89ef-5833b752a39b": {"doc_hash": "99045476a21df2031cb131e6512e54fd3650b9837bcc87f0ea492f8b903f45a1"}, "f0559b9e-453f-4fd1-8877-6d531c44e7b5": {"doc_hash": "be9dbbb0f8e39f5681302da7411e9a8bd56508741a44c1168a1033c6a3999a5b"}, "b5290997-ea94-4a07-a752-c0c616ce3ef5": {"doc_hash": "718892968b6fb894be89ff02666dcfa92a520d6783ffa7c73908ed95fb16c816"}, "4cf74559-d5d6-4a98-ab19-1c7d7a9d7cde": {"doc_hash": "785bcf464a46b60eda929caddfb82e6a2f7d9ac4d89dbdbaec3ff37aafd1ecae"}, "bffa26b9-2431-408b-81ee-f959a3174845": {"doc_hash": "a8295c1778d68486e3d89c2f4d01aa74d6aa95f0d96452743118ce06c7e1da1a"}, "0f9f74fc-05ca-4aa7-925d-df6bc371f754": {"doc_hash": "a822e5ea6edc02fcd67d0c84cf153504f450d2f55043e254a86649605cb389db"}, "422cd9fb-6433-4e96-8110-746a51d0c9d6": {"doc_hash": "b6a8788e55b711f7a907a4bdd6c0ba260f9b84a8ce400656e380456c8628912b"}, "818938df-3751-4856-ac52-756add4a2563": {"doc_hash": "7bded3281f0b8588f4a56059818e5e26ae1fb86d7c2fd558ed93c64171c006fa"}, "8ec416e8-3eb4-4bba-bae3-7ebe514589c4": {"doc_hash": "41bf701bf6b65d075d0070a691c8e4ee3a7488603f94393edbd64de00f7f22a8"}, "e9eed08c-5847-49bc-9ec0-5ed92dc0b59a": {"doc_hash": "5336817547c8816f8755bfa1b1593824c46fe82472f3a75a86ad4ed29100e166"}, "211e4a13-6a0a-4d1c-981e-ee78d0c43353": {"doc_hash": "331ced2152468c0a773f3c0a3dac60a6ae0ef45863a42507d9192df7e8b2b817"}, "5629088b-a33b-405d-b672-7158782478f1": {"doc_hash": "fc6ed9e0cc5d9538779e09c7c676e6fcb651a639778e48046cb40be16fa76da8"}, "88a0ecf0-8a27-4b0a-bdba-150026a1317d": {"doc_hash": "84ecc5ec8f47cf04928f43c3cba57ee818e0e23317ae4d1900692a96fc7e3391"}, "42deb119-9cea-476a-9565-40728cee8d0e": {"doc_hash": "b6a5dbc61ea5e510e3a7d2fc55e67b309f1b1b7d0589464fb626523f603ec1cb"}, "6e3047d6-c79a-4b2f-9448-0ed2b57eafb4": {"doc_hash": "159ba792133f756e1fd8c93ba6e7142b8ce0187145b3d3f713ca04c82e4acf50"}, "abba1498-9599-436c-a66b-b355ec73979f": {"doc_hash": "c65a719fcf07b5b95172298553ec73ee1c17bee1807c356893c413937ba47475"}, "a7e99a7f-a9f2-41a2-a711-f81b42b28d89": {"doc_hash": "bb38b31dc24fcfa9e0d9b3f731f0198932934fb9161b5007801a7ca6a3b0b702"}, "721f0066-2b6a-4cd2-84d3-777a69dc4275": {"doc_hash": "f8cadd019bd1ab34ce1d450ccc9445878eef3fde3a31eccec6bcedaed952791a"}, "072f11c1-052d-459f-b45f-32e37d664ead": {"doc_hash": "ffe465bec5222b97904006d59df6e9d25071ad2e4163f81d081e02a719e0c887"}, "9d61872e-852b-4c3a-9602-26775e1b10af": {"doc_hash": "6b7f3781a5747bff52bf9ab17920275f88126faf3142b69e32d932cfd1e6b071"}, "1fa86231-e9e9-44ad-909b-975ca71145ea": {"doc_hash": "db496ea81e00569cc21518ced8979df989367a1355d0dc2e408fb3019e8aa26a"}, "38de855c-7a09-4c32-8715-0284d8052273": {"doc_hash": "72a900d90fc2d24e457a8706db82fca4ae303e87bca2eb1d714139c42e347862"}, "aeabcbe8-72fe-4356-918a-beeaa7f8fd30": {"doc_hash": "2e4cffbc8ff8a9bd232ac207b358c14bfeb8dd92c2cdc89a932c5ea81c4ff592"}, "21142c1d-cfcf-4ae4-b2f4-4612bca3c454": {"doc_hash": "e1a02baf2bed8e8c0b0000e4ca4c5966d73a9608c466a832ab28b331554c7d96"}, "545857f2-f41e-493b-87dc-df30185c726b": {"doc_hash": "3ac1a24180ab273ace0f852f916ef475d9e00319d942498aed4a25b884c1993c"}, "d9faf2bf-e266-4260-a896-606d1fde1a1a": {"doc_hash": "6dd798eb66bf84ec70fc5b378f14ec99ae15bd032839cceff939ac2a17e9238f"}, "054f6bee-dd7e-4fd9-8edb-e5a07cefa5bd": {"doc_hash": "0e10baad524db2edbd67bee0a3f3a87927d2f3f7ef25fe5ad86eef79c6fae882"}, "2e45eb78-370e-4d14-b067-f102b9aab50f": {"doc_hash": "081b8941009c9ebdd76f3855442fb221fe431c35d53b3dd1682bd7e1b151dbf4"}, "6b21463d-93b6-4f4a-9305-5963bc2584cc": {"doc_hash": "5fd7c2c43deec2f80f582bf526f697beb3f081012ee821902494561e79129da7"}, "f6eb2aef-b06e-4c86-a8c7-2df6bb86c49b": {"doc_hash": "258f4fa34c549c3fbef99dfdcf653ade6f17197d60e97877a0bf271419f4d1ce"}, "c65c1b32-2885-45d3-9467-892377aad75a": {"doc_hash": "c9938b1fc838acd79f14f51ba5b92c071e247ef07fb4477b5eb83c8b9a575750"}, "bafb48b8-08ff-43ec-be6f-95a1bb58f15e": {"doc_hash": "99808ff2a5227638a2fbae1d30e72567d2b2489dc272439ddf938af63a9be283"}, "e6a76465-a51c-4132-bcc2-9420ebbc8629": {"doc_hash": "d01a3f0a12c102051896e871c520583f5b024d9acc0d8bd93cf61f5fd10163c8"}, "e3be5459-f28b-4169-8cc1-be3bc3c42085": {"doc_hash": "80b61a670e45572d9fbe55873d28a1d794b4fb6f1a6f1370d9ed649d128125da"}, "a0229611-9fff-477f-acf4-e1962cba5ef9": {"doc_hash": "347fded493f019ebddc7867d2801b48c045ac12c30d0261c32aa872f0431d06c"}, "fcd7a00c-f64a-4b94-a90e-31cd52c6e5c3": {"doc_hash": "e7c89bb81a1d599320f52cbd37fc7d05e6240ed9ef4b64ad646f39c59511ad69"}, "0c69d54c-a254-4aa0-9969-68a4a4c112f5": {"doc_hash": "2036cc5685e6655d2e6e32e02a4410659ad63f05b883e9761d26ab58e57c211a"}, "bc683263-7568-4a00-bc04-8260a60b66fe": {"doc_hash": "b71739297edf21ef3a8d5ff37a401be476cd1a3f2ac6fa9d27bd6764efe56c1c"}, "1fd4fbeb-8b99-4feb-ac68-a45884dd6b58": {"doc_hash": "13dacd45075734127b2eb518be12f24a88a5fb4775c7ad239492c76d3ede212a"}, "5a63eba7-3a52-4069-b2c8-ecf814f84e0d": {"doc_hash": "aeda9b329026711a1c1e4f8c78b720f68534c3f146bb0aacbea4632287bbd91c"}, "00ac99c7-740b-4753-a700-a7f5e8126c3d": {"doc_hash": "84a77df49763988134c9b0bffb5430b24f736d6fb3ef5bb9fb175ba575431de4"}, "73db8ea4-bb21-4dc5-ace9-a3c08a609c38": {"doc_hash": "2522ffcdee609f67b6ceb7520628cea1d0c672ebb82c9bfd570931e81fbe39f7"}, "4394768a-88ef-43e9-83cc-071925735387": {"doc_hash": "cb075bb3d2bd9de739b023a3487972d893b57c0417edc4af40af4d8aff6d9cf2"}, "fac5edcf-4007-444a-9183-28fb4ae5cbf9": {"doc_hash": "d2ba3a9380960093480fb0ebc586038050b7c099d73e6286c7c1a83896dd06f9"}, "383a043f-af27-482f-8897-dbebc5804f24": {"doc_hash": "2bc03001f31b15c32e52c8050d36cebfa5ec94023cec2083d8d5fc6bb8fe4fa2"}, "8ca2685e-37c4-4e9d-becc-f919d796bcda": {"doc_hash": "a867cfeeacbe1ca39eaff388e75d616074c7f10aed8900675f2d37efad8736dc"}, "ca8751b9-4577-4abf-b7cf-5d4fc77d6571": {"doc_hash": "c7211316604d7d1d2b55268a6820f0411dd9ff95e6367dfaa8b0068a6ecb4c45"}, "2d4b8818-69b1-4f61-8f82-fc4d8f7df54b": {"doc_hash": "dc69d6875dff1a6f6d44ece01adf8661934c1eb3cab9215f14aad9eb1c7a174d"}, "0a3f1463-b7d3-42b6-81f1-c19898984d97": {"doc_hash": "d1af5738d65dc025ab28d8e8a680e4163cce611648d5d431e4237c4383d6ed55"}, "99bba93b-91f2-4eee-94d0-c34af69ef966": {"doc_hash": "e54ed11dd2738252fc5209c9ed6aecb3c9460286f3287096bcf87a6d8e620cb4"}, "bd30ed6f-df65-4405-a0fd-be06cab65757": {"doc_hash": "18bfe7dded33d18fc795a871006e913636899f7ced42c8ff76979d51afadd8ef"}, "5d28adf1-3889-400d-b715-9bf6a3066cd9": {"doc_hash": "ecdd9e2a1e10c7dc9600c00d3bee8aca1ade722e79edb7b5e2ecf497a35b8284"}, "58cf8e5b-b9a7-4ee8-abe6-a810fa730042": {"doc_hash": "c46028e8418d85bc23bdfbf9c316ef04a7de0fbe184a1bfdf30a5e22ac0cdf56"}, "1c3b41cd-0987-4cf2-b45f-40c4461e88ec": {"doc_hash": "66beaa995b9019b1238735761785fb717e3ef59ab2467c8fc6795db4784b42bd"}, "e7d3effc-d9ad-4481-a1f1-0049d133a99d": {"doc_hash": "d57ca0ba5a7bd32dcdf6c647b3eea9c13c4fe9d87bdf2209919f67fc510cbf48"}, "049ff036-6e11-44e2-8095-39a025d686e1": {"doc_hash": "e9e8446380b24ea674f64e0d03fc87b02dd151f12b3eb2cd25c97332ce583a26"}, "db84f7dd-9a7b-403a-8a4b-6aeac7549916": {"doc_hash": "b04d33dc59476fe4586f63b201a798c35ce75d6ff1e4fae9893e7379a4b62c3c"}, "c6efae6b-f1f8-4dbe-ad3f-8cfde381eb01": {"doc_hash": "82dc51301cb5a13c9a82ba4d6f2a7230b471cb8a19323b44c0a59e92565b1fbc"}, "4de1dfc3-2705-43a7-ab85-6b0b8e5ba4a7": {"doc_hash": "a6d94ffa7c2d4225928c51db793cd4c09aaec2743d407a5e087a49c8be0565a8"}, "e5126c1b-dc03-44f8-9299-a433ced905a1": {"doc_hash": "f6447480d55bfa4e8f3d2ae1e0af4cd5b65a0b704b6e99b37f0ccd67f7738f14"}, "dfa079bd-3fd3-41f4-bb15-3dcd55bceaab": {"doc_hash": "6d2cb45713cfaf89036467aca3b22a3c3c60cd8735214e8ac61d0243ebff01f7"}, "b0c06f5d-0de4-4029-a0a0-65fdc2545907": {"doc_hash": "3b922652cf522235df33df6ed788fbb6a8e7f944f69b13ce0dee491d9739d159"}, "e76ca2df-f6b1-4208-8742-3c7991d83141": {"doc_hash": "30517150c5d7129cc03dd3b2621110e596f44e04c53d8c4ee9aa37bc3ba2b40b"}, "841821c6-f54d-4250-a40c-ea041358d2df": {"doc_hash": "d0a0d6b91a6b0462ff45e5cd304d9dda44395daa38d502944e0ae2379a14f930"}, "12fb9219-dbdf-48b4-9461-618bb847b98c": {"doc_hash": "6173a2ec8b6dcb56a12f8d147762519aa8de636cfc5f0ccf74a55427e9147eac"}, "2f4dbc75-c49d-4c21-b5d6-7d4ba1e10b1e": {"doc_hash": "db2c0f2474c1ac86a2374d627447012e856632be02c6219f9416009410f02717"}, "52b88dc7-18b3-416c-b38a-75f477c4b163": {"doc_hash": "d756674f63324d67bb886919b5ad8a0f68057b2f16b3629c23f029a8d359d2cb"}, "a036e6fa-8e38-4d88-9162-7dc63ee5e520": {"doc_hash": "27ed20cab14353c3c5bce10628f6266c2efe9055c242db5385b9d02baeb9904f"}, "43b06d07-9204-4c4b-a246-0b23c5af24ed": {"doc_hash": "3bfa12bca6ce3a601eb39c4b46f6963e22b395d774d77da318e555d355aa855a"}, "8a4b33d7-afa5-4875-849c-e4f8ec309402": {"doc_hash": "0bcc51410aab2a6ce1780acb3828a8dacc77b93b8bf9586f99999206350a93f3"}, "412e27e8-8143-45c8-89db-16268c269701": {"doc_hash": "b50b6cb929df938a1a85c9d201801806c52ad957cf149dfc7f66b9413f621a4d"}, "346383ba-907b-4272-af20-7f1121950fa8": {"doc_hash": "54deb889d7fdca21044e67d2d8d2ab75d41de14d6404b03fb75ea98626831bef"}, "ea26042b-9503-41f1-82bb-f8337b2f96c8": {"doc_hash": "3307c65e248249bf2af004471836f23825f205f25452710e6623999f0fde77ea"}, "b285d8fc-579c-4be7-8c81-a69c19b9ee59": {"doc_hash": "b1c43b2f94ea46973dc904342d0db6f2740293f8860879b301477a86a060f8b5"}, "da10c766-d5a9-4ec3-95d5-f65432d136ae": {"doc_hash": "3f11f8b37f13dd193c71e7ca8fc3b7d164e4a13aecfc59a793a24f4de8e26dca"}, "33532678-816f-4ab1-a694-6ced2eb79788": {"doc_hash": "11b8b814b96b6f6e2db57dfed5fab6f7c8c510d419cb406b9198424f45ffb7ef"}, "6bf083d3-b00b-476a-9329-8d89242f7676": {"doc_hash": "3fa306767fc5f8f4ba21b632b0c40d9b8990b530cda97b7437ec42a5a3890765"}, "e2ba94bb-eda1-4b6f-b7dc-17701554a485": {"doc_hash": "04f027ee1eef207fca140e805c5c9a5564eac8eb39c59a4a2029ab6f3979016d"}, "68c9d971-6d20-4286-be5f-1920ca1e4bc8": {"doc_hash": "31f003572b4972bba29c776148c68bd2df2974d59b706f3b4aea35b37e7b769f"}, "131e9ccf-945b-4914-8538-d96d062ada5f": {"doc_hash": "4659b369234871be0654aecf0ca294817e080802047e97116178ca7e0d45f268"}, "410d6767-b34f-44af-9056-bdb1ad2ddf87": {"doc_hash": "1332cb7d625bd7c4d4ea65eb3eb237c4a9669fbc003847d5707aea2f2d69a940"}, "157bdee0-6094-4bc8-9a99-51b549305942": {"doc_hash": "2a8e326d2030f2e78b68cb2859f39b5c07a7d9d93d7479d450244fca86270bed"}, "5941d376-ff8b-415d-8a48-c526773c0ee3": {"doc_hash": "5f6d9072cd7b63535a6def61c9ccff1227f9cd46720914785231a1ca0bf16c8a"}, "2e1654cc-e559-43b5-aeb0-9e11286de456": {"doc_hash": "057b4b293f8cc220e39567d683f7aa721d00f759f909801ac2cd25c83a93a652"}, "47295507-957a-4c4f-a0a6-baf566a5b854": {"doc_hash": "f55c3be793ee153050bede144714d2ae9f7afc3a1c1382a66bc32c21a4803eaa"}, "1d8b7d68-8728-4102-a755-d576e2794e4a": {"doc_hash": "12843f3a7741e8105048edc68a2d990ed8a15c5030c644ab9f27dbeb0a54293f"}, "1716a32b-b80f-4576-a281-67b8a4a9346e": {"doc_hash": "c8cb01c4e844f0a590aeae07631292bca2c52b66d6f01aa2edd63be164f0846d"}}, "docstore/data": {"48408684-a559-49a0-84af-e9ab56a5c002": {"__data__": {"text": "Linux\u00ae  \nBible\nTenth Edition", "doc_id": "48408684-a559-49a0-84af-e9ab56a5c002", "embedding": null, "doc_hash": "80cc5cde4460520c159ae62d7bb3db4ae68e028fb629cc70c923874b8e4f6e96", "extra_info": {"page_label": "1"}, "node_info": {"start": 0, "end": 28}, "relationships": {"1": "1055cab1-3de0-40fe-90f0-2d9033c4158d"}}, "__type__": "1"}, "9f96c364-aefb-46cb-8764-485843f9da81": {"__data__": {"text": "Linux\u00ae  \nBIBLE\nTenth Edition\nChristopher Negus", "doc_id": "9f96c364-aefb-46cb-8764-485843f9da81", "embedding": null, "doc_hash": "4faaa1aff918e550b7dbd6f5d40d1fc3c838253086a4d08f2b0f13f53455e0d2", "extra_info": {"page_label": "2"}, "node_info": {"start": 0, "end": 46}, "relationships": {"1": "0cb393b1-4fa3-4add-a052-1e3ba8f37bdb"}}, "__type__": "1"}, "6f521b0a-82c0-4d68-8eca-aee142e3abdd": {"__data__": {"text": "Copyright \u00a9 2020 by John Wiley & Sons, Inc., Indianapolis, Indiana\nPublished simultaneously in Canada\nISBN: 978-1-119-57888-8\nISBN: 978-1-119-57891-8 (ebk)\nISBN: 978-1-119-57889-5 (ebk)\nManufactured in the United States of America\nNo part of this publication may be reproduced, stored in a retrieval system or transmitted in any form or by \nany means, electronic, mechanical, photocopying, recording, scanning or otherwise, except as permitted under \nSections 107 or 108 of the 1976 United States Copyright Act, without either the prior written permission of \nthe Publisher, or authorization through payment of the appropriate per-copy fee to the Copyright Clearance \nCenter, 222 Rosewood Drive, Danvers, MA 01923, (978) 750-8400, fax (978) 646-8600. Requests to the Publisher \nfor permission should be addressed to the Permissions Department, John Wiley & Sons, Inc., 111 River Street, \nHoboken, NJ 07030, (201) 748-6011, fax (201) 748-6008, or online at http:/ /www.wiley.com/go/permissions .\nLimit of Liability/Disclaimer of Warranty: The publisher and the author make no representations or warranties \nwith respect to the accuracy or completeness of the contents of this work and specifically disclaim all warranties, \nincluding without limitation warranties of fitness for a particular purpose. No warranty may be created or \nextended by sales or promotional materials. The advice and strategies contained herein may not be suitable for \nevery situation. This work is sold with the understanding that the publisher is not engaged in rendering legal, \naccounting, or other professional services. If professional assistance is required, the services of a competent \nprofessional person should be sought. Neither the publisher nor the author shall be liable for damages arising \nherefrom. The fact that an organization or Web site is referred to in this work as a citation and/or a potential \nsource of further information does not mean that the author or the publisher endorses the information the \norganization or website may provide or recommendations it may make. Further, readers should be aware that \nInternet websites listed in this work may have changed or disappeared between when this work was written and \nwhen it is read.\nFor general information on our other products and services please contact our Customer Care Department within \nthe United States at (877) 762-2974, outside the United States at (317) 572-3993 or fax (317) 572-4002.\nWiley publishes in a variety of print and electronic formats and by print-on-demand. Some material included with \nstandard print versions of this book may not be included in e-books or in print-on-demand. If this book refers to \nmedia such as a CD or DVD that is not included in the version you purchased, you may download this material at \nhttp:/ /booksupport.wiley .com . For more information about Wiley products, visit www.wiley .com .\nLibrary of Congress Control Number: 2019956690\nTrademarks:  Wiley and the Wiley logo are trademarks or registered trademarks of John Wiley & Sons, Inc. and/or \nits affiliates, in the United States and other countries, and may not be used without written permission. Linux is \na registered trademark of Linus Torvalds. All other trademarks are the property of their respective owners. John \nWiley & Sons, Inc. is not associated with any product or vendor mentioned in this book.", "doc_id": "6f521b0a-82c0-4d68-8eca-aee142e3abdd", "embedding": null, "doc_hash": "d49a8fef037bcc2d196c8d204b54c61053671b0618716041c8aab08f30c599bc", "extra_info": {"page_label": "3"}, "node_info": {"start": 0, "end": 3368}, "relationships": {"1": "76b4ee5b-951c-4c62-bf89-cccdf9305ab1"}}, "__type__": "1"}, "5b3695ac-9465-48f0-8563-c1dfe5f58101": {"__data__": {"text": "As always, I dedicate this book to my wife, Sheree.", "doc_id": "5b3695ac-9465-48f0-8563-c1dfe5f58101", "embedding": null, "doc_hash": "00ac49980a8d79d19962c3bf6f3c38231279acf809fae9aacc9cda7f022eff5f", "extra_info": {"page_label": "4"}, "node_info": {"start": 0, "end": 51}, "relationships": {"1": "2882c793-8941-4b9f-a793-9bf9cb603102"}}, "__type__": "1"}, "fcfc89f8-3c8e-45c1-bbb4-90d3957f0aa6": {"__data__": {"text": "viiAbout the Author\nChris Negus  is a principal technical writer for Red Hat, Inc. In more than a decade with Red \nHat, Chris has taught hundreds of IT professionals to become Red Hat Certified Engineers \n(RHCEs), and he has written scores of documents on everything from Linux to virtualization \nto cloud computing and containerization.\nBefore joining Red Hat, Chris wrote or co-wrote dozens of books on Linux and UNIX, includ -\ning the Red Hat Linux Bible  (all editions), Docker Containers , CentOS Bible , Fedora Bible , Linux \nTroubleshooting Bible , Linux Toys , Linux Toys II , and, nine editions of this Linux Bible . Chris \nalso co-authored several books for the Linux Toolbox series for power users: Fedora Linux \nToolbox , SUSE Linux Toolbox, Ubuntu Linux Toolbox, Mac OS X Toolbox, and BSD UNIX Toolbox .\nBefore becoming an independent author, Chris worked for eight years with the organization \nat AT&T that developed the UNIX operating system before moving to Utah to help contribute \nto Novell\u2019s UnixWare project in the early 1990s. When not writing about Linux, Chris enjoys \nplaying soccer, hanging out with his wife, Sheree, and spending what time he can with his \nsons, Seth and Caleb.", "doc_id": "fcfc89f8-3c8e-45c1-bbb4-90d3957f0aa6", "embedding": null, "doc_hash": "af956d3dbc7f533ae057b845e442a23d31d14ef4803a00912e8ca07b77a31c4d", "extra_info": {"page_label": "5"}, "node_info": {"start": 0, "end": 1204}, "relationships": {"1": "29c86582-726a-4daa-8e6e-e79d82075de6"}}, "__type__": "1"}, "23c391c7-bd9d-4de5-9275-aa80ad842755": {"__data__": {"text": "ixAbout the Technical Editors\nJason W. Eckert is an experienced technical trainer, consultant, and best-selling author in \nthe Information Technology (IT) industry. With 45 industry certifications, over 30 years of \nIT experience, 4 published apps, and 24 published textbooks covering topics such as UNIX, \nLinux, security, Windows Server, Microsoft Exchange Server, PowerShell, BlackBerry Enter -\nprise Server, and video game development, Mr. Eckert brings his expertise to every class that \nhe teaches at triOS College in his role as the Dean of Technology. For more information about \nMr. Eckert, visit jasoneckert.net .\nDerrick Ornelas  is a senior software maintenance engineer at Red Hat, Inc. In his current \nrole as a product lead for Red Hat container technologies, including OpenShift Container Plat -\nform and Red Hat Enterprise Linux CoreOS, Derrick works to ensure both the supportability \nand quality of Red Hat\u2019s products. Previously, he worked as a senior technical support lead \nfor Red Hat virtualization technologies, such as libvirt, KVM, and the Red Hat Virtualiza -\ntion product.\nDuring his 12 years at Red Hat, Derrick earned the Red Hat Certified Engineer and Red Hat \nCertified Virtualization Administrator certifications, and he has applied his broad Linux \nknowledge to architect, deploy, and maintain various hardware labs and applications.\nDerrick\u2019s nearly two decades of Linux experience began while earning his BS in Computer \nScience from Appalachian State University. As a devoted Linux supporter, he enjoys teaching \nand assisting new Linux users both on and off the clock. When he\u2019s not working on his \nmonitor tan, Derrick enjoys mountain biking, motorcycling, and backpacking with his \nwife, Carolyn.", "doc_id": "23c391c7-bd9d-4de5-9275-aa80ad842755", "embedding": null, "doc_hash": "9b385a9cdaafffbca871c11f468c39b617f514f236b33919bd6e0c3719036082", "extra_info": {"page_label": "6"}, "node_info": {"start": 0, "end": 1737}, "relationships": {"1": "e8847db6-9b82-4bba-96b9-267d424fff7b"}}, "__type__": "1"}, "42adff5f-096d-4099-8fc1-0f326a3a81ee": {"__data__": {"text": "xiAcknowledgments\nWhen I was hired at Red Hat about a dozen years ago, I didn\u2019t know that Red Hat \nwould grow to about seven times its size, be bought by IBM for $34 billion, and (so \nfar) still maintain the spirit of openness and excitement that it had when I first \nsigned on. Every day when I come to work, I interact with many of the greatest Linux and \ncloud developers, testers, instructors, and support professionals in the world.\nWhile I can\u2019t thank everyone individually, I would like to salute the culture of cooperation \nand excellence at Red Hat that serves to improve my own Linux skills every day. I don\u2019t speak \nwell of Red Hat because I work there; I work at Red Hat because it lives up to the ideals of \nopen source software in ways that match my own beliefs.\nThat said, there are a few Red Hatters that I want to acknowledge in particular. At Red Hat, \nI\u2019m able to take on so many cool and challenging projects because of the freedom that I \nreceive from the people to whom I report. They include Michelle Bearer, Dawn Eisner, and Sam \nKnuth. Sam, in particular, has had my back and encouraged my work for more than a decade.\nIn my daily work, I want to give a shout out to Red Hatters Scott McCarty, Ben Breard,  \nLaurie Friedman, Dave Darrah, Micah Abbott, Steve Milner, and Ian McLeod (container tools, \nRHCOS, and OpenShift teams), and Tom McKay, Joey Schorr, Bill Dettelback, Richa Marwaha, \nand Dirk Herrmann (Quay team). Finally, a special thank you to Vikram Goyal, who luckily \nlives in Australia, so he is always available to bail me out when I blow up git in the middle of \nthe night.\nWhen it comes to support for writing this book, I have had the luxury of two excellent tech -\nnical editors: Jason Eckert and Derrick Ornelas. I didn\u2019t know Jason before he took on this \nrole, but his broad experience with different Linux systems has helped call me out when I get \ntoo Red Hat centric. Derrick, who I see almost every day, was asked to do this work because \nof his attention to detail and deep understanding of how Linux works and what people need \nto know to use it. Anyone reading this book will have a better experience because of the \nwork that Jason and Derrick have done reviewing it.\nAs for the people at Wiley, thanks for letting me continue to develop and improve this book \nover the years. Thanks to Gary Schwartz, who applies constant, gentle pressure to keep me \nworking on this book at times when I had no spare cycles to work on it.\u00a0When Gary\u2019s pressure \nwasn\u2019t enough, Devon Lewis would step in to paint a clearer picture about the importance of \ndeadlines. Thanks also to Margot Maley Hutchison from Waterside Productions for contracting \nthe book for me with Wiley and always looking out for my best interests.\nFinally, thanks to my wife, Sheree, for sharing her life with me and doing such a great job \nraising Seth and Caleb.\n\u2014Christopher Negus", "doc_id": "42adff5f-096d-4099-8fc1-0f326a3a81ee", "embedding": null, "doc_hash": "43c515e599fedf0e5a9ede95071192d053e5d0fb3aacecc3ecd8d9612390f9cf", "extra_info": {"page_label": "7"}, "node_info": {"start": 0, "end": 2894}, "relationships": {"1": "8e1b8a2a-0337-4ede-8e83-20bc988a8891"}}, "__type__": "1"}, "c4ed7c14-03d0-4bcc-8f77-eab06f2f0933": {"__data__": {"text": "xiiiContents at a Glance\nAcknowledgments  ........................................................................................................ xi\nIntroduction  ............................................................................................................ xxxv\nPart I: Getting Started   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\nChapter 1: Starting with Linux ....................................................................................... 3\nChapter 2: Creating the Perfect Linux Desktop ................................................................ 27\nPart II: Becoming a Linux Power User   . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\nChapter 3: Using the Shell ............................................................................................. 61\nChapter 4: Moving Around the Filesystem  ....................................................................  93\nChapter 5: Working with Text Files .............................................................................. 113\nChapter 6: Managing Running Processes ....................................................................... 131\nChapter 7: Writing Simple Shell Scripts ........................................................................ 147\nPart III: Becoming a Linux System Administrator  . . . . . . . . . . . . . . . . . . . 165\nChapter 8: Learning System Administration ................................................................. 167\nChapter 9: Installing Linux ......................................................................................... 195\nChapter 10: Getting and Managing Software ................................................................. 221\nChapter 11: Managing User Accounts ............................................................................ 249\nChapter 12: Managing Disks and Filesystems ................................................................ 273\nPart IV: Becoming a Linux Server Administrator   . . . . . . . . . . . . . . . . . . . 305\nChapter 13: Understanding Server Administration  ........................................................ 307\nChapter 14: Administering Networking  ........................................................................ 339\nChapter 15: Starting and Stopping Services .................................................................. 369\nChapter 16: Configuring a Print Server ......................................................................... 403\nChapter 17: Configuring a Web Server ........................................................................... 427\nChapter 18: Configuring an FTP Server ......................................................................... 455\nChapter 19: Configuring a Windows File Sharing (Samba) Server ..................................... 475\nChapter 20: Configuring an NFS File Server ................................................................... 499\nChapter 21: Troubleshooting Linux .............................................................................. 523\nPart V: Learning Linux Security Techniques  . . . . . . . . . . . . . . . . . . . . . . . 563\nChapter 22: Understanding Basic Linux Security ........................................................... 565\nChapter 23: Understanding Advanced Linux Security .................................................... 599\nChapter 24: Enhancing Linux Security with SELinux ..................................................... 635\nChapter 25: Securing Linux on a Network ..................................................................... 663", "doc_id": "c4ed7c14-03d0-4bcc-8f77-eab06f2f0933", "embedding": null, "doc_hash": "b6e1b5570a2de4f34e9870d271d50fa2765b8b189e357c1cd7e3f041b36cfee2", "extra_info": {"page_label": "8"}, "node_info": {"start": 0, "end": 3620}, "relationships": {"1": "18c8e4c5-7896-422e-b175-c9118d020d01"}}, "__type__": "1"}, "88548818-645f-44ec-bb73-3ce8757b329a": {"__data__": {"text": "Contents at a Glance\nxivPart VI: Engaging with Cloud Computing  . . . . . . . . . . . . . . . . . . . . . . . . . 691\nChapter 26: Shifting to Clouds and Containers .............................................................. 693\nChapter 27: Using Linux for Cloud Computing ............................................................... 709\nChapter 28: Deploying Linux to the Cloud .................................................................... 729\nChapter 29: Automating Apps and Infrastructure with Ansible ...................................... 749\nChapter 30: Deploying Applications as Containers with Kubernetes ................................ 765\nPart VII: Appendixes  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 785\nAppendix A: Media ..................................................................................................... 787\nAppendix B: Exercise Answers ..................................................................................... 797\nIndex  ........................................................................................................................ 863", "doc_id": "88548818-645f-44ec-bb73-3ce8757b329a", "embedding": null, "doc_hash": "2bb79f9c17630ffb36267434abbed494234932ac3b46841dd5bcb1e69b516ba7", "extra_info": {"page_label": "9"}, "node_info": {"start": 0, "end": 1142}, "relationships": {"1": "b6d2dab4-ac8d-4825-a919-f0fc8828e199"}}, "__type__": "1"}, "1b631852-6931-45e1-b1a8-5056c7225314": {"__data__": {"text": "xvContents\nAcknowledgments  \u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. xi\nIntroduction .\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. xxxv\nPart I: Getting Started 1\nChapter 1: Starting with Linux \u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 3\nUnderstanding What Linux Is  ................................................................................ 4\nUnderstanding How Linux Differs from Other Operating Systems .............................. 6\nExploring Linux History  ........................................................................................ 7\nFree-flowing UNIX culture at Bell Labs ........................................................... 7\nCommercial UNIX ......................................................................................... 9\nBerkeley Software Distribution arrives  .................................................. 9\nUNIX Laboratory and commercialization ............................................... 10\nGNU transitions UNIX to freedom ................................................................. 11\nBSD loses some steam .................................................................................. 12\nLinus builds the missing piece ..................................................................... 13\nOSI open source definition ........................................................................... 14\nUnderstanding How Linux Distributions Emerged ................................................... 16\nChoosing a Red Hat distribution ................................................................... 16\nUsing Red Hat Enterprise Linux ........................................................... 17\nUsing Fedora  ...................................................................................... 18\nChoosing Ubuntu or another Debian distribution ........................................... 19\nFinding Professional Opportunities with Linux Today ............................................. 19\nUnderstanding how companies make money with Linux ................................. 20\nBecoming Red Hat certified .......................................................................... 21\nRHCSA topics  ...................................................................................... 22\nRHCE topics  ........................................................................................ 23\nSummary  ............................................................................................................ 25\nChapter 2: Creating the Perfect Linux Desktop .\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 27\nUnderstanding Linux Desktop Technology ............................................................. 28\nStarting with the Fedora GNOME Desktop Live image .............................................. 30\nUsing the GNOME 3 Desktop .................................................................................. 31\nAfter the computer boots up ........................................................................ 31\nNavigating with the mouse .................................................................. 32\nNavigating with the keyboard .............................................................. 36\nSetting up the GNOME 3 desktop .................................................................. 38", "doc_id": "1b631852-6931-45e1-b1a8-5056c7225314", "embedding": null, "doc_hash": "96de4686adc567e462f818ac816d5f6797e5fa44539f35e7a7bc3259909f43ae", "extra_info": {"page_label": "10"}, "node_info": {"start": 0, "end": 3504}, "relationships": {"1": "4606b726-9a1e-4ef5-891a-13f972dce071"}}, "__type__": "1"}, "84f892ba-86cc-4722-b4c5-d8cd1b0e6fe9": {"__data__": {"text": "Contents\nxviExtending the GNOME 3 desktop ................................................................... 39\nUsing GNOME shell extensions .............................................................. 39\nUsing the GNOME Tweak Tool ............................................................... 40\nStarting with desktop applications ............................................................... 41\nManaging files and folders with Nautilus .............................................. 42\nInstalling and managing additional software ........................................ 43\nPlaying music with Rhythmbox ........................................................... 45\nStopping the GNOME 3 desktop ..................................................................... 46\nUsing the GNOME 2 Desktop .................................................................................. 46\nUsing the Metacity window manager ........................................................... 48\nChanging GNOME\u2019s appearance  ...................................................................... 49\nUsing the GNOME panels .............................................................................. 50\nUsing the Applications and System menus ............................................ 51\nAdding an applet ................................................................................ 51\nAdding another panel ......................................................................... 52\nAdding an application launcher ........................................................... 52\nAdding a drawer ................................................................................. 53\nChanging panel properties  ................................................................... 54\nAdding 3D effects with AIGLX ...................................................................... 54\nSummary  ............................................................................................................ 57\nExercises  ............................................................................................................. 57\nPart II: Becoming a Linux Power User 59\nChapter 3: Using the Shell \u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 61\nAbout Shells and Terminal Windows ...................................................................... 62\nUsing the shell prompt ................................................................................. 63\nUsing a Terminal window ............................................................................. 63\nUsing virtual consoles ................................................................................. 65\nChoosing Your Shell ............................................................................................. 65\nRunning Commands ............................................................................................. 66\nUnderstanding command syntax  .................................................................. 67\nLocating commands  ..................................................................................... 70\nRecalling Commands Using Command History ........................................................ 72\nCommand-line editing  ................................................................................. 73\nCommand-line completion  ............................................................................ 75\nCommand-line recall  .................................................................................... 76\nConnecting and Expanding Commands  .................................................................. 78\nPiping between commands ........................................................................... 78\nSequential commands .................................................................................. 79\nBackground commands  ................................................................................ 79\nExpanding commands  .................................................................................. 80\nExpanding arithmetic expressions  ................................................................ 80\nExpanding variables  .................................................................................... 80", "doc_id": "84f892ba-86cc-4722-b4c5-d8cd1b0e6fe9", "embedding": null, "doc_hash": "699f092bc7e563284b183268d540df8b78ec6ef1e4468a58f72ee7a7648050b7", "extra_info": {"page_label": "11"}, "node_info": {"start": 0, "end": 4314}, "relationships": {"1": "72adc90f-c95b-45f4-a40d-7cebd2141e0b"}}, "__type__": "1"}, "9b452be2-62c9-4ceb-b684-bea4dd154485": {"__data__": {"text": "Contents\nxviiUsing Shell Variables ............................................................................................ 81\nCreating and using aliases ........................................................................... 81\nExiting the shell  ......................................................................................... 83\nCreating Your Shell Environment .......................................................................... 84\nConfiguring your shell ................................................................................ 84\nSetting your prompt .................................................................................... 85\nAdding environment variables  ..................................................................... 87\nGetting Information about Commands ................................................................... 88\nSummary  ............................................................................................................ 90\nExercises  ............................................................................................................. 90\nChapter 4: Moving Around the Filesystem .\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 93\nUsing Basic Filesystem Commands ......................................................................... 96\nUsing Metacharacters and Operators  ...................................................................... 98\nUsing file-matching metacharacters  .............................................................. 98\nUsing file-redirection metacharacters  ........................................................... 99\nUsing brace expansion characters  ............................................................... 101\nListing Files and Directories  ............................................................................... 101\nUnderstanding File Permissions and Ownership .................................................... 105\nChanging permissions with chmod (numbers) .............................................. 106\nChanging permissions with chmod (letters) ................................................. 107\nSetting default file permission with umask ................................................. 108\nChanging file ownership ............................................................................ 109\nMoving, Copying, and Removing Files .................................................................. 109\nSummary  .......................................................................................................... 111\nExercises  ........................................................................................................... 111\nChapter 5: Working with Text Files \u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 113\nEditing Files with vim and vi .............................................................................. 113\nStarting with vi ........................................................................................ 115\nAdding text  ...................................................................................... 115\nMoving around in the text ................................................................ 116\nDeleting, copying, and changing text  ................................................. 117\nPasting (putting) text  ....................................................................... 118\nRepeating commands ........................................................................ 118\nExiting vi  ......................................................................................... 118\nSkipping around in the file ........................................................................ 119\nSearching for text  ..................................................................................... 119\nUsing ex mode .......................................................................................... 120\nLearning more about vi and vim ................................................................. 120\nFinding Files  ..................................................................................................... 120\nUsing locate to find files by name ............................................................... 121\nSearching for files with find ....................................................................... 122\nFinding files by name ........................................................................ 123\nFinding files by size .......................................................................... 124", "doc_id": "9b452be2-62c9-4ceb-b684-bea4dd154485", "embedding": null, "doc_hash": "af5ef1304cac919f130e5efee44985b2a78303265a1689e0a26e6748ce324726", "extra_info": {"page_label": "12"}, "node_info": {"start": 0, "end": 4620}, "relationships": {"1": "b1cb4d27-35eb-4e48-881c-de73f0c61abd"}}, "__type__": "1"}, "3465dd95-f4ed-4030-8a97-e5c2785ab8ef": {"__data__": {"text": "Contents\nxviiiFinding files by user ......................................................................... 124\nFinding files by permission ................................................................ 125\nFinding files by date and time ........................................................... 125\nUsing \u2018not\u2019 and \u2018or\u2019 when finding files ................................................. 126\nFinding files and executing commands ............................................... 127\nSearching in files with grep ....................................................................... 128\nSummary  .......................................................................................................... 129\nExercises  ........................................................................................................... 129\nChapter 6: Managing Running Processes .\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 131\nUnderstanding Processes  .................................................................................... 131\nListing Processes  ............................................................................................... 132\nListing processes with ps ........................................................................... 132\nListing and changing processes with top ..................................................... 134\nListing processes with System Monitor ........................................................ 136\nManaging Background and Foreground Processes  .................................................. 137\nStarting background processes  ................................................................... 138\nUsing foreground and background commands  .............................................. 139\nKilling and Renicing Processes ............................................................................ 140\nKilling processes with kill and killall .......................................................... 140\nUsing kill to signal processes by PID  .................................................. 140\nUsing killall to signal processes by name ............................................ 141\nSetting processor priority with nice and renice ........................................... 142\nLimiting Processes with cgroups ......................................................................... 143\nSummary  .......................................................................................................... 144\nExercises  ........................................................................................................... 145\nChapter 7: Writing Simple Shell Scripts \u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 147\nUnderstanding Shell Scripts ................................................................................ 147\nExecuting and debugging shell scripts ........................................................ 148\nUnderstanding shell variables .................................................................... 149\nSpecial shell positional parameters .................................................... 150\nReading in parameters  ...................................................................... 151\nParameter expansion in bash ............................................................. 151\nPerforming arithmetic in shell scripts ......................................................... 152\nUsing programming constructs in shell scripts ............................................ 153\nThe \u2033 if.\u00a0.\u00a0.then \u2033 statements  ............................................................... 153\nThe case command ............................................................................ 156\nThe \u2033 for.\u00a0.\u00a0.do \u2033 loop  .......................................................................... 157\nThe \u2033 while.\u00a0.\u00a0.do \u2033 and \u2033 until.\u00a0.\u00a0.do \u2033 loops  ........................................... 158\nTrying some useful text manipulation programs .......................................... 159\nThe general regular expression parser ................................................. 159\nRemove sections of lines of text (cut) ................................................ 159\nTranslate or delete characters (tr) ...................................................... 160\nThe stream editor (sed) ..................................................................... 160", "doc_id": "3465dd95-f4ed-4030-8a97-e5c2785ab8ef", "embedding": null, "doc_hash": "2608f2884e4e2a8ae89603fdb9bf72c47377fd243d9543e1f1fe218fc4de9bc4", "extra_info": {"page_label": "13"}, "node_info": {"start": 0, "end": 4416}, "relationships": {"1": "70b81647-b9f6-4947-84a1-8350567b6836"}}, "__type__": "1"}, "e222dcae-300e-4b6b-bd46-961a92811dc4": {"__data__": {"text": "Contents\nxixUsing simple shell scripts ........................................................................... 161\nTelephone list  ................................................................................... 161\nBackup script  ................................................................................... 162\nSummary  .......................................................................................................... 163\nExercises  ........................................................................................................... 163\nPart III: Becoming a Linux System Administrator 165\nChapter 8: Learning System Administration \u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 167\nUnderstanding System Administration  ................................................................ 167\nUsing Graphical Administration Tools .................................................................. 169\nUsing Cockpit browser-based administration  ............................................... 169\nUsing system-config-* tools ....................................................................... 171\nUsing other browser-based admin tools ....................................................... 173\nUsing the root User Account ............................................................................... 174\nBecoming root from the shell (su command) ................................................ 175\nAllowing administrative access via the GUI ................................................. 176\nGaining administrative access with sudo  .................................................... 176\nExploring Administrative Commands, Configuration Files, and Log Files ................ 178\nAdministrative commands  ......................................................................... 178\nAdministrative configuration files  .............................................................. 179\nAdministrative log files and systemd journal ...................................... 183\nUsing journalctl to view the systemd journal ...................................... 184\nManaging log messages with rsyslogd  ................................................. 184\nUsing Other Administrative Accounts  .................................................................. 185\nChecking and Configuring Hardware .................................................................... 186\nChecking your hardware  ............................................................................ 187\nManaging removable hardware  ................................................................... 189\nWorking with loadable modules .................................................................. 191\nListing loaded modules ..................................................................... 191\nLoading modules ............................................................................... 192\nRemoving modules  ............................................................................ 192\nSummary  .......................................................................................................... 193\nExercises  ........................................................................................................... 193\nChapter 9: Installing Linux \u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 195\nChoosing a Computer .......................................................................................... 196\nInstalling Fedora from Live Media ....................................................................... 198\nInstalling Red Hat Enterprise Linux from Installation Media ................................. 201\nUnderstanding Cloud-Based Installations  ............................................................. 204\nInstalling Linux in the Enterprise  ....................................................................... 205\nExploring Common Installation Topics ................................................................. 207\nUpgrading or installing from scratch  .......................................................... 207\nDual booting ............................................................................................. 208", "doc_id": "e222dcae-300e-4b6b-bd46-961a92811dc4", "embedding": null, "doc_hash": "c99ce49700354368f5abf3f01c4852f89d55fcb2ea74007014d7a9180fe71207", "extra_info": {"page_label": "14"}, "node_info": {"start": 0, "end": 4262}, "relationships": {"1": "632d3ac0-6d03-4732-9749-6bb66cbabef6"}}, "__type__": "1"}, "327d31c7-2dbc-4034-a918-1ba6000a3e71": {"__data__": {"text": "Contents\nxxInstalling Linux to run virtually ................................................................ 209\nUsing installation boot options .................................................................. 210\nBoot options for disabling features .................................................... 210\nBoot options for video problems ......................................................... 210\nBoot options for special installation types .......................................... 210\nBoot options for kickstarts and remote repositories ............................. 211\nMiscellaneous boot options ................................................................ 212\nUsing specialized storage ........................................................................... 213\nPartitioning hard drives ............................................................................ 214\nUnderstanding different partition types ............................................ 215\nTips for creating partitions ................................................................ 215\nUsing the GRUB boot loader ....................................................................... 217\nSummary  .......................................................................................................... 219\nExercises  ........................................................................................................... 219\nChapter 10: Getting and Managing Software \u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 221\nManaging Software on the Desktop ..................................................................... 221\nGoing Beyond the Software Window .................................................................... 223\nUnderstanding Linux RPM and DEB Software Packaging ........................................ 224\nUnderstanding DEB packaging  .................................................................... 225\nUnderstanding RPM packaging  ................................................................... 226\nWhat is in an RPM? ........................................................................... 226\nWhere do RPMs come from? ............................................................... 227\nInstalling RPMs  ................................................................................ 228\nManaging RPM Packages with YUM ...................................................................... 229\nTransitioning from yum to dnf ................................................................... 229\nUnderstanding how yum works .................................................................. 229\nUsing YUM with third-party software repositories ....................................... 233\nManaging software with the yum command ................................................ 233\nSearching for packages  ...................................................................... 234\nInstalling and removing packages ...................................................... 236\nUpdating packages  ............................................................................ 238\nUpdating groups of packages ............................................................. 239\nMaintaining your RPM package database and cache ............................. 240\nDownloading RPMs from a YUM repository .......................................... 241\nInstalling, Querying, and Verifying Software with the rpm Command .................... 241\nInstalling and removing packages with rpm ................................................ 241\nQuerying rpm information ......................................................................... 242\nVerifying RPM packages  ............................................................................. 244\nManaging Software in the Enterprise .................................................................. 245\nSummary  .......................................................................................................... 246\nExercises  ........................................................................................................... 247", "doc_id": "327d31c7-2dbc-4034-a918-1ba6000a3e71", "embedding": null, "doc_hash": "a67a2816852433a3c6388a569ba42a1de8bf9858cc949344374d1d561fe1c6cc", "extra_info": {"page_label": "15"}, "node_info": {"start": 0, "end": 4130}, "relationships": {"1": "fc4e5dd6-17dc-41ff-b944-0a5e44017832"}}, "__type__": "1"}, "4bcea138-4ea5-47ca-a138-f990ab7ca50c": {"__data__": {"text": "Contents\nxxiChapter 11: Managing User Accounts .\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 249\nCreating User Accounts ...................................................................................... 249\nAdding users with useradd ......................................................................... 252\nSetting user defaults ................................................................................. 255\nModifying users with usermod ................................................................... 257\nDeleting users with userdel ........................................................................ 258\nUnderstanding Group Accounts  ........................................................................... 259\nUsing group accounts  ................................................................................ 259\nCreating group accounts  ............................................................................ 260\nManaging Users in the Enterprise ........................................................................ 261\nSetting permissions with Access Control Lists ............................................. 262\nSetting ACLs with setfacl .................................................................. 262\nSetting default ACLs ......................................................................... 264\nEnabling ACLs  .................................................................................. 265\nAdding directories for users to collaborate .......................................... 267\nCreating group collaboration directories (set GID bit) .......................... 267\nCreating restricted deletion directories (sticky bit) ............................. 268\nCentralizing User Accounts  ................................................................................. 269\nSummary  .......................................................................................................... 270\nExercises  ........................................................................................................... 270\nChapter 12: Managing Disks and Filesystems .\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 273\nUnderstanding Disk Storage ................................................................................ 273\nPartitioning Hard Disks ...................................................................................... 275\nUnderstanding partition tables  .................................................................. 275\nViewing disk partitions ............................................................................. 276\nCreating a single-partition disk .................................................................. 277\nCreating a multiple-partition disk .............................................................. 281\nUsing Logical Volume Manager Partitions ............................................................. 285\nChecking an existing LVM  .......................................................................... 286\nCreating LVM logical volumes ..................................................................... 289\nGrowing LVM logical volumes ..................................................................... 290\nMounting Filesystems  ........................................................................................ 291\nSupported filesystems  ................................................................................ 291\nEnabling swap areas .................................................................................. 293\nDisabling swap area  ................................................................................... 294\nUsing the fstab file to define mountable file systems ................................... 295\nUsing the mount command to mount file systems ........................................ 297\nMounting a disk image in loopback ............................................................. 298\nUsing the umount command ...................................................................... 299\nUsing the mkfs Command to Create a Filesystem .................................................. 300\nManaging Storage with Cockpit ........................................................................... 301\nSummary  .......................................................................................................... 303\nExercises  ........................................................................................................... 303", "doc_id": "4bcea138-4ea5-47ca-a138-f990ab7ca50c", "embedding": null, "doc_hash": "017d9f7547e197a6d87d2a88fd81ae69c94b1ece65fe9b49c35dd72ec66a1822", "extra_info": {"page_label": "16"}, "node_info": {"start": 0, "end": 4558}, "relationships": {"1": "15d19c7a-a447-4094-9e6e-ec680417ef0f"}}, "__type__": "1"}, "394ba390-88e3-4b01-b16c-03f51c5ac493": {"__data__": {"text": "Contents\nxxiiPart IV: Becoming a Linux Server Administrator 305\nChapter 13: Understanding Server Administration \u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 307\nStarting with Server Administration  ................................................................... 308\nStep 1: Install the server ........................................................................... 308\nStep 2: Configure the server ....................................................................... 310\nUsing configuration files  ................................................................... 310\nChecking the default configuration .................................................... 310\nStep 3: Start the server .............................................................................. 311\nStep 4: Secure the server ........................................................................... 312\nPassword protection  .......................................................................... 312\nFirewalls  .......................................................................................... 313\nTCP Wrappers  .................................................................................... 313\nSELinux  ........................................................................................... 313\nSecurity settings in configuration files ............................................... 314\nStep 5: Monitor the server .......................................................................... 314\nConfigure logging ............................................................................. 314\nRun system activity reports ............................................................... 314\nWatch activity live with Cockpit ........................................................ 314\nKeep system software up to date ........................................................ 315\nCheck the filesystem for signs of crackers ........................................... 315\nChecking and Setting Servers ............................................................................. 316\nManaging Remote Access with the Secure Shell Service ........................................ 316\nStarting the openssh-server service  ............................................................ 317\nUsing SSH client tools ............................................................................... 318\nUsing ssh for remote login ................................................................. 318\nUsing ssh for remote execution .......................................................... 320\nCopying files between systems with scp and rsync .............................. 321\nInteractive copying with sftp ............................................................ 324\nUsing key-based (passwordless) authentication  ........................................... 324\nConfiguring System Logging ............................................................................... 326\nEnabling system logging with rsyslog ......................................................... 326\nUnderstanding the rsyslog.conf file .................................................... 327\nUnderstanding the messages log file .................................................. 329\nSetting up and using a loghost with rsyslogd ...................................... 330\nWatching logs with logwatch ...................................................................... 331\nChecking System Resources with sar ................................................................... 332\nChecking System Space  ...................................................................................... 334\nDisplaying system space with df ................................................................. 334\nChecking disk usage with du ...................................................................... 334\nFinding disk consumption with find  ........................................................... 335\nManaging Servers in the Enterprise ..................................................................... 336\nSummary  .......................................................................................................... 336\nExercises  ........................................................................................................... 337", "doc_id": "394ba390-88e3-4b01-b16c-03f51c5ac493", "embedding": null, "doc_hash": "9a3bf9924d57711de369fdbc3db5f33a51ee58c792c4d6270d6a76f57f25543a", "extra_info": {"page_label": "17"}, "node_info": {"start": 0, "end": 4333}, "relationships": {"1": "15b2b17a-5edb-4d24-b625-13942edb47a9"}}, "__type__": "1"}, "12e706e5-3d10-4846-bb2f-d701de452a60": {"__data__": {"text": "Contents\nxxiiiChapter 14: Administering Networking .\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 339\nConfiguring Networking for Desktops  .................................................................. 340\nChecking your network interfaces .............................................................. 342\nChecking your network from NetworkManager .................................... 342\nChecking your network from Cockpit .................................................. 343\nChecking your network from the command line .................................. 345\nConfiguring network interfaces  .................................................................. 349\nSetting IP addresses manually ........................................................... 349\nSetting IP address aliases .................................................................. 350\nSetting routes  .................................................................................. 351\nConfiguring a network proxy connection ..................................................... 352\nConfiguring Networking from the Command Line ................................................. 353\nConfigure networking with nmtui ............................................................... 354\nEditing a NetworkManager TUI connection .................................................. 354\nUnderstanding networking configuration files ............................................. 355\nNetwork interface files  ...................................................................... 356\nOther networking files  ...................................................................... 358\nSetting alias network interfaces ................................................................. 360\nSetting up Ethernet channel bonding ......................................................... 361\nSetting custom routes ............................................................................... 363\nConfiguring Networking in the Enterprise  ............................................................ 364\nConfiguring Linux as a router ..................................................................... 364\nConfiguring Linux as a DHCP server ............................................................ 365\nConfiguring Linux as a DNS server .............................................................. 365\nConfiguring Linux as a proxy server ............................................................ 366\nSummary  .......................................................................................................... 366\nExercises  ........................................................................................................... 367\nChapter 15: Starting and Stopping Services .\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 369\nUnderstanding the Initialization Daemon (init or systemd) ................................... 370\nUnderstanding the classic init daemons ...................................................... 371\nUnderstanding systemd initialization  ......................................................... 377\nLearning systemd basics ................................................................... 377\nLearning systemd\u2019s backward compatibility to SysVinit ....................... 382\nChecking the Status of Services .......................................................................... 384\nChecking services for SysVinit systems ....................................................... 385\nStopping and Starting Services ........................................................................... 387\nStopping and starting SysVinit services ...................................................... 387\nStopping a service with systemd ........................................................ 389\nStarting a service with systemd ......................................................... 389\nRestarting a service with systemd ..................................................... 389\nReloading a service with systemd ...................................................... 390\nEnabling Persistent Services  ............................................................................... 391\nConfiguring persistent services for SysVinit  ................................................ 391", "doc_id": "12e706e5-3d10-4846-bb2f-d701de452a60", "embedding": null, "doc_hash": "b63635a80f8e959e6e897b05b8ddf5415b23547696280b2a52b747edc2662a21", "extra_info": {"page_label": "18"}, "node_info": {"start": 0, "end": 4333}, "relationships": {"1": "3b2250d0-b93c-49ce-9c98-ddf0a2e5f90c"}}, "__type__": "1"}, "4eb89310-240b-47b5-b5ea-10d87bc1ab85": {"__data__": {"text": "Contents\nxxivEnabling a service with systemd ........................................................ 392\nDisabling a service with systemd ....................................................... 393\nConfiguring a Default Runlevel or Target Unit ...................................................... 394\nConfiguring the SysVinit default runlevel .................................................... 394\nAdding New or Customized Services .................................................................... 396\nAdding new services to SysVinit ................................................................. 396\nStep 1: Create a new or customized service script file .......................... 396\nStep 2: Add the service script to /etc/rc.d/init.d ................................. 398\nStep 3: Set appropriate permission on the script ................................. 398\nStep 4: Add the service to runlevel directories .................................... 398\nAdding new services to systemd ................................................................. 399\nStep 1: Create a new or customized service configuration unit file ........ 399\nStep 2: Move the service configuration unit file .................................. 399\nStep 3: Add the service to the Wants directory ................................... 400\nSummary  .......................................................................................................... 401\nExercises  ........................................................................................................... 401\nChapter 16: Configuring a Print Server .\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 403\nCommon UNIX Printing System ........................................................................... 403\nSetting Up Printers  ............................................................................................ 405\nAdding a printer automatically ................................................................... 405\nUsing web-based CUPS administration  ........................................................ 406\nAllow remote printing administration  ................................................ 406\nAdd a printer not automatically detected ............................................ 407\nUsing the Print Settings window  ................................................................ 409\nConfiguring local printers with the Print Settings window ................... 409\nConfiguring remote printers  .............................................................. 412\nAdding a remote CUPS printer ............................................................ 413\nAdding a remote UNIX (LDP/LPR) printer ............................................ 413\nAdding a Windows (SMB) printer ........................................................ 414\nWorking with CUPS Printing  ............................................................................... 415\nConfiguring the CUPS server (cupsd.conf) ................................................... 415\nStarting the CUPS server ........................................................................... 417\nConfiguring CUPS printer options manually ................................................. 417\nUsing Printing Commands  .................................................................................. 418\nPrinting with lp  ........................................................................................ 419\nListing status with lpstat -t ....................................................................... 419\nRemoving print jobs with lprm ................................................................... 419\nConfiguring Print Servers ................................................................................... 420\nConfiguring a shared CUPS printer .............................................................. 420\nConfiguring a shared Samba printer ............................................................ 422\nUnderstanding smb .conf for printing  ................................................. 422\nSetting up SMB clients ...................................................................... 423\nSummary  .......................................................................................................... 424\nExercises  ........................................................................................................... 424", "doc_id": "4eb89310-240b-47b5-b5ea-10d87bc1ab85", "embedding": null, "doc_hash": "8769e0c8225f37781f07e7e2e4b6101d90cba79e497b9e7d7efa96a97173feef", "extra_info": {"page_label": "19"}, "node_info": {"start": 0, "end": 4431}, "relationships": {"1": "6547b7de-10ba-4eb6-9257-7d27201f9301"}}, "__type__": "1"}, "6257cdce-4127-42fe-a04d-d2623ea1c107": {"__data__": {"text": "Contents\nxxvChapter 17: Configuring a Web Server \u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 427\nUnderstanding the Apache Web Server ................................................................ 427\nGetting and Installing Your Web Server ............................................................... 428\nUnderstanding the httpd package .............................................................. 428\nInstalling Apache  ...................................................................................... 431\nStarting Apache  ................................................................................................ 432\nSecuring Apache  ....................................................................................... 433\nApache file permissions and ownership .............................................. 433\nApache and firewalls ......................................................................... 433\nApache and SELinux ......................................................................... 434\nUnderstanding the Apache configuration files ............................................. 435\nUsing directives  ................................................................................ 435\nUnderstanding default settings .......................................................... 438\nAdding a virtual host to Apache ................................................................. 440\nAllowing users to publish their own web content ......................................... 442\nSecuring your web traffic with SSL/TLS ...................................................... 443\nUnderstanding how SSL is configured ................................................. 445\nGenerating an SSL key and self-signed certificate ............................... 447\nGenerating a certificate signing request ............................................. 448\nTroubleshooting Your Web Server ........................................................................ 449\nChecking for configuration errors  ............................................................... 449\nAccessing forbidden and server internal errors  ............................................ 451\nSummary  .......................................................................................................... 453\nExercises  ........................................................................................................... 453\nChapter 18: Configuring an FTP Server .\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 455\nUnderstanding FTP  ............................................................................................ 455\nInstalling the vsftpd FTP Server ......................................................................... 457\nStarting the vsftpd Service ................................................................................ 458\nSecuring Your FTP Server .................................................................................... 461\nOpening up your firewall for FTP ................................................................ 461\nConfiguring SELinux for your FTP server ..................................................... 463\nRelating Linux file permissions to vsftpd .................................................... 465\nConfiguring Your FTP Server ............................................................................... 465\nSetting up user access ............................................................................... 465\nAllowing uploading  ................................................................................... 467\nSetting up vsftpd for the Internet .............................................................. 468\nUsing FTP Clients to Connect to Your Server ......................................................... 469\nAccessing an FTP server from Firefox .......................................................... 470\nAccessing an FTP server with the lftp command .......................................... 470\nUsing the gFTP client ................................................................................ 472\nSummary  .......................................................................................................... 473\nExercises  ........................................................................................................... 473", "doc_id": "6257cdce-4127-42fe-a04d-d2623ea1c107", "embedding": null, "doc_hash": "3eec0222b295546accafd23451767b53a2f5fa0e06307a233f8018389043d321", "extra_info": {"page_label": "20"}, "node_info": {"start": 0, "end": 4416}, "relationships": {"1": "99bbc038-fd74-47bb-b0a2-3a3eed98385f"}}, "__type__": "1"}, "bc4e0317-9860-4a4a-8c48-a2f9901b5ad5": {"__data__": {"text": "Contents\nxxviChapter 19: Configuring a Windows File Sharing (Samba) Server \u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 475\nUnderstanding Samba  ........................................................................................ 475\nInstalling Samba  ............................................................................................... 476\nStarting and Stopping Samba ............................................................................. 478\nStarting the Samba (smb) service ............................................................... 478\nStarting the NetBIOS (nmbd) name server ................................................... 480\nStopping the Samba (smb) and NetBIOS (nmb) services ................................. 481\nSecuring Samba ................................................................................................. 482\nConfiguring firewalls for Samba .................................................................. 482\nConfiguring SELinux for Samba .................................................................. 484\nSetting SELinux Booleans for Samba .................................................. 484\nSetting SELinux file contexts for Samba ............................................. 485\nConfiguring Samba host/user permissions ................................................... 486\nConfiguring Samba  ............................................................................................. 486\nConfiguring the [global] section ................................................................. 486\nConfiguring the [homes] section ................................................................. 487\nConfiguring the [printers] section  .............................................................. 489\nCreating a Samba shared folder .......................................................... 489\nAdding the shared folder to Samba .................................................... 490\nChecking the Samba share ................................................................. 490\nAccessing Samba Shares  ..................................................................................... 493\nAccessing Samba shares in Linux ................................................................ 493\nAccessing Samba shares from a Linux file manager .............................. 493\nMounting a Samba share from a Linux command line .......................... 495\nAccessing Samba shares in Windows ........................................................... 496\nUsing Samba in the Enterprise ............................................................................ 497\nSummary  .......................................................................................................... 497\nExercises  ........................................................................................................... 498\nChapter 20: Configuring an NFS File Server \u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 499\nInstalling an NFS Server ..................................................................................... 502\nStarting the NFS service ..................................................................................... 502\nSharing NFS Filesystems ..................................................................................... 503\nConfiguring the /etc/exports file ................................................................ 504\nHostnames in /etc/exports  ................................................................ 505\nAccess options in /etc/exports ........................................................... 506\nUser mapping options in /etc/exports  ................................................ 506\nExporting the shared filesystems ................................................................ 507\nSecuring Your NFS Server ................................................................................... 508\nOpening up your firewall for NFS ................................................................ 508\nAllowing NFS access in TCP wrappers .......................................................... 510\nConfiguring SELinux for your NFS server ..................................................... 511\nUsing NFS Filesystems ........................................................................................ 512\nViewing NFS shares ................................................................................... 512", "doc_id": "bc4e0317-9860-4a4a-8c48-a2f9901b5ad5", "embedding": null, "doc_hash": "998d840200c081354ff3eddc59fed4a45e65ad84e08fa4e0ec1048ba74fc1d05", "extra_info": {"page_label": "21"}, "node_info": {"start": 0, "end": 4458}, "relationships": {"1": "9614a124-f62a-43c7-afac-379c1cac8718"}}, "__type__": "1"}, "b74a91ba-d4c7-42f0-b003-63584c4ef701": {"__data__": {"text": "Contents\nxxviiManually mounting an NFS filesystem ......................................................... 512\nMounting an NFS filesystem at boot time .................................................... 513\nMounting noauto filesystems  ............................................................. 514\nUsing mount options  ......................................................................... 515\nUsing autofs to mount NFS filesystems on demand ....................................... 517\nAutomounting to the /net directory  .................................................. 517\nAutomounting home directories  ......................................................... 518\nUnmounting NFS filesystems .............................................................................. 520\nSummary  .......................................................................................................... 521\nExercises  ........................................................................................................... 521\nChapter 21: Troubleshooting Linux .\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 523\nBoot-Up Troubleshooting  .................................................................................... 523\nUnderstanding Startup Methods ................................................................. 524\nStarting with System V init scripts .................................................... 524\nStarting with systemd ...................................................................... 525\nStarting from the firmware (BIOS or UEFI) .................................................. 526\nTroubleshooting BIOS setup  ............................................................... 526\nTroubleshooting boot order  ............................................................... 527\nTroubleshooting the GRUB boot loader ........................................................ 528\nThe GRUB Legacy boot loader ............................................................. 528\nGRUB 2 Boot loader ................................................................................... 530\nStarting the kernel ................................................................................... 532\nTroubleshooting the initialization system  .......................................... 533\nTroubleshooting System V initialization ............................................. 533\nTroubleshooting rc.sysinit  ................................................................. 533\nTroubleshooting runlevel processes  .................................................... 534\nTroubleshooting systemd initialization  .............................................. 538\nTroubleshooting Software Packages  ..................................................................... 542\nFixing RPM databases and cache ................................................................. 545\nTroubleshooting Networking  ............................................................................... 547\nTroubleshooting outgoing connections ........................................................ 547\nView network interfaces .................................................................... 547\nCheck physical connections  ............................................................... 548\nCheck routes  .................................................................................... 548\nCheck hostname resolution ................................................................ 549\nTroubleshooting incoming connections  ....................................................... 550\nCheck if the client can reach your system at all .................................. 551\nCheck if the service is available to the client ...................................... 551\nCheck the firewall on the server ......................................................... 552\nCheck the service on the server ......................................................... 553\nTroubleshooting Memory  .................................................................................... 553\nUncovering memory issues ......................................................................... 554\nChecking for memory problems  .......................................................... 556\nDealing with memory problems .......................................................... 558", "doc_id": "b74a91ba-d4c7-42f0-b003-63584c4ef701", "embedding": null, "doc_hash": "d91b76aac863cba386e02574123393cce1344f634ecc60a1a9b6061299da2332", "extra_info": {"page_label": "22"}, "node_info": {"start": 0, "end": 4391}, "relationships": {"1": "babf8ba1-22b6-42cd-86fa-c702119e7296"}}, "__type__": "1"}, "6f7f3332-c5a2-445a-98d4-836b45758eca": {"__data__": {"text": "Contents\nxxviiiTroubleshooting in Rescue Mode ......................................................................... 559\nSummary  .......................................................................................................... 561\nExercises  ........................................................................................................... 561\nPart V: Learning Linux Security Techniques 563\nChapter 22: Understanding Basic Linux Security \u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 565\nImplementing Physical Security .......................................................................... 565\nImplementing disaster recovery  ................................................................. 566\nSecuring user accounts  .............................................................................. 566\nOne user per user account ................................................................. 567\nLimiting access to the root user account ............................................ 567\nSetting expiration dates on temporary accounts ................................. 567\nRemoving unused user accounts ........................................................ 568\nSecuring passwords  ................................................................................... 570\nChoosing good passwords  .................................................................. 570\nSetting and changing passwords  ........................................................ 571\nEnforcing best password practices  ...................................................... 572\nUnderstanding the password files and password hashes ....................... 574\nSecuring the filesystem ............................................................................. 576\nManaging dangerous filesystem permissions  ....................................... 576\nSecuring the password files ............................................................... 577\nLocking down the filesystem ............................................................. 578\nManaging software and services ................................................................. 579\nUpdating software packages  .............................................................. 579\nKeeping up with security advisories ................................................... 580\nAdvanced implementation .......................................................................... 580\nMonitoring Your Systems .................................................................................... 580\nMonitoring log files ................................................................................... 581\nMonitoring user accounts  ........................................................................... 584\nDetecting counterfeit new accounts and privileges .............................. 584\nDetecting bad account passwords  ....................................................... 586\nMonitoring the filesystem .......................................................................... 587\nVerifying software packages  .............................................................. 588\nScanning the filesystem .................................................................... 589\nDetecting viruses and rootkits ........................................................... 590\nAuditing and Reviewing Linux ............................................................................ 595\nConducting compliance reviews  .................................................................. 595\nConducting security reviews ...................................................................... 596\nSummary  .......................................................................................................... 596\nExercises  ........................................................................................................... 597\nChapter 23: Understanding Advanced Linux Security \u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 599\nImplementing Linux Security with Cryptography ................................................. 599\nUnderstanding hashing  ............................................................................. 600", "doc_id": "6f7f3332-c5a2-445a-98d4-836b45758eca", "embedding": null, "doc_hash": "87395e1e9413f6bb062dbb186a3c68445d9cb49d8259819d319f103b42cdd638", "extra_info": {"page_label": "23"}, "node_info": {"start": 0, "end": 4223}, "relationships": {"1": "ba0fd3fb-2846-4096-9fe7-09db24c6613b"}}, "__type__": "1"}, "d2100c3b-2002-4c87-953a-48e0c9a4c1ba": {"__data__": {"text": "Contents\nxxixUnderstanding encryption/decryption  ........................................................ 602\nUnderstanding cryptographic ciphers  ................................................. 602\nUnderstanding cryptographic cipher keys  ........................................... 603\nUnderstanding digital signatures  ....................................................... 608\nImplementing Linux cryptography  ............................................................. 610\nEnsuring file integrity ...................................................................... 610\nEncrypting a Linux filesystem at installation ..................................... 611\nEncrypting a Linux directory  ............................................................. 613\nEncrypting a Linux file ..................................................................... 616\nEncrypting Linux with miscellaneous tools ........................................ 616\nUsing Encryption from the Desktop .................................................... 617\nImplementing Linux Security with PAM ............................................................... 618\nUnderstanding the PAM authentication process ........................................... 619\nUnderstanding PAM contexts ............................................................. 619\nUnderstanding PAM control flags  ....................................................... 620\nUnderstanding PAM modules .............................................................. 621\nAdministering PAM on your Linux system ................................................... 622\nManaging PAM-aware application configuration files ........................... 622\nManaging PAM system event configuration files .................................. 623\nImplementing time restrictions with PAM ........................................... 626\nEnforcing good passwords with PAM ................................................... 628\nEncouraging sudo use with PAM ......................................................... 632\nObtaining more information on PAM ........................................................... 633\nSummary  .......................................................................................................... 633\nExercises  ........................................................................................................... 633\nChapter 24: Enhancing Linux Security with SELinux \u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 635\nUnderstanding SELinux Benefits  ......................................................................... 635\nUnderstanding How SELinux Works ..................................................................... 637\nUnderstanding Type Enforcement  ............................................................... 637\nUnderstanding Multi-Level Security ............................................................ 638\nImplementing SELinux security models ....................................................... 639\nUnderstanding SELinux operational modes ......................................... 639\nUnderstanding SELinux security contexts ........................................... 640\nUnderstanding SELinux Policy types  .................................................. 643\nUnderstanding SELinux policy rule packages  ...................................... 644\nConfiguring SELinux  .......................................................................................... 645\nSetting the SELinux mode .......................................................................... 645\nSetting the SELinux policy type ................................................................. 647\nManaging SELinux security contexts .......................................................... 648\nManaging the user security context ................................................... 649\nManaging the file security context ..................................................... 650\nManaging the process security context ............................................... 651\nManaging SELinux policy rule packages ...................................................... 651\nManaging SELinux via Booleans ................................................................. 653\nMonitoring and Troubleshooting SELinux  ............................................................ 654", "doc_id": "d2100c3b-2002-4c87-953a-48e0c9a4c1ba", "embedding": null, "doc_hash": "60f51df9599a1020a57744941a4ea51b3702d453b1f18e24a742036fdae29b36", "extra_info": {"page_label": "24"}, "node_info": {"start": 0, "end": 4365}, "relationships": {"1": "361141c9-e7b5-4045-9f0f-4c1c5c68b2cc"}}, "__type__": "1"}, "98b8b684-e16c-47d3-84e8-bab3d0e7c19c": {"__data__": {"text": "Contents\nxxxUnderstanding SELinux logging  .................................................................. 654\nReviewing SELinux messages in the audit log ..................................... 655\nReviewing SELinux messages in the messages log ................................ 655\nTroubleshooting SELinux logging  ............................................................... 656\nTroubleshooting common SELinux problems  ................................................ 657\nUsing a nonstandard directory for a service ........................................ 657\nUsing a nonstandard port for a service ............................................... 658\nMoving files and losing security context labels ................................... 658\nBooleans set incorrectly .................................................................... 658\nPutting It All Together ....................................................................................... 659\nObtaining More Information on SELinux .............................................................. 659\nSummary  .......................................................................................................... 660\nExercises  ........................................................................................................... 660\nChapter 25: Securing Linux on a Network .\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 663\nAuditing Network Services ................................................................................. 663\nEvaluating access to network services with nmap ........................................ 665\nUsing nmap to audit your network services advertisements .......................... 668\nWorking with Firewalls  ....................................................................................... 672\nUnderstanding firewalls  ............................................................................. 673\nImplementing firewalls  .............................................................................. 674\nStarting with firewalld  ...................................................................... 675\nChanging firewall rules with Cockpit .................................................. 677\nUnderstanding the iptables utility ..................................................... 678\nUsing the iptables utility .................................................................. 680\nSummary  .......................................................................................................... 688\nExercises  ........................................................................................................... 688\nPart VI: Engaging with Cloud Computing 691\nChapter 26: Shifting to Clouds and Containers .\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 693\nUnderstanding Linux Containers  ......................................................................... 694\nNamespaces  .............................................................................................. 695\nContainer registries  ................................................................................... 695\nBase images and layers .............................................................................. 696\nStarting with Linux Containers  ........................................................................... 697\nPulling and running containers .................................................................. 697\nPulling a container ........................................................................... 697\nRunning a shell from a container ....................................................... 698\nRunning an FTP server from a container ............................................. 699\nStarting and stopping containers  ............................................................... 701\nBuilding a container image ........................................................................ 702\nBuild a simple container image .......................................................... 702\nBuild an FTP container from GitHub ................................................... 703", "doc_id": "98b8b684-e16c-47d3-84e8-bab3d0e7c19c", "embedding": null, "doc_hash": "2354f282be33a0fff54aaa8fd0920e9bd78e8d65857cb861e1a8314c3a0b358d", "extra_info": {"page_label": "25"}, "node_info": {"start": 0, "end": 4154}, "relationships": {"1": "d6edda22-194e-4dd8-82b9-86fdacddf479"}}, "__type__": "1"}, "c0191bac-3de7-4d6d-87d1-d521169c6125": {"__data__": {"text": "Contents\nxxxiTagging and pushing an image to a registry ................................................ 705\nUsing containers in the enterprise  .............................................................. 706\nSummary  .......................................................................................................... 706\nExercises  ........................................................................................................... 707\nChapter 27: Using Linux for Cloud Computing .\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 709\nOverview of Linux and Cloud Computing .............................................................. 710\nCloud hypervisors (aka compute nodes) ....................................................... 710\nCloud controllers  ....................................................................................... 711\nCloud storage  ............................................................................................ 711\nCloud authentication  ................................................................................. 712\nCloud deployment and configuration .......................................................... 712\nCloud platforms  ......................................................................................... 712\nTrying Basic Cloud Technology ............................................................................ 713\nSetting Up a Small Cloud .................................................................................... 714\nConfiguring hypervisors  ............................................................................ 715\nStep 1: Get Linux software ................................................................ 715\nStep 2: Check your computers ............................................................ 715\nStep 3: Install Linux on hypervisors ................................................... 716\nStep 4: Start services on the hypervisors ............................................ 717\nStep 5: Edit /etc/hosts, or set up DNS ................................................. 718\nConfiguring storage  ................................................................................... 718\nStep 1: Install Linux software ............................................................ 718\nStep 2: Configure NFS share ............................................................... 719\nStep 3: Start the NFS service ............................................................. 719\nStep 4: Mount the NFS share on the hypervisors .................................. 720\nCreating virtual machines  .......................................................................... 720\nStep 1: Get images to make virtual machines ...................................... 721\nStep 2: Check the network bridge ....................................................... 721\nStep 3: Start Virtual Machine Manager (virt-manager) ......................... 722\nStep 4: Check connection details ........................................................ 722\nStep 5: Create a new virtual machine ................................................. 722\nManaging virtual machines  ........................................................................ 724\nMigrating virtual machines  ........................................................................ 725\nStep 1: Identify other hypervisors ..................................................... 726\nStep 2: Migrate running VM to Other hypervisor ................................. 726\nSummary  .......................................................................................................... 727\nExercises  ........................................................................................................... 727\nChapter 28: Deploying Linux to the Cloud .\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 729\nGetting Linux to Run in a Cloud .......................................................................... 729\nCreating Linux Images for Clouds ........................................................................ 731\nConfiguring and running a cloud-init cloud instance ................................... 731\nInvestigating the cloud instance ................................................................ 733\nCloning the cloud instance ......................................................................... 734\nExpanding your cloud-init configuration ............................................ 735", "doc_id": "c0191bac-3de7-4d6d-87d1-d521169c6125", "embedding": null, "doc_hash": "5383290e585b9c2c699ce56b786b3ca531359f6f539211eaf8b6d57da64a8285", "extra_info": {"page_label": "26"}, "node_info": {"start": 0, "end": 4502}, "relationships": {"1": "e7632259-1f52-4687-b941-fd17f76991b6"}}, "__type__": "1"}, "384c421d-a650-402a-a59b-358614d5939a": {"__data__": {"text": "Contents\nxxxiiAdding ssh keys with cloud-init ......................................................... 736\nAdding software with cloud-init ........................................................ 737\nUsing cloud-init in enterprise computing  .................................................... 738\nUsing OpenStack to Deploy Cloud Images ............................................................. 739\nStarting from the OpenStack Dashboard ...................................................... 739\nConfiguring your OpenStack virtual network ...................................... 739\nConfiguring keys for remote access .................................................... 741\nLaunching a virtual machine in OpenStack ......................................... 742\nAccessing the virtual machine via ssh ................................................ 743\nUsing Amazon EC2 to Deploy Cloud Images .......................................................... 744\nSummary  .......................................................................................................... 746\nExercises  ........................................................................................................... 746\nChapter 29: Automating Apps and Infrastructure with Ansible \u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 749\nUnderstanding Ansible  ....................................................................................... 750\nExploring Ansible Components  ............................................................................ 751\nInventories  ............................................................................................... 751\nPlaybooks  ................................................................................................. 752\nPlays  ............................................................................................... 752\nTasks  ............................................................................................... 752\nModules  ........................................................................................... 752\nRoles, imports, and includes .............................................................. 753\nStepping Through an Ansible Deployment ............................................................ 753\nPrerequisites  ............................................................................................. 754\nSetting up SSH keys to each node ............................................................... 754\nInstalling Ansible  .............................................................................................. 756\nCreating an inventory  ................................................................................ 756\nAuthenticating to the hosts ....................................................................... 757\nCreating a playbook ................................................................................... 757\nRun the playbook ...................................................................................... 758\nRunning Ad-Hoc Ansible Commands .................................................................... 760\nTrying ad-hoc commands ........................................................................... 761\nAutomating Tasks with Ansible Tower Automation Framework .............................. 762\nSummary  .......................................................................................................... 763\nExercises  ........................................................................................................... 763\nChapter 30: Deploying Applications as Containers with Kubernetes \u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 765\nUnderstanding Kubernetes  ................................................................................. 766\nKubernetes masters  ................................................................................... 766\nKubernetes workers  ................................................................................... 767\nKubernetes applications  ............................................................................. 767\nKubernetes interfaces  ................................................................................ 768\nTrying Kubernetes  ............................................................................................. 768\nGetting Kubernetes  ................................................................................... 769\nStarting the Kubernetes Basics Tutorial .............................................. 769\nStarting Minikube  ............................................................................ 770", "doc_id": "384c421d-a650-402a-a59b-358614d5939a", "embedding": null, "doc_hash": "03b5e960e2d2dfa15be91952456ae9aa0df04d3d45eb31285ba711c1e4ed3ccc", "extra_info": {"page_label": "27"}, "node_info": {"start": 0, "end": 4644}, "relationships": {"1": "837295da-79b3-4a37-8320-3e6aa6cb8289"}}, "__type__": "1"}, "46d2a782-7f34-4aef-98fc-ff743ec222fe": {"__data__": {"text": "Contents\nxxxiiiRunning the Kubernetes Basics tutorial ...................................................... 771\nGet information about your cluster .................................................... 771\nDeploy a Kubernetes application ........................................................ 772\nGet information on the deployment\u2019s pods .......................................... 773\nExpose applications with services ...................................................... 776\nLabel a service ................................................................................. 777\nDelete a service ................................................................................ 778\nScale up an application ..................................................................... 779\nCheck the load balancer .................................................................... 780\nScale down an application ................................................................. 781\nEnterprise-Quality Kubernetes with OpenShift  ..................................................... 782\nSummary  .......................................................................................................... 783\nExercises  ........................................................................................................... 783\nPart VII: Appendixes 785\nAppendix A: Media .\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 787\nAppendix B: Exercise Answers \u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 797\nIndex .\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0.\u00a0. 863", "doc_id": "46d2a782-7f34-4aef-98fc-ff743ec222fe", "embedding": null, "doc_hash": "4e4b3d2cab2f1b3e915c8dbe35fbdda30f5bf3b5ea98b13df7f24937a8d7478d", "extra_info": {"page_label": "28"}, "node_info": {"start": 0, "end": 1731}, "relationships": {"1": "9bb3ac0c-a620-4cf4-89bc-18bc0f066e96"}}, "__type__": "1"}, "90dc78a7-b6be-44ba-845c-ca21caa823b6": {"__data__": {"text": "xxxvIntroduction\nYou can\u2019t learn Linux without using it.\nI\u2019ve come to that conclusion after more than two decades of teaching people how to use \nLinux. You can\u2019t just read a book; you can\u2019t just listen to a lecture. You need someone to \nguide you, and you need to jump in and do it yourself.\nIn 1999, I wrote my first Linux book, the Red Hat Linux Bible . The book\u2019s huge success gave \nme the opportunity to become a full-time, independent Linux author. For about a decade, I \nwrote dozens of Linux books and explored the best ways to explain Linux from the quiet of \nmy small home office.\nIn 2008, I hit the road. I was hired by Red Hat, Inc., as a full-time instructor, teaching Linux \nto professional system administrators seeking Red Hat Certified Engineer (RHCE) certifica -\ntion. In my three years as a Linux instructor, I honed my teaching skills in front of a live \naudience whose Linux experience ranged from none to experienced professionals. Over time, I \nwas able to broaden my own knowledge of Linux by acquiring about 10 certifications, includ -\ning the Red Hat Certified Architect (RHCA) certification.\nIn the previous edition of the Linux Bible , I turned my teaching experience into text to take \na reader from someone who has never used Linux to someone with the foundational skills to \nbecome a Linux professional. The skills that you could acquire from that edition remain in \neffect in this edition as well. They include the following:\nBeginner to certified professional : As long as you have used a computer, mouse, and \nkeyboard, you can start with this book. I tell you how to get Linux, begin using it, \nstep through critical topics, and ultimately excel at administering and securing it.\nSystem administrator focused : When you are finished with this book, you will know \nhow to use Linux and how to modify and maintain it. Almost all of the topics \nneeded to become a Red Hat Certified Engineer are introduced in this book. That \nsaid, many software developers have also used this book to understand how to work \non a Linux system as a development platform or target for their applications.\nEmphasis on command-line tools : Although point-and-click windows for managing \nLinux have improved greatly in recent years, many advanced features can only be \nutilized by entering commands and editing configuration files manually. I teach \nyou how to become proficient with the Linux command-line shell, and I occasionally \ncompare shell features with graphical tools for accomplishing the same tasks.\nAimed at fewer Linux distributions : In past editions, I described about 18 differ -\nent Linux distributions. With only a few notable exceptions, most popular Linux \ndistributions are either Red Hat based (Red Hat Enterprise Linux, Fedora, CentOS, ", "doc_id": "90dc78a7-b6be-44ba-845c-ca21caa823b6", "embedding": null, "doc_hash": "570186fe94ce17134fac42c76de48c5abe408b13151d60159fce2e47b6573091", "extra_info": {"page_label": "29"}, "node_info": {"start": 0, "end": 2770}, "relationships": {"1": "7eaa85f0-b4f5-4e80-9b96-8789c9a1b4f4"}}, "__type__": "1"}, "cf2bbd9d-e687-4783-b0aa-c88bc6397371": {"__data__": {"text": "Introduction\nxxxviand so on) or Debian based (Ubuntu, Linux Mint, KNOPPIX, and so forth). Although \nthis book most thoroughly covers Red Hat distributions, I increased the coverage \nof Ubuntu throughout the book, because that\u2019s where many of the biggest Linux \nfans begin.\nMany, many demos and exercises : Instead of just telling you what Linux does, I  \nactually show you what it does. Then, to make sure that you got it, you have the \nopportunity to try Linux exercises yourself. Every procedure and exercise has been \ntested to work in Fedora or Red Hat Enterprise Linux. Most work in Ubuntu as well.\nFor this 10th edition, major enhancements include a focus on simplified Linux administra -\ntion, automating tasks, and managing containerized applications (individually or at scale):\nCockpit administration web UI : Since Linux was created, people have tried to develop \nsimple graphical or browser-based interfaces for managing Linux systems. I believe \nthat Cockpit is the best web UI ever created for managing most basic Linux fea -\ntures. Throughout this book, I have replaced most older system-config* tool descrip -\ntions with those focusing on Cockpit. With Cockpit, you can now add users, manage \nstorage, monitor activities, and do many other administrative tasks through a single \ninterface.\nLead into cloud technologies : After introducing cloud technologies in the previous \nedition, I\u2019ve expanded on that coverage here. This coverage includes setting up your \nown Linux host for running virtual machines and running Linux in a cloud envi-\nronment, such as Amazon Web Services. Linux is at the heart of most technological \nadvances in cloud computing today. That means you need a solid understanding of \nLinux to work effectively in tomorrow\u2019s data centers. I help you learn Linux basics \nin the front of this book. Then in the last few chapters, I demonstrate how you can \ntry out Linux systems as hypervisors, cloud controllers, and virtual machines as \nwell as manage virtual networks and networked storage.\nAnsible : Automating tasks for managing systems is becoming more and more essen -\ntial in modern data centers. Using Ansible, you can create playbooks that define \nthe state of a Linux system. This includes things like setting which packages are \ninstalled, which services are running, and how features are configured. A play -\nbook can configure one system or a thousand systems, be combined to form a set \nof system services, and be run again to return a system to a defined state. In this \nedition, I introduce you to Ansible, help you create your first Ansible playbook, and \nshow you how to run ad-hoc Ansible commands.\nContainers : Packaging and running applications in containers is becoming the \npreferred method for deploying, managing, and updating small, scalable soft -\nware services and features. I describe how to pull containers to your system, run \nthem, stop them, and even build your own container images using podman  and \ndocker  commands.\nKubernetes and OpenShift : While containers are nice on their own, to be able to \ndeploy, manage, and upgrade containers in a large enterprise, you need an orches -\ntration platform. The Kubernetes project provides that platform. For a commercial, \nsupported Kubernetes platform, you can use a product such as OpenShift.", "doc_id": "cf2bbd9d-e687-4783-b0aa-c88bc6397371", "embedding": null, "doc_hash": "570145c9a7f007b775ca5b3c643b27ea3000685cbc3488283d92e3c0538b06ad", "extra_info": {"page_label": "30"}, "node_info": {"start": 0, "end": 3306}, "relationships": {"1": "d7fc2ff5-c0ca-4190-be2d-cc2ac02565b8"}}, "__type__": "1"}, "8ba5a3b1-4da3-4c53-ac08-91495941a71f": {"__data__": {"text": "Introduction\nxxxviiHow This Book Is Organized\nThe book is organized to enable you to start off at the very beginning with Linux and grow \nto become a professional Linux system administrator and power user.\nPart I, \u201cGetting Started,\u201d includes two chapters designed to help you understand what \nLinux is and get you started with a Linux desktop:\n\u25a0\u25a0Chapter\u00a01, \u201cStarting with Linux,\u201d covers topics such as what the Linux operating \nsystem is, where it comes from, and how to get started using it.\n\u25a0\u25a0Chapter\u00a02, \u201cCreating the Perfect Linux Desktop,\u201d provides information on how you \ncan create a desktop system and use some of the most popular desktop features.\nPart II, \u201cBecoming a Linux Power User,\u201d provides in-depth details on how to use the Linux \nshell, work with filesystems, manipulate text files, manage processes, and use shell scripts:\n\u25a0\u25a0Chapter\u00a03, \u201cUsing the Shell,\u201d includes information on how to access a shell, run \ncommands, recall commands (using history), and do tab completion. The chapter \nalso describes how to use variables, aliases, and man pages (traditional Linux \ncommand reference pages).\n\u25a0\u25a0Chapter\u00a04, \u201cMoving Around the Filesystem,\u201d includes commands for listing, cre -\nating, copying, and moving files and directories. More advanced topics in this \nchapter include filesystem security, such as file ownership, permissions, and access \ncontrol lists.\n\u25a0\u25a0Chapter\u00a05, \u201cWorking with Text Files,\u201d includes everything from basic text editors to \ntools for finding files and searching for text within files.\n\u25a0\u25a0Chapter\u00a06, \u201cManaging Running Processes,\u201d describes how to see what processes \nare running on your system and change them. Ways of changing processes include \nkilling, pausing, and sending other types of signals.\n\u25a0\u25a0Chapter\u00a07, \u201cWriting Simple Shell Scripts,\u201d includes shell commands and functions \nthat you can gather together into a file to run as a command itself.\nIn Part III, \u201cBecoming a Linux System Administrator,\u201d you learn how to administer \nLinux systems:\n\u25a0\u25a0Chapter\u00a08, \u201cLearning System Administration,\u201d provides information on basic \ngraphical tools, commands, and configuration files for administering Linux \nsystems. It introduces the Cockpit web UI for simplified, centralized Linux \nadministration.\n\u25a0\u25a0Chapter\u00a09, \u201cInstalling Linux,\u201d covers common installation tasks, such as disk par -\ntitioning and initial software package selection, as well as more advanced installa -\ntion tools, such as installing from kickstart files.\n\u25a0\u25a0Chapter\u00a010, \u201cGetting and Managing Software,\u201d provides an understanding of how \nsoftware packages work and how to get and manage software packages.\n\u25a0\u25a0Chapter\u00a011, \u201cManaging User Accounts,\u201d discusses tools for adding and deleting \nusers and groups as well as how to centralize user account management.", "doc_id": "8ba5a3b1-4da3-4c53-ac08-91495941a71f", "embedding": null, "doc_hash": "f4af56523c13f5415c2c05112bed4d18c5eac1d003c3313125703a333f7f22e9", "extra_info": {"page_label": "31"}, "node_info": {"start": 0, "end": 2759}, "relationships": {"1": "7f024ff2-fa4a-4aba-a83c-cf63b7887cbf"}}, "__type__": "1"}, "a75e2298-df88-4941-8d34-0691ad651bc0": {"__data__": {"text": "Introduction\nxxxviii\u25a0\u25a0Chapter\u00a012, \u201cManaging Disks and Filesystems,\u201d provides information on adding par -\ntitions, creating filesystems, and mounting filesystems, as well as working with \nlogical volume management.\nIn Part IV, \u201cBecoming a Linux Server Administrator,\u201d you learn to create powerful network \nservers and the tools needed to manage them:\n\u25a0\u25a0Chapter\u00a013, \u201cUnderstanding Server Administration,\u201d covers remote logging, moni-\ntoring tools, and the Linux boot process.\n\u25a0\u25a0Chapter\u00a014, \u201cAdministering Networking\u201d discusses how to configure networking.\n\u25a0\u25a0Chapter\u00a015, \u201cStarting and Stopping Services,\u201d provides information on starting and \nstopping services.\n\u25a0\u25a0Chapter\u00a016, \u201cConfiguring a Print Server,\u201d describes how to configure printers to use \nlocally on your Linux system or over the network from other computers.\n\u25a0\u25a0Chapter\u00a017, \u201cConfiguring a Web Server,\u201d describes how to configure an Apache \nweb server.\n\u25a0\u25a0Chapter\u00a018, \u201cConfiguring an FTP Server,\u201d covers procedures for setting up a vsftpd \nFTP server that can be used to enable others to download files from your Linux \nsystem over the network.\n\u25a0\u25a0Chapter\u00a019, \u201cConfiguring a Windows File Sharing (Samba) Server,\u201d covers Windows \nfile server configuration with Samba.\n\u25a0\u25a0Chapter\u00a020, \u201cConfiguring an NFS File Server,\u201d describes how to use Network File \nSystem features to share folders of files among systems over a network.\n\u25a0\u25a0Chapter\u00a021, \u201cTroubleshooting Linux,\u201d covers popular tools for troubleshooting your \nLinux system.\nIn Part V, \u201cLearning Linux Security Techniques,\u201d you learn how to secure your Linux sys -\ntems and services:\n\u25a0\u25a0Chapter\u00a022, \u201cUnderstanding Basic Linux Security,\u201d covers basic security concepts \nand techniques.\n\u25a0\u25a0Chapter\u00a023, \u201cUnderstanding Advanced Linux Security,\u201d provides information on \nusing Pluggable Authentication Modules (PAM) and cryptology tools to tighten \nsystem security and authentication.\n\u25a0\u25a0Chapter\u00a024, \u201cEnhancing Linux Security with SELinux,\u201d shows you how to enable \nSecurity Enhanced Linux (SELinux) to secure system services.\n\u25a0\u25a0Chapter\u00a025, \u201cSecuring Linux on a Network,\u201d covers network security features, such \nas firewalld  and iptables  firewalls, to secure system services.\nIn Part VI,\u201d Engaging with Cloud Computing\u201d the book pivots from a single-system focus \ntoward containerization, cloud computing, and automation:\n\u25a0\u25a0Chapter\u00a026, \u201cShifting to Clouds and Containers,\u201d describes how to pull, push, start, \nstop, tag, and build container images.", "doc_id": "a75e2298-df88-4941-8d34-0691ad651bc0", "embedding": null, "doc_hash": "74a686603f035e48ee8b52c7532ca66dfb520f8bcc3e51ce2148a767f2d88e3e", "extra_info": {"page_label": "32"}, "node_info": {"start": 0, "end": 2444}, "relationships": {"1": "2f38a15f-ed77-41da-af3e-ae6b716e45d6"}}, "__type__": "1"}, "f2fd141d-38b6-484f-960f-94ddf10c2f56": {"__data__": {"text": "Introduction\nxxxix\u25a0\u25a0Chapter\u00a027, \u201cUsing Linux for Cloud Computing,\u201d introduces concepts of cloud com-\nputing in Linux by describing how to set up hypervisors, build virtual machines, \nand share resources across networks.\n\u25a0\u25a0Chapter\u00a028, \u201cDeploying Linux to the Cloud,\u201d describes how to deploy Linux images \nto different cloud environments, including OpenStack, Amazon EC2, or a local Linux \nsystem that is configured for virtualization.\n\u25a0\u25a0Chapter\u00a029, \u201cAutomating Apps and Infrastructure with Ansible,\u201d tells you how to \ncreate Ansible playbooks and run ad-hoc Ansible commands to automate the config -\nuration of Linux systems and other devices.\n\u25a0\u25a0Chapter\u00a030, \u201cDeploying Applications as Containers with Kubernetes,\u201d describes the \nKubernetes project and how it is used to orchestrate container images, with the \npotential to massively scale up for large data centers.\nPart VII contains two appendixes to help you get the most from your exploration of Linux. \nAppendix A, \u201cMedia,\u201d provides guidance on downloading Linux distributions. Appendix \nB, \u201cExercise Answers,\u201d provides sample solutions to the exercises included in Chapters\u00a02 \nthrough\u00a030.\nConventions Used in This Book\nThroughout the book, special typography indicates code and commands. Commands and \ncode are shown in a monospaced font:\nThis is how code looks.\nIn the event that an example includes both input and output, the monospaced font is still \nused, but input is presented in bold type to distinguish the two. Here\u2019s an example:\n$ ftp ftp.handsonhistory.com\nName (home:jake): jake\nPassword: ******\nAs for styles in the text:\n\u25a0\u25a0New terms and important words appear in italic  when introduced.\n\u25a0\u25a0Keyboard strokes appear like this: Ctrl+A. This convention indicates to hold the Ctrl \nkey as you also press the \"a\" key.\n\u25a0\u25a0Filenames, URLs, and code within the text appear as follows: persistence  \n.properties .\nThe following items call your attention to points that are particularly important.\nNote\nA Note box provides extra information to which you need to pay special attention.", "doc_id": "f2fd141d-38b6-484f-960f-94ddf10c2f56", "embedding": null, "doc_hash": "d5dd10266bc7ac1e8aa3b9b4265b12465eb2489107227ace1fc6f2495fa8e1c8", "extra_info": {"page_label": "33"}, "node_info": {"start": 0, "end": 2040}, "relationships": {"1": "8ae09ae3-d073-4a80-b873-a5903f3508ae"}}, "__type__": "1"}, "73488434-4930-4218-839d-c4a34182cdc2": {"__data__": {"text": "Introduction\nxlCautio N\nA Caution box alerts you to take special care when executing a procedure or damage to your computer hardware or \nsoftware could result.\nJumping into Linux\nIf you are new to Linux, you might have vague ideas about what it is and where it came \nfrom. You may have heard something about it being free (as in cost) or free (as in freedom \nto use it as you please). Before you start putting your hands on Linux (which we will do \nsoon enough), Chapter\u00a01 seeks to answer some of your questions about the origins and fea -\ntures of Linux.\nTake your time and work through this book to get up to speed on Linux and how you can \nmake it work to meet your needs. This is your invitation to jump in and take the first step \ntoward becoming a Linux expert!\nHow to Contact Wiley or the Author\nYou can contact Christopher Negus at striker57@gmail.com .\nIf you believe you have found an error in this book, and it is not listed on the book\u2019s page \nat www.wiley.com , you can report the issue to our customer technical support team at \nsupport.wiley.com .tip\nA Tip box shows a special way of performing a particular task.\nVisit the Linux Bible  website\nTo find links to various Linux distributions, tips on gaining Linux certification, and corrections to the \nbook as they become available, go to www.wiley.com/go/linuxbible10e .", "doc_id": "73488434-4930-4218-839d-c4a34182cdc2", "embedding": null, "doc_hash": "c134febea70ac70728405819bad182f5f25c1fb6525020a6826ad33ca7217a3b", "extra_info": {"page_label": "34"}, "node_info": {"start": 0, "end": 1336}, "relationships": {"1": "5a6684de-876e-471d-b60c-642d70173437"}}, "__type__": "1"}, "2d8ea8f5-b845-4068-9492-6ed19a23799c": {"__data__": {"text": "IN THIS PART\nChapter\u00a01  \nStarting with Linux\nChapter\u00a02  \nCreating the Perfect Linux DesktopPart I\nGetting Started\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "2d8ea8f5-b845-4068-9492-6ed19a23799c", "embedding": null, "doc_hash": "e4121612a8948504789cc5d6e687dfde6ff93562fe869a299211ac5df4d7098d", "extra_info": {"page_label": "35"}, "node_info": {"start": 0, "end": 236}, "relationships": {"1": "ccd9de26-b535-4f35-a253-87772666276b"}}, "__type__": "1"}, "fc9ad232-734b-41ed-b8b8-bd5bfdabf6d5": {"__data__": {"text": "3\nCHAPTER1\nStarting with Linux\nIN THIS CHAPTER\nLearning what Linux is\nLearning where Linux came fromChoosing Linux distributionsExploring professional opportunities with LinuxBecoming certified in Linux\nThe operating systems war is over, and Linux has won. Proprietary operating systems simply \ncannot keep up with the pace of improvements and quality that Linux can achieve with its cul-ture of sharing and innovation. Even Microsoft, whose former CEO Steve Ballmer once referred \nto Linux as \u201ca cancer,\u201d now says that Linux\u2019s use on its Microsoft\u2019s Azure cloud computing service has surpassed the use of Windows.\nLinux is one of the most important technological advancements of the twenty-first century. Beyond its impact on the growth of the Internet and its place as an enabling technology for a range of com -\nputer-driven devices, Linux development has become a model for how collaborative projects can sur-\npass what single individuals and companies can do alone.\nG\noogle runs thousands upon thousands of Linux servers to power its search technology. Its Android \nphones are based on Linux. Likewise, when you download and run Google\u2019s Chrome OS, you get a \nbrowser that is backed by a Linux operating system.\nFacebook builds and deploys its site using what is referred to as a LAMP stack (Linux, Apache web \nserver, MySQL database, and PHP web scripting language)\u2014all open source projects. In fact, Facebook itself uses an open source development model, making source code for the applications and tools that drive Facebook available to the public. This model has helped Facebook shake out bugs quickly, get contributions from around the world, and fuel its exponential growth.\nFinancial organizations that have trillions of dollars riding on the speed and security of their \noperating systems also rely heavily on Linux. These include the New York Stock Exchange, Chicago Mercantile Exchange, and the Tokyo Stock Exchange.\nAs cloud  continues to be one of the hottest buzzwords today, a part of the cloud groundswell that \nisn\u2019t hype is that Linux and other open source technologies continue to be the foundation on which \nLinux\u00ae Bible , Tenth Edition. Christopher Negus.\n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "fc9ad232-734b-41ed-b8b8-bd5bfdabf6d5", "embedding": null, "doc_hash": "032f63753e39e5ee8e622ac9d8c2a58e896b4f2f4802cf2c6268569e5ce9fbba", "extra_info": {"page_label": "36"}, "node_info": {"start": 0, "end": 2253}, "relationships": {"1": "48bb859c-cf0c-47ed-8ea8-d188a9e6e485"}}, "__type__": "1"}, "badfca3b-6f23-4830-b7c3-274068dae3bc": {"__data__": {"text": "Part I: Getting Started4today\u2019s greatest cloud innovations are being built. Every software component that you need \nto build a private or public cloud (such as hypervisors, cloud controllers, network storage, \nvirtual networking, and authentication) is freely available for you to start using from the \nopen source world.\nThe widespread adoption of Linux around the world has created huge demand for Linux \nexpertise. This chapter starts you down a path to becoming a Linux expert by helping you \nunderstand what Linux is, where it came from, and what your opportunities are for becoming \nproficient in it.\nThe rest of this book provides you with hands-on activities to help you gain that expertise. \nFinally, I show you how to apply that expertise to cloud technologies, including automation \ntools, such as Ansible, and containerization orchestration technologies, such as Kubernetes \nand OpenShift.\nUnderstanding What Linux Is\nLinux  is a computer operating system. An operating system consists of the software that \nmanages your computer and lets you run applications on it. The features that make up \nLinux and similar computer operating systems include the following:\nDetecting and preparing hardware : When the Linux system boots up (when you turn \non your computer), it looks at the components on your computer (CPU, hard drive, \nnetwork cards, and so on) and loads the software (drivers and modules) needed to \naccess those particular hardware devices.\nManaging processes : The operating system must keep track of multiple processes \nrunning at the same time and decide which have access to the CPU and when. \nThe system also must offer ways of starting, stopping, and changing the status of \nprocesses.\nManaging memory : RAM and swap space (extended memory) must be allocated to \napplications as they need memory. The operating system decides how requests for \nmemory are handled.\nProviding user interfaces : An operating system must provide ways of accessing the \nsystem. The first Linux systems were accessed from a command-line interpreter \ncalled a shell . Today, graphical desktop interfaces are commonly available as well.\nControlling filesystems : Filesystem structures are built into the operating system (or \nloaded as modules). The operating system controls ownership and access to the files \nand directories (folders) that the filesystems contain.\nProviding user access and authentication : Creating user accounts and allowing \nboundaries to be set between users is a basic feature of Linux. Separate user and \ngroup accounts enable users to control their own files and processes.\nOffering administrative utilities : In Linux, hundreds (perhaps thousands) of com-\nmands and graphical windows are available to do such things as add users, manage ", "doc_id": "badfca3b-6f23-4830-b7c3-274068dae3bc", "embedding": null, "doc_hash": "140fd8083ac707b2b81eafc2cce491d6a5ba26d7f9a40dcf0087249549c7ff2e", "extra_info": {"page_label": "37"}, "node_info": {"start": 0, "end": 2766}, "relationships": {"1": "aa9b40b4-911f-4a5a-9cae-2e3862de69f1"}}, "__type__": "1"}, "9a1fdf7f-80fc-4698-a3c3-8d89fcc46a16": {"__data__": {"text": "Chapter 1: Starting with Linux\n5\n1disks, monitor the network, install software, and generally secure and manage your \ncomputer. Web UI tools, such as Cockpit, have lowered the bar for doing complex \nadministrative tasks.\nStarting up services : To use printers, handle log messages, and provide a variety \nof system and network services, processes called daemon processes run in the \nbackground, waiting for requests to come in. Many types of services run in Linux. \nLinux provides different ways of starting and stopping these services. In other \nwords, while Linux includes web browsers to view web pages, it can also be the com-\nputer that serves up web pages to others. Popular server features include web, mail, \ndatabase, printer, file, DNS, and DHCP servers.\nProgramming tools : A wide variety of programming utilities for creating applications \nand libraries for implementing specialty interfaces are available with Linux.\nAs someone managing Linux systems, you need to learn how to work with those features \njust described. While many features can be managed using graphical interfaces, an under -\nstanding of the shell command line is critical for someone administering Linux systems.\nModern Linux systems now go way beyond what the first UNIX systems (on which Linux \nwas based) could do. Advanced features in Linux, often used in large enterprises, include \nthe following:\nClustering: Linux can be configured to work in clusters so that multiple systems can \nappear as one system to the outside world. Services can be configured to pass back \nand forth between cluster nodes while appearing to those using the services that \nthey are running without interruption.\nVirtualization : To manage computing resources more efficiently, Linux can run as a \nvirtualization host. On that host, you could run other Linux systems, Microsoft \nWindows, BSD, or other operating systems as virtual guests. To the outside world, \neach of those virtual guests appears as a separate computer. KVM and Xen are two \ntechnologies in Linux for creating virtual hosts.\nCloud computing : To manage large-scale virtualization environments, you can use \nfull-blown cloud computing platforms based on Linux. Projects such as OpenStack \nand Red Hat Virtualization (and its upstream oVirt project) can simultaneously man -\nage many virtualization hosts, virtual networks, user and system authentication, \nvirtual guests, and networked storage. Projects such as Kubernetes can manage con -\ntainerized applications across massive data centers.\nReal-time computing : Linux can be configured for real-time computing, where high-\npriority processes can expect fast, predictable attention.\nSpecialized storage : Instead of just storing data on the computer\u2019s hard disk, you \ncan store it on many specialized local and networked storage interfaces that are \navailable in Linux. Shared storage devices available in Linux include iSCSI, Fibre \nChannel, and Infiniband. Entire open source storage platforms include projects such \nas Ceph (https://ceph.io ) and GlusterFS ( https://www.gluster.org ).", "doc_id": "9a1fdf7f-80fc-4698-a3c3-8d89fcc46a16", "embedding": null, "doc_hash": "cb47865de7393029d8b280360aa8cbd1878ad7877c9536dbb2ba76b4e503c9f2", "extra_info": {"page_label": "38"}, "node_info": {"start": 0, "end": 3070}, "relationships": {"1": "210986f7-26f4-4da7-8fb2-6b1137877b85"}}, "__type__": "1"}, "a26314d9-c4f7-4629-8720-c58d38fbab5f": {"__data__": {"text": "Part I: Getting Started6Some of these advanced topics are not covered in this book. However, the features \ncovered here for using the shell, working with disks, starting and stopping services, \nand configuring a variety of servers should serve as a foundation for working with those \nadvanced features.\nUnderstanding How Linux Differs from Other \nOperating Systems\nIf you are new to Linux, chances are good that you have used a Microsoft Windows or \nMacOS operating system. Although MacOS had its roots in a free software operating system, \nreferred to as the Berkeley Software Distribution (more on that later), operating systems \nfrom both Microsoft and Apple are considered proprietary operating systems. What that \nmeans is the following:\n\u25a0\u25a0You cannot see the code used to create the operating system, and therefore, you \ncannot change the operating system at its most basic levels if it doesn\u2019t suit your \nneeds, and you can\u2019t use the operating system to build your own operating system \nfrom source code.\n\u25a0\u25a0You cannot check the code to find bugs, explore security vulnerabilities, or simply \nlearn what that code is doing.\n\u25a0\u25a0You may not be able to plug your own software easily into the operating system if \nthe creators of that system don\u2019t want to expose the programming interfaces you \nneed to the outside world.\nYou might look at those statements about proprietary software and say, \u201cWhat do I care? \nI\u2019m not a software developer. I don\u2019t want to see or change how my operating system \nis built.\u201d\nThat may be true. However, the fact that others can take free and open source software \nand use it as they please has driven the explosive growth of the Internet (think Google), \nmobile phones (think Android), special computing devices (think TiVo), and hundreds of \ntechnology companies. Free software has driven down computing costs and allowed for an \nexplosion of innovation.\nMaybe you don\u2019t want to use Linux\u2014as Google, Facebook, and other companies have done\u2014\nto build the foundation for a multi-billion-dollar company. Nonetheless, those companies \nand others who now rely on Linux to drive their computer infrastructures need more and \nmore people with the skills to run those systems.\nYou may wonder how a computer system that is so powerful and flexible has come to be free \nas well. To understand how that could be, you need to see where Linux came from. Thus the \nnext sections of this chapter describe the strange and winding path of the free software \nmovement that led to Linux.", "doc_id": "a26314d9-c4f7-4629-8720-c58d38fbab5f", "embedding": null, "doc_hash": "b4edda1e607a81968637cec0872206298613b66a2990e915229288586fb15018", "extra_info": {"page_label": "39"}, "node_info": {"start": 0, "end": 2500}, "relationships": {"1": "c8db3186-7e1a-43ff-984d-eec665050d35"}}, "__type__": "1"}, "58a7d488-2645-4d12-9cf0-c9cd7475e999": {"__data__": {"text": "Chapter 1: Starting with Linux\n7\n1Exploring Linux History\nSome histories of Linux begin with the following message entitled \u201cWhat would you like to \nsee most in minix?\u201d posted by Linus Torvalds to the comp.os.minix  newsgroup on August \n25, 1991, at\nhttps://groups.google.com/forum/#!msg/comp.os.minix/dlNtH7RRrGA/SwRavCzVE7gJ\nLinus Benedict Torvalds\nHello everybody out there using minix -\nI\u2019m doing a (free) operating system (just a hobby, won\u2019t be big and professional \nlike gnu) for 386(486) AT clones. This has been brewing since april, and is starting \nto get ready. I\u2019d like any feedback on things people like/dislike in minix, as my OS \nresembles it somewhat (same physical layout of the file-system (due to practical \nreasons, among other things).\u00a0.\u00a0.Any suggestions are welcome, but I won\u2019t promise \nI\u2019ll implement them :-)\nLinus (torvalds@kruuna.helsinki.fi )\nPS. Yes \u2014 it\u2019s free of any minix code, and it has a multi-threaded fs. It is NOT \nprotable[sic] (uses 386 task switching etc), and it probably never will support \nanything other than AT-harddisks, as that\u2019s all I have :-(.\nMinix was a UNIX-like operating system that ran on PCs in the early 1990s. Like Minix, \nLinux was also a clone of the UNIX operating system. With few exceptions, such as Micro -\nsoft Windows, most modern computer systems (including MacOS and Linux itself) were \nderived from UNIX operating systems, created originally by AT&T.\nTo truly appreciate how a free operating system could have been modeled after a proprie -\ntary system from AT&T Bell Laboratories, it helps to understand the culture in which  \nUNIX was created and the chain of events that made the essence of UNIX possible to  \nreproduce freely.\nNote\nTo learn more about how Linux was created, pick up the book Just for Fun: The Story of an Accidental Revolutionary \nby Linus Torvalds (Harper Collins Publishing, 2001).\nFree-flowing UNIX culture at Bell Labs\nFrom the very beginning, the UNIX operating system was created and nurtured in a \ncommunal environment. Its creation was not driven by market needs but by a desire to \novercome impediments to producing programs. AT&T, which owned the UNIX trademark \noriginally, eventually made UNIX into a commercial product. By that time, however, many \nof the concepts (and even much of the early code) that made UNIX special had fallen into \nthe public domain.", "doc_id": "58a7d488-2645-4d12-9cf0-c9cd7475e999", "embedding": null, "doc_hash": "c9a941cfaca2a578af51cb2b6995f5fc3b79f463533e4b05300a21e72a95c766", "extra_info": {"page_label": "40"}, "node_info": {"start": 0, "end": 2361}, "relationships": {"1": "a76c5fbf-6b0a-4cbe-9a52-ce8df9a8ff97"}}, "__type__": "1"}, "46b254de-3187-4f58-bcf3-6642f5c6aa04": {"__data__": {"text": "Part I: Getting Started8If you are not old enough to remember when AT&T split up in 1984, you may not remember \na time when AT&T was the  phone company. Up until the early 1980s, AT&T didn\u2019t have to \nthink much about competition because if you wanted a phone in the United States, you had \nto go to AT&T. It had the luxury of funding pure research projects. The mecca for such pro -\njects was the Bell Laboratories site in Murray Hill, New Jersey.\nAfter a project called Multics failed around 1969, Bell Labs employees Ken Thompson and \nDennis Ritchie set off on their own to create an operating system that would offer an \nimproved environment for developing software. Up to that time, most programs were writ -\nten on paper punch cards that had to be fed in batches to mainframe computers. In a 1980 \nlecture on \u201cThe Evolution of the UNIX Time-sharing System,\u201d Dennis Ritchie summed up \nthe spirit that started UNIX:\nWhat we wanted to preserve was not just a good environment in which to do \nprogramming, but a system around which a fellowship could form. We knew from \nexperience that the essence of communal computing as supplied by remote-access, \ntime-shared machines is not just to type programs into a terminal instead of a \nkeypunch, but to encourage close communication.\nThe simplicity and power of the UNIX design began breaking down barriers that, until \nthis point, had impeded software developers. The foundation of UNIX was set with several \nkey elements:\nThe UNIX filesystem : Because it included a structure that allowed levels of subdirec -\ntories (which, for today\u2019s desktop users, look like folders inside of folders), UNIX \ncould be used to organize the files and directories in intuitive ways. Furthermore, \ncomplex methods of accessing disks, tapes, and other devices were greatly simplified \nby representing those devices as individual device files that you could also access as \nitems in a directory.\nInput/output redirection : Early UNIX systems also included input redirection and \npipes. From a command line, UNIX users could direct the output of a command to \na file using a right-arrow key ( >). Later, the concept of pipes ( |) was added where \nthe output of one command could be directed to the input of another command. \nFor example, the following command line concatenates ( cat) file1 and file2, sorts \n(sort ) the lines in those files alphabetically, paginates the sorted text for printing \n(pr), and directs the output to the computer\u2019s default printer ( lpr):\n        $ cat file1 file2 | sort | pr | lpr\nThis method of directing input and output enabled developers to create their own \nspecialized utilities that could be joined with existing utilities. This modularity \nmade it possible for lots of code to be developed by lots of different people. A user \ncould just put together the pieces they needed.\nPortability : Simplifying the experience of using UNIX also led to it becoming extraor -\ndinarily portable to run on different computer hardware. By having device drivers \n(represented by files in the filesystem tree), UNIX could present an interface to \napplications in such a way that the programs didn\u2019t have to know about the details ", "doc_id": "46b254de-3187-4f58-bcf3-6642f5c6aa04", "embedding": null, "doc_hash": "997171c5ee91b4e6d13ebf25629cdb9c36f38f006c782b2d55269653ad95e2ad", "extra_info": {"page_label": "41"}, "node_info": {"start": 0, "end": 3182}, "relationships": {"1": "e9b394d3-bdde-4611-a400-990cebc1d922"}}, "__type__": "1"}, "e9a2baed-a16e-4158-b29c-c1019e425caf": {"__data__": {"text": "Chapter 1: Starting with Linux\n9\n1of the underlying hardware. To port UNIX later to another system, developers had \nonly to change the drivers. The application programs didn\u2019t have to change for dif -\nferent hardware!\nTo make portability a reality, however, a high-level programming language was needed to \nimplement the software needed. To that end, Brian Kernighan and Dennis Ritchie created \nthe C programming language. In 1973, UNIX was rewritten in C. Today, C is still the primary \nlanguage used to create the UNIX (and Linux) operating system kernels.\nAs Ritchie went on to say in a 1979 lecture ( https://www.bell-labs.com/usr/dmr/\nwww/hist.html ):\nToday, the only important UNIX program still written in assembler is the \nassembler itself; virtually all the utility programs are in C, and so are most of the \napplication\u2019s programs, although there are sites with many in Fortran, Pascal, and \nAlgol 68 as well. It seems certain that much of the success of UNIX follows from \nthe readability, modifiability, and portability of its software that in turn follows \nfrom its expression in high-level languages.\nIf you are a Linux enthusiast and are interested in what features from the early days of \nLinux have survived, an interesting read is Dennis Ritchie\u2019s reprint of the first UNIX pro -\ngrammer\u2019s manual (dated November 3, 1971). You can find it at Dennis Ritchie\u2019s website: \nhttps://www.bell-labs.com/usr/dmr/www/1stEdman.html . The form of this docu -\nmentation is UNIX man pages, which is still the primary format for documenting UNIX and \nLinux operating system commands and programming tools today.\nWhat\u2019s clear as you read through the early documentation and accounts of the UNIX system \nis that the development was a free-flowing process, lacked ego, and was dedicated to mak -\ning UNIX excellent. This process led to a sharing of code (both inside and outside of Bell \nLabs), which allowed rapid development of a high-quality UNIX operating system. It also \nled to an operating system that AT&T would find difficult to reel back in later.\nCommercial UNIX\nBefore the AT&T divestiture in 1984, when it was split up into AT&T and seven \u201cBaby Bell\u201d \ncompanies, AT&T was forbidden to sell computer systems. Companies that would later \nbecome Verizon, Qwest, Nokia, and Alcatel-Lucent were all part of AT&T. As a result of \nAT&T\u2019s monopoly of the telephone system, the US government was concerned that an unre -\nstricted AT&T might dominate the fledgling computer industry.\nBecause AT&T was restricted from selling computers directly to customers before its dives -\ntiture, UNIX source code was licensed to universities for a nominal fee. This allowed UNIX \ninstallations to grow in size and mindshare among top universities. However, there was \nstill no UNIX operating system for sale from AT&T that you didn\u2019t have to compile yourself.\nBerkeley Software Distribution arrives\nIn 1975, UNIX V6 became the first version of UNIX available for widespread use outside of \nBell Laboratories. From this early UNIX source code, the first major variant of UNIX was ", "doc_id": "e9a2baed-a16e-4158-b29c-c1019e425caf", "embedding": null, "doc_hash": "2cdc360d7961e40fa9e4958e4c0b59ab61d74a954e1ca5ff6b99fc896001d8d2", "extra_info": {"page_label": "42"}, "node_info": {"start": 0, "end": 3070}, "relationships": {"1": "19ac6947-a140-473f-a316-b2007b0cbd08"}}, "__type__": "1"}, "7472e930-1480-4122-a4ff-327104fe4e92": {"__data__": {"text": "Part I: Getting Started10created at University of California, Berkeley. It was named the Berkeley Software Distribu -\ntion (BSD).\nFor most of the next decade, the BSD and Bell Labs versions of UNIX headed off in separate \ndirections. BSD continued forward in the free-flowing, share-the-code manner that was the \nhallmark of the early Bell Labs UNIX, whereas AT&T started steering UNIX toward commer -\ncialization. With the formation of a separate UNIX Laboratory, which moved out of Murray \nHill and down the road to Summit, New Jersey, AT&T began its attempts to commercialize \nUNIX. By 1984, divestiture was behind AT&T and it was really ready to start selling UNIX.\nUNIX Laboratory and commercialization\nThe UNIX Laboratory was considered a jewel that couldn\u2019t quite find a home or a way to \nmake a profit. As it moved between Bell Laboratories and other areas of AT&T, its name \nchanged several times. It is probably best remembered by the name it had as it began its \nspin-off from AT&T: UNIX System Laboratories (USL).\nThe UNIX source code that came out of USL, the legacy of which was sold in part to Santa \nCruz Operation (SCO), was used for a time as the basis for ever-dwindling lawsuits by SCO \nagainst major Linux vendors (such as IBM and Red Hat, Inc.). Because of that, I think the \nefforts from USL that have contributed to the success of Linux are lost on most people.\nDuring the 1980s, of course, many computer companies were afraid that a newly divested \nAT&T would pose more of a threat to controlling the computer industry than would an \nupstart company in Redmond, Washington. To calm the fears of IBM, Intel, Digital Equip -\nment Corporation, and other computer companies, the UNIX Lab made the following com-\nmitments to ensure a level playing field:\nSource code only : Instead of producing its own boxed set of UNIX, AT&T continued to \nsell source code only and to make it available equally to all licensees. Each company \nwould then port UNIX to its own equipment. It wasn\u2019t until about 1992, when the \nlab was spun off as a joint venture with Novell (called Univel), and then eventually \nsold to Novell, that a commercial boxed set of UNIX (called UnixWare) was produced \ndirectly from that source code.\nPublished interfaces : To create an environment of fairness and community to its OEMs \n(original equipment manufacturers), AT&T began standardizing what different ports \nof UNIX had to be able to do to still be called UNIX. To that end, Portable Operating \nSystem Interface (POSIX) standards and the AT&T UNIX System V Interface Defini-\ntion (SVID) were specifications UNIX vendors could use to create compliant UNIX \nsystems. Those same documents also served as road maps for the creation of Linux.\nNote\nIn an early email newsgroup post, Linus Torvalds made a request for a copy, preferably online, of the POSIX standard. \nI think that no one from AT&T expected someone actually to be able to write their own clone of UNIX from those inter -\nfaces without using any of its UNIX source code.", "doc_id": "7472e930-1480-4122-a4ff-327104fe4e92", "embedding": null, "doc_hash": "5796392b7cc6fee22ab3ef0e4ca018fc9850e87dc68937a54fbea222c1dbd9d6", "extra_info": {"page_label": "43"}, "node_info": {"start": 0, "end": 3022}, "relationships": {"1": "5b3a24ea-b8a4-44d7-896a-6495ee0ef268"}}, "__type__": "1"}, "6eaf9f2d-1e5d-40d8-8280-3b79317f95ec": {"__data__": {"text": "Chapter 1: Starting with Linux\n11\n1Technical approach : Again, until the very end of USL, most decisions on the direction \nof UNIX were made based on technical considerations. Management was promoted \nup through the technical ranks, and to my knowledge there was never any talk of \nwriting software to break other companies\u2019 software or otherwise restrict the suc -\ncess of USL\u2019s partners.\nWhen USL eventually started taking on marketing experts and creating a desktop UNIX \nproduct for end users, Microsoft Windows already had a firm grasp on the desktop market. \nAlso, because the direction of UNIX had always been toward source-code licensing destined \nfor large computing systems, USL had pricing difficulties for its products. For example, on \nsoftware that it was including with UNIX, USL found itself having to pay out per-computer \nlicensing fees that were based on $100,000 mainframes instead of $2,000 PCs. Add to that \nthe fact that no application programs were available with UnixWare and you can see why \nthe endeavor failed.\nSuccessful marketing of UNIX systems at the time, however, was happening with other \ncomputer companies. SCO had found a niche market, primarily selling PC versions of UNIX \nrunning dumb terminals in small offices. Sun Microsystems was selling lots of UNIX work -\nstations (originally based on BSD but merged with UNIX in SVR4) for programmers and \nhigh-end technology applications (such as stock trading).\nOther commercial UNIX systems were also emerging by the 1980s. This new ownership \nassertion of UNIX was beginning to take its toll on the spirit of open contributions. Law -\nsuits were being initiated to protect UNIX source code and trademarks. In 1984, this new, \nrestrictive UNIX gave rise to an organization that eventually led the path to Linux: the \nFree Software Foundation.\nGNU transitions UNIX to freedom\nIn 1984, Richard M. Stallman started the GNU project ( https://gnu.org ), recursively \nnamed by the phrase GNU is Not UNIX. As a project of the Free Software Foundation (FSF), \nGNU was intended to become a recoding of the entire UNIX operating system that could be \nfreely distributed.\nThe GNU Project page ( https://gnu.org/gnu/thegnuproject.html ) tells the story \nof how the project came about in Stallman\u2019s own words. It also lays out the problems that \nproprietary software companies were imposing on those software developers who wanted to \nshare, create, and innovate.\nAlthough rewriting millions of lines of code might seem daunting for one or two people, \nspreading the effort across dozens or even hundreds of programmers made the project pos -\nsible. Remember that UNIX was designed to be built in separate pieces that could be piped \ntogether. Because they were reproducing commands and utilities with well-known, pub -\nlished interfaces, that effort could easily be split among many developers.\nIt turned out that not only could the same results be gained by all new code, but in some \ncases that code was better than the original UNIX versions. Because everyone could see ", "doc_id": "6eaf9f2d-1e5d-40d8-8280-3b79317f95ec", "embedding": null, "doc_hash": "7b5e100a03cc55e0bb62db776fdc46e44946762ddf4a2bff7578ff8ed112fb80", "extra_info": {"page_label": "44"}, "node_info": {"start": 0, "end": 3046}, "relationships": {"1": "c2b87e2d-229e-40c4-bbbb-7be1230bec1d"}}, "__type__": "1"}, "e78e34d3-d4dc-47ca-b2ad-b15847c4e259": {"__data__": {"text": "Part I: Getting Started12the code being produced for the project, poorly written code could be corrected quickly or \nreplaced over time.\nIf you are familiar with UNIX, try searching the hundreds of GNU software packages, which \ncontain thousands of commands, for your favorite UNIX command from the Free Software \nDirectory ( https://directory.fsf.org/wiki/GNU ). Chances are good that you will find \nit there, along with many, many other available software projects.\nOver time, the term free software  has been mostly replaced by the term open source soft -\nware. The term free software  is preferred by the Free Software Foundation, while open source \nsoftware  is promoted by the Open Source Initiative ( https://opensource.org ).\nTo accommodate both camps, some people use the term Free and Open Source Software (FOSS) \ninstead. An underlying principle of FOSS, however, is that although you are free to use \nthe software as you like, you have some responsibility to make the improvements that you \nmake to the code available to others. This way, everyone in the community can benefit \nfrom your work, as you have benefited from the work of others.\nTo define clearly how open source software should be handled, the GNU software project \ncreated the GNU Public License, or GPL. Although many other software licenses cover \nslightly different approaches to protecting free software, the GPL is the most well known\u2014\nand it\u2019s the one that covers the Linux kernel itself. The GNU Public License includes the \nfollowing basic features:\nAuthor rights : The original author retains the rights to their software.\nFree distribution : People can use the GNU software in their own software, changing \nand redistributing it as they please. They do, however, have to include the source \ncode with their distribution (or make it easily available).\nCopyright maintained : Even if you were to repackage and resell the software, the \noriginal GNU agreement must be maintained with the software, which means that \nall future recipients of the software have the opportunity to change the source \ncode, just as you did.\nThere is no warranty on GNU software. If something goes wrong, the original developer of \nthe software has no obligation to fix the problem. However, many organizations, large and \nsmall, offer paid support (often in subscription form) for the software when it is included \nin their Linux or other open source software distribution. (See the section \u201cOSI open source \ndefinition\u201d later in this chapter for a more detailed definition of open source software.)\nDespite its success in producing thousands of UNIX utilities, the GNU project itself failed to \nproduce one critical piece of code: the kernel. Its attempts to build an open source kernel \nwith the GNU Hurd project ( https://gnu.org/software/hurd/ ) were unsuccessful at \nfirst, so it failed to become the premier open source kernel.\nBSD loses some steam\nThe one software project that had a chance of beating out Linux to be the premier \nopen source kernel was the venerable BSD project. By the late 1980s, BSD developers at ", "doc_id": "e78e34d3-d4dc-47ca-b2ad-b15847c4e259", "embedding": null, "doc_hash": "9469671dcfa863c583ae12276cb448fe5e0f56ac7d5ac9132a7450e819b2a407", "extra_info": {"page_label": "45"}, "node_info": {"start": 0, "end": 3087}, "relationships": {"1": "d4591de8-c26f-4fa8-81e7-c6036f843743"}}, "__type__": "1"}, "ee2f7c6b-a025-4c13-9f86-ac5703ad0cee": {"__data__": {"text": "Chapter 1: Starting with Linux\n13\n1University of California (UC), Berkeley realized that they had already rewritten most of the \nUNIX source code they had received a decade earlier.\nIn 1989, UC Berkeley distributed its own UNIX-like code as Net/1 and later (in 1991) as \nNet/2. Just as UC Berkeley was preparing a complete, UNIX-like operating system that was \nfree from all AT&T code, AT&T hit them with a lawsuit in 1992. The suit claimed that the \nsoftware was written using trade secrets taken from AT&T\u2019s UNIX system.\nIt\u2019s important to note here that BSD developers had completely rewritten the copyright-pro -\ntected code from AT&T. Copyright was the primary means AT&T used to protect its rights to \nthe UNIX code. Some believe that if AT&T had patented the concepts covered in that code, \nthere might not be a Linux (or any UNIX clone) operating system today.\nThe lawsuit was dropped when Novell bought UNIX System Laboratories from AT&T in 1994. \nNevertheless, during that critical period there was enough fear and doubt about the legal -\nity of the BSD code that the momentum that BSD had gained to that point in the fledgling \nopen source community was lost. Many people started looking for another open source \nalternative. The time was ripe for a college student from Finland who was working on his \nown kernel.\nNote\nToday, BSD versions are available from three major projects: FreeBSD, NetBSD, and OpenBSD. People generally  \ncharacterize FreeBSD as the easiest to use, NetBSD as available on the most computer hardware platforms, and \nOpenBSD as fanatically secure. Many security-minded individuals still prefer BSD to Linux. Also, because of its \nlicensing, BSD code can be used by proprietary software vendors, such as Microsoft and Apple, who don\u2019t want to \nshare their operating system code with others. MacOS is built on a BSD derivative.\nLinus builds the missing piece\nLinus Torvalds started work on Linux in 1991, while he was a student at the University of \nHelsinki, Finland. He wanted to create a UNIX-like kernel so that he could use the same \nkind of operating system on his home PC that he used at school. At the time, Linus was \nusing Minix, but he wanted to go beyond what the Minix standards permitted.\nAs noted earlier, Linus announced the first public version of the Linux kernel to the  \ncomp.os.minix  newsgroup on August 25, 1991, although Torvalds guesses that the first \nversion didn\u2019t actually come out until mid-September of that year.\nAlthough Torvalds stated that Linux was written for the 386 processor and probably wasn\u2019t \nportable, others persisted in encouraging (and contributing to) a more portable approach in \nthe early versions of Linux. By October 5, 1991, Linux 0.02 was released with much of the \noriginal assembly code rewritten in the C programming language, which made it possible to \nstart porting it to other machines.\nThe Linux kernel was the last\u2014and the most important\u2014piece of code that was needed \nto complete a whole UNIX-like operating system under the GPL. So when people started ", "doc_id": "ee2f7c6b-a025-4c13-9f86-ac5703ad0cee", "embedding": null, "doc_hash": "977dd3c87327c09febb6c1a23b11ed3ac9d8c82e0435334349d6d7c237802828", "extra_info": {"page_label": "46"}, "node_info": {"start": 0, "end": 3047}, "relationships": {"1": "62b3829b-14f8-44ed-a8e3-89131dc6c30d"}}, "__type__": "1"}, "5c611cb5-2b6a-4db5-96df-c1f1a34a56e8": {"__data__": {"text": "Part I: Getting Started14putting together distributions, the name Linux and not GNU is what stuck. Some \ndistributions, such as Debian, however, refer to themselves as GNU/Linux distributions. \n(Not including GNU in the title or subtitle of a Linux operating system is also a matter of \nmuch public grumbling by some members of the GNU project. See https://gnu.org .)\nToday, Linux can be described as an open source UNIX-like operating system that reflects \na combination of SVID, POSIX, and BSD compliance. Linux continues to aim toward com-\npliance with POSIX as well as with standards set by the owner of the UNIX trademark, The \nOpen Group ( https://opengroup.org ).\nThe nonprofit Open Source Development Labs, renamed the Linux Foundation after merging \nwith the Free Standards Group ( https://linuxfoundation.org ), which employs Linus \nTorvalds, manages the direction today of Linux development efforts. Its sponsors list is like \na Who\u2019s Who of commercial Linux system and application vendors, including IBM, Red Hat, \nSUSE, Oracle, HP, Dell, Computer Associates, Intel, Cisco Systems, and hundreds of others. \nThe Linux Foundation\u2019s primary charter is to protect and accelerate the growth of Linux by \nproviding legal protection and software development standards for Linux developers.\nAlthough much of the thrust of corporate Linux efforts is on enterprise computing, huge \nimprovements are continuing in the desktop arena as well. The KDE and GNOME desktop \nenvironments continuously improve the Linux experience for casual users. Newer light -\nweight desktop environments such as Chrome OS, Xfce, and LXDE now offer efficient alter -\nnatives that today bring Linux to thousands of netbook owners.\nLinus Torvalds continues to maintain and improve the Linux kernel.\nNote\nFor a more detailed history of Linux, see the book Open Sources: Voices from the Open Source Revolution  (O\u2019Reilly, \n1999). The entire first edition is available online at\nhttps://oreilly.com/openbook/opensources/book/\nOSI open source definition\nLinux provides a platform that lets software developers change the operating system as \nthey like and get a wide range of help creating the applications they need. One of the \nwatchdogs of the open source movement is the Open Source Initiative, or OSI ( https:// \nopensource.org ).\nAlthough the primary goal of open source software is to make source code available, other \ngoals of open source software are also defined by OSI in its open source definition. Most of \nthe following rules for acceptable open source licenses serve to protect the freedom and \nintegrity of the open source code:\nFree distribution : An open source license can\u2019t require a fee from anyone who resells \nthe software.", "doc_id": "5c611cb5-2b6a-4db5-96df-c1f1a34a56e8", "embedding": null, "doc_hash": "734bbecd5a4c79faacb5f9d2133247ce6da18c774a58a5544199151c094602b5", "extra_info": {"page_label": "47"}, "node_info": {"start": 0, "end": 2720}, "relationships": {"1": "538b4779-1103-45b7-b8bc-0b1b5a9a8115"}}, "__type__": "1"}, "06d61e52-6e86-4ac2-846a-4ed07a13593a": {"__data__": {"text": "Chapter 1: Starting with Linux\n15\n1Source code : The source code must be included with the software, and there can be no \nrestrictions on redistribution.\nDerived works : The license must allow modification and redistribution of the code \nunder the same terms.\nIntegrity of the author\u2019s source code : The license may require that those who use \nthe source code remove the original project\u2019s name or version if they change the \nsource code.\nNo discrimination against persons or groups : The license must allow all people to be \nequally eligible to use the source code.\nNo discrimination against fields of endeavor : The license can\u2019t restrict a project \nfrom using the source code because it is commercial, or because it is associated with \na field of endeavor that the software provider doesn\u2019t like.\nDistribution of license : No additional license should be needed to use and redistribute \nthe software.\nLicense must not be specific to a product : The license can\u2019t restrict the source code \nto a particular software distribution.\nLicense must not restrict other software : The license can\u2019t prevent someone \nfrom including the open source software on the same medium as non-open \nsource software.\nLicense must be technology neutral : The license can\u2019t restrict methods in which the \nsource code can be redistributed.\nOpen source licenses used by software development projects must meet these criteria to be \naccepted as open source software by OSI. About 70 different licenses are accepted by OSI to \nbe used to label software as \u201cOSI Certified Open Source Software.\u201d In addition to the GPL, \nother popular OSI-approved licenses include the following:\nLGPL : The GNU Lesser General Public License (LGPL) is often used for distributing \nlibraries that other application programs depend upon.\nBSD: The Berkeley Software Distribution License allows redistribution of source code, \nwith the requirement that the source code keep the BSD copyright notice and not \nuse the names of contributors to endorse or promote derived software without writ -\nten permission. A major difference from GPL, however, is that BSD does not require \npeople modifying the code to pass those changes on to the community. As a result, \nproprietary software vendors such as Apple and Microsoft have used BSD code in \ntheir own operating systems.\nMIT: The MIT license is like the BSD license, except that it doesn\u2019t include the endorse -\nment and promotion requirement.\nMozilla : The Mozilla license covers the use and redistribution of source code associ-\nated with the Firefox web browser and other software related to the Mozilla project ", "doc_id": "06d61e52-6e86-4ac2-846a-4ed07a13593a", "embedding": null, "doc_hash": "bf98286659a252b784b480d2caa6d5792efee64198c22859b5e362a8380d3fb8", "extra_info": {"page_label": "48"}, "node_info": {"start": 0, "end": 2614}, "relationships": {"1": "82b7897d-7334-4171-98ed-29352305c2a1"}}, "__type__": "1"}, "73478bc4-1c2f-43d7-8ab6-51438cb824fd": {"__data__": {"text": "Part I: Getting Started16(https://www.mozilla.org/en-US/ ). It is a much longer license than the others \njust mentioned because it contains more definitions of how contributors and those \nreusing the source code should behave. This includes submitting a file of changes \nwhen submitting modifications and that those making their own additions to the \ncode for redistribution should be aware of patent issues or other restrictions associ-\nated with their code.\nThe end result of open source code is software that has more flexibility to grow and fewer \nboundaries in how it can be used. Many believe that the fact that numerous people look \nover the source code for a project results in higher-quality software for everyone. As open \nsource advocate Eric S. Raymond says in an often-quoted line, \u201cGiven enough eyeballs, all \nbugs are shallow.\u201d\nUnderstanding How Linux Distributions Emerged\nHaving bundles of source code floating around the Internet that could be compiled and \npackaged into a Linux system worked well for geeks. More casual Linux users, however, \nneeded a simpler way to put together a Linux system. To respond to that need, some of the \nbest geeks began building their own Linux distributions.\nA Linux distribution  consists of the components needed to create a working Linux system \nand the procedures needed to get those components installed and running. Technically, \nLinux is really just what is referred to as the kernel . Before the kernel can be useful, you \nmust have other software, such as basic commands (GNU utilities), services that you \nwant to offer (such as remote login or web servers), and possibly a desktop interface and \ngraphical applications. Then you must be able to gather all that together and install it on \nyour computer\u2019s hard disk.\nSlackware ( http://www.slackware.com ) is one of the oldest Linux distributions still \nsupported today. It made Linux friendly for less technical users by distributing software \nalready compiled and grouped into packages. (Those packages of software components were \nin a format called tarballs .) Then you would use basic Linux commands to do things like \nformat your disk, enable swap, and create user accounts.\nBefore long, many other Linux distributions were created. Some Linux distributions were \ncreated to meet special needs, such as KNOPPIX (a live CD Linux), Gentoo (a cool customiz -\nable Linux), and Mandrake (later called Mandriva, which was one of several desktop Linux \ndistributions). But two major distributions rose to become the foundation for many other \ndistributions: Red Hat Linux and Debian.\nChoosing a Red Hat distribution\nWhen Red Hat Linux appeared in the late 1990s, it quickly became the most popular Linux \ndistribution for several reasons:\nRPM package management : Tarballs are fine for dropping software on your computer, \nbut they don\u2019t work as well when you want to update, remove, or even find out ", "doc_id": "73478bc4-1c2f-43d7-8ab6-51438cb824fd", "embedding": null, "doc_hash": "83ef3198ac31f2ebda3c1b5cf610830989c5d6073b700cfed608d98c6e29e06f", "extra_info": {"page_label": "49"}, "node_info": {"start": 0, "end": 2912}, "relationships": {"1": "e7ea49f3-3d57-4199-8bb6-001cb5e32e02"}}, "__type__": "1"}, "434c4fce-ac6a-41bd-bd39-968e0c944ad1": {"__data__": {"text": "Chapter 1: Starting with Linux\n17\n1about that software. Red Hat created the RPM packaging format so that a software \npackage could contain not only the files to be shared but also information about the \npackage version, who created it, which files were documentation or configuration \nfiles, and when it was created. By installing software packaged in RPM format, you \ncould store that information about each software package in a local RPM database. \nIt became easy to find what was installed, update it, or remove it.\nSimple installation : The Anaconda installer made it much simpler to install Linux. \nAs a user, you could step through some simple questions, in most cases accepting \ndefaults, to install Red Hat Linux.\nGraphical administration : Red Hat added simple graphical tools to configure printers, \nadd users, set time and date, and do other basic administrative tasks. As a result, \ndesktop users could use a Linux system without even having to run commands.\nFor years, Red Hat Linux was the preferred Linux distribution for both Linux professionals \nand enthusiasts. Red Hat, Inc., gave away the source code, as well as the compiled, ready-\nto-run versions of Red Hat Linux (referred to as the binaries). But as the needs of its Linux \ncommunity users and big-ticket customers began to move further apart, Red Hat abandoned \nRed Hat Linux and began developing two operating systems instead: Red Hat Enterprise \nLinux and Fedora.\nUsing Red Hat Enterprise Linux\nIn March 2012, Red Hat, Inc., became the first open source software company to bring in \nmore than $1 billion in yearly revenue. It achieved that goal by building a set of products \naround Red Hat Enterprise Linux (RHEL) that would suit the needs of the most demand -\ning enterprise computing environments. After expanding its product line to include many \ncomponents of hybrid cloud computing, Red Hat was purchased by IBM in July 2019 for \n$34 billion.\nWhile other Linux distributions focused on desktop systems or small business comput -\ning, RHEL worked on those features needed to handle mission-critical applications for big \nbusiness and government. It built systems that could speed transactions for the world\u2019s \nlargest financial exchanges and be deployed as clusters and virtual hosts.\nInstead of just selling RHEL, Red Hat offers an ecosystem of benefits upon which Linux cus -\ntomers could draw. To use RHEL, customers buy subscriptions that they can use to deploy \nany version of RHEL that they desire. If they decommission a RHEL system, they can use \nthe subscription to deploy another system.\nDifferent levels of support are available for RHEL, depending on customer needs. Customers \ncan be assured that, along with support, they can get hardware and third-party software \nthat is certified to work with RHEL. They can get Red Hat consultants and engineers to help \nthem put together the computing environments they need. They can also get training and \ncertification exams for their employees (see the discussion of RHCE certification later in \nthis chapter).", "doc_id": "434c4fce-ac6a-41bd-bd39-968e0c944ad1", "embedding": null, "doc_hash": "4c9139d413714f5d003251014061cf393f63e4f3e4b381a26c458d3718ad89dc", "extra_info": {"page_label": "50"}, "node_info": {"start": 0, "end": 3051}, "relationships": {"1": "a8798fdd-4d95-4e5d-bee7-a12528710767"}}, "__type__": "1"}, "dc1e515b-990c-4a75-9582-ec2bcdde3102": {"__data__": {"text": "Part I: Getting Started18Red Hat has also added other products as natural extensions to Red Hat Enterprise Linux. \nJBoss is a middleware product for deploying Java-based applications to the Internet or com-\npany intranets. Red Hat Virtualization comprises the virtualization hosts, managers, and \nguest computers that allow you to install, run, manage, migrate, and decommission huge \nvirtual computing environments.\nIn recent years, Red Hat has extended its portfolio into cloud computing. Red Hat  \nOpenStack Platform and Red Hat Virtualization offer complete platforms for running and \nmanaging virtual machines. However, the technology with the biggest impact in recent \nyears is Red Hat OpenShift, which provides a hybrid cloud suite of software that has Kuber -\nnetes, the most popular container orchestration platform project, as its foundation. With \nthe Red Hat acquisition, IBM has set a goal to containerize most of its applications to run \non OpenShift.\nThere are those who have tried to clone RHEL, using the freely available RHEL source code, \nrebuilding and rebranding it. Oracle Linux is built from source code for RHEL but currently \noffers an incompatible kernel. CentOS is a community-sponsored Linux distribution that is \nbuilt from RHEL source code. Recently, Red Hat took over support of the CentOS project.\nI\u2019ve chosen to use Red Hat Enterprise Linux for many of the examples in this book because, \nif you want a career working on Linux systems, there is a huge demand for those who \ncan administer RHEL systems. If you are starting out with Linux, however, Fedora can \nprovide an excellent entry point to the same skills that you need to use and administer \nRHEL systems.\nUsing Fedora\nWhile RHEL is the commercial, stable, supported Linux distribution, Fedora is the free, cut -\nting-edge Linux distribution that is sponsored by Red Hat, Inc. Fedora is the Linux system \nthat Red Hat uses to engage the Linux development community and encourage those who \nwant a free Linux for personal use and rapid development.\nFedora includes tens of thousands of software packages, many of which keep up with the \nlatest available open source technology. As a user, you can try the latest Linux desktop, \nserver, and administrative interfaces in Fedora for free. As a software developer, you can \ncreate and test your applications using the latest Linux kernel and development tools.\nBecause the focus of Fedora is on the latest technology, it focuses less on stability. So, \nexpect that you might need to do some extra work to get everything working and that not \nall the software will be fully baked.\nI recommend that you use Fedora or RHEL for most of the examples in this book for the fol -\nlowing reasons:\n\u25a0\u25a0Fedora is used as a proving ground for Red Hat Enterprise Linux. Red Hat tests \nmany new applications in Fedora before committing them to RHEL. By using \nFedora, you will learn the skills you need to work with features as they are being \ndeveloped for Red Hat Enterprise Linux.", "doc_id": "dc1e515b-990c-4a75-9582-ec2bcdde3102", "embedding": null, "doc_hash": "f1d9cce02cc26c091ff0e5691a6576fe70514952b62929801dcb6dde70a5c1bf", "extra_info": {"page_label": "51"}, "node_info": {"start": 0, "end": 3002}, "relationships": {"1": "16728635-dfaf-485b-a202-083254e21728"}}, "__type__": "1"}, "49fc0429-b09a-4c50-aa4f-3b0ab0276b36": {"__data__": {"text": "Chapter 1: Starting with Linux\n19\n1\u25a0\u25a0For learning, Fedora is more convenient than RHEL, yet still includes many of the \nmore advanced, enterprise-ready tools that are in RHEL.\n\u25a0\u25a0Fedora is free, not only as in \u201cfreedom,\u201d but also as in \u201cyou don\u2019t have to \npay for it.\u201d\nFedora is extremely popular with those who develop open source software. However, in \nthe past few years, another Linux distribution has captured the attention of many people \nstarting out with Linux: Ubuntu.\nChoosing Ubuntu or another Debian distribution\nLike Red Hat Linux, the Debian GNU/Linux distribution was an early Linux distribution \nthat excelled at packaging and managing software. Debian uses the deb packaging format \nand tools to manage all of the software packages on its systems. Debian also has a reputa -\ntion for stability.\nMany Linux distributions can trace their roots back to Debian. According to DistroWatch \n(https://distrowatch.com ), more than 130 active Linux distributions can be traced \nback to Debian. Popular Debian-based distributions include Linux Mint, elementary OS, \nZorin OS, LXLE, Kali Linux, and many others. However, the Debian derivative that has \nachieved the most success is Ubuntu ( https://ubuntu.com ).\nBy relying on stable Debian software development and packaging, the Ubuntu Linux dis -\ntribution (sponsored by Canonical Ltd.) was able to come along and add those features \nthat Debian lacked. In pursuit of bringing new users to Linux, the Ubuntu project added a \nsimple graphical installer and easy-to-use graphical tools. It also focused on full-featured \ndesktop systems while still offering popular server packages.\nUbuntu was also an innovator in creating new ways to run Linux. Using live CDs or live USB \ndrives offered by Ubuntu, you could have Ubuntu up and running in just a few minutes. \nOften included on live CDs were open source applications, such as web browsers and word \nprocessors, that actually ran in Windows. This made the transition to Linux from Windows \neasier for some people.\nIf you are using Ubuntu, don\u2019t fear. Most of subject matter covered in this book will work as \nwell in Ubuntu as it does in Fedora or RHEL.\nFinding Professional Opportunities with Linux Today\nIf you want to develop an idea for a computer-related research project or technology com-\npany, where do you begin? You begin with an idea. After that, you look for the tools that \nyou need to explore and eventually create your vision. Then you look for others to help you \nduring that creation process.\nToday, the hard costs of starting a company like Google or Facebook include just a com-\nputer, a connection to the Internet, and enough caffeinated beverage of your choice to ", "doc_id": "49fc0429-b09a-4c50-aa4f-3b0ab0276b36", "embedding": null, "doc_hash": "3b52cf0295e53583634459703c736f778866707abb4aec90aaae5c86adaf4093", "extra_info": {"page_label": "52"}, "node_info": {"start": 0, "end": 2691}, "relationships": {"1": "2c75a539-cc0f-4b2e-a575-81c3d7ef8e47"}}, "__type__": "1"}, "91d535ba-4e10-47e5-a233-2e359af83f7c": {"__data__": {"text": "Part I: Getting Started20keep you up all night writing code. If you have your own world-changing idea, Linux and \nthousands of software packages are available to help you build your dreams. The open \nsource world also comes with communities of developers, administrators, and users who are \navailable to help you.\nIf you want to get involved with an existing open source project, projects are always \nlooking for people to write code, test software, or write documentation. In those projects, \nyou will find people who use the software, work on that software, and are usually willing to \nshare their expertise to help you as well.\nWhether you seek to develop the next great open source software project, or you simply \nwant to gain the skills needed to compete for the thousands of well-paying Linux admin -\nistrator or development jobs, it will help you to know how to install, secure, and maintain \nLinux systems.\nIn March 2020, more than 60,000 jobs requiring Linux skills were listed at Indeed.com. \nNearly half of those offered pay of $100,000 per year or more. Site such as Fossjobs.net pro -\nvide a venue for posting and finding jobs associated with Linux and other free and open \nsource software skills.\nThe message to take from these job sites is that Linux continues to grow and create \ndemands for Linux expertise. Companies that have begun using Linux have continued to \nmove forward with it. Those using Linux continue to expand its use and find that cost \nsavings, security, and the flexibility it offers continue to make Linux a good investment.\nUnderstanding how companies make money with Linux\nOpen source enthusiasts believe that better software can result from an open source soft -\nware development model than from proprietary development models. So, in theory, any \ncompany creating software for its own use can save money by adding its software contribu-\ntions to those of others to gain a much better end product for themselves.\nCompanies that want to make money by selling software need to be more creative than \nthey were in the old days. Although you can sell the software you create, which includes \nGPL software, you must pass the source code of that software forward. Of course, others \ncan then recompile that product, basically using and even reselling your product without \ncharge. Here are a few ways that companies are dealing with that issue:\nSoftware subscriptions : Red Hat, Inc., sells its Red Hat Enterprise Linux products on \na subscription basis. For a certain amount of money per year, you get binary code \nto run Linux (so you don\u2019t have to compile it yourself), guaranteed support, tools \nfor tracking the hardware and software on your computer, access to the company\u2019s \nknowledge base, and other assets.\nAlthough Red Hat\u2019s Fedora project includes much of the same software and is also \navailable in binary form, there are no guarantees associated with the software or ", "doc_id": "91d535ba-4e10-47e5-a233-2e359af83f7c", "embedding": null, "doc_hash": "e818a8937b739e7aa8b2093048d697a3c590db15106043fea4964b88064e6564", "extra_info": {"page_label": "53"}, "node_info": {"start": 0, "end": 2913}, "relationships": {"1": "650ba54a-e415-456b-bdac-82b3b29b223d"}}, "__type__": "1"}, "7a30e3cb-cf53-4443-ba9d-922a08c22b2c": {"__data__": {"text": "Chapter 1: Starting with Linux\n21\n1future updates of that software. A small office or personal user might take a risk \non using Fedora (which is itself an excellent operating system), but a big company \nthat\u2019s running mission-critical applications will probably put down a few dollars for \nRHEL.\nTraining and certification : With Linux system use growing in government and big \nbusiness, professionals are needed to support those systems. Red Hat offers training \ncourses and certification exams to help system administrators become proficient \nusing Red Hat Enterprise Linux systems. In particular, the Red Hat Certified Engi-\nneer (RHCE) and Red Hat Certified System Administrator (RHCSA) certifications  \nhave become popular ( https://www.redhat.com/en/services/training-\nand-certification/why-get-certified ). More on RHCE/RHCSA certifications \nlater in this chapter.\nOther certification programs are offered by Linux Professional Institute ( https://www  \n.lpi.org ) and CompTIA ( wwww..comptia.org /). LPI and CompTIA are profes -\nsional computer industry associations.\nBounties : Software bounties are a fascinating way for open source software companies \nto make money. Suppose that you are using XYZ software package and you need \na new feature right away. By paying a software bounty to the project itself, or to \nother software developers, you can have your required improvements moved to the \nhead of the queue. The software you pay for will remain covered by its open source \nlicense, but you will have the features you need\u2014probably at a fraction of the cost \nof building the project from scratch.\nDonations : Many open source projects accept donations from individuals or open \nsource companies that use code from their projects. Amazingly, many open source \nprojects support one or two developers and run exclusively on donations.\nBoxed sets, mugs, and T-shirts : Some open source projects have online stores where \nyou can buy boxed sets (some people still like physical DVDs and hard copies of doc -\numentation) and a variety of mugs, T-shirts, mouse pads, and other items. If you \nreally love a project, for goodness sake, buy a T-shirt!\nThis is in no way an exhaustive list, because more creative ways are being invented every \nday to support those who create open source software. Remember that many people have \nbecome contributors to and maintainers of open source software because they needed or \nwanted the software themselves. The contributions they make for free are worth the return \nthey get from others who do the same.\nBecoming Red Hat certified\nAlthough this book is not focused on becoming certified in Linux, it touches on the activ -\nities that you need to be able to master to pass popular Linux certification exams. In ", "doc_id": "7a30e3cb-cf53-4443-ba9d-922a08c22b2c", "embedding": null, "doc_hash": "0b462ec7295f846c41d3da9debc13a63518c85cf25cee128790bdc65c9df2bfa", "extra_info": {"page_label": "54"}, "node_info": {"start": 0, "end": 2756}, "relationships": {"1": "fa9973d9-6c6d-479a-a851-a2a9783eecdf"}}, "__type__": "1"}, "62a5a01a-f88f-4f0b-8c6a-c0d5a437c99c": {"__data__": {"text": "Part I: Getting Started22particular, most of what is covered in the Red Hat Certified Engineer (RHCE) and Red Hat \nCertified System Administrator (RHCSA) exams for Red Hat Enterprise Linux 8 is described \nin this book.\nIf you are looking for a job as a Linux IT professional, RHCSA or RHCE certification is often \nlisted as a requirement, or at least a preference, for employment. The RHCSA exam (EX200) \nprovides basic certification, covering such topics as configuring disks and filesystems, add -\ning users, setting up a simple web and FTP server, and adding swap space. The RHCE exam \n(EX300) tests for more advanced server configuration as well an advanced knowledge of \nsecurity features, such as SELinux and firewalls.\nThose of us who have taught RHCE/RHCSA courses and given exams (as I did for three \nyears) are not allowed to tell you exactly what is on the exam. However, Red Hat gives \nan overview of how the exams work as well as a list of topics that you can expect to see \ncovered in the exam. You can find those exam objectives on the following sites:\nRHCSA\nhttps://redhat.com/en/services/training/ex200-red-hat-certified-\nsystem-administrator-rhcsa-exam\nRHCE\nhttps://redhat.com/en/services/training/ex294-red-hat-certified-  \nengineer-rhce-exam-red-hat-enterprise-linux-8\nAs the exam objectives state, the RHCSA and RHCE exams are performance based, which \nmeans that you are given tasks to do and you must perform those tasks on an actual Red \nHat Enterprise Linux system, as you would on the job. You are graded on how well you \nobtained the results of those tasks.\nIf you plan to take the exams, check back to the exam objectives pages often because they \nchange from time to time. Also keep in mind that the RHCSA is a standalone certification; \nhowever, you must pass the RHCSA and the RHCE exams to get an RHCE certification. Often, \nthe two exams are given on the same day.\nYou can sign up for RHCSA and RHCE training and exams at\u00a0 https://redhat.com/en/  \nservices/training-and-certification . Training and exams are given at major cit -\nies all over the United States and around the world. The skills that you need to complete \nthese exams are described in the following sections.\nRHCSA topics\nAs noted earlier, RHCSA exam topics cover basic system administration skills. These are \nthe current topics listed for Red Hat Enterprise Linux 8 at the RHCSA exam objectives site \n(again, check the exam objectives site in case they change) and where in this book you can \nlearn about them:\nUnderstand essential tools : You are expected to have a working knowledge of the \ncommand shell (bash), including how to use proper command syntax and do input/", "doc_id": "62a5a01a-f88f-4f0b-8c6a-c0d5a437c99c", "embedding": null, "doc_hash": "03ad3c54b28722470300cbebca8b01e97eb6b7197494cecf63f8c87816abfc3b", "extra_info": {"page_label": "55"}, "node_info": {"start": 0, "end": 2671}, "relationships": {"1": "c9bf726c-dd98-430a-8ac5-e62efa48f608"}}, "__type__": "1"}, "5aa4957e-d08e-4a1a-bb66-7a1235faaecb": {"__data__": {"text": "Chapter 1: Starting with Linux\n23\n1output redirection ( < > >> ). You need to know how to log in to remote and local \nsystems. Expect to have to create, edit, move, copy, link, delete, and change permis -\nsion and ownership on files. Likewise, you should know how to look up information \non man pages and /usr/share/doc. Most of these topics are covered in Chapter\u00a03 \nand Chapter\u00a04 in this book. Chapter\u00a05 describes how to edit and find files.\nOperate running systems : In this category, you must understand the Linux boot pro -\ncess, and how to shut down, reboot, and change to different targets (previously \ncalled runlevels ). You need to identify processes and kill processes as requested. You \nmust be able to find and interpret log files. Chapter\u00a015 describes how to change tar -\ngets and manage system services. See Chapter\u00a06 for information on managing and \nchanging processes. Logging is described in Chapter\u00a013.\nConfigure local storage : Setting up disk partitions includes creating physical volumes \nand configuring them to be used for Logical Volume Management (LVM) or encryp -\ntion (LUKS). You should also be able to set up those partitions as filesystems or \nswap space that can be mounted or enabled at boot time. Disk partitioning and LVM \nare covered in Chapter\u00a012. LUKS and other encryption topics are described in Chap -\nter\u00a023, \u201cUnderstanding Advanced Linux Security.\u201d\nCreate and configure filesystems : Create and automatically mount different kinds of \nfilesystems, including regular Linux filesystems (ext2, ext3, or ext4) and network \nfilesystems (NFS). Create collaborative directories using the set group ID bit feature. \nYou must also be able to use LVM to extend the size of a logical volume. Filesystem \ntopics are covered in Chapter\u00a012. See Chapter\u00a020 for NFS coverage.\nDeploy, configure, and maintain systems : This covers a range of topics, including \nconfiguring networking and creating cron  tasks. For software packages, you must \nbe able to install packages from Red Hat Content Delivery Network (CDN), a remote \nrepository, or the local filesystem. The cron  facility is described in Chapter\u00a013.\nManage users and groups : You must know how to add, delete, and change user and \ngroup accounts. Another topic that you should know is password aging, using the \nchage  command. See Chapter\u00a011 for information on configuring users and groups.\nManage security : You must have a basic understanding of how to set up a firewall \n(firewalld , system-config-firewall , or iptables ) and how to use SELinux. \nYou must be able to set up SSH to do key-based authentication. Learn about SELinux \nin Chapter\u00a024. Firewalls are covered in Chapter\u00a025. Chapter\u00a013 includes a description \nof key-based authentication.\nMost of these topics are covered in this book. Refer to Red Hat documentation ( https://\naccess.redhat.com/documentation ) under the Red Hat Enterprise Linux heading for \ndescriptions of features not found in this book. In particular, the system administration \nguides contain descriptions of many of the RHCSA-related topics.\nRHCE topics\nRHCE exam topics cover more advanced server configuration, along with a variety of secu -\nrity features for securing those servers in Red Hat Enterprise Linux 8. Again, check the ", "doc_id": "5aa4957e-d08e-4a1a-bb66-7a1235faaecb", "embedding": null, "doc_hash": "2cad66da3bd4b9b3129a9593fc1cbf1d5215ae0d858f719d85e66da11bd649e6", "extra_info": {"page_label": "56"}, "node_info": {"start": 0, "end": 3254}, "relationships": {"1": "1f35a55b-9669-4d1a-bce1-63fed7692545"}}, "__type__": "1"}, "133f19a2-2277-4de2-97b6-9ebd272df02f": {"__data__": {"text": "Part I: Getting Started24RHCE exam objectives site for the most up-to-date information on topics that you should \nstudy for the exam.\nSystem configuration and management\nThe system configuration and management requirement for the RHCE exam covers a range \nof topics, including the following:\nFirewalls : Block or allow traffic to selected ports on your system that offer services \nsuch as web, FTP, and NFS, as well as block or allow access to services based on the \noriginator\u2019s IP address. Firewalls are covered in Chapter\u00a025, \u201cSecuring Linux on \na Network.\u201d\nKerberos authentication : Use Kerberos to authenticate users on a RHEL system.\nSystem reports : Use features such as sar  to report on system use of memory, disk \naccess, network traffic, and processor utilization. Chapter\u00a013 describes how to use \nthe sar  command.\nShell scripting : Create a simple shell script to take input and produce output in var -\nious ways. Shell scripting is described in Chapter\u00a07.\nSELinux : With Security Enhanced Linux in Enforcing mode, make sure that all server \nconfigurations described in the next section are properly secured with SELinux. \nSELinux is described in Chapter\u00a024.\nAnsible : Understand core Ansible components (inventories, modules, playbooks, and \nso on). Be able to install and configure an Ansible control node. Work with Ansible \nroles and use advanced Ansible features. See Chapter\u00a029 for information on using \nAnsible playbooks to install and manage Linux systems.\nInstalling and configuring network services\nFor each of the network services in the list that follows, make sure you can go through \nthe steps to install packages required by the service, set up SELinux to allow access to the \nservice, set the service to start at boot time, secure the service by host or by user (using \niptables or features provided by the service itself), and configure it for basic operation. \nThese are the services:\nWeb server : Configure an Apache (HTTP/HTTPS) server. You must be able to set up \na virtual host, deploy a CGI script, use private directories, and allow a particu -\nlar Linux group to manage the content. Chapter\u00a017 describes how to configure a \nweb server.\nDNS server : Set up a DNS server (bind package) to act as a caching-only name server \nthat can forward DNS queries to another DNS server. No need to configure master or \nslave zones. DNS is described from the client side in Chapter\u00a014. For information on \nconfiguring a DNS server with Bind, see the RHEL Networking Guide at\nhttps://access.redhat.com/documentation/en-us/red _hat_enter-\nprise _linux/7/html-single/networking _guide/index", "doc_id": "133f19a2-2277-4de2-97b6-9ebd272df02f", "embedding": null, "doc_hash": "39f453e3d5e42f54076784d153d343aaa0dcf9db86a2fc522352c3f3726cd64b", "extra_info": {"page_label": "57"}, "node_info": {"start": 0, "end": 2611}, "relationships": {"1": "0f1c7a88-cbb5-469c-b220-4d0ee4d341f1"}}, "__type__": "1"}, "413b2e84-bee2-4bdc-a817-1bb494debf9f": {"__data__": {"text": "Chapter 1: Starting with Linux\n25\n1NFS server : Configure an NFS server to share specific directories to specific client sys -\ntems so they can be used for group collaboration. Chapter\u00a020 covers NFS.\nWindows file sharing server : Set up Linux (Samba) to provide SMB shares to specific \nhosts and users. Configure the shares for group collaboration. See Chapter\u00a019 to \nlearn about configuring Samba.\nMail server : Configure postfix or sendmail to accept incoming mail from outside of \nthe local host. Relay mail to a smart host. Mail server configuration is not covered \nin this book (and should not be done lightly). See the RHEL System Administrator\u2019s \nGuide for information on configuring mail servers at:\nhttps://access.redhat.com/documentation/en-us/red _hat_enter-\nprise _linux/7/html-single/system _administrators _guide/index#ch-\nMail _Servers\nSecure Shell server : Set up the SSH service (sshd) to allow remote login to your local \nsystem as well as key-based authentication. Otherwise, configure the sshd.conf  \nfile as needed. Chapter\u00a013 describes how to configure the sshd service.\nNetwork Time server : Configure a Network Time Protocol server (ntpd) to synchronize \ntime with other NTP peers.\nDatabase server : Configure the MariaDB database and manage it in various ways. Learn \nhow to configure the MariaDB from the MariaDB.org  site (https://mariadb  \n.com/kb/en/library/documentation/ ).\nAlthough there are other tasks in the RHCE exam, as just noted, keep in mind that most \nof the tasks have you configure servers and then secure those servers using any technique \nthat you need. Those can include firewall rules (iptables), SELinux, or any features built \ninto configuration files for the particular service.\nSummary\nLinux is an operating system that is built by a community of software developers around \nthe world, which is led by its creator, Linus Torvalds. It is derived originally from the UNIX \noperating system but has grown beyond UNIX in popularity and power over the years.\nThe history of the Linux operating system can be tracked from early UNIX systems that \nwere distributed free to colleges and improved upon by initiatives such as the Berkeley \nSoftware Distribution (BSD). The Free Software Foundation helped make many of the com-\nponents needed to create a fully free UNIX-like operating system. The Linux kernel itself \nwas the last major component needed to complete the job.\nMost Linux software projects are protected by one of a set of licenses that fall under the \nOpen Source Initiative umbrella. The most prominent of these is the GNU Public License \n(GPL). Standards such as the Linux Standard Base and world-class Linux organizations and ", "doc_id": "413b2e84-bee2-4bdc-a817-1bb494debf9f", "embedding": null, "doc_hash": "26ffa3bdc06725de4fbf84143c8cd9f905091a89c565ce80aba43130dab5e696", "extra_info": {"page_label": "58"}, "node_info": {"start": 0, "end": 2685}, "relationships": {"1": "0b1afb59-43f0-4c49-b51d-71d4eab6c7f0"}}, "__type__": "1"}, "73aba02f-d110-49a3-a165-58191e42cf60": {"__data__": {"text": "Part I: Getting Started26companies (such as Canonical Ltd. and Red Hat, Inc.) make it possible for Linux to con-\ntinue to be a stable, productive operating system into the future.\nLearning the basics of how to use and administer a Linux system will serve you well in any \naspect of working with Linux. The remaining chapters provide a series of exercises with \nwhich you can test your understanding. That\u2019s why, for the rest of the book, you will learn \nbest with a Linux system in front of you so that you can work through the examples in \neach chapter and complete the exercises successfully.\nThe next chapter explains how to get started with Linux by describing how to get and use \na Linux desktop system.", "doc_id": "73aba02f-d110-49a3-a165-58191e42cf60", "embedding": null, "doc_hash": "efc62733e9ddf055758626bd28670761fb92e1947e554ad73c8e7e3018da2c55", "extra_info": {"page_label": "59"}, "node_info": {"start": 0, "end": 708}, "relationships": {"1": "7cca6699-08af-490b-82f9-d6698b5922d7"}}, "__type__": "1"}, "1d450dd1-4cd9-4887-9bbe-59b23e03cc7e": {"__data__": {"text": "27\nCHAPTER2\nCreating the Perfect \nLinux Desktop\nIN THIS CHAPTER\nUnderstanding the X Window System and desktop environments\nRunning Linux from a Live DVD image\nNavigating the GNOME 3 desktop\nAdding extensions to GNOME 3\nUsing Nautilus to manage files in GNOME 3\nWorking with the GNOME 2 desktop\nEnabling 3D effects in GNOME 2\nUsing Linux as your everyday desktop system is becoming easier to do all the time. As with \neverything in Linux, you have choices. There are fully featured GNOME or KDE desktop envi-\nronments or lightweight desktops such as LXDE or Xfce. There are even simpler standalone \nwindow managers.\nAfter you have chosen a desktop, you will find that almost every major type of desktop application you \nhave on a Windows or Mac system has equivalent applications in Linux. For applications that are not avail -\nable in Linux, you can often run a Windows application in Linux using Windows compatibility software.\nThe goal of this chapter is to familiarize you with the concepts related to Linux desktop systems and \nto give you tips for working with a Linux desktop. In this chapter you do the following:\n\u25a0\u25a0Step through the desktop features and technologies that are available in Linux\n\u25a0\u25a0Tour the major features of the GNOME desktop environment\n\u25a0\u25a0Learn tips and tricks for getting the most out of your GNOME desktop experience\nTo use the descriptions in this chapter, I recommend that you have a Fedora system running in front \nof you. You can get Fedora in lots of ways, including the following:\nRunning Fedora from a live medium Refer to Appendix A for information on downloading \nand burning Fedora Live image to a DVD or USB drive so that you can boot it live to use with \nthis chapter.\nInstalling Fedora permanently  Install Fedora to your hard disk and boot it from there (as \ndescribed in Chapter\u00a09, \u201cInstalling Linux\u201d).\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "1d450dd1-4cd9-4887-9bbe-59b23e03cc7e", "embedding": null, "doc_hash": "39a424c78823af79a11bc2d6b7b2d12c6f3e0cb0379daef3c21769a396c9aa7a", "extra_info": {"page_label": "60"}, "node_info": {"start": 0, "end": 1966}, "relationships": {"1": "3a027864-b685-4c01-8201-cddeccaa02c3"}}, "__type__": "1"}, "fd044a4f-fb88-48e2-af67-23ef5759798d": {"__data__": {"text": "Part I: Getting Started28Because the current release of Fedora uses the GNOME 3 interface, most of the procedures \ndescribed in this chapter work with other Linux distributions that have GNOME 3 available. \nIf you are using an older Red Hat Enterprise Linux system (RHEL 6 uses GNOME 2, but RHEL 7 \nand RHEL 8 use GNOME 3), I added descriptions of GNOME 2 that you can try as well.\nNote\nUbuntu switched from its own Unity desktop as its default to GNOME 3 with release 17.10. Unity is still available for \nnewer releases, but only from the unsupported, community-maintained Universe  repository.\nUnderstanding Linux Desktop Technology\nModern computer desktop systems offer graphical windows, icons, and menus that are \noperated from a mouse and keyboard. If you are under 40 years old, you might think that \nthere\u2019s nothing special about that. However, the first Linux systems did not have graphical \ninterfaces available. Also, many Linux servers today that are tuned for special tasks (for \nexample, functioning as a web server or file server) don\u2019t have desktop software installed.\nNearly every major Linux distribution that offers desktop interfaces is based on the X \nWindow System originally from the X.Org Foundation ( http://www.x.org ). The X Window \nSystem provides a framework on which different types of desktop environments or simple \nwindow managers can be built. A replacement for X.Org called Wayland ( http://wayland  \n.freedesktop.org ) is being developed. Although Wayland is the default X server for \nFedora now, you can still choose X.Org instead.\nThe X Window System (sometimes simply called X ) was created before Linux existed, and \nit even predates Microsoft Windows. It was built to be a lightweight, networked desktop \nframework.\nX works in sort of a backward client/server model. The X server runs on the local system, \nproviding an interface to your screen, mouse, and keyboard. X clients (such as word proces -\nsors, music players, and image viewers) can be launched from the local system or from any \nsystem on your network to which the X server gives permission to do so.\nX was created in a time when graphical terminals (thin clients) simply managed the key -\nboard, mouse, and display. Applications, disk storage, and processing power were all on \nlarger centralized computers. So, applications ran on larger machines but were displayed \nand managed over the network on the thin client. Later, thin clients were replaced \nby desktop personal computers. Most client applications on PCs ran locally using local \nprocessing power, disk space, memory, and other hardware features, while applications that \ndid not start from the local system were not allowed.\nX itself provides a plain gray background and a simple \u201cX\u201d mouse cursor. There are no \nmenus, panels, or icons on a plain X screen. If you were to launch an X client (such as a ter -\nminal window or word processor), it would appear on the X display with no border around it \nto move, minimize, or close the window. Those features are added by a window manager.", "doc_id": "fd044a4f-fb88-48e2-af67-23ef5759798d", "embedding": null, "doc_hash": "1c32d6f23dc8d86f5df0e0e51b706ca87ce04761fc91d5670cb9678ab9a1b1da", "extra_info": {"page_label": "61"}, "node_info": {"start": 0, "end": 3050}, "relationships": {"1": "c5376c86-67b5-4e08-b6cc-4394797f0cfe"}}, "__type__": "1"}, "b4b52a8b-9f03-43f4-afef-051c965fe819": {"__data__": {"text": "Chapter 2: Creating the Perfect Linux Desktop\n29\n2A window manager  adds the capability to manage the windows on your desktop and often \nprovides menus for launching applications and otherwise working with the desktop. A \nfull-blown desktop environment includes a window manager, but it also adds menus, \npanels, and usually an application programming interface that is used to create applica -\ntions that play well together.\nSo how does an understanding of how desktop interfaces work in Linux help you when it \ncomes to using Linux? Here are some of the ways:\n\u25a0\u25a0Because Linux desktop environments are not required to run a Linux system, a \nLinux system may have been installed without a desktop. It might offer only a \nplain-text, command-line interface. You can choose to add a desktop later. After it \nis installed, you can choose whether to start up the desktop when your computer \nboots or start it as needed.\n\u25a0\u25a0For a very lightweight Linux system, such as one meant to run on less powerful \ncomputers, you can choose an efficient, though less feature-rich, window man -\nager (such as twm  or fluxbox ) or a lightweight desktop environment (such as \nLXDE or Xfce).\n\u25a0\u25a0For more robust computers, you can choose more powerful desktop environments \n(such as GNOME and KDE) that can do things such as watch for events to happen \n(such as inserting a USB flash drive) and respond to those events (such as opening \na window to view the contents of the drive).\n\u25a0\u25a0You can have multiple desktop environments installed and you can choose which \none to launch when you log in. In this way, different users on the same computer \ncan use different desktop environments.\nMany different desktop environments are available to choose from in Linux. Here are \nsome examples:\nGNOME  GNOME is the default desktop environment for Fedora, Red Hat Enterprise \nLinux, and many others. Think of it as a professional desktop environment focusing \non stability more than fancy effects.\nK Desktop Environment KDE is probably the second most popular desktop envi-\nronment for Linux. It has more bells and whistles than GNOME and offers more \nintegrated applications. KDE is also available with Fedora, Ubuntu, and many other \nLinux systems. For RHEL 8, KDE was dropped from the distribution.\nXfce The Xfce desktop was one of the first lightweight desktop environments. It is \ngood to use on older or less powerful computers. It is available with Fedora, Ubuntu, \nand other Linux distributions.\nLXDE The Lightweight X11 Desktop Environment (LXDE) was designed to be a fast-\nperforming, energy-saving desktop environment. Often, LXDE is used on less-expen -\nsive devices (such as netbook computers) and on live media (such as a live CD or live \nUSB stick). It is the default desktop for the KNOPPIX live CD distribution. Although \nLXDE is not included with RHEL, you can try it with Fedora or Ubuntu.", "doc_id": "b4b52a8b-9f03-43f4-afef-051c965fe819", "embedding": null, "doc_hash": "b06f7920565a7cf16811e8daab190f1601c0bdeff2a4f411233720e3395e9c36", "extra_info": {"page_label": "62"}, "node_info": {"start": 0, "end": 2874}, "relationships": {"1": "7d47bdef-ae9b-46e9-806e-f6cd221f9123"}}, "__type__": "1"}, "97265181-2202-428f-915c-58e8d8e7985c": {"__data__": {"text": "Part I: Getting Started30GNOME was originally designed to resemble the MacOS desktop, while KDE was meant to \nemulate the Windows desktop environment. Because it is the most popular desktop envi-\nronment, and the one most often used in business Linux systems, most desktop procedures \nand exercises in this book use the GNOME desktop. Using GNOME, however, still gives you \nthe choice of several different Linux distributions.\nStarting with the Fedora GNOME Desktop Live image\nA live Linux ISO image is the quickest way to get a Linux system up and running so that \nyou can begin trying it out. Depending on its size, the image can be burned to a CD, DVD, \nor USB drive and booted on your computer. With a Linux live image, you can have Linux \ntake over the operation of your computer temporarily without harming the contents of your \nhard drive.\nIf you have Windows installed, Linux just ignores it and takes control of your computer \nitself. When you are finished with the Linux live image, you can reboot the computer, pop \nout the CD or DVD, and go back to running whatever operating system was installed on the \nhard disk.\nTo try out a GNOME desktop along with the descriptions in this section, I suggest that you \nget a Fedora Live DVD (as described in Appendix A). Because a live DVD does all its work \nfrom the DVD and in memory, it runs slower than an installed Linux system. Also, although \nyou can change files, add software, and otherwise configure your system, by default, the \nwork you do disappears when you reboot unless you explicitly save that data to your hard \ndrive or external storage.\nThe fact that changes you make to the live environment go away on reboot is very good for \ntrying out Linux but not that great if you want an ongoing desktop or server system. For \nthat reason, I recommend that if you have a spare computer, you install Linux permanently \non that computer\u2019s hard disk to use with the rest of this book (as described in Chapter\u00a09).\nAfter you have a live CD or DVD in hand, do the following to get started:\n1. Get a computer . If you have a standard PC (32-bit or 64-bit) with a CD/DVD drive, \nat least 1GB of memory (RAM), and at least a 1GHz processor, you are ready to start. \n(Just make sure that the image you download matches your computer\u2019s architec -\nture\u2014a 64-bit medium does not run on a 32-bit computer. Fedora 31 and RHEL 7 \ndropped 32-bit support, so you would need older versions of those distributions to \nrun on those older machines.)\n2. Start the live CD/DVD . Insert the live CD/DVD or USB drive into your computer and \nreboot your computer. Depending on the boot order set on your computer, the live \nimage might start up directly from the BIOS (the code that controls the computer \nbefore the operating system starts).", "doc_id": "97265181-2202-428f-915c-58e8d8e7985c", "embedding": null, "doc_hash": "412f6a3017412bf9e51d702ecd65a97fa30b36a8ec4766c47dcdc0fdef12fb10", "extra_info": {"page_label": "63"}, "node_info": {"start": 0, "end": 2777}, "relationships": {"1": "090d5bf7-5c24-43e4-aa5b-12ae9c5cb4eb"}}, "__type__": "1"}, "655925b4-fcb0-4054-bbe6-fa15a63be5ae": {"__data__": {"text": "Chapter 2: Creating the Perfect Linux Desktop\n31\n2Note\nIf, instead of the live medium booting, your installed operating system starts up instead, you need to perform an \nadditional step to start the live CD/DVD. Reboot again, and when you see the BIOS screen, look for some words that \nsay something like \u201cBoot Order.\u201d The onscreen instructions may say to press the F12 or F1 key. Press that key imme -\ndiately from the BIOS screen. Next, you should see a screen that shows available selections. Highlight an entry for \nCD/DVD or USB drive, and press Enter to boot the live image. If you don\u2019t see the drive there, you may need to go into \nBIOS setup and enable the CD/DVD or USB drive there.\n3. Start Fedora . If the selected drive is able to boot, you see a boot screen. For \nFedora, with Start Fedora highlighted, press Enter to start the live medium.\n4. Begin using the desktop . For Fedora, the live medium lets you choose between \ninstalling Fedora or booting it directly from the medium to a GNOME 3 desktop.\nYou can now proceed to the next section, \u201cUsing the GNOME 3 Desktop\u201d (which includes \ninformation on using GNOME 3 in Fedora, Red Hat Enterprise Linux, and other operating \nsystems). Following that, I\u2019ll cover the GNOME 2 desktop.\nUsing the GNOME 3 Desktop\nThe GNOME 3 desktop offers a radical departure from its GNOME 2. x counterparts. GNOME 2. x \nis serviceable, but GNOME 3 is elegant. With GNOME 3, a Linux desktop now appears more \nlike the graphical interfaces on mobile devices, with less focus on multiple mouse buttons \nand key combinations and more focus on mouse movement and one-click operations.\nInstead of feeling structured and rigid, the GNOME 3 desktop seems to expand as you need \nit to. As a new application is run, its icon is added to the Dash. As you use the next work -\nspace, a new one opens, ready for you to place more applications.\nAfter the computer boots up\nIf you booted up a live image, when you reach the desktop, you are assigned as the Live \nSystem User for your username. For an installed system, you see the login screen, with user \naccounts on the system ready for you to select and enter a password. Log in with the user -\nname and password that you have defined for your system.\nFigure\u00a02.1 is an example of the GNOME 3 desktop screen that appears in Fedora. Press the \nWindows key (or move the mouse cursor to the upper-left corner of the desktop) to toggle \nbetween a blank desktop and the Overview screen.", "doc_id": "655925b4-fcb0-4054-bbe6-fa15a63be5ae", "embedding": null, "doc_hash": "0dee8a9c2fbb99ad8776844964ff5d073b73297f60ab84dce1ca6f3032869fbd", "extra_info": {"page_label": "64"}, "node_info": {"start": 0, "end": 2463}, "relationships": {"1": "31cf824d-caf8-4ab8-8cb4-f112e97917f3"}}, "__type__": "1"}, "d3629797-ef26-4310-a593-baa9553ea709": {"__data__": {"text": "Part I: Getting Started32There is very little on the GNOME 3 desktop when you start out. The top bar has the word \n\u201cActivities\u201d on the left, a clock in the middle, and some icons on the right for such things \nas adjusting audio volume, checking your network connection, and viewing the name of \nthe current user. The Overview screen is where you can select to open applications, active \nwindows, or different workspaces.\nNavigating with the mouse\nTo get started, try navigating the GNOME 3 desktop with your mouse:\n1. Toggle activities and windows . Move your mouse cursor to the upper-left corner \nof the screen near the Activities button. Each time you move there, your screen \nchanges between showing you the windows that you are actively using and a set of \navailable Activities. (This has the same effect as pressing the Windows key.)\n2. Open windows from applications bar . Click to open some applications from the \nDash on the left (Firefox, File Manager, Rhythmbox, or others). Move the mouse to \nthe upper-left corner again, and toggle between showing all active windows min -\nimized (Overview screen) and showing them overlapping (full-sized). Figure\u00a02.2 \nshows an example of the miniature windows view.\n3. Open applications from Applications list . From the Overview screen, select the \nApplication button from the bottom of the left column (the button has nine dots in \na box). The view changes to a set of icons representing the applications installed on \nyour system, as shown in Figure\u00a02.3.\nFIGURE 2.1\nStarting with the GNOME 3 desktop in Fedora.", "doc_id": "d3629797-ef26-4310-a593-baa9553ea709", "embedding": null, "doc_hash": "337026c5ae1d7685bf860e6b06728d9ab54af28417ce1288a2c2bd3c33850313", "extra_info": {"page_label": "65"}, "node_info": {"start": 0, "end": 1561}, "relationships": {"1": "940ee1c9-c6d1-430a-aeb2-3e8f07321b6a"}}, "__type__": "1"}, "5a1d8454-b571-4741-9e20-d8db17748d56": {"__data__": {"text": "Chapter 2: Creating the Perfect Linux Desktop\n33\n2\nFIGURE 2.2\nShow all windows on the desktop minimized.\nFIGURE 2.3\nShow the list of available applications.", "doc_id": "5a1d8454-b571-4741-9e20-d8db17748d56", "embedding": null, "doc_hash": "1c9331e4f16ac3bcf6004451bef67038e6b2c64296d5a7f29ee159bb1458e62d", "extra_info": {"page_label": "66"}, "node_info": {"start": 0, "end": 156}, "relationships": {"1": "2efa351d-3719-4de0-8f4c-82cf333f0f4e"}}, "__type__": "1"}, "89206f4e-1f3d-4560-b86f-e7919533ec1f": {"__data__": {"text": "Part I: Getting Started344. View additional applications . From the Applications screen, you can change the \nview of your applications in several ways, as well as launch them in different ways:\na. Page through . To see icons representing applications that are not onscreen, use \nthe mouse to click dots on the right to page through applications. If you have a \nwheel mouse, you can use that instead to scroll the icons.\nb. Frequent . Select the Frequent button on the bottom of the screen to see often-\nrun applications or the All button to see all applications again.\nc. Launching an application . To start the application you want, left-click its icon \nto open the application in the current workspace. Right-click to open a menu \nthat lets you choose to open a New Window, add or remove the application from \nFavorites (so the application\u2019s icon appears on the Dash), or Show Details about \nthe application. Figure\u00a02.4 shows an example of the menu.\n5. Open additional applications . Start up additional applications. Notice that as you \nopen a new application, an icon representing that application appears in the Dash \nbar on the left. Here are other ways to start applications:\na. Application icon . Click any application icon to open that application.\nb. Drop Dash icons on workspace . From the Windows view, you can drag any \napplication icon from the Dash by pressing and holding the left mouse button \non it and dragging that icon to any of the miniature workspaces on the right.\n6. Use multiple workspaces . Move the mouse to the upper-left corner again to show a \nminimized view of all windows. Notice all of the applications on the right jammed \ninto a small representation of one workspace while an additional workspace is \nempty. Drag and drop a few of the windows to an empty desktop space. Figure\u00a02.5 \nshows what the small workspaces look like. Notice that an additional empty \nFIGURE 2.4\nClick the middle mouse button to display an application\u2019s selection menu.", "doc_id": "89206f4e-1f3d-4560-b86f-e7919533ec1f", "embedding": null, "doc_hash": "cfdc582b7dc1e9a141ac3ad958a8ad9f523480c973b0e2bedc6a0c80ec24bf67", "extra_info": {"page_label": "67"}, "node_info": {"start": 0, "end": 1978}, "relationships": {"1": "bf07e478-238d-4f39-a0a7-3576c19b2c6e"}}, "__type__": "1"}, "46024538-2902-48c2-be0c-7e605af14d68": {"__data__": {"text": "Chapter 2: Creating the Perfect Linux Desktop\n35\n2workspace is created each time the last empty one is used. You can drag and drop \nthe miniature windows to any workspace and then select the workspace to view it.\n7. Use the window menu . Move the mouse to the upper-left corner of the screen to \nreturn to the active workspace (large window view). Right-click the title bar on a \nwindow to view the window menu. Try these actions from that menu:\na. Minimize . Remove window temporarily from view.\nb. Maximize . Expand window to maximum size.\nc. Move . Change window to moving mode. Moving your mouse moves the window. \nClick to fix the window to a spot.\nd. Resize . Change the window to resize mode. Moving your mouse resizes the \nwindow. Click to keep the size.\ne. Workspace selections . Several selections let you use workspaces in different \nways. Select Always on Top to make the current window always on top of other \nwindows in the workspace. Select Always on Visible Workspace to always show \nthe window on the workspace that is visible, or select Move to Workspace Up or \nMove to Workspace Down to move the window to the workspace above or below, \nrespectively.\nIf you don\u2019t feel comfortable navigating GNOME 3 with your mouse, or if you don\u2019t have a \nmouse, the next section helps you navigate the desktop from the keyboard.\nFIGURE 2.5\nAs new desktops are used, additional ones appear on the right.", "doc_id": "46024538-2902-48c2-be0c-7e605af14d68", "embedding": null, "doc_hash": "76542bcac7b9c19e77c0eda6126da1cac5880be723f6998e24d9875aa626736a", "extra_info": {"page_label": "68"}, "node_info": {"start": 0, "end": 1407}, "relationships": {"1": "d312e8d8-f400-4be1-8479-145c93fd4eac"}}, "__type__": "1"}, "3a86a7bf-5060-45d6-a2e7-567a2cf6a70e": {"__data__": {"text": "Part I: Getting Started36Navigating with the keyboard\nIf you prefer to keep your hands on the keyboard, you can work with the GNOME 3 desktop \ndirectly from the keyboard in a number of ways, including the following:\nWindows key . Press the Windows key on the keyboard. On most PC keyboards, this is \nthe key with the Microsoft Windows logo on it next to the Alt key. This toggles the \nmini-window (Overview) and active-window (current workspace) views. Many people \nuse this key often.\nSelect different views . From the Windows or Applications view, hold Ctrl+Alt+Tab to \nsee a menu of the different views (see Figure\u00a02.6). Still holding the Ctrl+Alt keys, \npress Tab again to highlight one of the following icons from the menu and release to \nselect it:\nTop Bar . Highlights the top bar. After it is selected, you can tab between items on \nthat bar (Activities, Calendar, and the Top Bar menu).\nDash. Highlights the first application in the application bar on the left. Use arrow \nkeys to move up and down that menu, and press Enter to open the highlighted \napplication.\nWindows . Selects the Windows view.\nFIGURE 2.6\nPress Ctrl+Alt+Tab to display additional desktop areas to select.", "doc_id": "3a86a7bf-5060-45d6-a2e7-567a2cf6a70e", "embedding": null, "doc_hash": "0d023172f2bfb2db60f114824827f242a3f1f902316d9d1a16cb2452496210d2", "extra_info": {"page_label": "69"}, "node_info": {"start": 0, "end": 1184}, "relationships": {"1": "c20dc0d9-6268-42b9-9f3f-cda9176fedc1"}}, "__type__": "1"}, "849cdc2c-92a1-447e-92f5-811d90aa05d7": {"__data__": {"text": "Chapter 2: Creating the Perfect Linux Desktop\n37\n2Applications . Selects the Applications view.\nSearch . Highlights the search box. Type a few letters to show only icons for appli-\ncations that contain the letters you type. When you have typed enough letters \nto uniquely identify the application you want, press Enter to launch the \napplication.\nSelect an active window . Return to any of your workspaces (press the Windows key if \nyou are not already on an active workspace). Press Alt+Tab to see a list of all active \nwindows (see Figure\u00a02.7). Continue to hold the Alt key as you press the Tab key (or \nright or left arrow keys) to highlight the application that you want from the list of \nactive desktop application windows. If an application has multiple windows open, \npress Alt+` (back-tick, located above the Tab key) to choose among those sub-win -\ndows. Release the Alt key to select it.\nLaunch a command or application . From any active workspace, you can launch a \nLinux command or a graphical application. Here are some examples:\nApplications . From the Overview screen, press Ctrl+Alt+Tab and continue to press \nTab until the Applications icon is highlighted; then release Ctrl+Alt. The Appli-\ncations view appears, with the first icon highlighted. Use the Tab key or arrow \nkeys (up, down, right, and left) to highlight the application icon you want, and \npress Enter.\nCommand box . If you know the name (or part of a name) of a command that you \nwant to run, press Alt+F2 to display a command box. Type the name of the \ncommand that you want to run into the box (try gnome-calculator  to open a cal -\nculator application, for example).\nFIGURE 2.7\nPress Alt+Tab to select which running application to go to.", "doc_id": "849cdc2c-92a1-447e-92f5-811d90aa05d7", "embedding": null, "doc_hash": "ca47c767485bf054f3c20d8830113d2781d2676ab20fc7e806fc12eae883909e", "extra_info": {"page_label": "70"}, "node_info": {"start": 0, "end": 1722}, "relationships": {"1": "9359c0a0-bb1b-4300-841d-c5011befab70"}}, "__type__": "1"}, "ca5b1d49-385e-4f85-ade1-0f15900a63eb": {"__data__": {"text": "Part I: Getting Started38Search box . From the Overview screen, press Ctrl+Alt+Tab and continue to press Tab \nuntil the magnifying glass (Search) icon is highlighted; then release Ctrl+Alt. In \nthe search box now highlighted, type a few letters in an application\u2019s name or \ndescription (type scr  to see what you get). Keep typing until the application you \nwant is highlighted (in this case, Screenshot), and press Enter to launch it.\nDash. From the Overview screen, press Ctrl+Alt+Tab and continue to press Tab until \nthe star (Dash) icon is highlighted; then release Ctrl+Alt. From the Dash, move \nthe up and down arrows to highlight an application that you want to launch and \npress Enter.\nEscape . When you are stuck in an action that you don\u2019t want to complete, try pressing \nthe Esc key. For example, after pressing Alt+F2 (to enter a command), opening an \nicon from the top bar, or going to an overview page, pressing Esc returns you to the \nactive window on the active desktop.\nI hope you now feel comfortable navigating the GNOME 3 desktop. Next, you can try \nrunning some useful and fun desktop applications from GNOME 3.\nSetting up the GNOME 3 desktop\nMuch of what you need GNOME 3 to do for you is set up automatically. However, you need to \nmake a few tweaks to get the desktop the way you want. Most of these setup activities are \navailable from the System Settings window (see Figure\u00a02.8). Open the Settings icon from \nthe Applications list.\nFIGURE 2.8\nChange desktop settings from the System Settings window.", "doc_id": "ca5b1d49-385e-4f85-ade1-0f15900a63eb", "embedding": null, "doc_hash": "2fd2413cd76cb66557ec0349555190032035b4d6de7969d0e923eb160f9f35d3", "extra_info": {"page_label": "71"}, "node_info": {"start": 0, "end": 1525}, "relationships": {"1": "9f010ffb-3286-4b48-bd12-d308b15c4fe0"}}, "__type__": "1"}, "890e256d-faa2-45a0-9afd-8d14090aca03": {"__data__": {"text": "Chapter 2: Creating the Perfect Linux Desktop\n39\n2Here are some suggestions for configuring a GNOME 3 desktop:\nConfigure networking . A wired network connection is often configured automatically \nwhen you boot up your Fedora system. For wireless, you probably have to select \nyour wireless network and add a password when prompted. An icon in the top bar \nlets you do any wired or wireless network configuration that you need to do. Refer \nto Chapter\u00a014, \u201cAdministering Networking,\u201d for further information on configuring \nnetworking.\nBluetooth . If your computer has Bluetooth hardware, you can enable that device to \ncommunicate with other Bluetooth devices (such as a Bluetooth headset or printer).\nDevices . From the Devices screen, you can configure your keyboard, mouse and touch -\npad, printers, removable media, and other settings.\nSound . Click the Sound settings button to adjust sound input and output devices on \nyour system.\nExtending the GNOME 3 desktop\nIf the GNOME 3 shell doesn\u2019t do everything you\u2019d like, don\u2019t despair. You can add extensions \nto provide additional functionality to GNOME 3. Also, a tool called GNOME Tweaks lets you \nchange advanced settings in GNOME 3.\nUsing GNOME shell extensions\nGNOME shell extensions are available to change the way your GNOME desktop looks and \nbehaves. Visit the GNOME Shell Extensions site ( http://extensions.gnome.org ) from \nyour Firefox browser on your GNOME 3 desktop. That site tells you what extensions you \nhave installed and which ones are available for you to install. (You must select to allow the \nsite to see those extensions.)\nBecause the extensions page knows what extensions you have and the version of GNOME 3 \nthat you are running, it can present only those extensions that are compatible with your \nsystem. Many of the extensions help you add back in features from GNOME 2, including the \nfollowing:\nApplications Menu . Adds an Applications menu to the top panel, just as it was \nin GNOME 2.\nPlaces Status Indicator . Adds a systems status menu, similar to the Places menu in \nGNOME 2, to let you navigate quickly to useful folders on your system.\nWindow list . Adds a list of active windows to the top panel, similar to the Window list \nthat appeared on the bottom panel in GNOME 2.\nTo install an extension, simply select the ON button next to the name. Or, you can click the \nextension name from the list to see the extension\u2019s page and click the button on that page \nfrom OFF to ON. Click Install when you are asked if you want to download and install the \nextension. The extension is then added to your desktop.", "doc_id": "890e256d-faa2-45a0-9afd-8d14090aca03", "embedding": null, "doc_hash": "357c18ca9412eb14c8353e062b3b8b5c07aa1e4d1ef13df3f9d77abc0fec85e0", "extra_info": {"page_label": "72"}, "node_info": {"start": 0, "end": 2595}, "relationships": {"1": "e1d83966-80b2-413a-b755-eb25c3b2ac9b"}}, "__type__": "1"}, "ef7d5c7b-70b4-4bc6-b7f0-5b8170f64593": {"__data__": {"text": "Part I: Getting Started40Figure\u00a02.9 shows an example of the Applications menu Window List (showing several active \napplications icons), and Places Status Indicator (with folders displayed from a drop-down \nmenu) extensions installed.\nMore than 100 GNOME shell extensions are available now, and more are being added all the \ntime. Other popular extensions include Notifications Alert (which alerts you of unread mes -\nsages), Presentation Mode (which prevents the screensaver from coming on when you are \ngiving a presentation), and Music Integration (which integrates popular music players into \nGNOME 3, so that you are alerted about songs being played).\nBecause the Extensions site can keep track of your extensions, you can click the Installed \nextensions button at the top of the page and see every extension that is installed. You can \nturn the extensions off and on from there and even delete them permanently.\nUsing the GNOME Tweak Tool\nIf you don\u2019t like the way some of the built-in features of GNOME 3 behave, you can change \nmany of them with the GNOME Tweak Tool. This tool is not installed by default with the \nFedora GNOME Live CD, but you can add it by installing the gnome-tweaks  package. (See \nChapter\u00a010, \u201cGetting and Managing Software,\u201d for information on how to install software \npackages in Fedora.) After installation, the GNOME Tweak Tool is available by launching the \nAdvanced Settings icon from your Applications screen. Start with the Desktop category to \nconsider what you might want to change in GNOME 3. Figure\u00a02.10 shows the Tweak Tool dis -\nplaying Appearance settings.\nFIGURE 2.9\nExtensions add features to the GNOME 3 desktop.", "doc_id": "ef7d5c7b-70b4-4bc6-b7f0-5b8170f64593", "embedding": null, "doc_hash": "5537dc9d732b4973c5fb4b914da3e965f32ddf9583893dfa2eb33f6476c258f9", "extra_info": {"page_label": "73"}, "node_info": {"start": 0, "end": 1660}, "relationships": {"1": "3fdf4850-6dcb-4dd1-a0aa-29d56b223799"}}, "__type__": "1"}, "704d61e8-16ec-4b8d-bd50-0f41c875f7d3": {"__data__": {"text": "Chapter 2: Creating the Perfect Linux Desktop\n41\n2If fonts are too small for you, select the Fonts category and click the plus sign next to the \nScaling Factor box to increase the font size, or change fonts individually for documents, \nwindow titles, or monospace fonts.\nUnder Top Bar settings, you can change how clock information is displayed in the top bar \nor set whether to show the week number in the calendar. To change the look of the desk -\ntop, select the Appearance category and change the Icons theme and GTK+ theme as you \nlike from drop-down boxes.\nStarting with desktop applications\nThe Fedora GNOME 3 desktop live DVD comes with some cool applications that you can start \nusing immediately. To use GNOME 3 as your everyday desktop, you should install it perma -\nnently to your computer\u2019s hard disk and add the applications you need (a word processor, \nimage editor, drawing application, and so on). If you are just getting started, the following \nsections list some cool applications to try out.\nFIGURE 2.10\nChange desktop settings using the GNOME Tweak Tool (Appearance settings).", "doc_id": "704d61e8-16ec-4b8d-bd50-0f41c875f7d3", "embedding": null, "doc_hash": "f8e144a42e5fddf624b8e1b1da66c46f9cc55e598655a5d80dc5a00e49d3023a", "extra_info": {"page_label": "74"}, "node_info": {"start": 0, "end": 1097}, "relationships": {"1": "4d11d444-d350-46a4-a077-b2c5cca495c2"}}, "__type__": "1"}, "ad2cd4b7-686e-46c6-96c5-278508bb4e27": {"__data__": {"text": "Part I: Getting Started42Managing files and folders with Nautilus\nTo move, copy, delete, rename, and otherwise organize files and folders in GNOME 3, you \ncan use the Nautilus file manager. Nautilus comes with the GNOME desktop and works like \nother file managers that you may use in Windows or Mac.\nTo open Nautilus, click the Files icon from the GNOME Dash or Applications list. Your user \naccount starts with a set of folders designed to hold the most common types of content: \nMusic, Pictures, Videos, and the like. These are all stored in what is referred to as your \nHome directory. Figure\u00a02.11 shows Nautilus open to a Home directory.\nWhen you want to save files that you downloaded from the Internet or created with a word \nprocessor, you can organize them into these folders. You can create new folders as needed, \ndrag and drop files and folders to copy and move them, and delete them.\nBecause Nautilus is not much different from most file managers that you have used on \nother computer systems, this chapter does not go into detail about how to use drag-and-\ndrop and traverse folders to find your content. However, I do want to make a few observa -\ntions that may not be obvious about how to use Nautilus:\nHome folder You have complete control over the files and folders that you create in \nyour Home folder. Most other parts of the filesystem are not accessible to you as a \nregular user.\nFilesystem organization  Although it appears under the name Home, your Home \nfolder is actually located in the filesystem under the /home  folder in a folder named \nFIGURE 2.11\nManage files and folders from the Nautilus window.", "doc_id": "ad2cd4b7-686e-46c6-96c5-278508bb4e27", "embedding": null, "doc_hash": "5ac1562075b835edd8729a6142da1d272392c2b5f6cdae40fabd0797b242f8e9", "extra_info": {"page_label": "75"}, "node_info": {"start": 0, "end": 1629}, "relationships": {"1": "0e821136-d2a5-4739-87c7-85f0569d0248"}}, "__type__": "1"}, "145bf9ea-bd38-4be9-8529-426120ee7e55": {"__data__": {"text": "Chapter 2: Creating the Perfect Linux Desktop\n43\n2after your username: for example, /home/liveuser  or /home/chris . In the next \nfew chapters, you learn how the filesystem is organized (especially in relation to the \nLinux command shell).\nWorking with files and folders Right-click a file or folder icon to see how you can \nact on it. For example, you can copy, cut, move to trash (delete), or open any file or \nfolder icon.\nCreating folders To create a new folder, right-click in a folder window and select New \nFolder. Type the new folder name over the highlighted Untitled Folder, and press \nEnter to name the folder.\nAccessing remote content  Nautilus can display content from remote servers as well \nas the local filesystem. In Nautilus, select Other Locations from the file menu. From \nthe Connect to Server box that appears, you can connect to a remote server via SSH \n(secure shell), FTP with login, Public FTP, Windows share, WebDav (HTTP), or Secure \nWebDav (HTTPS). Add appropriate user and password information as needed, and \nthe content of the remote server appears in the Nautilus window. Figure\u00a02.12 shows \nan example of a Nautilus window prompting you for a password to log into a remote \nserver over SSH protocol ( ssh://192.168.122.81 ).\nInstalling and managing additional software\nThe Fedora Live Desktop comes with a web browser (Firefox), a file manager (Nautilus), and \na few other common applications. However, there are many other useful applications that, \nbecause of their size, just wouldn\u2019t fit on a live CD. If you install the live Fedora Worksta -\ntion to your hard disk (as described in Chapter\u00a09), you almost certainly will want to add \nsome more software.\nFIGURE 2.12\nAccess remote folders using the Nautilus Connect to Server feature.", "doc_id": "145bf9ea-bd38-4be9-8529-426120ee7e55", "embedding": null, "doc_hash": "94049d3ac1b7cbba825a8600e18306b08abb081b6406e2b70362944087d899a3", "extra_info": {"page_label": "76"}, "node_info": {"start": 0, "end": 1770}, "relationships": {"1": "c6356939-17c5-4d79-b5ed-5595f769c38d"}}, "__type__": "1"}, "1ccf5faa-e80a-49ad-a9db-dbd35603a999": {"__data__": {"text": "Part I: Getting Started44Note\nYou can try installing software if you are running the live medium. However, keep in mind that because writeable \nspace on a live medium uses virtual memory (RAM), that space is limited and can easily run out. Also, when you \nreboot your system, anything that you install disappears.\nWhen Fedora is installed, it is automatically configured to connect your system to the huge \nFedora software repository that is available on the Internet. As long as you have an Inter -\nnet connection, you can run the Add/Remove software tool to download and install any of \nthousands of Fedora packages.\nAlthough the entire facility for managing software in Fedora (the yum  and rpm  features) is \ndescribed in detail in Chapter\u00a010, you can start installing some software packages without \nknowing much about how the feature works. Begin by going to the applications screen and \nopening the Software window. Figure 2.13 shows an example of the Software window.\nWith the Software window open, you can select the applications that you want to install by \nsearching (type the name into the Find box) or choosing a category. Each category offers \npackages sorted by subcategories and featured packages in that category. \nSelect the spyglass icon in the upper-left corner, and then type a word associated with the \nsoftware package that you want to install. You can read a description of each package that \ncomes up in your search. When you are ready, click Install to install the package and any \ndependent packages needed to make it work.\nFIGURE 2.13\nDownload and install software from the huge Fedora repository.", "doc_id": "1ccf5faa-e80a-49ad-a9db-dbd35603a999", "embedding": null, "doc_hash": "3839d5f73794da3c1c40c7e70b1d2a879fb1cf11164c16e27cbdb0cab83786a8", "extra_info": {"page_label": "77"}, "node_info": {"start": 0, "end": 1625}, "relationships": {"1": "06463ff4-1428-466d-827b-32dba89abc5d"}}, "__type__": "1"}, "9b15b938-07d6-4ad0-9663-c79169d40ba9": {"__data__": {"text": "Chapter 2: Creating the Perfect Linux Desktop\n45\n2By searching for and installing some common desktop applications, you should be able to \nstart using your desktop effectively. Refer to Chapter\u00a010 for details on how to add software \nrepositories and use dnf , yum , and rpm  commands to manage software in Fedora and Red \nHat Enterprise Linux.\nPlaying music with Rhythmbox\nRhythmbox is the music player that comes on the Fedora GNOME Live Desktop. You can \nlaunch Rhythmbox from the GNOME 3 Dash and immediately play music CDs, podcasts, or \nInternet radio shows. You can import audio files in WAV and Ogg Vorbis formats or add plug-\nins for MP3 or other audio formats.\nFigure\u00a02.14 shows an example of the Rhythmbox window with music playing from an \nimported audio library.\nFIGURE 2.14\nPlay music, podcasts, and Internet radio from Rhythmbox.", "doc_id": "9b15b938-07d6-4ad0-9663-c79169d40ba9", "embedding": null, "doc_hash": "b87ed439f6710682e81d4bb9ee8a46a89aa84fadd2c5b2c8f5b7cf7a1295fc6e", "extra_info": {"page_label": "78"}, "node_info": {"start": 0, "end": 843}, "relationships": {"1": "ff858135-bbde-49f4-8c8a-1b4ef8be8571"}}, "__type__": "1"}, "9a62de42-46f5-4058-8608-d340f10d81d0": {"__data__": {"text": "Part I: Getting Started46Here are a few ways that you can get started with Rhythmbox:\nRadio  Double-click the Radio selection under Library and choose a radio station from \nthe list that appears to the right.\nPodcasts  Search for podcasts on the Internet and find the URL for one that inter -\nests you. Right-click the Podcasts entry and select New Podcast Feed. Paste or type \nin the URL to the podcast and click Add. A list of podcasts from the site that you \nselected appears to the right. Double-click the one to which you want to listen.\nAudio CDs  Insert an audio CD, and press Play when it appears in the Rhythmbox \nwindow. Rhythmbox also lets you rip and burn audio CDs.\nAudio files  Rhythmbox can play WAV and Ogg Vorbis files. By adding plug-ins, you \ncan play many other audio formats, including MP3. Because there are patent issues \nrelated to the MP3 format, the ability to play MP3s is not included with Fedora. In \nChapter\u00a010, I describe how to get software that you need that is not in the reposi-\ntory of your Linux distribution.\nPlug-ins are available for Rhythmbox to get cover art, show information about artists \nand songs, add support for music services (such as Last.fm and Magnatune), and fetch \nsong lyrics.\nStopping the GNOME 3 desktop\nWhen you are finished with your GNOME 3 session, select the down arrow button in the \nupper-right corner of the top bar. From there, you can choose the On/Off button, which \nallows you to log out or switch to a different user account without logging out.\nUsing the GNOME 2 Desktop\nThe GNOME 2 desktop is the default desktop interface used up through Red Hat Enterprise \nLinux 6. It is well-known, stable, and perhaps a bit boring.\nGNOME 2 desktops provide the more standard menus, panels, icons, and workspaces. If you \nare using a Red Hat Enterprise Linux system up to RHEL 6, or an older Fedora or Ubuntu \ndistribution, you are probably looking at a GNOME 2 desktop. I will now provide a tour of \nGNOME 2, along with some opportunities for sprucing it up a bit. GNOME 2 releases include \n3D effects (see \u201cAdding 3D effects with AIGLX\u201d later in this chapter).\nTo use your GNOME desktop, you should become familiar with the following components:\nMetacity (window manager) The default window manager for GNOME 2 is Metacity. \nMetacity configuration options let you control such things as themes, window bor -\nders, and controls used on your desktop.\nCompiz (window manager) You can enable this window manager in GNOME to pro -\nvide 3D desktop effects.\nNautilus (file manager/graphical shell) When you open a folder (by double-\nclicking the Home icon on your desktop, for example), the Nautilus window opens ", "doc_id": "9a62de42-46f5-4058-8608-d340f10d81d0", "embedding": null, "doc_hash": "645315ef0119091ae66f83deae67656a23d2dd3b663026b1c1b8f7a663428611", "extra_info": {"page_label": "79"}, "node_info": {"start": 0, "end": 2668}, "relationships": {"1": "2f43b949-148f-4471-8d7a-a579926f65a9"}}, "__type__": "1"}, "42644151-95f5-4e6f-8ed3-ad52c00de26a": {"__data__": {"text": "Chapter 2: Creating the Perfect Linux Desktop\n47\n2and displays the contents of the selected folder. Nautilus can also display other \ntypes of content, such as shared folders from Windows computers on the network \n(using SMB).\nGNOME panels (application/task launcher) These panels, which line the top and \nbottom of your screen, are designed to make it convenient for you to launch the \napplications you use, manage running applications, and work with multiple virtual \ndesktops. By default, the top panel contains menu buttons (Applications, Places, \nand System), desktop application launchers (Evolution email and Firefox web \nbrowser), a workspace switcher (for managing four virtual desktops), and a clock. \nIcons appear in the panel when you need software updates or SELinux detects a \nproblem. The bottom panel has a Show Desktop button, window lists, a trash can, \nand workspace switcher.\nDesktop area The windows and icons you use are arranged on the desktop area, \nwhich supports drag-and-drop between applications, a desktop menu (right-click \nto see it), and icons for launching applications. A Computer icon consolidates CD \ndrives, floppy drives, the filesystem, and shared network resources in one place.\nGNOME also includes a set of Preferences windows that enable you to configure different \naspects of your desktop. You can change backgrounds, colors, fonts, keyboard shortcuts, \nand other features related to the look and behavior of the desktop. Figure\u00a02.15 shows how \nthe GNOME 2 desktop environment appears the first time you log in, with a few windows \nadded to the screen.\nFIGURE 2.15\nThe GNOME 2 desktop environment", "doc_id": "42644151-95f5-4e6f-8ed3-ad52c00de26a", "embedding": null, "doc_hash": "f60ed213b4f9ba051eec793a5ef1712bb94fcb3f1c51f94b8c99627f51dc259b", "extra_info": {"page_label": "80"}, "node_info": {"start": 0, "end": 1638}, "relationships": {"1": "a698474b-5e04-40e1-85a9-e96d6484439d"}}, "__type__": "1"}, "52b692c9-0491-4525-86bc-540affb584fa": {"__data__": {"text": "Part I: Getting Started48The desktop shown in Figure\u00a02.15 is for Red Hat Enterprise Linux. The following sections \nprovide details on using the GNOME 2 desktop.\nUsing the Metacity window manager\nThe Metacity window manager seems to have been chosen as the default window manager \nfor GNOME because of its simplicity. The creator of Metacity refers to it as a \u201cboring window \nmanager for the adult in you\u201d and then goes on to compare other window managers to col -\norful, sugary cereal, whereas Metacity is characterized as Cheerios.\nNote\nTo use 3D effects, your best solution is to use the Compiz window manager, described later in this chapter. You can\u2019t \ndo much with Metacity (except get your work done efficiently). You assign new themes to Metacity and change colors \nand window decorations through the GNOME preferences (described later).\nBasic Metacity functions that might interest you are keyboard shortcuts and the workspace \nswitcher. Table\u00a02.1 shows keyboard shortcuts to get around the Metacity window manager.\nYou can use other keyboard shortcuts with the window manager as well. Select System \u27aa \nPreferences \u27aa Keyboard Shortcuts to see a list of shortcuts, such as the following:\nRun Dialog  To run a command to launch an application from the desktop by \ncommand name, press Alt+F2. From the dialog box that appears, type the command \nand press Enter. For example, type gedit  to run a simple graphical text editor.\nLock Screen If you want to step away from your screen and lock it, press Ctrl+Alt+L. \nYou need to type your user password to open the screen again.\nShow Main Menu To open an application from the Applications, Places, or System \nmenu, press Alt+F1. Then use the up and down arrow keys to select from the current \nmenu or use the right and left arrow keys to select from other menus.\nPrint Screen Press the Print Screen key to take a picture of the entire desktop. Press \nAlt+Print Screen to take a picture of the current window.TABLE 2.1  Keyboard Shortcuts\nActions Keystrokes\nCycle backward, without pop-up icons Alt+Shift+Esc\nCycle backward among panels Alt+Ctrl+Shift+Tab\nClose menu Esc", "doc_id": "52b692c9-0491-4525-86bc-540affb584fa", "embedding": null, "doc_hash": "9d7447df42a42e9c99c7ef82f1f1cec669e03ab93c79166b9ad7ce6e767190ba", "extra_info": {"page_label": "81"}, "node_info": {"start": 0, "end": 2119}, "relationships": {"1": "da8f3218-cf74-4160-9c1b-5d8203861969"}}, "__type__": "1"}, "a5da3c12-cefd-4820-9843-095e4b3f9174": {"__data__": {"text": "Chapter 2: Creating the Perfect Linux Desktop\n49\n2Another Metacity feature of interest is the workspace switcher. Four virtual workspaces \nappear in the workspace switcher on the GNOME 2 panel. You can do the following with the \nWorkspace Switcher:\nChoose current workspace Four virtual workspaces appear in the workspace \nswitcher. Click any of the four virtual workspaces to make it your current \nworkspace.\nMove windows to other workspaces Click any window, each represented by a tiny \nrectangle in a workspace, to drag and drop it to another workspace. Likewise, you \ncan drag an application from the Window list to move that application to another \nworkspace.\nAdd more workspaces Right-click the Workspace Switcher and select Preferences. \nYou can add workspaces (up to 32).\nName workspaces  Right-click the Workspace Switcher and select Preferences. Click in \nthe Workspaces pane to change names of workspaces to any names you choose.\nYou can view and change information about Metacity controls and settings using the \ngconf-editor  window (type gconf-editor  from a Terminal window). As the window \nsays, it is not the recommended way to change preferences, so when possible, you should \nchange the desktop through GNOME 2 preferences. However, gconf-editor  is a good way \nto see descriptions of each Metacity feature.\nFrom the gconf-editor  window, select apps \u27aa metacity, and choose from general, global_\nkeybindings, keybindings_commands, window_keybindings, and workspace_names. Click \neach key to see its value, along with short and long descriptions of the key.\nChanging GNOME\u2019s appearance\nYou can change the general look of your GNOME desktop by selecting System \u27aa Preferences \n\u27aa Appearance. From the Appearance Preferences window, select from three tabs:\nTheme  Entire themes are available for the GNOME 2 desktop that change the colors, \nicons, fonts, and other aspects of the desktop. Several different themes come with \nthe GNOME desktop, which you can simply select from this tab to use. Or click \u201cGet \nmore themes online\u201d to choose from a variety of available themes.\nBackground  To change your desktop background, select from a list of backgrounds \non this tab to have the one you choose immediately take effect. To add a different \nbackground, put the background you want on your system (perhaps download one \nby selecting \u201cGet more backgrounds online\u201d and downloading it to your Pictures \nfolder). Then click Add and select the image from your Pictures folder.\nFonts Different fonts can be selected to use by default with your applications, docu -\nments, desktop, window title bar, and for fixed width.", "doc_id": "a5da3c12-cefd-4820-9843-095e4b3f9174", "embedding": null, "doc_hash": "7f4eeb157b985377dcb91e5987b0cdbcca9ac6fc65a6e9eaa2d4eaba5911b583", "extra_info": {"page_label": "82"}, "node_info": {"start": 0, "end": 2626}, "relationships": {"1": "43f00195-60dd-4633-9dca-76186edcb5ae"}}, "__type__": "1"}, "4c320d49-b781-44a0-bbd9-fb081f4766cd": {"__data__": {"text": "Part I: Getting Started50Using the GNOME panels\nThe GNOME panels are placed on the top and bottom of the GNOME desktop. From those \npanels, you can start applications (from buttons or menus), see what programs are active, \nand monitor how your system is running. You can also change the top and bottom panels in \nmany ways\u2014by adding applications or monitors or by changing the placement or behavior \nof the panel, for example.\nRight-click any open space on either panel to see the Panel menu. Figure\u00a02.16 shows the \nPanel menu on the top.\nFrom GNOME\u2019s Panel menu, you can choose from a variety of functions, including these:\nUse the menus :\n\u25a0\u25a0The Applications menu displays most of the applications and system tools that you \nwill use from the desktop.\n\u25a0\u25a0The Places menu lets you select places to go, such as the Desktop folder, Home \nfolder, removable media, or network locations.\n\u25a0\u25a0The System menu lets you change preferences and system settings as well as get \nother information about GNOME.\nAdd to Panel . Add an applet, menu, launcher, drawer, or button.\nProperties . Change the panel\u2019s position, size, and background properties.\nDelete This Panel . Delete the current panel.\nNew Panel . Add panels to your desktop in different styles and locations.\nYou can also work with items on a panel. For example, you can do the following:\nMove items . To move an item on a panel, right-click it, select Move, and drag and drop \nit to a new position.\nFIGURE 2.16\nThe GNOME Panel menu", "doc_id": "4c320d49-b781-44a0-bbd9-fb081f4766cd", "embedding": null, "doc_hash": "3c5f5670c61e42f016972cfd04f24b03c686030afd4087162a28de8a4de4a10c", "extra_info": {"page_label": "83"}, "node_info": {"start": 0, "end": 1478}, "relationships": {"1": "f18a417d-ec4d-4851-8e98-61bf8fb3c057"}}, "__type__": "1"}, "56b5413a-3aad-4e3b-8ef3-b0aed325dc2a": {"__data__": {"text": "Chapter 2: Creating the Perfect Linux Desktop\n51\n2Resize items . You can resize some elements, such as the Window list, by clicking an \nedge and dragging it to the new size.\nUse the Window list . Tasks running on the desktop appear in the Window list area. \nClick a task to minimize or maximize it.\nThe following sections describe some things that you can do with the GNOME panel.\nUsing the Applications and System menus\nClick Applications on the panel and you see categories of applications and system tools that \nyou can select. Click the application that you want to launch. To add an item from a menu \nso that it can launch from the panel, drag and drop the item that you want to the panel.\nYou can add items to your GNOME 2 menus. To do that, right-click any of the menu names \nand select Edit Menus. The window that appears lets you add or delete menus associated \nwith the Applications and System menus. You can also add items to launch from those \nmenus by selecting New Item and typing the name, command, and comment for the item.\nAdding an applet\nYou can run several small applications, called applets , directly on the GNOME panel. These \napplications can show information that you may want to see on an ongoing basis or may \njust provide some amusement. To see what applets are available and to add applets that you \nwant to your panel, follow these steps:\n1. Right-click an open space in the panel so that the Panel menu appears .\n2. Click Add to Panel . An Add to Panel window appears.\n3. Select from among several dozen applets, including a clock, dictionary lookup, \nstock ticker, and weather report . The applet you select appears on the panel, \nready for you to use.\nFigure\u00a02.17 shows (from left to right) eyes, system monitor, weather report, terminal, and \nWanda the fish.\nAfter an applet is installed, right-click it on the panel to see what options are available. \nFor example, select Preferences for the stock ticker and you can add or delete stocks whose \nprices you want to monitor. If you don\u2019t like the applet\u2019s location, right-click it, click Move, \nslide the mouse until the applet is where you want it (even to another panel), and click to \nset its location.\nFIGURE 2.17\nPlacing applets on the panel makes accessing them easy.", "doc_id": "56b5413a-3aad-4e3b-8ef3-b0aed325dc2a", "embedding": null, "doc_hash": "10ea7fec615577ea7d60218c9e3b85634e513763445bb8836526b9c6153683da", "extra_info": {"page_label": "84"}, "node_info": {"start": 0, "end": 2256}, "relationships": {"1": "dafdc982-4db5-4582-af55-d929d003ddc6"}}, "__type__": "1"}, "90f9b884-5c4c-4259-8bb2-2328115cd409": {"__data__": {"text": "Part I: Getting Started52If you no longer want an applet to appear on the panel, right-click it, and click Remove \nFrom Panel. The icon representing the applet disappears. If you find that you have run out \nof room on your panel, you can add a new panel to another part of the screen, as described \nin the next section.\nAdding another panel\nIf you run out of space on the top or bottom panels, you can add more panels to your desk -\ntop. You can have several panels on your GNOME 2 desktop. You can add panels that run \nalong the entire bottom, top, or side of the screen. To add a panel, follow these steps:\n1. Right-click an open space in the panel so that the Panel menu appears .\n2. Click New Panel . A new panel appears on the side of the screen.\n3. Right-click an open space in the new panel and select Properties .\n4. From the Panel Properties, select where you want the panel from the Orienta -\ntion box (Top, Bottom, Left, or Right).\nAfter you\u2019ve added a panel, you can add applets or application launchers to it as you did \nwith the default panel. To remove a panel, right-click it and select Delete This Panel.\nAdding an application launcher\nIcons on your panel represent a web browser and several office productivity applications. \nYou can add your own icons to launch applications from the panel as well. To add a new \napplication launcher to the panel, follow these steps:\n1. Right-click in an open space on the panel .\n2. Click Add to Panel \u27aa Application Launcher from the menu . All application cate -\ngories from your Applications and System menus appear.\n3. Select the arrow next to the category of application you want, and then select \nAdd. An icon representing the application appears on the panel.\nTo launch the application that you just added, simply click the icon on the panel.\nIf the application that you want to launch is not on one of your menus, you can build a \nlauncher yourself as follows:\n1. Right-click in an open space on the panel .\n2. Click Add to Panel \u27aa Custom Application Launcher \u27aa Add . The Create Launcher \nwindow appears.\n3. Provide the following information for the application you want to add :\na. Type. Select Application (to launch a regular GUI application) or Application \nin Terminal. Use Application in Terminal if the application is a character-based \nor ncurses application. (Applications written using the ncurses library run in a \nTerminal window but offer screen-oriented mouse and keyboard controls.)", "doc_id": "90f9b884-5c4c-4259-8bb2-2328115cd409", "embedding": null, "doc_hash": "20d64a70a79eb4546fcf741ec45187b9ff66d02b2a3c328ff7ce610ea14df400", "extra_info": {"page_label": "85"}, "node_info": {"start": 0, "end": 2458}, "relationships": {"1": "7c75f5d2-2355-4287-8160-3cc09f95da25"}}, "__type__": "1"}, "cc5d295c-481e-4981-a523-21bfc9e5fa72": {"__data__": {"text": "Chapter 2: Creating the Perfect Linux Desktop\n53\n2b. Name . Choose a name to identify the application. (This appears in the tooltip \nwhen your mouse is over the icon.)\nc. Command. This identifies the command line that is run when the application is \nlaunched. Use the full pathname, plus any required options.\nd. Comment . Enter a comment describing the application. It also appears when \nyou later move your mouse over the launcher.\n4. Click the Icon box (it might say No Icon), select one of the icons shown, and \nclick OK . Alternatively, you can browse your filesystem to choose an icon.\n5. Click OK .\nThe application should now appear in the panel. Click it to start the application.\nNote\nIcons available to represent your application are contained in the /usr/share/pixmaps  directory. These icons \nare either in PNG or XPM format. If there isn\u2019t an icon in the directory that you want to use, create your own (in one of \nthose two formats) and assign it to the application.\nAdding a drawer\nA drawer  is an icon that you can click to display other icons representing menus, applets, \nand launchers; it behaves just like a panel. Essentially, any item that you can add to a \npanel you can add to a drawer. By adding a drawer to your GNOME panel, you can include \nseveral applets and launchers that together take up the space of only one icon. Click the \ndrawer to show the applets and launchers as if they were being pulled out of a drawer icon \non the panel.\nTo add a drawer to your panel, right-click the panel and select Add to Panel \u27aa Drawer. A \ndrawer appears on the panel. Right-click it and add applets or launchers to it as you would \nto a panel. Click the icon again to retract the drawer.\nFigure\u00a02.18 shows a portion of the panel with an open drawer that includes an icon for \nlaunching a weather report, sticky notes, and stock monitor.\nFIGURE 2.18\nAdd launchers or applets to a drawer on your GNOME 2 panel.", "doc_id": "cc5d295c-481e-4981-a523-21bfc9e5fa72", "embedding": null, "doc_hash": "9413a948e283fa25b77e5ed302ae28500c8cff8bd083945441727db5b0af4dc2", "extra_info": {"page_label": "86"}, "node_info": {"start": 0, "end": 1924}, "relationships": {"1": "17e3e098-7cf2-4a0a-abe8-6282aef059cf"}}, "__type__": "1"}, "7b488069-ffd0-4979-8b3e-d6936284158c": {"__data__": {"text": "Part I: Getting Started54Changing panel properties\nYou can change the orientation, size, hiding policy, and background properties of your \ndesktop panels. To open the Panel Properties window that applies to a specific panel, right-\nclick an open space on the panel and choose Properties. The Panel Properties window that \nappears includes the following values:\nOrientation  Move the panel to a different location on the screen by clicking a \nnew position.\nSize Select the size of your panel by choosing its height in pixels (48 pixels \nby default).\nExpand \u00a0Select this check box to have the panel expand to fill the entire side or clear \nthe check box to make the panel only as wide as the applets it contains.\nAutoHide  Select whether a panel is automatically hidden (appearing only when the \nmouse pointer is in the area).\nShow Hide buttons Choose whether the Hide/Unhide buttons (with pixmap arrows \non them) appear on the edges of the panel.\nArrows on Hide buttons If you select Show Hide Buttons, you can choose to have \narrows on those buttons.\nBackground  From the Background tab, you can assign a color to the background of \nthe panel, assign a pixmap image, or just leave the default (which is based on the \ncurrent system theme). Click the Background Image check box if you want to select \nan Image for the background, and then select an image, such as a tile from /usr/\nshare/backgrounds/tiles  or another directory.\ntip\nI usually turn on the AutoHide feature and turn off the Hide buttons. Using AutoHide gives you more desktop space \nwith which you can work. When you move your mouse to the edge where the panel is located, the panel pops up\u2014so \nyou don\u2019t need Hide buttons.\nAdding 3D effects with AIGLX\nSeveral initiatives have made strides in recent years to bring 3D desktop effects to Linux. \nUbuntu, openSUSE, and Fedora used AIGLX ( https://fedoraproject.org/wiki/  \nRenderingProject/aiglx ).\nThe goal of the Accelerated Indirect GLX project (AIGLX) is to add 3D effects to everyday \ndesktop systems. It does this by implementing OpenGL ( http://opengl.org ) accelerated \neffects using the Mesa ( http://www.mesa3d.org ) open source OpenGL implementation.\nCurrently, AIGLX supports a limited set of video cards and implements only a few 3D \neffects, but it does offer some insight into the eye candy that is in the works.\nIf your video card was properly detected and configured, you may be able simply to turn \non the Desktop Effects feature to see the effects that have been implemented so far. To ", "doc_id": "7b488069-ffd0-4979-8b3e-d6936284158c", "embedding": null, "doc_hash": "769bfe25043ae7868ded473d0cfb8f61e41fc02e63ab3b7bf0b70048b871616b", "extra_info": {"page_label": "87"}, "node_info": {"start": 0, "end": 2518}, "relationships": {"1": "57e06875-98ac-470d-aa88-7af7053a1e78"}}, "__type__": "1"}, "e876464b-a92d-4655-a04e-0d795a6a5198": {"__data__": {"text": "Chapter 2: Creating the Perfect Linux Desktop\n55\n2turn on Desktop Effects, select System \u27aa Preferences \u27aa Desktop Effects. When the Desktop \nEffects window appears, select Compiz. (If the selection is not available, install the com-\npiz package.)\nEnabling Compiz does the following:\nStarts Compiz Stops the current window manager and starts the Compiz \nwindow manager.\nEnables the Windows Wobble When Moved effect With this effect on, when you \ngrab the title bar of the window to move it, the window wobbles as it moves. Menus \nand other items that open on the desktop also wobble.\nEnables the Workspaces on a Cube effect Drag a window from the desktop to the \nright or the left, and the desktop rotates like a cube, with each of your desktop \nworkspaces appearing as a side of that cube. Drop the window on the workspace \nwhere you want it to go. You can also click the Workspace Switcher applet in the \nbottom panel to rotate the cube to display different workspaces.\nOther nice desktop effects result from using the Alt+Tab keys to tab among different \nrunning windows. As you press Alt+Tab, a thumbnail of each window scrolls across the \nscreen as the window it represents is highlighted.\nFigure\u00a02.19 shows an example of a Compiz desktop with AIGLX enabled. The figure illus -\ntrates a web browser window being moved from one workspace to another as those work -\nspaces rotate on a cube.\nFIGURE 2.19\nRotate workspaces on a cube with AIGLX desktop effects enabled.", "doc_id": "e876464b-a92d-4655-a04e-0d795a6a5198", "embedding": null, "doc_hash": "1d5b255cdd64ca6c828dfb62b618f231465cb6197e868aeb59ba73f16aff26e4", "extra_info": {"page_label": "88"}, "node_info": {"start": 0, "end": 1467}, "relationships": {"1": "8b259ffc-b866-4844-ba2b-f19cbf73809d"}}, "__type__": "1"}, "61da4309-2e75-423c-8f33-bd30fad41a1d": {"__data__": {"text": "Part I: Getting Started56The following are some interesting effects that you can get with your 3D AIGLX desktop:\nSpin cube  Hold Ctrl+Alt keys and press the right and left arrow keys. The desktop \ncube spins to each successive workspace (forward or back).\nSlowly rotate cube Hold the Ctrl+Alt keys, press and hold the left mouse button, \nand move the mouse around on the screen. The cube moves slowly with the mouse \namong the workspaces.\nScale and separate windows  If your desktop is cluttered, hold Ctrl+Alt and press \nthe up arrow key. Windows shrink down and separate on the desktop. Still holding \nCtrl+Alt, use your arrow keys to highlight the window you want and release the keys \nto have that window come to the surface.\nTab through windows  Hold the Alt key and press the Tab key. You will see reduced \nversions of all your windows in a strip in the middle of your screen, with the \ncurrent window highlighted in the middle. Still holding the Alt key, press Tab or \nShift+Tab to move forward or backward through the windows. Release the keys when \nthe one you want is highlighted.\nScale and separate workspaces  Hold Ctrl+Alt and press the down arrow key to see \nreduced images of the workspace shown on a strip. Still holding Ctrl+Alt, use the \nright and left arrow keys to move among the different workspaces. Release the keys \nwhen the workspace you want is highlighted.\nSend current window to next workspace Hold Ctrl+Alt+Shift keys together and \npress the left and right arrow keys. The next workspace to the left or right, respec -\ntively, appears on the current desktop.\nSlide windows around Press and hold the left mouse button on the window title bar, \nand then press the left, right, up, or down arrow key to slide the current window \naround on the screen.\nIf you get tired of wobbling windows and spinning cubes, you can easily turn off the AIGLX \n3D effects and return to using Metacity as the window manager. Select System \u27aa Prefer -\nences \u27aa Desktop Effects again, and toggle off the Enable Desktop Effects button to turn off \nthe feature.\nIf you have a supported video card but find that you cannot turn on the Desktop Effects, \ncheck that your X server started properly. In particular, make sure that your /etc/X11/\nxorg.conf  file is properly configured. Make sure that dri  and glx  are loaded in the \nModule section. Also, add an extensions section anywhere in the file (typically at the end \nof the file) that appears as follows:\nSection \"extensions\"\n Option \"Composite\"\nEndSection", "doc_id": "61da4309-2e75-423c-8f33-bd30fad41a1d", "embedding": null, "doc_hash": "91499743d44448771182e21257bc9257b5be34fdb0f38feb24067a82d84d154b", "extra_info": {"page_label": "89"}, "node_info": {"start": 0, "end": 2510}, "relationships": {"1": "10b2b03f-3dc0-435e-84ea-3f27fa1e7f35"}}, "__type__": "1"}, "27fd9ba2-9cc7-4831-b38e-d522e8e27d40": {"__data__": {"text": "Chapter 2: Creating the Perfect Linux Desktop\n57\n2Another option is to add the following line to the /etc/X11/xorg.conf  file in the \nDevice section:\nOption \"XAANoOffscreenPixmaps\"\nThe XAANoOffscreenPixmaps  option improves performance. Check your /var/log/\nXorg.log  file to make sure that DRI and AIGLX features were started correctly. The mes -\nsages in that file can help you debug other problems as well.\nSummary\nThe GNOME desktop environment has become the default desktop environment for many \nLinux systems, including Fedora and RHEL. The GNOME 3 desktop (now used in Fedora and \nRHEL 7 and RHEL 8) is a modern, elegant desktop, designed to match the types of inter -\nfaces available on many of today\u2019s mobile devices. The GNOME 2 desktop (used through \nRHEL 6) provides a more traditional desktop experience.\nBesides GNOME desktops, you can try out other popular and useful desktop environments. \nThe K Desktop Environment (KDE) offers many more bells and whistles than GNOME, and it \nis used by default in several Linux distributions. Netbooks and live CD distributions some -\ntimes use the LXDE or Xfce desktops.\nNow that you have a grasp of how to get and use a Linux desktop, it\u2019s time to start digging \ninto the more professional administrative interfaces. Chapter\u00a03, \u201cUsing the Shell,\u201d intro -\nduces you to the Linux command-line shell interface.\nExercises\nUse these exercises to test your skill in using a GNOME desktop. You can use either a GNOME \n2.x (Red Hat Enterprise Linux up until RHEL 6. x) or GNOME 3. x (Fedora 16 or later or Ubuntu \nup to 11.10, or later using the Ubuntu GNOME project) desktop. If you are stuck, solutions \nto the tasks for both the GNOME 2 and GNOME 3 desktops are shown in Appendix B.\n1. Obtain a Linux system with either a GNOME 2 or GNOME 3 desktop available. Start \nthe system and log in to a GNOME desktop.\n2. Launch the Firefox web browser and go to the GNOME home page ( http://\ngnome.org ).\n3. Pick a background you like from the GNOME art site ( http://gnome-look.org ), \ndownload it to your Pictures folder, and select it as your current background.\n4. Start a Nautilus File Manager window and move it to the second workspace on \nyour desktop.\n5. Find the image that you downloaded to use as your desktop background and open it \nin any image viewer.", "doc_id": "27fd9ba2-9cc7-4831-b38e-d522e8e27d40", "embedding": null, "doc_hash": "9b4c376df22b53fccd981a237bbee834caea6933299cae9fb274b38e19ef617d", "extra_info": {"page_label": "90"}, "node_info": {"start": 0, "end": 2305}, "relationships": {"1": "821aeec8-6443-46c8-abda-67e5cdb47607"}}, "__type__": "1"}, "d4d61a44-08e1-4f51-8ebe-d4193a502470": {"__data__": {"text": "Part I: Getting Started586. Move back and forth between the workspace with Firefox on it and the one with \nthe Nautilus file manager.\n7. Open a list of applications installed on your system and select an image viewer to \nopen from that list. Use as few clicks or keystrokes as possible.\n8. Change the view of the windows on your current workspace to smaller views you \ncan step through. Select any window you\u2019d like to make it your current window.\n9. From your desktop, using only the keyboard, launch a music player.\n10. Take a picture of your desktop, using only keystrokes.", "doc_id": "d4d61a44-08e1-4f51-8ebe-d4193a502470", "embedding": null, "doc_hash": "6a506cc391b8580c07f7f45a0d08377f37c36d12c2bd851b2b42b2c89c937bd1", "extra_info": {"page_label": "91"}, "node_info": {"start": 0, "end": 576}, "relationships": {"1": "764a9f6b-e887-4973-85fb-51fe02dc70fc"}}, "__type__": "1"}, "11a87556-3692-425e-869c-7964c56a4c4a": {"__data__": {"text": "Part IIIN THIS PART\nChapter\u00a03 \nUsing the Shell\nChapter\u00a04 \nMoving Around the Filesystem\nChapter\u00a05 \nWorking with Text Files\nChapter\u00a06 \nManaging Running Processes\nChapter\u00a07 \nWriting Simple Shell ScriptsBecoming a Linux \nPower User\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "11a87556-3692-425e-869c-7964c56a4c4a", "embedding": null, "doc_hash": "2ea91142ee3a3eb62efafeccaec02bc8617c006d81fa9417562fdbf26c3120ce", "extra_info": {"page_label": "92"}, "node_info": {"start": 0, "end": 350}, "relationships": {"1": "db573aad-fc81-41a8-a25c-dd7fd401a41e"}}, "__type__": "1"}, "01a4611c-8d60-4ce3-bc67-92061393b259": {"__data__": {"text": "61\nCHAPTER3\nUsing the Shell\nIN THIS CHAPTER\nUnderstanding the Linux shell\nUsing the shell from consoles or TerminalsUsing commandsUsing command history and tab completionConnecting and expanding commandsUnderstanding variables and aliasesMaking shell settings permanentUsing man pages and other documentation\nBefore icons and windows took over computer screens, you typed commands to interact with \nmost computers. On UNIX systems, from which Linux was derived, the program used to inter-pret and manage commands was referred to as the shell .\nNo matter which Linux distribution you are using, you can always count on the fact that the shell is available to you. It provides a way to create executable script files, run programs, work with file -\nsystems, compile computer code, and manage the computer. Although the shell is less intuitive than c\nommon graphical user interfaces (GUIs), most Linux experts consider the shell to be much more pow -\nerful than GUIs. Shells have been around a long time, and many advanced features that aren\u2019t avail-\nable from the desktop can be accessed by running shell commands.\nT\nhe Linux shell illustrated in this chapter is called the bash shell , which stands for Bourne Again \nShell. The name is derived from the fact that bash is compatible with the one of the earliest \nUNIX shells: the Bourne shell (named after its creator, Stephen Bourne, and represented by the sh command).\nAlthough bash is included with most distributions and considered a standard, other shells are avail -\nable, including the C shell ( c\n sh), which is popular among BSD UNIX users, and the Korn shell ( ksh), \nwhich is popular among UNIX System V users. Ubuntu uses the dash shell by default at boot time, which is designed to perform faster than the bash shell. Linux also has a tcsh  shell (an improved C \nshell) and an ash shell (another Bourne shell look-alike).\nThe odds are strong that the Linux distribution you are using has more than one shell available \nfor your use. This chapter, however, focuses primarily on the bash shell. That is because the Linux \nLinux\u00ae Bible , Tenth Edition. Christopher Negus.\n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "01a4611c-8d60-4ce3-bc67-92061393b259", "embedding": null, "doc_hash": "92e5f913bd0ba268b465ffee1e203b85151ebf5160852c0caee9d54b1a7fcc4a", "extra_info": {"page_label": "93"}, "node_info": {"start": 0, "end": 2202}, "relationships": {"1": "2ed98680-b4f8-4dbb-a474-bf07ef6b530a"}}, "__type__": "1"}, "56f8ae87-3588-4b30-a2a8-ae43836c7c97": {"__data__": {"text": "Part II: Becoming a Linux Power User62distributions featured in this book, Fedora, Ubuntu, and Red Hat Enterprise Linux, all use \nthe bash shell by default when you open a Terminal window.\nThe following are a few major reasons to learn how to use the shell:\n\u25a0\u25a0You will learn to get around any Linux or other UNIX-like system . For example, I can \nlog in to my Red Hat Enterprise Linux web server, my home multimedia server, my \nhome router, or my wife\u2019s Mac and explore and use any of those computer systems \nfrom a shell. I can even log in and run commands on my Android phone. They all \nrun Linux or similar systems on the inside.\n\u25a0\u25a0Special shell features enable you to gather data input and direct data output between \ncommands and Linux filesystems . To save on typing, you can find, edit, and repeat \ncommands from your shell history. Many power users hardly touch a graphical \ninterface, doing most of their work from a shell.\n\u25a0\u25a0You can gather commands into a file using programming constructs such as conditional \ntests, loops, and case statements to perform complex operations quickly, which would \nbe difficult to retype over and over . Programs consisting of commands that are stored \nand run from a file are referred to as shell scripts . Many Linux system administra -\ntors use shell scripts to automate tasks such as backing up data, monitoring log \nfiles, or checking system health.\nThe shell is a command language interpreter. If you have used Microsoft operating systems, \nyou\u2019ll see that using a shell in Linux is similar to, but generally much more powerful than, \nthe PowerShell interpreter used to run commands. You can happily use Linux from a graphical \ndesktop interface, but as you grow into Linux you will surely need to use the shell at some \npoint to track down a problem or administer some features.\nHow to use the shell isn\u2019t obvious at first, but with the right help you can quickly learn many \nof the most important shell features. This chapter is your guide to working with the Linux \nsystem commands, processes, and filesystem from the shell. It describes the shell environ -\nment and helps you tailor it to your needs.\nAbout Shells and Terminal Windows\nThere are several ways to get to a shell interface in Linux. Three of the most common are \nthe shell prompt, Terminal window, and virtual console, which you learn more about in the \nfollowing sections.\nTo start, boot up your Linux system. On your screen, you should see either a graphical login \nscreen or a plain-text login prompt similar to the following:\nRed Hat Enterprise Linux Server release 8.0 (Ootpa)\nKernel 4.18.0-42.el8.x86_64 on an X86\nmylinuxhost login:\nIn either case, you should log in with a regular user account. If you have a plain-text login \nprompt, continue to the next section, \u201cUsing the shell prompt.\u201d If you log in through a \ngraphical screen, go to the section \u201cUsing a Terminal window\u201d to see how to access a shell ", "doc_id": "56f8ae87-3588-4b30-a2a8-ae43836c7c97", "embedding": null, "doc_hash": "4e153e0a09377d5aa2a2120f7b7ee52da9319043af1fa86a14109096a66d3c82", "extra_info": {"page_label": "94"}, "node_info": {"start": 0, "end": 2929}, "relationships": {"1": "42e7f4ca-d857-45f7-8f1a-efb5cd790c1f"}}, "__type__": "1"}, "4543d55b-ecab-49e4-976b-47068e153f4e": {"__data__": {"text": "Chapter 3: Using the Shell\n63\n3from the desktop. In either case, you can access more shells as described in the section \n\u201cUsing virtual consoles,\u201d which appears shortly in this chapter.\nUsing the shell prompt\nIf your Linux system has no graphical user interface (or one that isn\u2019t working at the \nmoment), you will most likely see a shell prompt after you log in. Typing commands from \nthe shell will probably be your primary means of using the Linux system.\nThe default prompt for a regular user is simply a dollar sign:\n$\nThe default prompt for the root user is a pound sign (also called a number sign or a \nhash tag ):\n#\nIn most Linux systems, the $  and #  prompts are preceded by your username, system name, \nand current directory name. For example, a login prompt for the user named jake on a \ncomputer named pine with /usr/share/ as the current working directory would appear \nas follows:\n[jake@pine share]$\nYou can change the prompt to display any characters you like and even read in pieces of \ninformation about your system. For example, you can use the current working directory, \nthe date, the local computer name, or any string of characters as your prompt. To configure \nyour prompt, see the section \u201cSetting your prompt\u201d later in this chapter.\nAlthough a tremendous number of features are available with the shell, it\u2019s easy to begin by \njust entering a few commands. Try some of the commands shown in the remaining sections \nto become familiar with your current shell environment.\nIn the examples that follow, the dollar ( $) and pound ( #) symbols indicate a prompt. A \n$ indicates that the command can be run by any user, but a # typically means that you \nshould run the command as the root user; that is, many administrative tools require root \npermission to be able to run them. The prompt is followed by the command that you type \n(and then press Enter). The lines that follow show the output resulting from the command.\nNote \nAlthough we use # to indicate that a command be run as the root user, you do not need to log in as the root user \nto run a command as root. In fact, the most common way to run a command as a root user is to use the sudo  \ncommand. See Chapter\u00a08, \u201cLearning System Administration,\u201d for further information about the sudo  command.\nUsing a Terminal window\nWith the desktop GUI running, you can open a Terminal emulator program (sometimes \nreferred to as a Terminal window) to start a shell. Most Linux distributions make it easy for ", "doc_id": "4543d55b-ecab-49e4-976b-47068e153f4e", "embedding": null, "doc_hash": "9f2833fdbe9fd251ca2c8c68798f69014139ee4182d669d7b2f033a9f32b59c7", "extra_info": {"page_label": "95"}, "node_info": {"start": 0, "end": 2478}, "relationships": {"1": "5fca64ff-ee5e-4a7d-9c4f-93553f0e0053"}}, "__type__": "1"}, "b854ca3a-6214-4037-a03d-98a5eb372199": {"__data__": {"text": "Part II: Becoming a Linux Power User64you to get to a shell from the GUI. Here are two common ways to launch a Terminal window \nfrom a Linux desktop:\nRight-click the desktop. In the context menu that appears, if you see Open in Termi-\nnal, Shells, New Terminal, Terminal Window, Xterm, or some similar item, select it to \nstart a Terminal window. (Some distributions have disabled this feature.)\nClick the panel menu. Many Linux desktops include a panel at the top or bottom of \nthe screen from which you can launch applications. For example, in some systems \nthat use the GNOME 2 desktop, you can select Applications \u27aa System Tools \u27aa Termi -\nnal to open a Terminal window. In GNOME 3, click the Activities menu, type Ter -\nminal , and press Enter.\nIn all cases, you should be able to type a command as you would from a shell with no GUI. \nDifferent Terminal emulators are available with Linux. In Fedora, Red Hat Enterprise Linux \n(RHEL), and other Linux distributions that use the GNOME desktop, the default Terminal \nemulator window is the GNOME Terminal (started by the gnome-terminal  command).\nGNOME Terminal supports many features beyond the basic shell. For example, you can \ncut and paste text to or from a GNOME Terminal window, change fonts, set a title, choose \ncolors or images to use as background, and set how much text to save when text scrolls off \nthe screen.\nTo try some GNOME Terminal features, start up a Fedora or RHEL system and log in to the \ndesktop. Then follow this procedure:\n1. Select Applications \u27aa Utilities \u27aa Terminal (or click on the Activities menu and \ntype Terminal ). A Terminal window should open on your desktop.\n2. Select Edit \u27aa Profile Preferences or Preferences.\n3. On the General tab or current profile (depending on your version of GNOME), check \nthe \u201cCustom font\u201d box.\n4. Select the Font field, try a different font and size, and then click Select. The new \nfont appears in the Terminal window.\n5. Unselect the \u201cCustom font\u201d box. This takes you back to the original font.\n6. On the Colors tab, clear the \u201cUse colors from system theme\u201d check box. From here, \nyou can try some different font and background colors.\n7. Re-select the \u201cUse colors from system theme\u201d box to go back to the default colors.\n8. Go to your Profile window. There are other features with which you may want to \nexperiment, such as setting how much scrolled data is kept.\n9. Close the Profile window when you are finished. You are now ready to use your Ter -\nminal window.\nIf you are using Linux from a graphical desktop, you will probably most often access the \nshell from a Terminal window.", "doc_id": "b854ca3a-6214-4037-a03d-98a5eb372199", "embedding": null, "doc_hash": "5887f81a37d20916e0053b4e08ae166770ced17bd7c5fe3abdc3816a5909a8d7", "extra_info": {"page_label": "96"}, "node_info": {"start": 0, "end": 2607}, "relationships": {"1": "5ad41971-ff37-4829-bcb9-d6a25a8bd679"}}, "__type__": "1"}, "a951a192-737f-428f-91e3-4da8fecb8207": {"__data__": {"text": "Chapter 3: Using the Shell\n65\n3Using virtual consoles\nMost Linux systems that include a desktop interface start multiple virtual consoles running \non the computer. Virtual consoles are a way to have multiple shell sessions open at once in \naddition to the graphical interface you are using.\nYou can switch between virtual consoles by holding the Ctrl and Alt keys and pressing a \nfunction key between F1 and F6. For example, in Fedora, press Ctrl+Alt+F1 (or F2, F3, F4, \nand so on up to F6 on most Linux systems) to display one of seven virtual consoles. The GUI \nis typically located on one of the first two virtual consoles, and the other six virtual con -\nsoles are typically text-based virtual consoles.\nYou can return to the GUI (if one is running) by pressing Ctrl+Alt+F1. On some systems, the \nGUI may run on a different virtual console, such as virtual console 2 (Ctrl+Alt+F2). Newer \nsystems, such as Fedora 29, now start the gdm (the login screen) persistently on tty1 to \nallow multiple simultaneous GUI sessions: the gdm is on tty1, the first desktop is started on \ntty2, the second desktop is started on tty3, and so on.\nTry it right now. Hold down the Ctrl+Alt keys and press F3. You should see a plain-text \nlogin prompt. Log in using your username and password. Try a few commands. When you \nare finished, type exit  to exit the shell and then press Ctrl+Alt+F1 or Ctrl+Alt+F2 to return \nto your graphical desktop interface. You can go back and forth between these consoles as \nmuch as you like.\nChoosing Your Shell\nIn most Linux systems, your default shell is the bash shell. To find out what is your default \nlogin shell, enter the following commands:\n$ who am i\nchris   pts/0        2019-10-21 22:45 (:0.0)\n$ grep chris /etc/passwd\nchris:x:13597:13597:Chris Negus:/home/chris:/bin/bash\nNotice that the command-line examples shown here and throughout the book show the \ncommand followed by output from that command. When the command completes, you are \npresented with the command prompt again.\nThe who am i command shows your username, and the grep  command (replacing chris  \nwith your username) shows the definition of your user account in the /etc/passwd  file. \nThe last field in that entry shows that the bash shell ( /bin/bash ) is your default shell \n(the one that starts up when you log in or open a Terminal window).\nIt\u2019s possible, although not likely, that you might have a different default shell set. To try a \ndifferent shell, simply type the name of that shell (examples include ksh , tcsh , csh, sh, \ndash , and others, assuming that they are installed). You can try a few commands in that \nshell and type exit  when you are finished to return to the bash shell.", "doc_id": "a951a192-737f-428f-91e3-4da8fecb8207", "embedding": null, "doc_hash": "a9ee2d858a6d1c9de2e9c437fbe904868e2f0b32b1f4fc93cb30a575e637045d", "extra_info": {"page_label": "97"}, "node_info": {"start": 0, "end": 2695}, "relationships": {"1": "ba0d59dc-efd5-46d8-95bf-e9eea36b5838"}}, "__type__": "1"}, "c1adedd3-3dd3-4dd0-9810-ed322bab345d": {"__data__": {"text": "Part II: Becoming a Linux Power User66You might choose to use different shells for the following reasons:\n\u25a0\u25a0You are used to using UNIX System V systems (often ksh  by default) or Sun Micro -\nsystems and other Berkeley UNIX-based distributions (frequently csh  by default), \nand you are more comfortable using default shells from those environments.\n\u25a0\u25a0You want to run shell scripts that were created for a particular shell environment, \nand you need to run the shell for which they were made so that you can test or use \nthose scripts from your current shell.\n\u25a0\u25a0You simply prefer features in one shell over those in another. For example, a \nmember of my Linux Users Group prefers ksh  over bash  because he doesn\u2019t like the \nway aliases are used with bash .\nAlthough most Linux users have a preference for one shell or another, when you know how \nto use one shell, you can quickly learn any of the others by occasionally referring to the \nshell\u2019s man page (for example, type man bash ). The man pages (described later in the \nsection \u201cGetting Information about Commands\u201d) provide documentation for commands, \nfile formats, and other components in Linux. Most people use bash just because they don\u2019t \nhave a particular reason for using a different shell. The rest of this chapter describes the \nbash shell.\nBash includes features originally developed for sh  and ksh  shells in early UNIX systems, as \nwell as some csh  features. Expect bash to be the default login shell in most Linux systems \nthat you are using, with the exception of some specialized Linux systems (such as some \nthat run on embedded devices) that may require a smaller shell that needs less memory and \nrequires fewer features. Most of the examples in this chapter are based on the bash shell.\ntip\nThe bash shell is worth knowing not only because it is the default in most installations, but because it is the one you \nwill use with most Linux certification exams.\nRunning Commands\nThe simplest way to run a command is just to type the name of the command from a shell. \nFrom your desktop, open a Terminal window. Then enter the following command:\n$ date\nThu Jun 29 08:14:53 EDT 2019\nEntering the date  command, with no options or arguments, causes the current day, month, \ndate, time, time zone, and year to be displayed as just shown.\nHere are a few other commands you can try:\n$ pwd\n/home/chris\n$ hostname", "doc_id": "c1adedd3-3dd3-4dd0-9810-ed322bab345d", "embedding": null, "doc_hash": "7b5e2dbce9ed8695d2d850edd1b1e1280fa02d0eb18c75b17676b32b1c0a2eb7", "extra_info": {"page_label": "98"}, "node_info": {"start": 0, "end": 2377}, "relationships": {"1": "febbfc1e-6a8e-41a9-b548-424a43e0b1de"}}, "__type__": "1"}, "8ae4d3c8-cf5c-4b02-bcb4-a2da2ded5ccb": {"__data__": {"text": "Chapter 3: Using the Shell\n67\n3mydesktop\n$ ls\nDesktop    Downloads  Pictures  Templates\nDocuments  Music      Public    Videos\nThe pwd  command shows your current working directory. Entering hostname  shows your \ncomputer\u2019s hostname. The ls  command lists the files and directories in your current direc -\ntory. Although many commands can be run by just entering command names, it\u2019s more \ncommon to type other characters after the command to modify its behavior. The characters \nand words that you can type after a command are called options  and arguments .\nUnderstanding command syntax\nMost commands have one or more options  that you can add to change the command\u2019s \nbehavior. Options typically consist of a single letter preceded by a hyphen. However, you \ncan group single-letter options together or precede each with a hyphen to use more than \none option at a time. For example, the following two uses of options for the ls  command \nare the same:\n$ ls -l -a -t\n$ ls -lat\nIn both cases, the ls  command is run with the -l  (long listing), -a  (show hidden dot \nfiles), and -t  options (list by time).\nSome commands include options that are represented by a whole word. To tell a \ncommand to use a whole word as an option, you typically precede it with a double \nhyphen (--). For example, to use the help option on many commands, you enter --help  \non the command line. Without the double hyphen, the letters h , e, l, and p  would be \ninterpreted as separate options. There are some commands that don\u2019t follow the double \nhyphen convention, using a single hyphen before a word, but most commands use double \nhyphens for word options.\nNote\nYou can use the --help  option with most commands to see the options and arguments that they support. For \nexample, try typing hostname --help .\nMany commands also accept arguments after certain options are entered or at the end \nof the entire command line. An argument  is an extra piece of information, such as a file -\nname, directory, username, device, or other item, that tells the command what to act on. \nFor example, cat /etc/passwd  displays the contents of the /etc/passwd  file on your \nscreen. In this case, /etc/passwd  is the argument. Usually, you can have as many argu -\nments as you want on the command line, limited only by the total number of characters \nallowed on a command line. Sometimes, an argument is associated with an option. In that \ncase, the argument must immediately follow the option. With single-letter options, the ", "doc_id": "8ae4d3c8-cf5c-4b02-bcb4-a2da2ded5ccb", "embedding": null, "doc_hash": "aa1b633f5eac9ae2495aa0b2b4f1d3603c29082d14b934f721b2aa58301a44c2", "extra_info": {"page_label": "99"}, "node_info": {"start": 0, "end": 2495}, "relationships": {"1": "f8872a99-6a46-4616-9862-c143071ef0d3"}}, "__type__": "1"}, "49eba7cf-fa70-4c19-b746-2e76da424040": {"__data__": {"text": "Part II: Becoming a Linux Power User68argument typically follows after a space. For full-word options, the argument often follows \nan equal sign ( =). Here are some examples:\n$ ls --hide=Desktop\nDocuments  Music     Public    Videos\nDownloads  Pictures  Templates\nIn the previous example, the --hide  option tells the ls  command not to display the file or \ndirectory named Desktop  when listing the contents of the directory. Notice that the equal \nsign immediately follows the option (no space) and then the argument (again, no space).\nHere\u2019s an example of a single-letter option that is followed by an argument:\n$ tar -cvf backup.tar /home/chris\nIn the tar  example just shown, the options say to create ( c) a file (f) named backup.tar  \nthat includes all of the contents of the /home/chris  directory and its subdirectories and \nshow verbose ( v) messages as the backup is created. Because backup.tar  is an argument \nto the f option, backup.tar  must immediately follow the option.\nHere are a few commands that you can try out. See how they behave differently with dif -\nferent options:\n$ ls\nDesktop  Documents  Downloads  Music  Pictures  Public  Templates  \nVideos\n$ ls -a\n.              Desktop     .gnome2_private  .lesshst       Public\n..             Documents   .gnote           .local         Templates\n.bash_history  Downloads   .gnupg           .mozilla       Videos\n.bash_logout   .emacs      .gstreamer-0.10  Music          .xsession-\nerrors\n.bash_profile  .esd_auth   .gtk-bookmarks   Pictures       .zshrc\n.bashrc        .fsync.log  .gvfs            Pictures\n$ uname\nLinux\n$ uname -a\nLinux mydesktop 5.3.7-301.fc31.x86_64 #1 SMP Mon Oct 21 19:18:58 UTC \n     2019 x86_64 x86_64 x86_64 GNU/Linux\n$ date\nWed 04 Mar 2020 09:06:25 PM EST\n$ date +'%d/%m/%y'\n04/03/20\n$ date +'%A, %B %d, %Y'\nWednesday, March 04, 2020\nThe ls  command, by itself, shows all regular files and directories in the current directory. \nBy adding the -a , you can also see the hidden files in the directory (those beginning with \na dot). The uname  command shows the type of system you are running (Linux). When you \nadd -a , you also can see the hostname, kernel release, and kernel version.", "doc_id": "49eba7cf-fa70-4c19-b746-2e76da424040", "embedding": null, "doc_hash": "2311a9b0f2c147d3529f8d252652d6237126ac4d23cbac3f1c349eee39ea883e", "extra_info": {"page_label": "100"}, "node_info": {"start": 0, "end": 2181}, "relationships": {"1": "0d78b2bd-2a61-4de7-8c99-3ea0b5c86d44"}}, "__type__": "1"}, "da1fc032-6a10-4ba5-8703-38e0e434fcb8": {"__data__": {"text": "Chapter 3: Using the Shell\n69\n3The date  command has some special types of options. By itself, date  simply prints the \ncurrent day, date, and time as shown above. But the date  command supports a special + \nformat option, which lets you display the date in different formats. Enter date --help  to \nsee different format indicators you can use.\nTry the id  and who  commands to get a feel for your current Linux environment, as \ndescribed in the following paragraphs.\nWhen you log in to a Linux system, Linux views you as having a particular identity, which \nincludes your username, group name, user ID, and group ID. Linux also keeps track of your \nlogin session: It knows when you logged in, how long you have been idle, and where you \nlogged in from.\nTo find out information about your identity, use the id  command as follows:\n$ id\nuid=1000(chris) gid=1000(chris) groups=1005(sales), 7(lp)\nIn this example, the username is chris , which is represented by the numeric user ID (uid) \n1000. The primary group for chris also is called chris , which has a group ID (gid) of 1000 . \nIt is normal for Fedora and Red Hat Enterprise Linux users to have the same primary group \nname as their username. The user chris  also belongs to other groups called sales  (gid \n1005) and lp  (gid 7 ). These names and numbers represent the permissions that chris  has \nto access computer resources.\nNote\nLinux distributions that have Security Enhanced Linux (SELinux) enabled, such as Fedora and RHEL, show additional \ninformation at the end of the id  output. That output might look something like the following:\n    context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023\nSELinux provides a means of tightly locking down the security of a Linux system. See Chapter\u00a024, \u201cEnhancing Linux \nSecurity with SELinux,\u201d if you want to learn about SELinux.\nYou can see information about your current login session by using the who  command. In \nthe following example, the -u  option says to add information about idle time and the pro -\ncess ID and -H  asks that a header be printed:\n$ who -uH\nNAME      LINE    TIME             IDLE     PID   COMMENT\nchris     tty1    Jan 13 20:57     .        2019\nThe output from this who  command shows that the user chris  is logged in on tty1  \n(which is the first virtual console on the monitor connected to the computer) and his login \nsession began at 20:57 on January 13. The IDLE  time shows how long the shell has been \nopen without any command being typed (the dot indicates that it is currently active). \nPID shows the process ID of the user\u2019s login shell. COMMENT  would show the name of \nthe remote computer from which the user had logged in, if that user had logged in from ", "doc_id": "da1fc032-6a10-4ba5-8703-38e0e434fcb8", "embedding": null, "doc_hash": "55cdca023ba786b5274fd16f9df85a4f9ea6ac0874b1c661615b11b26c5e7221", "extra_info": {"page_label": "101"}, "node_info": {"start": 0, "end": 2706}, "relationships": {"1": "498d7b76-5609-4ab6-9c8e-df3f6e43b806"}}, "__type__": "1"}, "df6e6f8c-5a8d-40ab-a844-7bd97febe3ca": {"__data__": {"text": "Part II: Becoming a Linux Power User70another computer on the network, or the name of the local X display if that user were using \na Terminal window (such as :0.0).\nLocating commands\nNow that you have typed a few commands, you may wonder where those commands are \nlocated and how the shell finds the commands you type. To find commands you type, the \nshell looks in what is referred to as your path . For commands that are not in your path, you \ncan type the complete identity of the location of the command.\nIf you know the directory that contains the command that you want to run, one way to run \nit is to type the full, or absolute, path to that command. For example, you run the date  \ncommand from the /bin  directory by entering the following:\n$ /bin/date\nOf course, this can be inconvenient, especially if the command resides in a directory with a \nlong pathname. The better way is to have commands stored in well-known directories and \nthen add those directories to your shell\u2019s PATH  environment variable. The path consists of \na list of directories that are checked sequentially for the commands you enter. To see your \ncurrent path, enter the following:\n$ echo $PATH\n/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:\u21b5\n/home/chris/bin\nThe results show a common default path for a regular Linux user. Directories in the path \nlist are separated by colons. Most user commands that come with Linux are stored in the /\nbin, /usr/bin , or /usr/local/bin  directory. The /sbin  and /usr/sbin  directories \ncontain administrative commands (some Linux systems don\u2019t put those directories in reg -\nular users\u2019 paths). The last directory shown is the bin  directory in the user\u2019s home  direc -\ntory (/home/chris/bin ).\ntip\nIf you want to add your own commands or shell scripts, place them in the bin  directory in your home directory (such \nas /home/chris/bin  for the user named chris ). This directory is automatically added to your path in some \nLinux systems, although you may need to create that directory or add it to your PATH  on other Linux systems. So, \nas long as you add the command to your bin  with execute permission, you can begin using it by simply typing the \ncommand name at your shell prompt. To make commands available to all users, add them to /usr/local/bin .\nUnlike some other operating systems, Linux does not, by default, check the current direc -\ntory for an executable before searching the path. It immediately begins searching the path, \nand executables in the current directory are run only if they are in the PATH  variable or \nyou give their absolute (such as /home/chris/scriptx.sh ) or relative (for example,  \n./scriptx.sh ) location.", "doc_id": "df6e6f8c-5a8d-40ab-a844-7bd97febe3ca", "embedding": null, "doc_hash": "946b490449c4bd402713bffed928976ea628e2811d8653da380cbe40799c4986", "extra_info": {"page_label": "102"}, "node_info": {"start": 0, "end": 2681}, "relationships": {"1": "b5e13dff-a8b0-4414-8680-cc1cab1924b9"}}, "__type__": "1"}, "bf25cf1a-001b-4fd5-8c2e-3d3a880c0f0b": {"__data__": {"text": "Chapter 3: Using the Shell\n71\n3The path directory order is important. Directories are checked from left to right. So, in this \nexample, if there is a command called foo  located in both the /usr/bin  and /bin  direc -\ntories, the one in /usr/bin  is executed. To have the other foo  command run, you either \ntype the full path to the command or change your PATH  variable. (Changing your PATH  \nand adding directories to it are described later in this chapter.)\nNot all of the commands you run are located in directories in your PATH  variable. Some \ncommands are built into the shell. Other commands can be overridden by creating aliases \nthat define any commands and options that you want the command to run. There are also \nways of defining a function that consists of a stored series of commands. Here is the order \nin which the shell checks for the commands you type:\n1. Aliases . These are names set by the alias  command that represent a particular \ncommand and a set of options. Type alias  to see what aliases are set. Often, \naliases enable you to define a short name for a long, complicated command.  \n(I describe how to create your own aliases later in this chapter.)\n2. Shell reserved word . These are words reserved by the shell for special use. Many \nof these are words that you would use in programming-type functions, such as \ndo, while , case , and else . (I cover some of these reserved words in Chapter\u00a07, \n\u201cWriting Simple Shell Scripts.\u201d)\n3. Function . This is a set of commands that is executed together within the \ncurrent shell.\n4. Built-in command. This is a command built into the shell. As a result, there is no \nrepresentation of the command in the filesystem. Some of the most common com-\nmands that you will use are shell built-in commands, such as cd  (to change direc -\ntories), echo  (to output text to the screen), exit  (to exit from a shell), fg  (to \nbring a command running in the background to the foreground), history  (to see a \nlist of commands that were previously run), pwd  (to list the present working direc -\ntory), set  (to set shell options), and type  (to show the location of a command).\n5. Filesystem command . This command is stored in and executed from the computer\u2019s \nfilesystem. (These are the commands that are indicated by the value of the PATH  \nvariable.)\nTo determine the location of a particular command, you can use the type  command. (If \nyou are using a shell other than bash , use the which  command instead.) For example, to \nfind out where the bash shell command is located, enter the following:\n$ type bash\nbash is /bin/bash\nTry these few words with the type  command to see other locations of commands: which , \ncase , and return . If a command resides in several locations, you can add the -a  option \nto have all of the known locations of the command printed. For example, the command \ntype -a ls should show an aliased and filesystem location for the ls  command.", "doc_id": "bf25cf1a-001b-4fd5-8c2e-3d3a880c0f0b", "embedding": null, "doc_hash": "696b71dc515179083c29ff1692d09107a7c3e9f44631ce670b882ca8a6382891", "extra_info": {"page_label": "103"}, "node_info": {"start": 0, "end": 2936}, "relationships": {"1": "cf5a78b4-997f-4f57-9a23-b82b62d41cdc"}}, "__type__": "1"}, "75ce63b5-a8c1-4833-b03b-7749d2f6446e": {"__data__": {"text": "Part II: Becoming a Linux Power User72tip\nSometimes, you run a command and receive an error message that the command was not found or that permission to \nrun the command was denied. If the command was not found, check that you spelled the command correctly and that \nit is located in your PATH  variable. If permission to run the command was denied, the command may be in the PATH  \nvariable but may not be executable. Also remember that case is important, so typing CAT or Cat will not find the cat  \ncommand.\nIf a command is not in your PATH  variable, you can use the locate  command to try to \nfind it. Using locate , you can search any part of the system that is accessible to you. \n(Some files are only accessible to the root user.) For example, if you wanted to find the loca -\ntion of the chage  command, you could enter the following:\n$ locate chage\n/usr/bin/chage\n/usr/sbin/lchage\n/usr/share/man/fr/man1/chage.1.gz\n/usr/share/man/it/man1/chage.1.gz\n/usr/share/man/ja/man1/chage.1.gz\n/usr/share/man/man1/chage.1.gz\n/usr/share/man/man1/lchage.1.gz\n/usr/share/man/pl/man1/chage.1.gz\n/usr/share/man/ru/man1/chage.1.gz\n/usr/share/man/sv/man1/chage.1.gz\n/usr/share/man/tr/man1/chage.1.gz\nNotice that locate  not only found the chage  command, it also found the lchage  \ncommand and a variety of man pages associated with chage  for different languages. The \nlocate  command looks all over your filesystem, not just in directories that contain com-\nmands. (If locate  does not find files recently added to your system, run updatedb  as \nroot to update the locate database.)\nIn the coming chapters, you learn to use additional commands. For now, I want you to \nbecome more familiar with how the shell itself works. So next I discuss features for recall -\ning commands, completing commands, using variables, and creating aliases.\nRecalling Commands Using Command History\nBeing able to repeat a command you ran earlier in a shell session can be convenient. Recall -\ning a long and complex command line that you mistyped can save you some trouble. Fortu-\nnately, some shell features enable you to recall previous command lines, edit those lines, or \ncomplete a partially typed command line.\nThe shell history is a list of the commands that you have entered before. Using the his -\ntory  command in a bash shell, you can view your previous commands. Then using various ", "doc_id": "75ce63b5-a8c1-4833-b03b-7749d2f6446e", "embedding": null, "doc_hash": "410d7a13d4dfbabb5e50fdc08afa4b5933c4e021f67fcf09955465446edb44d2", "extra_info": {"page_label": "104"}, "node_info": {"start": 0, "end": 2367}, "relationships": {"1": "41048dd5-ad77-4e0e-9c0c-98107d098458"}}, "__type__": "1"}, "94ef656c-001b-4622-9ef4-f1f3112ce30a": {"__data__": {"text": "Chapter 3: Using the Shell\n73\n3shell features, you can recall individual command lines from that list and change them \nhowever you please.\nThe rest of this section describes how to do command-line editing, how to complete parts \nof command lines, and how to recall and work with the history list.\nCommand-line editing\nIf you type something wrong on a command line, the bash shell ensures that you don\u2019t \nhave to delete the entire line and start over. Likewise, you can recall a previous command \nline and change the elements to make a new command.\nBy default, the bash shell uses command-line editing that is based on the emacs text edi-\ntor. (Type man emacs  to read about it, if you care to do so.) If you are familiar with \nemacs, you probably already know most of the keystrokes described here.\ntip\nIf you prefer the vi  command for editing shell command lines, you can easily make that happen. Add the following \nline to the .bashrc  file in your home directory:\n    set -o vi\nThe next time you open a shell, you can use vi  commands to edit your command lines.\nTo do the editing, you can use a combination of control keys, meta keys, and arrow keys. \nFor example, Ctrl+F means to hold down the Ctrl key, and type f. Alt+F means to hold down \nthe Alt key, and type f. (Instead of the Alt key, your keyboard may use a Meta key or the \nEsc key. On a Windows keyboard, you can use the Windows key.)\nTo try out a bit of command-line editing, enter the following:\n$ ls /usr/bin | sort -f | less\nThis command lists the contents of the /usr/bin  directory, sorts the contents in alpha -\nbetical order (regardless of case), and pipes the output to less . The less  command dis -\nplays the first page of output, after which you can go through the rest of the output a line \n(press Enter) or a page (press spacebar) at a time. Simply press q when you are finished. \nNow, suppose that you want to change /usr/bin  to /bin . You can use the following steps \nto change the command:\n1. Press the up arrow ( \u2191) key . This displays the most recent command from your \nshell history.\n2. Press Ctrl+A . This moves the cursor to the beginning of the command line.\n3. Press Ctrl+F or the right arrow ( \u2192) key . Repeat this command a few times to \nposition the cursor under the first slash ( /).\n4. Press Ctrl+D . Type this command four times to delete /usr  from the line.", "doc_id": "94ef656c-001b-4622-9ef4-f1f3112ce30a", "embedding": null, "doc_hash": "e08f88ac9b9b9f4e750644f4334f929d12093a41ab7a5d7dfb7efa761ebc7e14", "extra_info": {"page_label": "105"}, "node_info": {"start": 0, "end": 2356}, "relationships": {"1": "8d555154-769e-441d-abf1-3891e04ece7c"}}, "__type__": "1"}, "276b7a87-5c77-490c-88c5-662ab77c7739": {"__data__": {"text": "Part II: Becoming a Linux Power User745. Press Enter . This executes the command line.\nAs you edit a command line, at any point you can type regular characters to add those \ncharacters to the command line. The characters appear at the location of your text cursor. \nYou can use right \u2192 and left \u2190 arrows to move the cursor from one end to the other on the \ncommand line. You can also press the up \u2191 and down \u2193 arrow keys to step through previous \ncommands in the history list to select a command line for editing. (See the section \u201cCom-\nmand-line recall\u201d for details on how to recall commands from the history list.) You can use \nmany keystrokes to edit your command lines. Table\u00a03.1 lists the keystrokes that you can \nuse to move around the command line.\nThe keystrokes in Table\u00a03.2 can be used to edit command lines.TABLE 3.1  Keystrokes for Navigating Command Lines\nKeystroke Full Name Meaning\nCtrl+F Character forward Go forward one character.\nCtrl+B Character backward Go backward one character.\nAlt+F Word forward Go forward one word.\nAlt+B Word backward Go backward one word.\nCtrl+A Beginning of line Go to the beginning of the current line.\nCtrl+E End of line Go to the end of the line.\nCtrl+L Clear screen Clear screen and leave line at the top of the screen.\nTABLE 3.2  Keystrokes for Editing Command Lines\nKeystroke Full Name Meaning\nCtrl+D Delete current Delete the current character.\nBackspace Delete previous Delete the previous character.\nCtrl+T Transpose character Switch positions of current and previous characters.\nAlt+T Transpose words Switch positions of current and previous words.\nAlt+U Uppercase word Change the current word to uppercase.\nAlt+L Lowercase word Change the current word to lowercase.\nAlt+C Capitalize word Change the current word to an initial capital.\nCtrl+V Insert special  \ncharacterAdd a special character. For example, to add a Tab char -\nacter, press Ctrl+V+Tab.", "doc_id": "276b7a87-5c77-490c-88c5-662ab77c7739", "embedding": null, "doc_hash": "335407d0fbca436aac935ee96bea8d3bf25d15ce9cf0be7bb49e4901f0b0071e", "extra_info": {"page_label": "106"}, "node_info": {"start": 0, "end": 1906}, "relationships": {"1": "5d3954f6-bdf5-43f6-8d0f-dc067211a638"}}, "__type__": "1"}, "f5d7a1e7-7d0d-4003-8fdc-dfde908e7eaa": {"__data__": {"text": "Chapter 3: Using the Shell\n75\n3Use the keystrokes in Table\u00a03.3 to cut and paste text on a command line.\nCommand-line completion\nTo save you a few keystrokes, the bash shell offers several different ways of completing \npartially typed values. To attempt to complete a value, type the first few characters and \npress Tab. Here are some of the values you can type partially from a bash shell:\nCommand, alias, or function If the text you type begins with regular characters, \nthe shell tries to complete the text with a command, alias, or function name.\nVariable  If the text you type begins with a dollar sign ( $), the shell completes the \ntext with a variable from the current shell.\nUsername  If the text you type begins with a tilde ( ~), the shell completes the text \nwith a username. As a result, ~ username  indicates the home directory of the \nnamed user.\nHostname  If the text you type begins with the at symbol ( @), the shell completes the \ntext with a hostname taken from the /etc/hosts  file.\ntip\nTo add hostnames from an additional file, you can set the HOSTFILE  variable to the name of that file. The file must \nbe in the same format as /etc/hosts .\nHere are a few examples of command completion. (When you see <Tab> , it means to press \nthe Tab key on your keyboard.) Enter the following:\n$ echo $OS<Tab>\n$ cd ~ro<Tab>\n$ userm<Tab>TABLE 3.3  Keystrokes for Cutting and Pasting Text from within \nCommand Lines\nKeystroke Full Name Meaning\nCtrl+K Cut end of line Cut text to the end of the line.\nCtrl+U Cut beginning of line Cut text to the beginning of the line.\nCtrl+W Cut previous word Cut the word located behind the cursor.\nAlt+D Cut next word Cut the word following the cursor.\nCtrl+Y Paste recent text Paste most recently cut text.\nAlt+Y Paste earlier text Rotate back to previously cut text and paste it.\nCtrl+C Delete whole line Delete the entire line.", "doc_id": "f5d7a1e7-7d0d-4003-8fdc-dfde908e7eaa", "embedding": null, "doc_hash": "0df108975609955f67070c963fa8bd0405b865c30aefd9a1df6213b6b7ce2298", "extra_info": {"page_label": "107"}, "node_info": {"start": 0, "end": 1872}, "relationships": {"1": "25de274a-2641-4859-ad7c-8ff593656e90"}}, "__type__": "1"}, "047015f3-bbb7-4810-82d2-00182ca2bb4e": {"__data__": {"text": "Part II: Becoming a Linux Power User76The first example causes $OS  to expand to the $OSTYPE  variable. In the next example, \n~ro expands to the root user\u2019s home directory ( ~root/ ). Next, userm  expands to the \nusermod  command.\nPressing Tab twice offers some wonderful possibilities. Sometimes, several possible comple -\ntions for the string of characters you have entered are available. In those cases, you can \ncheck the possible ways that text can be expanded by pressing Tab twice at the point where \nyou want to do completion.\nThe following shows the result you would get if you checked for possible comple -\ntions on $P :\n$ echo $P<Tab><Tab>\n$PATH $PPID $PS1 $PS2 $PS4 $PWD\n$ echo $P\nIn this case, there are six possible variables that begin with $P . After possibilities are dis -\nplayed, the original command line returns, ready for you to complete it as you choose. For \nexample, if you typed another P and hit Tab again, the command line would be completed \nwith $PPID  (the only unique possibility).\nCommand-line recall\nAfter you type a command, the entire command line is saved in your shell\u2019s history list. \nThe list is stored in the current shell until you exit the shell. After that, it is written to a \nhistory file, from which any command can be recalled to be run again in your next session. \nAfter a command is recalled, you can modify the command line, as described earlier.\nTo view your history list, use the history  command. Enter the command without options \nor followed by a number to list that many of the most recent commands. For example:\n$ history 8\n 382 date\n 383 ls /usr/bin | sort -a | more\n 384 man sort\n 385 cd /usr/local/bin\n 386 man more\n 387 useradd -m /home/chris -u 101 chris\n 388 passwd chris\n 389 history 8\nA number precedes each command line in the list. You can recall one of those commands \nusing an exclamation point ( !). Keep in mind that when an exclamation point is used, the \ncommand runs blind without presenting an opportunity to confirm the command you\u2019re \nreferencing. There are several ways to run a command immediately from this list, including \nthe following:\n!n   Run command number . Replace the n with the number of the command line and \nthat line is run. For example, here\u2019s how to repeat the date  command shown as \ncommand number 382 in the preceding history listing:\n         $ !382", "doc_id": "047015f3-bbb7-4810-82d2-00182ca2bb4e", "embedding": null, "doc_hash": "7bb8989ad70c962cb32cfdf5621107f3cbf836a652d54dc6f37483a384d2f6e0", "extra_info": {"page_label": "108"}, "node_info": {"start": 0, "end": 2349}, "relationships": {"1": "30b32d73-8ede-4207-b90e-486ae9a844c1"}}, "__type__": "1"}, "fd7d7be9-3312-4811-bfea-33a94c3efea3": {"__data__": {"text": "Chapter 3: Using the Shell\n77\n3         date\n         Fri Jun 29 15:47:57 EDT 2019\n!!\u2014!!  Run previous command . Runs the previous command line. Here\u2019s how you would \nimmediately run that same date  command:\n         $ !!\n         date\n         Fri Jun 29 15:53:27 EDT 2019\n!?string \u2014? Run command containing string . This runs the most recent command that \ncontains a particular string of characters. For example, you can run the date  \ncommand again by just searching for part of that command line as follows:\n         $ !?dat?\n \n         date\n         Fri Jun 29 16:04:18 EDT 2019\nInstead of just running a history  command line immediately, you can recall a particular \nline and edit it. You can use the following keys or key combinations to do that, as shown in \nTable\u00a03.4.\nAnother way to work with your history list is to use the fc  command. Type fc  followed \nby a history line number, and that command line is opened in a text editor ( vi by default, \ntype :wq  to save and exit or :q!  to just exit if you are stuck in vi ). Make the changes that \nyou want. When you exit the editor, the command runs. You can also give a range of line \nTABLE 3.4  Keystrokes for Using Command History\nKey(s) Function Name Description\nArrow \nkeys (\u2191 and \u2193 )Step Press the up and down arrow keys to step through \neach command line in your history list to arrive at \nthe one you want. (Ctrl+P and Ctrl+N do the same \nfunctions, respectively.)\nCtrl+R Reverse \nincremental searchAfter you press these keys, you enter a search string \nto do a reverse search. As you type the string, \na matching command line appears that you can \nrun or edit.\nCtrl+S Forward \nincremental searchThis is the same as the preceding function but for \nforward search. (It may not work in all instances.)\nAlt+P Reverse search After you press these keys, you enter a string to do \na reverse search. Type a string and press Enter to \nsee the most recent command line that includes \nthat string.\nAlt+N Forward search This is the same as the preceding function but for \nforward search. (It may not work in all instances.)", "doc_id": "fd7d7be9-3312-4811-bfea-33a94c3efea3", "embedding": null, "doc_hash": "6eb5308d6844a4a36b542b91eb4181b50e5bfab0feba078c9c14f898f1d71537", "extra_info": {"page_label": "109"}, "node_info": {"start": 0, "end": 2081}, "relationships": {"1": "0dcc16e3-f73e-4769-9008-ee8b71415b87"}}, "__type__": "1"}, "da16f4c3-0f7f-4561-b8d6-4c1ca5dba149": {"__data__": {"text": "Part II: Becoming a Linux Power User78numbers (for example, fc 100 105 ). All of the commands open in your text editor and \nthen run one after the other when you exit the editor.\nAfter you close your shell, the history list is stored in the .bash _ history  file in your \nhome directory. Up to 1,000 history commands are stored for you by default.\nNote\nSome people disable the history feature for the root user by setting the HISTFILE  shell variable to /dev/null  \nor simply leaving HISTSIZE  blank. This prevents information about the root user\u2019s activities from potentially being \nexploited. If you are an administrative user with root privileges, you may want to consider emptying your file upon \nexiting as well for the same reasons. Also, because shell history is stored permanently when the shell exits prop -\nerly, you can prevent storing a shell\u2019s history by killing a shell. For example, to kill a shell with process ID 1234, type \nkill -9 1234  from any shell.\nConnecting and Expanding Commands\nA truly powerful feature of the shell is the capability to redirect the input and output \nof commands to and from other commands and files. To allow commands to be strung \ntogether, the shell uses metacharacters. A metacharacter  is a typed character that has spe -\ncial meaning to the shell for connecting commands or requesting expansion.\nMetacharacters include the pipe character ( |), ampersand ( &), semicolon ( ;), right parenthe -\nsis ()), left parenthesis ( (), less than sign ( <), and greater than sign ( >). The next sections \ndescribe how to use metacharacters on the command line to change how commands behave.\nPiping between commands\nThe pipe (|) metacharacter connects the output from one command to the input of another \ncommand. This lets you have one command work on some data and then have the next \ncommand deal with the results. Here is an example of a command line that includes pipes:\n$ cat /etc/passwd | sort | less\nThis command lists the contents of the /etc/passwd  file and pipes the output to the \nsort  command. The sort  command takes the usernames that begin each line of the /\netc/passwd  file, sorts them alphabetically, and pipes the output to the less  command \n(to page through the output).\nPipes are an excellent illustration of how UNIX, the predecessor of Linux, was created as an \noperating system made up of building blocks. A standard practice in UNIX was to connect \nutilities in different ways to get different jobs done. For example, before the days of graphical \nword processors, users created plain-text files that included macros to indicate formatting. To \nsee how the document really appeared, they would use a command such as the following:\n$ gunzip < /usr/share/man/man1/grep.1.gz | nroff -c -man | less", "doc_id": "da16f4c3-0f7f-4561-b8d6-4c1ca5dba149", "embedding": null, "doc_hash": "e8b83554e241c3ddbf4851a2f9c5f36915da24a61d84b36bc41fa9832729ce8d", "extra_info": {"page_label": "110"}, "node_info": {"start": 0, "end": 2761}, "relationships": {"1": "66bae01c-709a-4d44-9404-3f9047f2a3a1"}}, "__type__": "1"}, "9001d674-842a-4670-91bb-2dd8d45a0284": {"__data__": {"text": "Chapter 3: Using the Shell\n79\n3In this example, the contents of the grep  man page ( grep.1.gz ) are directed to the gun -\nzip command to be unzipped. The output from gunzip  is piped to the nroff  command to \nformat the man page using the manual macro ( -man). To display the output, it is piped to \nthe less  command. Because the file being displayed is in plain text, you could have sub -\nstituted any number of options to work with the text before displaying it. You could sort \nthe contents, change or delete some of the content, or bring in text from other documents. \nThe key is that, instead of all of those features being in one program, you get results from \npiping and redirecting input and output between multiple commands.\nSequential commands\nSometimes, you may want a sequence of commands to run, with one command completing \nbefore the next command begins. You can do this by typing several commands on the same \ncommand line and separating them with semicolons ( ;):\n$ date ; troff -me verylargedocument | lpr ; date\nIn this example, I was formatting a huge document and wanted to know how long it would \ntake. The first command ( date ) showed the date and time before the formatting started. \nThe troff  command formatted the document and then piped the output to the printer. \nWhen the formatting was finished, the date and time were printed again (so I knew how \nlong the troff  command took to complete).\nAnother useful command to add to the end of a long command line is mail . You could add \nthe following to the end of a command line:\n; mail -s \"Finished the long command\" chris@example.com\nThen, for example, a mail message is sent to the user you choose after the command \ncompletes.\nBackground commands\nSome commands can take a while to complete. Sometimes, you may not want to tie up your \nshell waiting for a command to finish. In those cases, you can have the commands run in \nthe background by using the ampersand ( &).\nText formatting commands (such as nroff  and troff , described earlier) are examples of \ncommands that can be run in the background to format a large document. You also might \nwant to create your own shell scripts that run in the background to check continuously for \ncertain events to occur, such as the hard disk filling up or particular users logging in.\nThe following is an example of a command being run in the background:\n$ troff -me verylargedocument | lpr &\nDon\u2019t close the shell until the process is completed or that kills the process. Other ways \nto manage background and foreground processes are described in Chapter\u00a06, \u201cManaging \nRunning Processes.\u201d", "doc_id": "9001d674-842a-4670-91bb-2dd8d45a0284", "embedding": null, "doc_hash": "46555677e053827a6b0b1e0d04ddce7363907843360bb85fa903af7b85c47731", "extra_info": {"page_label": "111"}, "node_info": {"start": 0, "end": 2613}, "relationships": {"1": "0ba1aae8-c08b-416a-a089-e448cd0dac8e"}}, "__type__": "1"}, "601760b6-cab2-4438-9ebd-c5db34c64eeb": {"__data__": {"text": "Part II: Becoming a Linux Power User80Expanding commands\nWith command substitution, you can have the output of a command interpreted by the \nshell instead of by the command itself. In this way, you can have the standard output of a \ncommand become an argument for another command. The two forms of command substitu -\ntion are $(command)  and `command`  (backticks, not single quotes).\nThe command in this case can include options, metacharacters, and arguments. The follow -\ning is an example of using command substitution:\n$ vi $(find /home | grep xyzzy)\nIn this example, the command substitution is done before the vi  command is run. First, \nthe find  command starts at the /home  directory and prints out all of the files and direc -\ntories below that point in the filesystem. The output is piped to the grep  command, which \nfilters out all files except for those that include the string xyzzy  in the filename. Finally, \nthe vi  command opens all filenames for editing (one at a time) that include xyzzy . (If you \nrun this and are not familiar with vi , you can type :q!  to exit the file.)\nThis particular example is useful if you want to edit a file for which you know the name but \nnot the location. As long as the string is uncommon, you can find and open every instance \nof a filename existing beneath a point you choose in the filesystem. (In other words, don\u2019t \nuse grep  from the root filesystem or you\u2019ll match and try to edit several thousand files.)\nExpanding arithmetic expressions\nSometimes, you want to pass arithmetic results to a command. There are two forms that \nyou can use to expand an arithmetic expression and pass it to the shell: $ [expression]  \nor $(expression) . The following is an example:\n$ echo \"I am $[2020 - 1957] years old.\"\nI am 63 years old.\nThe shell interprets the arithmetic expression first ( 2020 - 1957 ) and then passes that \ninformation to the echo  command. The echo  command displays the text with the results \nof the arithmetic ( 63) inserted.\nHere\u2019s an example of the other form:\n$ echo \"There are $(ls | wc -w) files in this directory.\"\nThere are 14 files in this directory.\nThis lists the contents of the current directory ( ls) and runs the word count command to \ncount the number of files found ( wc -w ). The resulting number (14, in this case) is echoed \nback with the rest of the sentence shown.\nExpanding variables\nVariables that store information within the shell can be expanded using the dollar sign ( $) \nmetacharacter. When you expand an environment variable on a command line, the value of \nthe variable is printed instead of the variable name itself, as follows:\n$ ls -l $BASH\n-rwxr-xr-x. 1 root root 1219248 Oct 12 17:59 /usr/bin/bash", "doc_id": "601760b6-cab2-4438-9ebd-c5db34c64eeb", "embedding": null, "doc_hash": "238541530d7bebb189ba10c4696015575060ef8b9daf310dca33ce94921d3b5b", "extra_info": {"page_label": "112"}, "node_info": {"start": 0, "end": 2705}, "relationships": {"1": "857614ac-526c-4f59-a12d-6029525bc104"}}, "__type__": "1"}, "bb64ea57-bd9d-49c4-8f02-12c2e8d6747e": {"__data__": {"text": "Chapter 3: Using the Shell\n81\n3Using $BASH  as an argument to ls -l  causes a long listing of the bash command to \nbe printed.\nUsing Shell Variables\nThe shell itself stores information that may be useful to the user\u2019s shell session in what are \ncalled variables . Examples of variables include $SHELL  (which identifies the shell you are \nusing), $PS1  (which defines your shell prompt), and $MAIL  (which identifies the location \nof your user\u2019s mailbox).\nYou can see all variables set for your current shell by typing the set  command. A subset of \nyour local variables is referred to as environment variables . Environment variables are var -\niables that are exported to any new shells opened from the current shell. Type env  to see \nenvironment variables.\nYou can type echo $ VALUE , where VALUE  is replaced by the name of a particular environ -\nment variable you want to list. And because there are always multiple ways to do anything \nin Linux, you can also type declare  to get a list of the current environment variables and \ntheir values along with a list of shell functions.\nBesides those that you set yourself, system files set variables that store things such as \nlocations of configuration files, mailboxes, and path directories. They can also store values \nfor your shell prompts, the size of your history list, and type of operating system. You can \nrefer to the value of any of those variables by preceding it with a dollar sign ( $) and plac -\ning it anywhere on a command line. For example:\n$ echo $USER\nchris\nThis command prints the value of the USER  variable, which holds your username ( chris ). \nSubstitute any other value for USER  to print its value instead.\nWhen you start a shell (by logging in via a virtual console or opening a Terminal \nwindow), many environment variables are already set. Table\u00a03.5 shows some variables \nthat are either set when you use a bash shell or that can be set by you to use with dif -\nferent features.\nCreating and using aliases\nUsing the alias  command, you can effectively create a shortcut to any command and \noptions that you want to run later. You can add and list aliases with the alias  command. \nConsider the following examples of using alias  from a bash shell:\n$ alias p='pwd ; ls \u2013CF'\n$ alias rm='rm -i'\nIn the first example, the letter p  is assigned to run the command pwd  and then to run \nls -CF  to print the current working directory and list its contents in column form. ", "doc_id": "bb64ea57-bd9d-49c4-8f02-12c2e8d6747e", "embedding": null, "doc_hash": "768e59b33c4ac09bbcf138e686217780cccc8ef45bda4b87bdbef4b866451071", "extra_info": {"page_label": "113"}, "node_info": {"start": 0, "end": 2447}, "relationships": {"1": "51f23144-4921-4e93-9e46-73aeac749fb6"}}, "__type__": "1"}, "59a04634-8fa5-4ef0-85d1-4188055bc5e2": {"__data__": {"text": "Part II: Becoming a Linux Power User82TABLE 3.5  Common Shell Environment Variables\nVariable Description\nBASH This contains the full pathname of the bash  command. This is usually \n/bin/bash .\nBASH_VERSION This is a number representing the current version of the \nbash  command.\nEUID This is the effective user ID number of the current user. It is assigned \nwhen the shell starts, based on the user\u2019s entry in the /etc/passwd  file.\nFCEDIT If set, this variable indicates the text editor used by the fc  command \nto edit history  commands. If this variable isn\u2019t set, the vi  \ncommand is used.\nHISTFILE This is the location of your history file. It is typically located at $HOME/.\nbash_history .\nHISTFILESIZE This is the number of history entries that can be stored. After this \nnumber is reached, the oldest commands are discarded. The default \nvalue is 1000.\nHISTCMD This returns the number of the current command in the history  list.\nHOME This is your home directory. It is your current working directory each \ntime you log in or type the cd command with any options.\nHOSTTYPE This is a value that describes the computer architecture on which \nthe Linux system is running. For Intel-compatible PCs, the value is \ni386, i486, i586, i686, or something like i386-linux . For AMD 64-bit \nmachines, the value is x86_64 .\nMAIL This is the location of your mailbox file. The file is typically your user -\nname in the /var/spool/mail directory .\nOLDPWD This is the directory that was the working directory before you changed \nto the current working directory.\nOSTYPE This name identifies the current operating system. For Fedora Linux, \nthe OSTYPE  value is either linux  or linux-gnu , depending on the \ntype of shell you are using. (Bash can run on other operating sys -\ntems as well.)\nPATH This is the colon-separated list of directories used to find commands \nthat you type. The default value for regular users varies for different \ndistributions but typically includes the following: /bin:/usr/bin:/\nusr/local/bin:/usr/bin/X11:/usr/X11R6/bin:~/bin . You need to \ntype the full path or a relative path to a command that you want to run \nwhich is not in your PATH. For the root user, the value also includes /\nsbin , /usr/sbin , and /usr/local/sbin .\nPPID This is the process ID of the command that started the current shell (for \nexample, the Terminal window containing the shell).", "doc_id": "59a04634-8fa5-4ef0-85d1-4188055bc5e2", "embedding": null, "doc_hash": "d6466d88f139412655241cf88f885ebba1d8f8e63898120b77e0e47728f39dcb", "extra_info": {"page_label": "114"}, "node_info": {"start": 0, "end": 2381}, "relationships": {"1": "5ac5bce2-022e-4dab-a6a8-b4071c6005b8"}}, "__type__": "1"}, "cfbd397a-82e7-45a6-87d2-e91e88259d51": {"__data__": {"text": "Chapter 3: Using the Shell\n83\n3The second example runs the rm  command with the -i  option each time you type \nrm. (This is an alias that is often set automatically for the root user. Instead of just \nremoving files, you are prompted for each individual file removal. This prevents you from \nautomatically removing all of the files in a directory by mistakenly typing something \nsuch as rm * .)\nWhile you are in the shell, you can check which aliases are set by typing the alias  \ncommand. If you want to remove an alias, use unalias . (Remember that if the alias  \nis set in a configuration file, it will be set again when you open another shell.)\nExiting the shell\nTo exit the shell when you are finished, type exit  or press Ctrl+D. If you go to the shell \nfrom a Terminal window and you are using the original shell from that window, exiting \ncauses the Terminal window to close. If you are at a virtual console, the shell exits and \nreturns you to a login prompt.Variable Description\nPROMPT_COMMAND This can be set to a command name that is run each time before your \nshell prompt is displayed. Setting PROMPT_COMMAND=date lists the \ncurrent date/time before the prompt appears.\nPS1 This sets the value of your shell prompt. There are many items that you \ncan read into your prompt (date, time, username, hostname, and so on). \nSometimes a command requires additional prompts, which you can set \nwith the variables PS2 , PS3, and so on.\nPWD This is the directory that is assigned as your current directory. This value \nchanges each time you change directories using the cd command.\nRANDOM Accessing this variable causes a random number to be generated. The \nnumber is between 0 and 99999.\nSECONDS This is the number of seconds since the time the shell was started.\nSHLVL This is the number of shell levels associated with the current shell \nsession. When you log in to the shell, the SHLVL  is 1. Each time you \nstart a new bash command (by, for example, using su  to become a new \nuser, or by simply typing bash ), this number is incremented.\nTMOUT This can be set to a number representing the number of seconds the \nshell can be idle without receiving input. After the number of seconds \nis reached, the shell exits. This security feature makes it less likely for \nunattended shells to be accessed by unauthorized people. (This must \nbe set in the login shell for it actually to cause the shell to log out the  \nuser.)", "doc_id": "cfbd397a-82e7-45a6-87d2-e91e88259d51", "embedding": null, "doc_hash": "7453b762d9c9676d04f12da6984528fdd2e656579873c8eae7e5296271653cef", "extra_info": {"page_label": "115"}, "node_info": {"start": 0, "end": 2425}, "relationships": {"1": "454f036c-11a4-417b-9da4-0cddd497e953"}}, "__type__": "1"}, "cf087e60-596b-457d-ae74-e17036c49961": {"__data__": {"text": "Part II: Becoming a Linux Power User84If you have multiple shells open from the same shell session, exiting a shell simply returns \nyou to the shell that launched the current shell. For example, the su  command opens a \nshell as a new user. Exiting from that shell simply returns you to the original shell.\nCreating Your Shell Environment\nYou can tune your shell to help you work more efficiently. You can set aliases to create \nshortcuts to your favorite command lines and environment variables to store bits of infor -\nmation. By adding those settings to shell configuration files, you can have the settings \navailable every time you open a shell.\nConfiguring your shell\nSeveral configuration files support how your shell behaves. Some of the files are executed \nfor every user and every shell, whereas others are specific to the user who creates the con -\nfiguration file. Table\u00a03.6 shows the files that are of interest to anyone using the bash shell \nin Linux. (Notice the use of ~ in the filenames to indicate that the file is located in each \nuser\u2019s home directory.)\nTo change the /etc/profile  or /etc/bashrc  files, you must be the root user. It is better \nto create an /etc/profile.d/custom.sh  file to add system-wide settings instead of \nTABLE 3.6  Bash Configuration Files\nFile Description\n/etc/profile This sets up user environment information for every user. It is executed \nwhen you first log in. This file provides values for your path in addition \nto setting environment variables for such things as the location of your \nmailbox and the size of your history files. Finally, /etc/profile  gathers \nshell settings from configuration files in the /etc/profile.d  directory.\n/etc/bashrc This executes for every user who runs the bash shell each time a bash \nshell is opened. It sets the default prompt and may add one or more \naliases. Values in this file can be overridden by information in each user\u2019s \n~/.bashrc  file.\n~/.\nbash_profileThis is used by each user to enter information that is specific to his or \nher use of the shell. It is executed only once\u2014when the user logs in. \nBy default, it sets a few environment variables and executes the user\u2019s \n.bashrc  file. This is a good place to add environment variables because, \nonce set, they are inherited by future shells.\n~/.bashrc This contains the information that is specific to your bash shells. It is read \nwhen you log in and also each time you open a new bash shell. This is the \nbest location to add aliases so that your shell picks them up.\n~/.\nbash_logoutThis executes each time you log out (exit the last bash shell).", "doc_id": "cf087e60-596b-457d-ae74-e17036c49961", "embedding": null, "doc_hash": "7479a030a72310a33994e09da4940edcb5f5a96f449cb979567e954457fa6da3", "extra_info": {"page_label": "116"}, "node_info": {"start": 0, "end": 2599}, "relationships": {"1": "1687e99f-7724-4f24-9079-d30ffd2a5d2a"}}, "__type__": "1"}, "e053c873-b43e-4b4e-8506-b8786504f608": {"__data__": {"text": "Chapter 3: Using the Shell\n85\n3editing those files directly, however. Users can change the information in the $HOME/  \n.bash_profile , $HOME/.bashrc , and $HOME/.bash_logout files in their own home \ndirectories.\nUntil you learn to use the vi  editor, described in Chapter\u00a05, \u201cWorking with Text Files,\u201d you \ncan use a simple editor called nano  to edit plain-text files. For example, enter the follow -\ning to edit and add stuff to your $HOME/.bashrc  file:\n$ nano $HOME/.bashrc\nWith the file open in nano , move the cursor down to the bottom of the file (using the \ndown arrow key). Type the line you want (for example, you could type alias d='date \n+%D' ). To save the file, press Ctrl+O (the letter O ); to quit, press Ctrl+X. The next time you \nlog in or open a new shell, you can use the new alias (in this case, just type d ). To have \nthe new information you just added to the file available from the current shell, type the \nfollowing:\n$ source $HOME/.bashrc\n$ d\n06/29/19\nThe following sections provide ideas about items to add to your shell configuration files. In \nmost cases, you add these values to the .bashrc  file in your home directory. However, if \nyou administer a system, you may want to set some of these values as defaults for all your \nLinux system\u2019s users.\nSetting your prompt\nYour prompt consists of a set of characters that appear each time the shell is ready to \naccept a command. The PS1  environment variable sets what the prompt contains and is \nwhat you will interact with most of the time. If your shell requires additional input, it uses \nthe values of PS2 , PS3 , and PS4 .\nWhen your Linux system is installed, often a prompt is set to contain more than just a \ndollar sign or pound sign. For example, in Fedora or Red Hat Enterprise Linux, your prompt \nis set to include the following information: your username, your hostname, and the base \nname of your current working directory. That information is surrounded by brackets and \nfollowed by a dollar sign (for regular users) or a pound sign (for the root user). The follow -\ning is an example of that prompt:\n[chris@myhost bin]$\nIf you change directories, the bin  name would change to the name of the new directory. \nLikewise, if you were to log in as a different user or to a different host, that information \nwould change.\nYou can use several special characters (indicated by adding a backslash to a variety of \nletters) to include different information in your prompt. Special characters can be used to \noutput your Terminal number, the date, and the time as well as other pieces of information. \nTable\u00a03.7 provides some examples (you can find more on the bash man page).", "doc_id": "e053c873-b43e-4b4e-8506-b8786504f608", "embedding": null, "doc_hash": "f749e9a87776222bb4f04bb0fd470ae3afb277f5b41a7c67bd2efd39cbc81a3d", "extra_info": {"page_label": "117"}, "node_info": {"start": 0, "end": 2659}, "relationships": {"1": "ac01eb7d-579b-4442-944e-d470cdaf74c3"}}, "__type__": "1"}, "5d533c52-3b66-47da-bf53-43cd16ea65dd": {"__data__": {"text": "Part II: Becoming a Linux Power User86tip\nIf you are setting your prompt temporarily by typing at the shell, you should put the value of PS1  in quotes. For exam -\nple, you could type export PS1= \"[\\t \\w]\\$ \" to see a prompt that looks like this:\n    [20:26:32 /var/spool]$.\nTo make a change to your prompt permanent, add the value of PS1  to your .bashrc   \nfile in your home directory (assuming that you are using the bash shell). There may  \nalready be a PS1  value in that file, which you can modify. Refer to the Bash Prompt HOWTO  TABLE 3.7  Characters to Add Information to Bash Prompt\nSpecial Character Description\n\\! This shows the current command history number. This includes all previous \ncommands stored for your username.\n\\# This shows the command number of the current command. This includes only \nthe commands for the active shell.\n\\$ This shows the user prompt ( $) or root prompt ( #), depending on which type \nof user you are.\n\\W This shows only the current working directory base name. For example, \nif the current working directory was /var/spool/mail , this value simply \nappears as mail .\n\\[ This precedes a sequence of nonprinting characters. This can be used to \nadd a Terminal control sequence into the prompt for such things as changing \ncolors, adding blink effects, or making characters bold. (Your Terminal deter -\nmines the exact sequences available.)\n\\] This follows a sequence of nonprinting characters.\n\\\\ This shows a backslash.\n\\d This displays the day name, month, and day number of the current date, for \nexample, Sat Jan 23.\n\\h This shows the hostname of the computer running the shell.\n\\n This causes a newline to occur.\n\\nnn This shows the character that relates to the octal number replacing nnn .\n\\s This displays the current shell name. For the bash shell, the value \nwould be bash .\n\\t This prints the current time in hours, minutes, and seconds, for exam -\nple, 10:14:39.\n\\u This prints your current username.\n\\w This displays the full path to the current working directory.", "doc_id": "5d533c52-3b66-47da-bf53-43cd16ea65dd", "embedding": null, "doc_hash": "d5377a4fe71e353dc7438f1bb556035f9be1971dc2a9e3b3dc934751b43ef45c", "extra_info": {"page_label": "118"}, "node_info": {"start": 0, "end": 2020}, "relationships": {"1": "d8210e9a-9042-4e19-be93-2fc2df776b63"}}, "__type__": "1"}, "4afbbc40-ac79-4467-b845-a96a319782c5": {"__data__": {"text": "Chapter 3: Using the Shell\n87\n3(http://www.tldp.org/HOWTO/Bash-Prompt-HOWTO ) for information on changing colors, com-\nmands, and other features of your bash shell prompt.\nAdding environment variables\nYou might want to consider adding a few environment variables to your .bashrc  file. \nThese can help make working with the shell more efficient and effective:\nTMOUT  This sets how long the shell can be inactive before bash automatically exits. \nThe value is the number of seconds for which the shell has not received input. This \ncan be a nice security feature, in case you leave your desk while you are still logged \nin to Linux. To prevent being logged off while you are working, you may want to set \nthe value to something like TMOUT=1800  (to allow 30 minutes of idle time). You can \nuse any Terminal session to close the current shell after a set number of seconds, for \nexample, TMOUT=30 .\nPATH As described earlier, the PATH variable sets the directories that are searched for \nthe commands that you use. If you often use directories of commands that are not in \nyour path, you can permanently add them. To do this, add a PATH variable to your \n.bashrc file. For example, to add a directory called /getstuff/bin, add the \nfollowing:\n         PATH=$PATH:/getstuff/bin ; export PATH\nThis example first reads all of the current path directories into the new PATH \n($PATH ), adds the /getstuff/bin  directory, and then exports the new PATH.\nCautio N\nSome people add the current directory to their PATH by adding a directory identified simply as a dot ( .), as follows:\n PATH=.:$PATH ; export PATH\nThis enables you to run commands in your current directory before evaluating any other command in the path (which \npeople may be used to if they have used DOS). However, the security risk with this procedure is that you could be in a \ndirectory that contains a command that you don\u2019t intend to run from that directory. For example, a malicious person \ncould put an ls  command in a directory that, instead of listing the content of your directory, does something devi -\nous. Because of this, the practice of adding the dot to your path is highly discouraged.\nWHATEVER  You can create your own environment variables to provide shortcuts in \nyour work. Choose any name that is not being used and assign a useful value to it. \nFor example, if you do lots of work with files in the /work/time/files/info/\nmemos  directory, you could set the following variable:\n         M=/work/time/files/info/memos ; export M\nYou could make that your current directory by typing cd $M . You could run a pro -\ngram from that directory called hotdog  by typing $M/hotdog . You could edit a \nfile from there called bun  by typing vi $M/bun .", "doc_id": "4afbbc40-ac79-4467-b845-a96a319782c5", "embedding": null, "doc_hash": "d5221ba8e624ee4bdcb46f40ff1f550db4674475a2586614cd08ea08826dca18", "extra_info": {"page_label": "119"}, "node_info": {"start": 0, "end": 2720}, "relationships": {"1": "b577be9d-89c2-4205-9feb-675d1fd64212"}}, "__type__": "1"}, "3ebaa7d7-81f8-4273-82c7-b2f975c3b027": {"__data__": {"text": "Part II: Becoming a Linux Power User88Getting Information about Commands\nWhen you first start using the shell, it can be intimidating. All that you see is a prompt. \nHow do you know which commands are available, which options they use, or how to use \nadvanced features? Fortunately, lots of help is available. Here are some places that you can \nlook to supplement what you learn in this chapter:\n\u25a0\u25a0Check the PATH. Type echo $PATH . You see a list of the directories containing \ncommands that are immediately accessible to you. Listing the contents of those \ndirectories displays most standard Linux commands. For example:\n$ ls /bin\narch     dd            fusermount   loadkeys   mv                   \nawk      df            gawk         login      nano                   \nbasename dmesg         gettext      ls         netstat                \nbash     dnsdomainname grep         lsblk      nice                 \ncat      domainname    gtar         lscgroup   nisdomainname          \nchgrp    echo          gunzip       lssubsys   ping               \nchmod    ed            gzip         mail       ping6           \nchown    egrep         hostname     mailx      ps                      \ncp       env           ipcalc       mkdir      pwd                  \ncpio     ex            kbd_mode     mknod      readlink              \ncsh      false         keyctl       mktemp     red                   \ncut      fgrep         kill         more       redhat_lsb_init        \ndash     find          link         mount      rm              \ndate     findmnt       ln           mountpoint rmdir           \n\u25a0\u25a0Use the help  command.  Some commands are built into the shell, so they do not \nappear in a directory. The help  command lists those commands and shows options \navailable with each of them. (Enter help | less  to page through the list.) For help \nwith a particular built-in command, enter help  command , replacing command with \nthe name that interests you. The help  command works with the bash shell only.\n\u25a0\u25a0Use --help  with the command. Many commands include a --help  option that \nyou can use to get information about how the command is used. For example, if you \nenter date --help | less , the output shows not only options, but also time \nformats that you can use with the date  command. Other commands simply use a \n\u2013h option, like fdisk -h .", "doc_id": "3ebaa7d7-81f8-4273-82c7-b2f975c3b027", "embedding": null, "doc_hash": "69f535e3a8184a05bdb81ab86379f7c154be78a3ffb663dc952cc415364c36e4", "extra_info": {"page_label": "120"}, "node_info": {"start": 0, "end": 2345}, "relationships": {"1": "2b042c68-67cb-449f-a093-24242822580e"}}, "__type__": "1"}, "42d91795-6991-4ed1-b71a-fddfb5162f53": {"__data__": {"text": "Chapter 3: Using the Shell\n89\n3\u25a0\u25a0Use the info  command.  The info  command is another tool for displaying infor -\nmation about commands from the shell. The info  command can move among a \nhierarchy of nodes to find information about commands and other items. Not all \ncommands have information available in the info database, but sometimes more \ninformation can be found there than on a man page.\n\u25a0\u25a0Use the man  command.  To learn more about a particular command, enter man  \ncommand . (Replace command with the command name you want.) A description of \nthe command and its options appears on the screen.\nMan pages are the most common means of getting information about commands as well as \nother basic components of a Linux system. Each man page falls into one of the categories \nlisted in Table\u00a03.8. As a regular user, you will be most interested in man pages in section\u00a01. \nAs a system administrator, you will also be interested in sections 5 and 8, and occasionally \nsection\u00a04. Programmers will be interested in section\u00a02 and 3 man pages.\nTABLE 3.8  Manual Page Sections\nSection Number Section Name Description\n1 User Commands Commands that can be run from the shell by a \nregular user (typically no administrative privilege \nis needed)\n2 System Calls Programming functions used within an application \nto make calls to the kernel\n3 C Library Functions Programming functions that provide interfaces to \nspecific programming libraries (such as those for \ncertain graphical interfaces or other libraries that \noperate in user space)\n4 Devices and \nSpecial FilesFilesystem nodes that represent hardware devices \n(such as Terminals or CD drives) or software devices \n(such as random number generators)\n5 File Formats and \nConventionsTypes of files (such as a graphics or word processing \nfile) or specific configuration files (such as the \npasswd  or group  file)\n6 Games Games available on the system\n7 Miscellaneous Overviews of topics such as protocols, filesystems, \ncharacter set standards, and so on\n8 System Administration \nTools and DaemonsCommands that require root or other administrative \nprivileges to use", "doc_id": "42d91795-6991-4ed1-b71a-fddfb5162f53", "embedding": null, "doc_hash": "5e4ac1dc422aa0a74eaaf86628da944879a8c3bf58b7e9e347efd7eaa1dbf3ae", "extra_info": {"page_label": "121"}, "node_info": {"start": 0, "end": 2116}, "relationships": {"1": "b1050cd5-7a1b-42ff-8e71-e5ef766fa427"}}, "__type__": "1"}, "8ef22460-9569-4e31-a62f-57039b3ab45f": {"__data__": {"text": "Part II: Becoming a Linux Power User90Options to the man  command enable you to search the man page database or display man \npages on the screen. Here are some examples of man commands and options:\n$ man -k passwd\n...\npasswd               (1)  - update user's authentication tokens\npasswd               (5)  - password file\n$ man passwd\n$ man 5 passwd\nUsing the -k  option, you can search the name and summary sections of all man pages \ninstalled on the system. There are about a dozen man pages that include \u201c passwd \u201d in the \nname or description of a command.\nNote\nIf man -k  displays no output, it may be that the man page database has not been initialized. Type mandb  as root \nto initialize the man page database.\nLet\u2019s say that the two man pages in which I am interested are the passwd  command (in \nsection\u00a01 of the man pages) and the passwd  file (in section\u00a05) man pages. Because just \ntyping man passwd  displays the section\u00a01 page, I need to request explicitly the section\u00a05 \nman page if I want to see that instead ( man 5 passwd ).\nWhile you are displaying a man page, you can view different parts of the file using Page \nDown and Page Up keys (to move a page at a time). Use the Enter key or up and down \narrows to move a line at a time. Press a forward slash ( /) and type a term to search the \ndocument for that term. Press n to repeat the search forward or N to repeat the search \nbackward. To quit the man page, type q .\nSummary\nTo become an expert Linux user, you must be able to use the shell to type commands. This \nchapter focuses on the bash shell, which is the one that is most commonly used with Linux \nsystems. You learned how commands are structured and how many special features, such as \nvariables, command completion, and aliases, are used.\nThe next chapter describes how to move around the Linux filesystem from the shell command line.\nExercises\nUse these exercises to test your knowledge of using the shell. These tasks assume that you \nare running a Fedora or Red Hat Enterprise Linux system (although some tasks work on \nother Linux systems as well). If you are stuck, solutions to the tasks are shown in Appendix \nB (although in Linux, there are often multiple ways to complete a task).", "doc_id": "8ef22460-9569-4e31-a62f-57039b3ab45f", "embedding": null, "doc_hash": "986bc9c9bbd2af9f8ef309bab6cc0a3e6bae74eef16552d401d71b1a7caab4ea", "extra_info": {"page_label": "122"}, "node_info": {"start": 0, "end": 2220}, "relationships": {"1": "e6ed634f-3ce9-4b0c-81d8-08a6587d0e09"}}, "__type__": "1"}, "9ac4f0cd-4510-4838-97d0-1825a73b455f": {"__data__": {"text": "Chapter 3: Using the Shell\n91\n31. From your desktop, switch to the third virtual console and log in to your user \naccount. Run a few commands. Then exit the shell and return to the desktop.\n2. Open a Terminal window and change the font color to red and the background \nto yellow.\n3. Find the location of the mount  command and the tracepath  man page.\n4. Type the following three commands, and then recall and change those commands \nas described:\n         $ cat /etc/passwd\n         $ ls $HOME\n         $ date\na. Use the command-line recall feature to recall the cat  command and change /\netc/passwd  to /etc/group .\nb. Recall the ls  command, determine how to list files by time (using the man \npage), and add that option to the ls $HOME  command line.\nc. Add format indicators to the date  command to display the date output as \nmonth /day/year.\n5. Run the following command, typing as few characters as possible (using tab \ncompletion):\n         basename /usr/share/doc/\n6. Use the cat  command to list the contents of the /etc/services  file and pipe \nthose contents to the less  command so that you can page through it (press q to \nquit when you are finished).\n7. Run the date  command in such a way that the output from that command pro -\nduces the current day, month, date, and year. Have that read into another \ncommand line, resulting in text that appears like the following (your date, of \ncourse, will be different): Today is Thursday, December 19, 2019 .\n8. Using variables, find out what your hostname, username, shell, and home direc -\ntories are currently set to.\n9. Create an alias called mypass  that displays the contents of the /etc/passwd  file \non your screen in such a way that it is available every time you log in or open a \nnew shell from your user account.\n10. Display the man page for the mount  system call.", "doc_id": "9ac4f0cd-4510-4838-97d0-1825a73b455f", "embedding": null, "doc_hash": "4797c2fea5ad7d5d0a256e13d8f61d00241511c963834758eac8373f7d88bcdd", "extra_info": {"page_label": "123"}, "node_info": {"start": 0, "end": 1835}, "relationships": {"1": "4e38e080-5759-48d7-bb6d-0056fa1c23ba"}}, "__type__": "1"}, "099c0fde-afc9-4757-b452-98bd77c8ee24": {"__data__": {"text": "93\nCHAPTER4\nMoving Around the Filesystem\nIN THIS CHAPTER\nLearning about the Linux filesystem\nListing file and directory attributes\nMaking files and directories\nListing and changing permission and ownership\nMaking copies and moving files\nThe Linux filesystem is the structure in which all of the information on your computer is stored. \nIn fact, one of the defining properties of the UNIX systems on which Linux is based is that \nnearly everything you need to identify on your system (data, commands, symbolic links, \ndevices, and directories) is represented by items in the filesystems. Knowing where things are and \nunderstanding how to get around the filesystem from the shell are critical skills in Linux.\nIn Linux, files are organized within a hierarchy of directories. Each directory can contain files as \nwell as other directories. You can refer to any file or directory using either a full path (for example, /\nhome/joe/myfile.txt ) or a relative path (for example, if /home/joe  were your current directory, \nyou could simply refer to the file as myfile.txt ).\nIf you were to map out the files and directories in Linux, it would look like an upside-down tree. At \nthe top is the root  directory (not to be confused with the root user), which is represented by a single \nslash (/). Below that is a set of common directories in the Linux system, such as bin , dev , home , \nlib, and tmp , to name a few. Each of those directories, as well as directories added to the root direc -\ntory, can contain subdirectories.\nFigure\u00a04.1 illustrates how the Linux filesystem is organized as a hierarchy. To demonstrate how \ndirectories are connected, the figure shows a /home  directory that contains a subdirectory for  \nthe user joe . Within the joe  directory are Desktop, Documents , and other subdirectories. To \nrefer to a file called memo1.doc  in the memos  directory, you can type the full path of /home/\njoe/Documents/memos/memo1.doc . If your current directory is /home/joe/ , refer to the file \nas Documents/memos/memo1.doc .\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "099c0fde-afc9-4757-b452-98bd77c8ee24", "embedding": null, "doc_hash": "7593aeccf897cae6b994e7c69bf6133e8e5bcab055e5fd5d4a4b5e3d86e55d03", "extra_info": {"page_label": "124"}, "node_info": {"start": 0, "end": 2153}, "relationships": {"1": "f5ae953c-eb66-46ce-82b4-3e00de3602af"}}, "__type__": "1"}, "d3a0e19d-b350-4df0-b41c-2da3d94f9102": {"__data__": {"text": "Part II: Becoming a Linux Power User94Some of these Linux directories may interest you:\n/bin Contains common Linux user commands, such as ls , sort , date , and chmod .\n/boot Has the bootable Linux kernel, initial RAM disk, and boot loader configuration \nfiles (GRUB).\n/dev Contains files representing access points to devices on your systems. These \ninclude terminal devices ( tty* ), hard disks ( hd* or sd* ), RAM (ram* ), and CD-ROM \n(cd*). Users can access these devices directly through these device files; however, \napplications often hide the actual device names to end users.\n/etc Contains administrative configuration files. Most of these files are plain-text files \nthat, given the user has proper permission, can be edited with any text editor.\n/home Contains directories assigned to each regular user with a login account. (The root \nuser is an exception, using /root  as his or her home directory.)\n/media Provides a standard location for automounting devices (removable media in par -\nticular). If the medium has a volume name, that name is typically used as the mount \npoint. For example, a USB drive with a volume name of myusb  would be mounted \non /media/myusb .\n/lib Contains shared libraries needed by applications in /bin  and /sbin  to boot \nthe system.\n/mnt A common mount point for many devices before it was supplanted by the stan -\ndard /media  directory. Some bootable Linux systems still use this directory to \nmount hard disk partitions and remote filesystems. Many people still use this \ndirectory to temporarily mount local or remote filesystems, which are not mounted \npermanently.\n/misc A directory sometimes used to automount filesystems upon request.\n/opt Directory structure available to store add-on application software.Downloads Documents Desktop\nprojects plans memos\nmemo1.docPictures Musicjoebin dev etc lib misc opt root usr\nboot home media mnt proc sbin tmp var/FIGURE 4.1\nThe Linux filesystem is organized as a hierarchy of directories.", "doc_id": "d3a0e19d-b350-4df0-b41c-2da3d94f9102", "embedding": null, "doc_hash": "7e852f96c2d709be4fcb445fa4a63ceff89ae9f442ca07ee67155cc7fb6128d5", "extra_info": {"page_label": "125"}, "node_info": {"start": 0, "end": 1981}, "relationships": {"1": "4af756e0-789a-44a1-8e5b-64fe974f1dd6"}}, "__type__": "1"}, "1e34e8c3-1add-41b2-87aa-7cc98e47191c": {"__data__": {"text": "Chapter 4: Moving Around the Filesystem\n95\n4/proc Contains information about system resources.\n/root Represents the root user\u2019s home directory. The home directory for root does not \nreside beneath /home  for security reasons.\n/sbin Contains administrative commands and daemon processes.\n/sys Contains parameters for such things as tuning block storage and \nmanaging cgroups.\n/tmp Contains temporary files used by applications.\n/usr Contains user documentation, games, graphical files ( X11), libraries ( lib), and a \nvariety of other commands and files that are not needed during the boot process. \nThe /usr  directory is meant for files that don\u2019t change after installation (in theory, \n/usr  could be mounted read-only).\n/var Contains directories of data used by various applications. In particular, this is  \nwhere you would place files that you share as an FTP server ( /var/ftp ) or a web \nserver (/var/www ). It also contains all system log files ( /var/log ) and spool files in  \n/var/spool  (such as mail , cups , and news ). The /var  directory contains directories \nand files that are meant to change often. On server computers, it is common to create \nthe /var  directory as a separate filesystem, using a filesystem type that can be  \neasily expanded.\nThe filesystems in the DOS or Microsoft Windows operating systems differ from Linux\u2019s file \nstructure, as the sidebar \u201cLinux Filesystems versus Windows-Based Filesystems\u201d explains.\nLinux Filesystems versus Windows-Based \nFilesystems\nAlthough similar in many ways, the Linux filesystem has some striking differences when compared to \nfilesystems used in MS-DOS and Windows operating systems. Here are a few of these differences:\n\u25a0\u25a0In MS-DOS and Windows filesystems, drive letters represent different storage devices. In \nLinux, all storage devices are connected to the filesystem hierarchy. So, the fact that all of \n/usr  may be on a separate hard disk or that /mnt/remote1  is a filesystem from another \ncomputer is invisible to the user.\n\u25a0\u25a0Slashes, rather than backslashes, are used to separate directory names in Linux. So  \nC:\\home\\joe  in a Microsoft system is /home/joe  in a Linux system.\n\u25a0\u25a0Filenames almost always have suffixes in DOS (such as .txt  for text files or .docx  for word-\nprocessing files). Although at times you can use that convention in Linux, three-character \nsuffixes have no required meaning in Linux. They can be useful for identifying a file type. \nMany Linux applications and desktop environments use file suffixes to determine the con -\ntents of a file. In Linux, however, DOS command extensions such as .com , .exe , and .bat  \ndon\u2019t necessarily signify an executable. (Permission flags make Linux files executable.)\n\u25a0\u25a0Every file and directory in a Linux system has permissions and ownership associated with it. \nSecurity varies among Microsoft systems. Because DOS and Microsoft Windows began as \nsingle-user systems, file ownership was not built into those systems when they were designed. \nLater releases added features such as file and folder attributes to address this problem.", "doc_id": "1e34e8c3-1add-41b2-87aa-7cc98e47191c", "embedding": null, "doc_hash": "afeb9452f0e5f603386771866a77918d438a66f090f8011db7f6c0d56cada477", "extra_info": {"page_label": "126"}, "node_info": {"start": 0, "end": 3078}, "relationships": {"1": "10aca370-0630-4f8c-92fe-f972d434803f"}}, "__type__": "1"}, "95cac827-53ca-4e9d-b9e8-e39a41290010": {"__data__": {"text": "Part II: Becoming a Linux Power User96Using Basic Filesystem Commands\nI want to introduce you to a few simple commands for getting around the filesystem to \nstart out. If you want to follow along, log in and open a shell. When you log in to a Linux \nsystem and open a shell, you are placed in your home directory. As a Linux user, most of \nthe files you save and work with will probably be in that directory or in subdirectories that \nyou create. Table\u00a04.1 shows commands to create and use files and directories.\nOne of the most basic commands that you use from the shell is cd . The cd  command can \nbe used with no options (to take you to your home directory) or with full or relative paths. \nConsider the following commands:\n$ cd /usr/share/\n$ pwd\n/usr/share\n$ cd doc\n$ pwd\n/usr/share/doc\n$ cd\n$ pwd\n/home/chris\nThe /usr/share  option represents the absolute path to a directory on the system. Because \nit begins with a slash ( /), this path tells the shell to start at the root of the filesystem and \ntake you to the share  directory that exists in the usr  directory. The doc  option to the \ncd command looks for a directory called doc  that is relative to the current directory. So \nthat command made /usr/share/doc  your current directory.\nAfter that, by typing cd  alone, you are returned to your home directory. If you ever \nwonder where you are in the filesystem, the pwd  command can help you. Here are a few \nother interesting cd  command options:\n$ cd ~\n$ pwd\n/home/chrisTABLE 4.1  Commands to Create and Use Files\nCommand Result\ncd Changes to another directory\npwd Prints the name of the current (or present) working directory\nmkdir Creates a directory\nchmod Changes the permission on a file or directory\nls Lists the contents of a directory", "doc_id": "95cac827-53ca-4e9d-b9e8-e39a41290010", "embedding": null, "doc_hash": "ba40ae392ed40f2fb0194844e5525ddb9e5704077a2045ede50eb2a4ec9f4706", "extra_info": {"page_label": "127"}, "node_info": {"start": 0, "end": 1755}, "relationships": {"1": "6259eb95-dfa8-47d0-9403-64eaaea39db5"}}, "__type__": "1"}, "485f11b9-7bdd-49a4-8c0d-a6de84f1b298": {"__data__": {"text": "Chapter 4: Moving Around the Filesystem\n97\n4$ cd ~/Music\n$ pwd\n/home/chris/Music\n$ cd ../../../usr\n$ pwd\n/usr\nThe tilde (~) represents your home directory. So cd ~  takes you there. You can use the \ntilde to refer to directories relative to your home directory as well, such as /home/chris/\nMusic  with ~/Music . Typing a name as an option takes you to a directory below the \ncurrent directory, but you can use two dots ( ..) to go to a directory above the current \ndirectory. The example shown takes you up three directory levels (to / ), and then takes \nyou into the /usr  directory.\nThe following steps lead you through the process of creating directories within your home \ndirectory and moving among your directories, with a mention of setting appropriate file \npermissions:\n1. Go to your home directory. To do this, simply type cd  in a shell and press Enter. \n(For other ways of referring to your home directory, see the sidebar \u201cIdentifying \nDirectories.\u201d)\n2. To make sure that you\u2019re in your home directory, type pwd. When I do this, I get \nthe following response (yours will reflect your home directory):\n$ pwd\n/home/joe\n3. Create a new directory called test  in your home directory, as follows:\n$ mkdir test\n4. Check the permissions of the directory:\n$ ls -ld test\ndrwxr-xr-x 2 joe sales 1024 Jan 24 12:17 test\nThis listing shows that test  is a directory ( d). The d is followed by the permis -\nsions (rwxr-xr-x ), which are explained later in the section \u201cUnderstanding File \nPermissions and Ownership.\u201d The rest of the information indicates the owner ( joe), \nthe group ( sales ), and the date that the files in the directory were most recently \nmodified (Jan 24 at 12:17 p.m.).\nNote\nWhen you add a new user in Fedora and Red Hat Enterprise Linux, the user is assigned to a group of the same name \nby default. For example, in the preceding text, the user joe  would be assigned to the group joe . This approach to \nassigning groups is referred to as the user private group scheme .\nFor now, enter the following:\n        $ chmod 700 test", "doc_id": "485f11b9-7bdd-49a4-8c0d-a6de84f1b298", "embedding": null, "doc_hash": "549e1c7b2ec4008932404b12bceb3a517fc825e9cf76c1900d219e8a0f662e26", "extra_info": {"page_label": "128"}, "node_info": {"start": 0, "end": 2049}, "relationships": {"1": "e6f66dfc-2c2b-4745-8dfb-d9c00d88aec4"}}, "__type__": "1"}, "d9ec12a4-5aab-46e7-bbd0-2fb793bbdf1e": {"__data__": {"text": "Part II: Becoming a Linux Power User98This step changes the permissions of the directory to give you complete access and \neveryone else no access at all. (The new permissions should read rwx ------.)\n5. Make the test directory your current directory as follows:\n$ cd test\n$ pwd\n/home/joe/test\nIf you followed along, at this point a subdirectory of your home directory called test  is \nyour current working directory. You can create files and directories in the test  directory \nalong with the descriptions in the rest of this chapter.\nUsing Metacharacters and Operators\nWhether you are listing, moving, copying, removing, or otherwise acting on files in your \nLinux system, certain special characters, referred to as metacharacters and operators, help \nyou to work with files more efficiently. Metacharacters can help you match one or more files \nwithout completely typing each filename. Operators enable you to direct information from \none command or file to another command or file.\nUsing file-matching metacharacters\nTo save you some keystrokes and enable you to refer easily to a group of files, the bash shell \nlets you use metacharacters. Anytime you need to refer to a file or directory, such as to \nlist, open, or remove it, you can use metacharacters to match the files you want. Here are \nsome useful metacharacters for matching filenames:\n* Matches any number of characters.\n? Matches any one character.\n[...] Matches any one of the characters between the brackets, which can include a hyphen-\nseparated range of letters or numbers.\nTry out some of these file-matching metacharacters by first going to an empty direc -\ntory (such as the test  directory described in the previous section) and creating some \nempty files:\n$ touch apple banana grape grapefruit watermelon\nThe touch  command creates empty files. The commands that follow show you how to use \nshell metacharacters with the ls  command to match filenames. Try the following com-\nmands to see whether you get the same responses:\n$ ls a*\napple\n$ ls g*\ngrape grapefruit\n$ ls g*t", "doc_id": "d9ec12a4-5aab-46e7-bbd0-2fb793bbdf1e", "embedding": null, "doc_hash": "e7a46ced57f08d87cb77f8a3c34a7d056a53fea73a8ae8bde5f00a750965d41f", "extra_info": {"page_label": "129"}, "node_info": {"start": 0, "end": 2047}, "relationships": {"1": "bc49cc78-5026-4547-a553-7a48caf7e892"}}, "__type__": "1"}, "a3a83ad9-c0e5-41c9-85c2-2ce8da7a35a6": {"__data__": {"text": "Chapter 4: Moving Around the Filesystem\n99\n4grapefruit\n$ ls *e*\napple grape grapefruit watermelon\n$ ls *n*\nbanana watermelon\nThe first example matches any file that begins with a ( apple ). The next example matches \nany files that begin with g ( grape , grapefruit ). Next, files beginning with g and \nending in t are matched ( grapefruit ). Next, any file that contains e in the name is \nmatched (apple , grape , grapefruit , watermelon ). Finally, any file that contains n is \nmatched (banana , watermelon ).\nHere are a few examples of pattern matching with the question mark ( ?):\n$ ls ????e\napple grape\n$ ls g???e*\ngrape grapefruit\nThe first example matches any five-character file that ends in e ( apple , grape ). The \nsecond matches any file that begins with g and has e as its fifth character ( grape , \ngrapefruit ).\nThe following examples use braces to do pattern matching:\n$ ls [abw]*\napple banana watermelon\n$ ls [agw]*[ne]\napple grape watermelon\nIn the first example, any file beginning with a , b, or w is matched. In the second, any \nfile that begins with a , g, or w and also ends with either n or e is matched. You can also \ninclude ranges within brackets. For example:\n$ ls [a-g]*\napple banana grape grapefruit\nHere, any filenames beginning with a letter from a through g are matched.\nUsing file-redirection metacharacters\nCommands receive data from standard input and send it to standard output. Using pipes \n(described earlier), you can direct standard output from one command to the standard \ninput of another. With files, you can use less than ( <) and greater than ( >) signs to direct \ndata to and from files. Here are the file-redirection characters:\n< Directs the contents of a file to the command. In most cases, this is the default action \nexpected by the command and the use of the character is optional; using less bigfile  \nis the same as less < bigfile .\n> Directs the standard output of a command to a file. If the file exists, the content of that \nfile is overwritten.", "doc_id": "a3a83ad9-c0e5-41c9-85c2-2ce8da7a35a6", "embedding": null, "doc_hash": "184afa2e9f3768a2c79038687e4888b3e63abcfe20702607f44eb5c1cd4e7b54", "extra_info": {"page_label": "130"}, "node_info": {"start": 0, "end": 2002}, "relationships": {"1": "5ada9111-0098-48d9-ad24-91da4e16be51"}}, "__type__": "1"}, "e8adb925-4bbe-499b-848e-3aaa84bdc0f6": {"__data__": {"text": "Part II: Becoming a Linux Power User1002> Directs standard error (error messages) to the file.\n&> Directs both standard output and standard error to the file.\n>> Directs the output of a command to a file, adding the output to the end of the \nexisting file.\nThe following are some examples of command lines where information is directed to and \nfrom files:\n$ mail root < ~/.bashrc\n$ man chmod | col -b > /tmp/chmod\n$ echo \"I finished the project on $(date)\" >> ~/projects\nIn the first example, the content of the .bashrc  file in the home directory is sent in a \nmail message to the computer\u2019s root user. The second command line formats the chmod  \nman page (using the man  command), removes extra back spaces ( col -b), and sends the \noutput to the file /tmp/chmod  (erasing the previous /tmp/chmod  file, if it exists). The \nfinal command results in the following text being added to the user\u2019s project file:\nI finished the project on Sat Jun 15 13:46:49 EDT 2019\nAnother type of redirection, referred to as here text  (also called here document ), enables you \nto type text that can be used as standard input for a command. Here documents involve \nentering two less-than characters ( <<) after a command, followed by a word. All typing fol -\nlowing that word is taken as user input until the word is repeated on a line by itself. Here \nis an example:\n$ mail root cnegus rjones bdecker << thetext\n> I want to tell everyone that there will be a 10 a.m.\n> meeting in conference room B. Everyone should attend.\n>\n> -- James\n> thetext\n$\nThis example sends a mail message to root, cnegus, rjones, and bdecker usernames. The \ntext entered between <<thetext  and thetext  becomes the content of the message. \nA common use of here text is to use it with a text editor to create or add to a file from \nwithin a script:\n/bin/ed /etc/resolv.conf <<resendit \na\nnameserver 100.100.100.100\n.\nw\nq\nresendit\nWith these lines added to a script run by the root user, the ed text editor adds the IP \naddress of a DNS server to the /etc/resolv.conf  file.", "doc_id": "e8adb925-4bbe-499b-848e-3aaa84bdc0f6", "embedding": null, "doc_hash": "796260931b3f261d5147b19b102482d0a89fbaf13d9813a0a26918a42cf73968", "extra_info": {"page_label": "131"}, "node_info": {"start": 0, "end": 2035}, "relationships": {"1": "f6c1500d-9301-4206-b926-33d4813eaf3c"}}, "__type__": "1"}, "88186046-2f14-4193-801f-62c1610a0831": {"__data__": {"text": "Chapter 4: Moving Around the Filesystem\n101\n4Using brace expansion characters\nBy using curly braces ( {}), you can expand out a set of characters across filenames, direc -\ntory names, or other arguments to which you give commands. For example, if you want to \ncreate a set of files such as memo1  through memo5 , you can do that as follows:\n$ touch memo{1,2,3,4,5}\n$ ls\nmemo1 memo2 memo3 memo4 memo5\nThe items that are expanded don\u2019t have to be numbers or even single digits. For example, \nyou could use ranges of numbers or digits. You could also use any string of characters, as \nlong as you separate them with commas. Here are some examples:\n$ touch {John,Bill,Sally}-{Breakfast,Lunch,Dinner}\n$ ls\nBill-Breakfast Bill-Lunch John-Dinner Sally-Breakfast Sally-Lunch\nBill-Dinner John-Breakfast John-Lunch Sally-Dinner\n$ rm -f {John,Bill,Sally}-{Breakfast,Lunch,Dinner}\n$ touch {a..f}{1..5}\n$ ls\na1 a3 a5 b2 b4 c1 c3 c5 d2 d4 e1 e3 e5 f2 f4\na2 a4 b1 b3 b5 c2 c4 d1 d3 d5 e2 e4 f1 f3 f5\nIn the first example, the use of two sets of braces means John, Bill, and Sally each have \nfilenames associated with Breakfast, Lunch, and Dinner. If I had made a mistake, I could \neasily recall the command and change touch  to rm -f  to delete all of the files. In the \nnext example, the use of two dots between letters a and f and numbers 1 and 5 specifies \nthe ranges to be used. Note the files that were created from those few characters.\nListing Files and Directories\nThe ls  command is the most common command used to list information about files and \ndirectories. Many options available with the ls  command allow you to gather different sets \nof files and directories as well as to view different kinds of information about them.\nBy default, when you type the ls  command, the output shows you all non-hidden files and \ndirectories contained in the current directory. When you type ls , however, many Linux \nsystems (including Fedora and RHEL) assign an alias ls  to add options. To see if ls  is \naliased, enter the following:\n$ alias ls\nalias ls='ls --color=auto'\nThe --color=auto  option causes different types of files and directories to be displayed in \ndifferent colors. So, return to the $HOME/test  directory created earlier in the chapter, add \na couple of different types of files, and then see what they look like with the ls  command.\n$ cd $HOME/test\n$ touch scriptx.sh apple", "doc_id": "88186046-2f14-4193-801f-62c1610a0831", "embedding": null, "doc_hash": "2f21dd3d6722d0a450751772a969e62170268017cb56bf1f4b42e60b46912c5b", "extra_info": {"page_label": "132"}, "node_info": {"start": 0, "end": 2380}, "relationships": {"1": "e655e4b7-40b9-4e3a-8cd7-7f870b921fde"}}, "__type__": "1"}, "9c1c62de-0914-48fd-8a74-5322d395a967": {"__data__": {"text": "Part II: Becoming a Linux Power User102$ chmod 755 scriptx.sh\n$ mkdir Stuff\n$ ln -s apple pointer_to_apple\n$ ls\napple pointer_to_apple scriptx.sh Stuff\nAlthough you can\u2019t see it in the preceding code example, the directory Stuff  shows up in \nblue, pointer_to_apple (a symbolic link) appears as aqua, and scriptx.sh  (which is \nan executable file) appears in green. All other regular files show up in black. Typing ls -l  \nto see a long listing of those files can make these different types of files clearer still:\n$ ls -l\ntotal 4\n-rw-rw-r--. 1 joe joe 0 Dec 18 13:38 apple\nlrwxrwxrwx. 1 joe joe 5 Dec 18 13:46 pointer_to_apple -> apple\n-rwxr-xr-x. 1 joe joe 0 Dec 18 13:37 scriptx.sh\ndrwxrwxr-x. 2 joe joe 4096 Dec 18 13:38 Stuff\nAs you look at the long listing, notice that the first character of each line shows the \ntype of file. A hyphen ( -) indicates a regular file, d indicates a directory, and l (lower -\ncase L ) indicates a symbolic link. An executable file (a script or binary file that runs as a \ncommand) has execute bits turned on ( x). See more on execute bits in the upcoming sec -\ntion \u201cUnderstanding File Permissions and Ownership.\u201d\nYou should become familiar with the contents of your home directory next. Use the -l  and \n-a options to ls .\n$ ls -la /home/joe\ntotal 158\ndrwxrwxrwx 2     joe   sales   4096 May 12 13:55 .\ndrwxr-xr-x 3     root  root    4096 May 10 01:49 ..\n-rw------- 1     joe   sales   2204 May 18 21:30 .bash_history\n-rw-r--r-- 1     joe   sales     24 May 10 01:50 .bash_logout\n-rw-r--r-- 1     joe   sales    230 May 10 01:50 .bash_profile\n-rw-r--r-- 1     joe   sales    124 May 10 01:50 .bashrc\ndrw-r--r-- 1     joe   sales   4096 May 10 01:50 .kde\n-rw-rw-r-- 1     joe   sales 149872 May 11 22:49 letter\n \n^          ^     ^     ^     ^      ^            ^\ncol 1  col 2 col 3 col 4 col 5 col  6        col 7\nDisplaying a long list ( -l option) of the contents of your home directory shows you more \nabout file sizes and directories. The total  line shows the total amount of disk space used \nby the files in the list (158 kilobytes in this example). Adding the all files option ( -a) dis-\nplays files that begin with a dot ( .). Directories such as the current directory ( .) and the \nparent directory ( ..)\u2014the directory above the current directory\u2014are noted as directories \nby the letter d at the beginning of each entry. Each directory begins with a d and each file \nbegins with a dash ( -).", "doc_id": "9c1c62de-0914-48fd-8a74-5322d395a967", "embedding": null, "doc_hash": "630023a6e4f131fdea7c54ffb6feffd33c3c5feaeb0bbab4608f8eda626b0f97", "extra_info": {"page_label": "133"}, "node_info": {"start": 0, "end": 2439}, "relationships": {"1": "1fc9dd74-5621-477c-b253-e131e9531c88"}}, "__type__": "1"}, "e7d15af7-f384-44d7-a6af-63138b0acb64": {"__data__": {"text": "Chapter 4: Moving Around the Filesystem\n103\n4The file and directory names are shown in column 7. In this example, a dot ( .) represents /\nhome/joe  and two dots ( ..) represent /home \u2014the parent directory of /joe . Most of the \nfiles in this example are dot ( .) files that are used to store GUI properties ( .kde  directory) \nor shell properties ( .bash  files). The only non-dot file in this list is the one named letter . \nColumn 3 shows the directory or file owner. The /home  directory is owned by root, and \neverything else is owned by the user joe, who belongs to the sales group (groups are listed \nin column 4).\nIn addition to the d or - , column 1 on each line contains the permissions set for that file \nor directory. Other information in the listing includes the number of hard links to the item \n(column 2), the size of each file in bytes (column 5), and the date and time each file was \nmost recently modified (column 6).\nHere are a few other facts about file and directory listings:\n\u25a0\u25a0The number of characters shown for a directory (4096 bytes in these examples) \nreflects the size of the file containing information about the directory. Although \nthis number can grow above 4096 bytes for a directory that contains lots of files, \nthis number doesn\u2019t reflect the size of files contained in that directory.\n\u25a0\u25a0The format of the time and date column can vary. Instead of displaying \u201cMay 12,\u201d \nthe date might be displayed as \u201c2019-05-12,\u201d depending upon the distribution \nand the language setting ( LANG  variable).\n\u25a0\u25a0On occasion, instead of seeing the execute bit ( x) set on an executable file, you \nmay see an s  in that spot instead. With an s  appearing within either the owner \n(-rwsr-xr-x ) or group ( -rwxr-sr-x ) permissions, or both ( -rwsr-sr-x ), the \napplication can be run by any user, but ownership of the running process is \nassigned to the application\u2019s user/group instead of that of the user launching the \ncommand. This is referred to as a set UID or set GID  program, respectively. For \nexample, the mount  command has permissions set as -rwsr-xr-x . This allows \nany user to run mount  to list mounted filesystems (although you still have to \nbe root to use mount  to actually mount filesystems from the command line, in \nmost cases).\n\u25a0\u25a0If a t  appears at the end of a directory, it indicates that the sticky bit  is set for \nthat directory (for example, drwxrwxr-t ). By setting the sticky bit on a direc -\ntory, the directory\u2019s owner can allow other users and groups to add files to the \ndirectory but prevent users from deleting each other\u2019s files in that directory. \nWith a set GID assigned to a directory, any files created in that directory are \nassigned the same group as the directory\u2019s group. (If you see a capital S  or T \ninstead of the execute bits on a directory, it means that the set GID or sticky bit \npermission, respectively, was set, but for some reason the execute bit was not \nalso turned on.)\n\u25a0\u25a0If you see a plus sign at the end of the permission bits (for example, -rw-rw-\nr--+), it means that extended attributes ( +), such as Access Control Lists (ACLs), \nare set on the file. A dot at the end (. ) indicates that SELinux is set on the file.", "doc_id": "e7d15af7-f384-44d7-a6af-63138b0acb64", "embedding": null, "doc_hash": "c026eb757beb61f09959fa345c2cc7b8127c4faf5f75ce9c311cb63ebefbc9ff", "extra_info": {"page_label": "134"}, "node_info": {"start": 0, "end": 3199}, "relationships": {"1": "ce6ae0e0-9ea9-44ec-b936-889d16a7b6e0"}}, "__type__": "1"}, "4252ff8b-69c8-498a-8fd2-00cedc96d2c2": {"__data__": {"text": "Part II: Becoming a Linux Power User104As I mentioned earlier, there are many useful options for the ls  command. Return to \nthe $HOME/test  directory in which you\u2019ve been working. Here are some examples of \nls options. Don\u2019t worry if the output doesn\u2019t exactly match what is in your directory at \nthis point.\nAny file or directory beginning with a dot ( .) is considered hidden and is not displayed by \ndefault with ls . These dot files are typically configuration files or directories that need to \nbe in your home directory but don\u2019t need to be seen in your daily work. The -a  lets you see \nthose files.\nThe -t  option displays files in the order in which they were most recently modified. With \nthe -F  option, a backslash ( /) appears at the end of directory names, an asterisk ( *) is \nadded to executable files, and an at sign ( @) is shown next to symbolic links.\nTo show hidden and non-hidden files:\n$ ls -a\n. apple docs grapefruit pointer_to_apple .stuff watermelon\n.. banana grape .hiddendir script.sh .tmpfile\nTo list all files by time most recently modified:\n$ ls -at\n.tmpfile .hiddendir .. docs watermelon banana script.sh\n. .stuff pointer_to_apple grapefruit apple grapeIdentifying Directories\nWhen you need to identify your home directory on a shell command line, you can use the following:\n$HOME This environment variable stores your home directory name.\n~ The tilde (~) represents your home directory on the command line.\nYou can also use the tilde to identify someone else\u2019s home directory. For example, ~joe  would be \nexpanded to the joe home directory (probably /home/joe) . So, if I wanted to go to the directory /\nhome/joe/test , I could enter cd ~joe/test  to get there.\nOther special ways of identifying directories in the shell include the following:\n. A single dot (. ) refers to the current directory.\n.. Two dots ( ..) refer to a directory directly above the current directory.\n$PWD This environment variable refers to the current working directory.\n$OLDPWD This environment variable refers to the previous working directory before you \nchanged to the current one. (Entering cd \u2013 returns you to the directory repre -\nsented by $OLDPWD .)", "doc_id": "4252ff8b-69c8-498a-8fd2-00cedc96d2c2", "embedding": null, "doc_hash": "e8f615a450ed12324d17a28772de52b7c31f1a26d82b3b8824069f8f47869d86", "extra_info": {"page_label": "135"}, "node_info": {"start": 0, "end": 2168}, "relationships": {"1": "e035d4e2-8194-4f90-9fdf-430c37f109ec"}}, "__type__": "1"}, "b0bd8c6a-5162-4f13-b824-e9c9b3e04435": {"__data__": {"text": "Chapter 4: Moving Around the Filesystem\n105\n4To list files and append file-type indicators:\n$ ls -F\napple banana docs/ grape grapefruit pointer_to_apple@ script.sh* \nwatermelon\nTo avoid displaying certain files or directories when you use ls , use the --hide=  option. \nIn the next set of examples, any file beginning with g does not appear in the output. Using \na -d option on a directory shows information about that directory instead of showing \nthe files and directories the directory contains. The -R  option lists all files in the current \ndirectory as well as any files or directories that are associated with the original directory. \nThe -S  option lists files by size.\nTo exclude any files beginning with the letter g in the list:\n$ ls --hide=g*\napple banana docs pointer_to_apple script.sh watermelon\nTo list info about a directory instead of the files it contains:\n$ ls -ld $HOME/test/\ndrwxrwxr-x. 4 joe joe 4096 Dec 18 22:00 /home/joe/test/\nTo create multiple directory layers (-p  is needed):\n$ mkdir -p $HOME/test/documents/memos/\nTo list all files and directories recursively from current directory down:\n$ ls -R\n...\nTo list files by size:\n$ ls -S\n...\nUnderstanding File Permissions and Ownership\nAfter you\u2019ve worked with Linux for a while, you are almost sure to get a Permission \ndenied  message. Permissions associated with files and directories in Linux were designed \nto keep users from accessing other users\u2019 private files and to protect important system files.\nThe nine bits assigned to each file for permissions define the access that you and others \nhave to your file. Permission bits for a regular file appear as -rwxrwxrwx . Those bits are \nused to define who can read, write, or execute the file.\nNote\nFor a regular file, a dash appears in front of the nine-bit permissions indicator. Instead of a dash, you might see a d \n(for a directory), l (for a symbolic link), b (for a block device), c (for a character device), s (for a socket), or p (for a \nnamed pipe).", "doc_id": "b0bd8c6a-5162-4f13-b824-e9c9b3e04435", "embedding": null, "doc_hash": "3a6f93d76eb5c34b9eaf673be9c4ac124e96450a7a8a3fb122f09c24549fc8b4", "extra_info": {"page_label": "136"}, "node_info": {"start": 0, "end": 1989}, "relationships": {"1": "8b72022d-35f0-4864-82e2-e23ee93e45b0"}}, "__type__": "1"}, "2e0a495a-e4d8-4d5d-8e28-a394f2674e23": {"__data__": {"text": "Part II: Becoming a Linux Power User106Of the nine-bit permissions, the first three bits apply to the owner\u2019s permission, the next \nthree apply to the group assigned to the file, and the last three apply to all others. The r \nstands for read, the w stands for write, and the x stands for execute permissions. If a dash \nappears instead of the letter, it means that permission is turned off for that associated \nread, write, or execute bit.\nBecause files and directories are different types of elements, read, write, and execute per -\nmissions on files and directories mean different things. Table\u00a04.2 explains what you can do \nwith each of them.\nAs noted earlier, you can see the permission for any file or directory by typing the ls -ld  \ncommand. The named file or directory appears as those shown in this example:\n$ ls -ld ch3 test\n-rw-rw-r-- 1 joe sales 4983 Jan 18 22:13 ch3\ndrwxr-xr-x 2 joe sales 1024 Jan 24 13:47 test\nThe first line shows that the ch3  file has read and write permission for the owner and the \ngroup. All other users have read permission, which means that they can view the file but \ncannot change its contents or remove it. The second line shows the test  directory (indi -\ncated by the letter d before the permission bits). The owner has read, write, and execute \npermissions while the group and other users have only read and execute permissions. As a \nresult, the owner can add, change, or delete files in that directory, and everyone else can \nonly read the contents, change to that directory, and list the contents of the directory. (If \nyou had not used the -d  options to ls , you would have listed files in the test directory \ninstead of permissions of that directory.)\nChanging permissions with chmod (numbers)\nIf you own a file, you can use the chmod  command to change the permission on it as you \nplease. In one method of doing this, each permission (read, write, and execute) is assigned \na number\u2014r=4, w=2, and x=1\u2014and you use each set\u2019s total number to establish the TABLE 4.2  Setting Read, Write, and Execute Permissions\nPermission File Directory\nRead View what\u2019s \nin the file.See what files and subdirectories it contains.\nWrite Change the file\u2019s \ncontent, rename it, \nor delete it.Add files or subdirectories to the directory. Remove files or \ndirectories from the directory.\nExecute Run the file as \na program.Change to the directory as the current directory, search \nthrough the directory, or execute a program from the \ndirectory. Access file metadata (file size, time stamps, and \nso on) of files in that directory.", "doc_id": "2e0a495a-e4d8-4d5d-8e28-a394f2674e23", "embedding": null, "doc_hash": "404f78042c72c68a0e7536bfe1715de0c6615d68479a14090b9ae8754cd33064", "extra_info": {"page_label": "137"}, "node_info": {"start": 0, "end": 2564}, "relationships": {"1": "2eabdcf0-f245-4cb0-a2fd-6c53a5374e93"}}, "__type__": "1"}, "895db094-7bc9-41ab-b9a5-7df9ebe2ef86": {"__data__": {"text": "Chapter 4: Moving Around the Filesystem\n107\n4permission. For example, to make permissions wide open for yourself as owner, you would \nset the first number to 7 (4+2+1), and then you would give the group and others read-only \npermission by setting both the second and third numbers to 4 (4+0+0), so that the final \nnumber is 744. Any combination of permissions can result from 0 (no permission) through 7 \n(full permission).\nHere are some examples of how to change permission on a file (named file ) and what the \nresulting permission would be:\nThe following chmod  command results in this permission: rwxrwxrwx\n# chmod 777 file\nThe following chmod  command results in this permission: rwxr-xr-x\n# chmod 755 file\nThe following chmod  command results in this permission: rw-r--r--\n# chmod 644 file\nThe following chmod  command results in this permission: ---------\n# chmod 000 file\nThe chmod  command also can be used recursively. For example, suppose that you wanted \nto give an entire directory structure 755 permission ( rwxr-xr-x ), starting at the $HOME/\nmyapps  directory. To do that, you could use the -R  option, as follows:\n$ chmod -R 755 $HOME/myapps\nAll files and directories below, and including, the myapps  directory in your home directory \nwill have 755 permissions set. Because the numbers approach to setting permission changes \nall permission bits at once, it\u2019s more common to use letters to change permission bits recur -\nsively over a large set of files.\nChanging permissions with chmod (letters)\nYou can also turn file permissions on and off using plus ( +) and minus ( \u2013) signs, respec -\ntively, along with letters to indicate what changes and for whom. Using letters, for each \nfile you can change permission for the user ( u), group (g), other (o), and all users ( a). \nWhat you would change includes the read ( r), write (w), and execute ( x) bits. For example, \nstart with a file that has all permissions open ( rwxrwxrwx ). Run the following chmod  \ncommands using minus sign options. The resulting permissions are shown to the right of \neach command.\nThe following chmod  command results in this permission: r-xr-xr-x\n$ chmod a-w file\nThe following chmod  command results in this permission: rwxrwxrw-\n$ chmod o-x file\nThe following chmod  command results in this permission: rwx------", "doc_id": "895db094-7bc9-41ab-b9a5-7df9ebe2ef86", "embedding": null, "doc_hash": "6821676b8e0ff46fc36fed20b5d835717765c2d2bb09c18c02cab555df107050", "extra_info": {"page_label": "138"}, "node_info": {"start": 0, "end": 2311}, "relationships": {"1": "25527a5f-1249-4765-a3e5-ccc1f86ba521"}}, "__type__": "1"}, "a652d009-6e8e-4c35-b04f-c2f609e05270": {"__data__": {"text": "Part II: Becoming a Linux Power User108$ chmod go-rwx file\nLikewise, the following examples start with all permissions closed ( --------- ). The plus \nsign is used with chmod  to turn permissions on.\nThe following chmod  command results in this permission: rw-------\n$ chmod u+rw files\nThe following chmod  command results in this permission: --x--x--x\n$ chmod a+x files\nThe following chmod  command results in this permission: r-xr-x---\n$ chmod ug+rx files\nUsing letters to change permission recursively with chmod  generally works better than \nusing numbers because you can change bits selectively instead of changing all permission \nbits at once. For example, suppose that you want to remove write permission for \u201cother\u201d \nwithout changing any other permission bits on a set of files and directories. You could do \nthe following:\n$ chmod -R o-w $HOME/myapps\nThis example recursively removes write permissions for \u201cother\u201d on any files and directories \nbelow the myapps  directory. If you had used numbers such as 644, execute permission \nwould be turned off for directories; using 755, execute permission would be turned on for \nregular files. Using o-w , only one bit is turned off and all other bits are left alone.\nSetting default file permission with umask\nWhen you create a file as a regular user, it\u2019s given permission rw-rw-r--  by default. A \ndirectory is given the permission rwxrwxr-x . For the root user, file and directory permis -\nsion are rw-r--r--  and rwxr-xr-x , respectively. These default values are determined by \nthe value of umask . Enter umask  to see what your umask  value is. For example:\n$ umask\n0002\nIf you ignore the leading zero for the moment, the umask  value masks what is considered \nto be fully opened permissions for a file 666 or a directory 777. The umask  value of 002 \nresults in permission for a directory of 775 ( rwxrwxr-x ). That same umask  results in a file \npermission of 644 ( rw-rw-r-- ). (Execute permissions are off by default for regular files.)\nTo change your umask  value temporarily, run the umask  command. Then try creating \nsome files and directories to see how the umask  value affects how permissions are set. \nFor example:\n$ umask 777 ; touch file01 ; mkdir dir01 ; ls -ld file01 dir01\nd---------. 2 joe joe 6 Dec 19 11:03 dir01\n----------. 1 joe joe 0 Dec 19 11:02 file01\n$ umask 000 ; touch file02 ; mkdir dir02 ; ls -ld file02 dir02", "doc_id": "a652d009-6e8e-4c35-b04f-c2f609e05270", "embedding": null, "doc_hash": "b67b4b11613daba6152da428b61908233675a1f0df20028aae160918af8c4169", "extra_info": {"page_label": "139"}, "node_info": {"start": 0, "end": 2397}, "relationships": {"1": "e76167d3-aabb-4ee5-820b-bac028ab042a"}}, "__type__": "1"}, "8e1a7291-61b8-41fd-b9f0-c596dca14cfa": {"__data__": {"text": "Chapter 4: Moving Around the Filesystem\n109\n4drwxrwxrwx. 2 joe joe 6 Dec 19 11:00 dir02/\n-rw-rw-rw-. 1 joe joe 0 Dec 19 10:59 file02\n$ umask 022 ; touch file03 ; mkdir dir03 ; ls -ld file03 dir03\ndrwxr-xr-x. 2 joe joe 6 Dec 19 11:07 dir03\n-rw-r--r--. 1 joe joe 0 Dec 19 11:07 file03\nIf you want to change your umask  value permanently, add a umask  command to the \n.bashrc  file in your home directory (near the end of that file). The next time you open a \nshell, your umask  is set to whatever value you chose.\nChanging file ownership\nAs a regular user, you cannot change ownership of files or directories to have them belong \nto another user. You can  change ownership as the root user. For example, suppose that you \ncreated a file called memo.txt  in the user joe \u2019s home directory while you were root user. \nHere\u2019s how you could change it to be owned by joe :\n# chown joe /home/joe/memo.txt\n# ls -l /home/joe/memo.txt\n-rw-r--r--. 1 joe root 0 Dec 19 11:23 /home/joe/memo.txt\nNotice that the chown  command changed the user to joe  but left the group as root . To \nchange both user and group to joe , you could enter the following instead:\n# chown joe:joe /home/joe/memo.txt\n# ls -l /home/joe/memo.txt\n-rw-r--r--. 1 joe joe 0 Dec 19 11:23 /home/joe/memo.txt\nThe chown  command can be use recursively as well. Using the recursive option ( -R) is help -\nful if you need to change a whole directory structure to ownership by a particular user. For \nexample, if you inserted a USB drive, which is mounted on the /media/myusb  directory, \nand you wanted to give full ownership of the contents of that drive to the user joe , you \ncould enter the following:\n# chown -R joe:joe /media/myusb\nMoving, Copying, and Removing Files\nCommands for moving, copying, and deleting files are fairly straightforward. To change \nthe location of a file, use the mv  command. To copy a file from one location to another, use \nthe cp  command. To remove a file, use the rm  command. These commands can be used to \nact on individual files and directories or recursively to act on many files and directories at \nonce. Here are some examples:\n$ mv abc def\n$ mv abc ~\n$ mv /home/joe/mymemos/ /home/joe/Documents/\nThe first mv  command moves the file abc  to the file def  in the same directory (essentially \nrenaming it), whereas the second mv  command moves the file abc  to your home directory ", "doc_id": "8e1a7291-61b8-41fd-b9f0-c596dca14cfa", "embedding": null, "doc_hash": "c188b35cf8821d11331b8279f144ac8923a9e0a886d59aafbc5df296e2254a45", "extra_info": {"page_label": "140"}, "node_info": {"start": 0, "end": 2372}, "relationships": {"1": "77a31f89-215d-4d74-a6bc-365b27bc278a"}}, "__type__": "1"}, "ebe07a89-1b27-4c43-8de5-c2ced123c616": {"__data__": {"text": "Part II: Becoming a Linux Power User110(~). The next mv  command moves the mymemos  directory (and all its contents) to the /\nhome/joe/Documents  directory.\nBy default, the mv  command overwrites any existing files if the file to which you are \nmoving exists. However, many Linux systems alias the mv  command so that it uses the -i  \noption (which causes mv  to prompt you before overwriting existing files). Here\u2019s how to \ncheck if that is true on your system:\n$ alias mv\nalias mv='mv -i'\nHere are some examples of using the cp  command to copy files from one location \nto another:\n$ cp abc def\n$ cp abc ~\n$ cp -r /usr/share/doc/bash-completion* /tmp/a/\n$ cp -ra /usr/share/doc/bash-completion* /tmp/b/\nThe first copy command ( cp) copies abc  to the new name def  in the same directory, \nwhereas the second copies abc  to your home directory ( ~), keeping the name abc . The two \nrecursive (-r) copies copy the bash-completion  directory and all of the files it contains, \nfirst to new /tmp/a/  and /tmp/b/  directories. If you run ls -l  on those two directories, \nyou see that for the cp  command run with the archive ( -a) option, the date/time stamps \nand permissions are maintained by the copy. Without the -a , current date/time stamps are \nused, and permissions are determined by your umask.\nThe cp  command typically also is aliased with the -i  option in order to prevent you from \ninadvertently overwriting files.\nAs with the cp  and mv  commands, rm  is also usually aliased to include the -i  option. This \ncan prevent the damage that can come from an inadvertent recursive remove ( -r) option. \nHere are some examples of the rm  command:\n$ rm abc\n$ rm *\nThe first remove command deletes the abc  file; the second removes all of the files in the \ncurrent directory (except that it doesn\u2019t remove directories and/or any files that start \nwith a dot). If you want to remove a directory, you need to use the recursive ( -r) option \nto rm  or, for an empty directory, you can use the rmdir  command. Consider the follow -\ning examples:\n$ rmdir /home/joe/nothing/\n$ rm -r /home/joe/bigdir/\n$ rm -rf /home/joe/hugedir/\nThe rmdir  command in the preceding code only removes the directory ( nothing ) if it is \nempty. The rm -r  example removes the directory bigdir  and all of its contents (files and \nmultiple levels of subdirectories), but it prompts you before each is removed. When you \nadd the force option ( -f), the hugedir  directory and all of its contents are immediately \nremoved, without prompting.", "doc_id": "ebe07a89-1b27-4c43-8de5-c2ced123c616", "embedding": null, "doc_hash": "35beeea0aadf723e966d3fa135d51d05233fb06a0aebe928b568408857d03402", "extra_info": {"page_label": "141"}, "node_info": {"start": 0, "end": 2518}, "relationships": {"1": "f4afdaaa-6044-45f9-b97e-be5d91f9246a"}}, "__type__": "1"}, "8c832c06-b34d-4d8a-ae08-47c80f6b3338": {"__data__": {"text": "Chapter 4: Moving Around the Filesystem\n111\n4Cautio N\nWhen you override the -i  option on the mv , cp, and rm  commands, you risk removing some (or lots) of files by mis -\ntake. Using wildcards (such as * ) and no -i  makes mistakes even more likely. That said, sometimes you don\u2019t want \nto be bothered to step through each file you delete. You have other options as follows:\n\u25a0\u25a0As noted with the -f  option, you can force rm  to delete without prompting. An alternative is to run rm , \ncp, or mv  with a backslash in front of it ( \\rm bigdir ). The backslash causes any command to run una -\nliased.\n\u25a0\u25a0Another alternative with mv  is to use the -b  option. With -b , if a file of the same name exists at the desti -\nnation, a backup copy of the old file is made before the new file is moved there.\nSummary\nCommands for moving around the filesystem, copying files, moving files, and removing files \nare among the most basic commands that you need to work from the shell. This chapter \ncovers lots of commands for moving around and manipulating files as well as commands for \nchanging ownership and permission.\nThe next chapter describes commands for editing and searching for files. These commands \ninclude the vim /vi text editors, the find  command, and the grep  command.\nExercises\nUse these exercises to test your knowledge of efficient ways to get around the Linux file -\nsystem and work with files and directories. When possible, try to use shortcuts to type \nas little as possible to get the desired results. These tasks assume that you are running a \nFedora or Red Hat Enterprise Linux system (although some tasks work on other Linux sys -\ntems as well). If you are stuck, solutions to the tasks are shown in Appendix B (although in \nLinux, there are often multiple ways to complete a task).\n1. Create a directory in your home directory called projects . In the projects  \ndirectory, create nine empty files that are named house1 , house2 , house3 , and \nso on up to house9 . Assuming that there are lots of other files in that directory, \ncome up with a single argument to ls  that would list just those nine files.\n2. Make the $HOME/projects/houses/doors/  directory path. Create the following \nempty files within this directory path (try using absolute and relative paths from \nyour home directory):\n        $HOME/projects/houses/bungalow.txt\n        $HOME/projects/houses/doors/bifold.txt\n        $HOME/projects/outdoors/vegetation/landscape.txt", "doc_id": "8c832c06-b34d-4d8a-ae08-47c80f6b3338", "embedding": null, "doc_hash": "cd299d1e514ec5e9e6b97c99beaa8cebff84babc76be7dc198286e640e04c5d9", "extra_info": {"page_label": "142"}, "node_info": {"start": 0, "end": 2455}, "relationships": {"1": "86b8a0c0-56e9-443e-990c-8c414c3e0e74"}}, "__type__": "1"}, "1f0aa7b4-fd65-4088-ad29-72d20ef68132": {"__data__": {"text": "Part II: Becoming a Linux Power User1123. Copy the files house1  and house5  to the $HOME/projects/houses/  directory.\n4. Recursively copy the /usr/share/doc/initscripts*  directory to the $HOME/\nprojects/  directory. Maintain the current date/time stamps and permissions.\n5. Recursively list the contents of the $HOME/projects/  directory. Pipe the output \nto the less  command so that you can page through the output.\n6. Remove the files house6 , house7 , and house8  without being prompted.\n7. Move house3  and house4  to the $HOME/projects/houses/doors  directory.\n8. Remove the $HOME/projects/houses/doors  directory and its contents.\n9. Change the permissions on the $HOME/projects/house2  file so that it can be \nread by and written to by the user who owns the file, only read by the group, and \nhave no permission for others.\n10. Recursively change permissions of the $HOME/projects/  directory so that \nnobody has write permission to any files or directory beneath that point in the \nfilesystem.", "doc_id": "1f0aa7b4-fd65-4088-ad29-72d20ef68132", "embedding": null, "doc_hash": "345c1eb01a37dd1cf4b7207d5ba20b2499dbdede59d880383bab261ad120f4bf", "extra_info": {"page_label": "143"}, "node_info": {"start": 0, "end": 1004}, "relationships": {"1": "38bf3468-8b9b-4e88-a101-1b416ebad97e"}}, "__type__": "1"}, "e6af6716-5c31-468b-80e3-1654459b527a": {"__data__": {"text": "113\nIN THIS CHAPTER\nUsing vim  and vi  to edit text files\nSearching for files\nSearching in files\nWhen the UNIX system, on which Linux was based, was created, most information was \nmanaged on the system in plain-text files. Thus, it was critical for users to know how to use \ntools for searching for and within plain-text files and to be able to change and configure \nthose files.\nToday, configuration of Linux systems can still be done by editing plain-text files. Whether you are \nmodifying files in the /etc  directory to configure a local service or editing Ansible inventory files to \nconfigure sets of host computers, plain-text files are still in common use for those tasks.\nBefore you can become a full-fledged system administrator, you need to be able to use a plain-text \neditor. The fact that most professional Linux servers don\u2019t even have a graphical interface avail -\nable makes the need for editing of plain-text configuration files with a non-graphical text editor \nnecessary.\nAfter you know how to edit text files, you still might find it tough to figure out where the files are \nlocated that you need to edit. With commands such as find , you can search for files based on var -\nious attributes (filename, size, modification date, and ownership to name a few). With the grep  \ncommand, you can search inside of text files to find specific search terms.\nEditing Files with vim and vi\nIt\u2019s almost impossible to use Linux for any period of time and not need a text editor because, as \nnoted earlier, most Linux configuration files are plain-text files that you will almost certainly need \nto change manually at some point.\nIf you are using a GNOME desktop, you can run gedit (type gedit  into the Search box and press \nEnter, or select Applications \u27aa Accessories \u27aa gedit), which is fairly intuitive for editing text.  Working with Text FilesCHAPTER5\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "e6af6716-5c31-468b-80e3-1654459b527a", "embedding": null, "doc_hash": "561cc2cc3d618cc043159c482341efa26219a6d41802fd6cec2f119d4e99c307", "extra_info": {"page_label": "144"}, "node_info": {"start": 0, "end": 1986}, "relationships": {"1": "d34affb4-f471-407d-b31d-03a4787b1aaf"}}, "__type__": "1"}, "0481642f-3849-44f8-8eb2-592e12506acd": {"__data__": {"text": "Part II: Becoming a Linux Power User114You can also run a simple text editor called nano  from the shell. However, most Linux shell \nusers use either the vi  or emacs  command to edit text files.\nThe advantage of vi  or emacs  over a graphical editor is that you can use the command \nfrom any shell, character terminal, or character-based connection over a network (using \ntelnet  or ssh,  for example)\u2014no graphical interface is required. They each also contain \ntons of features, so you can continue to grow with them.\nThe following sections provide a brief tutorial on the vi  text editor, which you can use \nto manually edit a text file from any shell. It also describes the improved versions of vi  \ncalled vim . (If vi  doesn\u2019t suit you, see the sidebar \u201cExploring Other Text Editors\u201d for fur -\nther options.)\nThe vi  editor is difficult to learn at first, but after you know it, you never have to use a \nmouse or a function key\u2014you can edit and move around quickly and efficiently within files \njust by using the keyboard.\nExploring Other Text Editors\nDozens of text editors are available for use with Linux. Some alternatives might be in your Linux distri -\nbution. You can try them out if you find vi  to be too taxing. Here are some of the options:\nnano : This popular, streamlined text editor is used with many bootable Linux systems and other \nlimited-space Linux environments. For example, nano  is available to edit text files during a \nGentoo Linux install process.\ngedit : The GNOME text editor runs on the desktop.\njed: This screen-oriented editor was made for programmers. Using colors, jed  can highlight \ncode that you create so that you can easily read the code and spot syntax errors. Use the Alt \nkey to select menus to manipulate your text.\njoe: The joe editor is similar to many PC text editors. Use control and arrow keys to move \naround. Press Ctrl+C to exit with no save or Ctrl+X to save and exit.\nkate : This nice-looking editor comes in the kdebase  package. It has lots of bells and whis -\ntles, such as highlighting for different types of programming languages and controls for \nmanaging word wrap.\nkedit : This GUI-based text editor comes with the KDE desktop.\nmcedit : In this editor, function keys help you get around, save, copy, move, and delete \ntext. Like jed  and joe , mcedit  is screen oriented. It comes in the mc package in RHEL \nand Fedora.\nnedit : This is an excellent programmer\u2019s editor. You need to install the optional nedit  \npackage to get this editor.\nIf you use ssh  to log in to other Linux computers on your network, you can use any available text edi -\ntor to edit files. If you use ssh -X  to connect to the remote system, a GUI-based editor pops up on \nyour local screen. When no GUI is available, you need a text editor that runs in the shell, such as vi , \njed, or joe .", "doc_id": "0481642f-3849-44f8-8eb2-592e12506acd", "embedding": null, "doc_hash": "d3181c76ef8fab87c4a6c1376b21a7490b8c65a79959613c12fb876a1505b6a8", "extra_info": {"page_label": "145"}, "node_info": {"start": 0, "end": 2831}, "relationships": {"1": "9a3a8250-2296-4dd1-8e08-a032b86a9308"}}, "__type__": "1"}, "9a62d6f7-34ee-40b5-ba4e-cd5e8399dba8": {"__data__": {"text": "Chapter 5: Working with Text Files\n115\n5Starting with vi\nMost often, you start vi  to open a particular file. For example, to open a file called /tmp/\ntest , enter the following command:\n$ vi /tmp/test\nIf this is a new file, you should see something similar to the following:\n\u25a1\n~\n~\n~\n~\n~\n\"/tmp/test\" [New File]\nA blinking box at the top represents where your cursor is located. The bottom line keeps \nyou informed about what is going on with your editing (here, you just opened a new file). \nIn between, there are tildes ( ~) as filler because there is no text in the file yet. Now here\u2019s \nthe intimidating part: There are no hints, menus, or icons to tell you what to do. To make \nit worse, you can\u2019t just start typing. If you do, the computer is likely to beep at you. (And \nsome people complain that Linux isn\u2019t friendly.)\nFirst, you need to know the two main operating modes: command and input. The vi  editor \nalways starts in command mode. Before you can add or change text in the file, you have to \ntype a command (one or two letters, sometimes preceded by an optional number) to tell vi  \nwhat you want to do. Case is important, so use uppercase and lowercase exactly as shown in \nthe examples!\nAdding text\nTo get into input mode, type an input command letter. To begin, type any of the following \nletters. When you are finished inputting text, press the Esc key (sometimes twice) to return \nto command mode. Remember the Esc key!\na: The add  command. With this command, you can input text that starts to the right  of \nthe cursor.\nA: The add at end command. With this command, you can input text starting at the \nend of the current line.Note\nOn Red Hat Enterprise Linux, Fedora, and other Linux distributions, for regular users the vi  command is aliased \nto run vim . If you type alias vi , you should see alias vi='vim' . The first obvious difference between vi  \nand vim  is that any known text file type, such as HTML, C code, or a common configuration file, appears in color. \nThe colors indicate the structure of the file. Other features of vim  that are not in vi  include features such as visual \nhighlighting and split-screen mode. By default, the root user doesn\u2019t have vi  aliased to vim . If vim  is not on your \nsystem, try installing the vim-enhanced package.", "doc_id": "9a62d6f7-34ee-40b5-ba4e-cd5e8399dba8", "embedding": null, "doc_hash": "2398f205d68dc61dc90c9e28c1370dc866bbedb9a8be4ce9d997931b09536702", "extra_info": {"page_label": "146"}, "node_info": {"start": 0, "end": 2282}, "relationships": {"1": "1c7fb51d-08e0-4d66-ba35-56b0cde4fdaf"}}, "__type__": "1"}, "3f10434d-6d77-4b4d-9aa9-eb4c88694ddf": {"__data__": {"text": "Part II: Becoming a Linux Power User116i: The insert  command. With this command, you can input text that starts to the left  \nof the cursor.\nI: The insert at beginning  command. With this command, you can input text that starts \nat the beginning of the current line.\no: The open below command. This command opens a line below the current line and \nputs you in insert mode.\nO: The open above  command. This command opens a line above the current line and \nputs you in insert mode.\nType a few words, and press Enter. Repeat that a few times until you have a few lines of \ntext. When you\u2019re finished typing, press Esc to return to command mode. Now that you \nhave a file with some text in it, try moving around in your text with the keys or letters \ndescribed in the next section.\nMoving around in the text\nTo move around in the text, you can use the up, down, right, and left arrows. However, many of \nthe keys for moving around are right under your fingertips when they are in typing position:\nArrow keys : Move the cursor up, down, left, or right in the file one character at a time. \nTo move left and right, you can also use Backspace and the spacebar, respectively. \nIf you prefer to keep your fingers on the keyboard, move the cursor with h (left), l \n(right), j (down), or k (up).\nw: Moves the cursor to the beginning of the next word (delimited by spaces, tabs, or \npunctuation).\nW: Moves the cursor to the beginning of the next word (delimited by spaces or tabs).\nb: Moves the cursor to the beginning of the previous word (delimited by spaces, tabs, \nor punctuation).\nB: Moves the cursor to the beginning of the previous word (delimited by \nspaces or tabs).\n0 (zero) : Moves the cursor to the beginning of the current line.\n$: Moves the cursor to the end of the current line.\nH: Moves the cursor to the upper-left corner of the screen (first line on the screen).tip\nWhen you are in insert mode, -- INSERT -- appears at the bottom of the screen.\ntip\nRemember the Esc key! It always places you back into command mode. Remember that sometimes you must press \nEsc twice. For example, if you type a colon ( :) to go into ex  mode, you must press Esc twice to return to command \nmode.", "doc_id": "3f10434d-6d77-4b4d-9aa9-eb4c88694ddf", "embedding": null, "doc_hash": "d72f41fe751b08c057adaf5ba1bb4c8a3b5ce1df9fb930c74e351c6b28962da0", "extra_info": {"page_label": "147"}, "node_info": {"start": 0, "end": 2185}, "relationships": {"1": "1e46dfa7-2624-49bf-9626-0948ebdc29d7"}}, "__type__": "1"}, "8d958897-0bad-40dd-a1e8-1210016a3a9c": {"__data__": {"text": "Chapter 5: Working with Text Files\n117\n5M: Moves the cursor to the first character of the middle line on the screen.\nL: Moves the cursor to the lower-left corner of the screen (last line on the screen).\nDeleting, copying, and changing text\nThe only other editing that you need to know is how to delete, copy, or change text. The  \nx, d, y, and c commands can be used to delete and change text. These can be used along \nwith movement keys (arrows, PgUp, PgDn, letters, and special keys) and numbers to indi-\ncate exactly what you are deleting, copying, or changing. Consider the following examples:\nx: Deletes the character under the cursor.\nX: Deletes the character directly before the cursor.\nd<?>: Deletes some text.\nc<?>: Changes some text.\ny<?>: Yanks (copies) some text.\nThe <?>  after each letter in the preceding list identifies the place where you can use a \nmovement command to choose what you are deleting, changing, or yanking. For example:\ndw: Deletes (d) a word (w) after the current cursor position.\ndb: Deletes (d) a word (b) before the current cursor position.\ndd: Deletes (d) the entire current line ( d).\nc$: Changes ( c) the characters (actually erases them) from the current character to the \nend of the current line ( $) and goes into input mode.\nc0: Changes ( c) (again, erases) characters from the previous character to the beginning \nof the current line ( 0) and goes into input mode.\ncl: Erases (c) the current letter ( l) and goes into input mode.\ncc: Erases (c) the line ( c) and goes into input mode.\nyy: Copies (y) the current line ( y) into the buffer.\ny): Copies (y) the current sentence ( ) ), to the right of the cursor, into the buffer.\ny}: Copies (y) the current paragraph ( } ), to the right of the cursor, into the buffer.\nAny of the commands just shown can be further modified using numbers, as you can see in \nthe following examples:\n3dd: Deletes (d) three (3) lines (d), beginning at the current line.\n3dw: Deletes (d) the next three ( 3) words (w).\n5cl: Changes ( c) the next five ( 5) letters (l) (that is, removes the letters and enters \ninput mode).\n12j: Moves down ( j) 12 lines ( 12).\n5cw: Erases (c) the next five ( 5) words (w) and goes into input mode.\n4y): Copies (y) the next four ( 4) sentences ( ) ).", "doc_id": "8d958897-0bad-40dd-a1e8-1210016a3a9c", "embedding": null, "doc_hash": "ee21f5ec893353c1555510e256e3637c97c1725955c5f6e4893a62298572df98", "extra_info": {"page_label": "148"}, "node_info": {"start": 0, "end": 2253}, "relationships": {"1": "a69df4c0-ea51-4dcb-9a17-c69805fa9b6c"}}, "__type__": "1"}, "47247f16-8589-49f1-9959-602e9f9fc179": {"__data__": {"text": "Part II: Becoming a Linux Power User118Pasting (putting) text\nAfter text has been copied to the buffer (by deleting, changing, or yanking it), you can \nplace that text back in your file using the letter p or P . With both commands, the text most \nrecently stored in the buffer is put into the file in different ways.\nP: Puts the copied text to the left of the cursor if the text consists of letters or words; \nputs the copied text above the current line if the copied text contains lines of text.\np: Puts the buffered text to the right of the cursor if the text consists of letters or \nwords; puts the buffered text below the current line if the buffered text contains \nlines of text.\nRepeating commands\nAfter you delete, change, or paste text, you can repeat that action by typing a period ( .). \nFor example, with the cursor on the beginning of the name Joe , you type cw  and then \ntype Jim  to change Joe  to Jim . You search for the next occurrence of Joe  in the file, \nposition the cursor at the beginning of that name, and press a period. The word changes to \nJim, and you can search for the next occurrence. You can go through a file this way, press -\ning n to go to the next occurrence and period ( .) to change the word.\nExiting vi\nTo wrap things up, use the following commands to save or quit the file:\nZZ: Saves the current changes to the file and exits from vi .\n:w: Saves the current file, but you can continue editing.\n:wq: Works the same as ZZ .\n:q: Quits the current file. This works only if you don\u2019t have any unsaved changes.\n:q!: Quits the current file and doesn\u2019t  save the changes you just made to the file.\nYou have learned a few vi  editing commands. I describe more commands in the following \nsections. First, however, consider the following tips to smooth out your first trials with vi :\nEsc: Remember that Esc gets you back to command mode. (I\u2019ve watched people press \nevery key on the keyboard trying to get out of a file.) Esc followed by ZZ  gets you \nout of command mode, saves the file, and exits.\nu: Press u to undo the previous change you made. Continue to press u to undo the \nchange before that and the one before that.tip\nIf you\u2019ve really trashed the file by mistake, the :q!  command is the best way to exit and abandon your changes. The \nfile reverts to the most recently changed version. So, if you just saved with :w , you are stuck with the changes up \nto that point. However, despite having saved the file, you can type u to back out of changes (all the way back to the \nbeginning of the editing session if you like) and then save again.", "doc_id": "47247f16-8589-49f1-9959-602e9f9fc179", "embedding": null, "doc_hash": "cb3a54214ddf5a213e50cea67a6ff302870f99d65b6b304e3a00d2c2a40b6896", "extra_info": {"page_label": "149"}, "node_info": {"start": 0, "end": 2581}, "relationships": {"1": "da41f435-b72a-4994-bce2-25541f68afd4"}}, "__type__": "1"}, "95a57764-0915-4b4f-9824-2b9f570903a5": {"__data__": {"text": "Chapter 5: Working with Text Files\n119\n5Ctrl+R : If you decide that you didn\u2019t want to undo the previous undo command, use \nCtrl+R for Redo. Essentially, this command undoes your undo.\nCaps Lock : Beware of hitting Caps Lock by mistake. Everything that you type in vi  \nhas a different meaning when the letters are capitalized. You don\u2019t get a warning \nthat you are typing capitals; things just start acting weird.\n:!command : You can run a shell command while you are in vi  using :!  followed by a \nshell command name. For example, type :!date  to see the current date and time, \ntype :!pwd  to see what your current directory is, or type :!jobs  to see whether \nyou have any jobs running in the background. When the command completes, press \nEnter and you are back to editing the file. You could even use this technique to \nlaunch a shell (:!bash)  from vi , run a few commands from that shell, and then \ntype exit  to return to vi . (I recommend doing a save before escaping to the shell, \njust in case you forget to go back to vi .)\nCtrl+g : If you forget what you are editing, pressing these keys displays the name of the \nfile that you are editing and the current line that you are on at the bottom of the \nscreen. It also displays the total number of lines in the file, the percentage of how \nfar you are through the file, and the column number the cursor is on. This just helps \nyou get your bearings after you\u2019ve stopped for a cup of coffee at 3 a.m.\nSkipping around in the file\nBesides the few movement commands described earlier, there are other ways of moving \naround a vi  file. To try these out, open a large file that you can\u2019t damage too much. (Try \ncopying /var/log/messages  to /tmp  and opening it in vi .) Here are some movement \ncommands that you can use:\nCtrl+f : Pages ahead one page at a time.\nCtrl+b : Pages back one page at a time.\nCtrl+d : Pages ahead one-half page at a time.\nCtrl+u : Pages back one-half page at a time.\nG: Goes to the last line of the file.\n1G: Goes to the first line of the file.\n35G: Goes to any line number (35, in this case).\nSearching for text\nTo search for the next or previous occurrence of text in the file, use either the slash ( /) or \nthe question mark ( ?) character. Follow the slash or question mark with a pattern (string of \ntext) to search forward or backward, respectively, for that pattern. Within the search, you \ncan also use metacharacters. Here are some examples:\n/hello : Searches forward for the word hello .\n?goodbye : Searches backward for the word goodbye .", "doc_id": "95a57764-0915-4b4f-9824-2b9f570903a5", "embedding": null, "doc_hash": "1671f5d75313dfb75032931a43d920cc559103c0027d191bb1f08041d46ec8b0", "extra_info": {"page_label": "150"}, "node_info": {"start": 0, "end": 2532}, "relationships": {"1": "496f15d6-052f-4ba9-83a4-5e05adc6378d"}}, "__type__": "1"}, "a4261f44-e4cd-46b8-b24d-dd8ef8bc60bf": {"__data__": {"text": "Part II: Becoming a Linux Power User120/The.*foot : Searches forward for a line that has the word The  in it and also, after \nthat at some point, the word foot .\n?[pP]rint : Searches backward for either print  or Print . Remember that case mat -\nters in Linux, so make use of brackets to search for words that could have different \ncapitalization.\nAfter you have entered a search term, simply type n or N to search again in the same direc -\ntion (n) or the opposite direction ( N) for the term.\nUsing ex mode\nThe vi  editor was originally based on the ex  editor, which didn\u2019t let you work in full-\nscreen mode. However, it did enable you to run commands that let you find and change \ntext on one or more lines at a time. When you type a colon and the cursor goes to the bot -\ntom of the screen, you are essentially in ex  mode. The following are examples of some of \nthose ex  commands for searching for and changing text. (I chose the words Local  and \nRemote  to search for, but you can use any appropriate words.)\n:g/Local : Searches for the word Local  and prints every occurrence of that \nline from the file. (If there is more than a screenful, the output is piped to the \nmore  command.)\n:s/Local/Remote : Substitutes Remote  for the first occurrence of the word Local  \non the current line.\n:g/Local/s//Remote : Substitutes the first occurrence of the word Local  on every \nline of the file with the word Remote .\n:g/Local/s//Remote/g : Substitutes every occurrence of the word Local  with the \nword Remote  in the entire file.\n:g/Local/s//Remote/gp : Substitutes every occurrence of the word Local  with the \nword Remote  in the entire file and then prints each line so that you can see the \nchanges (piping it through less  if output fills more than one page).\nLearning more about vi and vim\nTo learn more about the vi  editor, try typing vimtutor . The vimtutor  command opens a \ntutorial in the vim  editor that steps you through common commands and features you can \nuse in vim . To use vimtutor , install the vim -enhanced package.\nFinding Files\nEven a basic Linux installation can have thousands of files installed on it. To help you find \nfiles on your system, you can use commands such as locate  (to find commands by name), \nfind  (to find files based on lots of different attributes), and grep  (to search within text \nfiles to find lines in files that contain search text).", "doc_id": "a4261f44-e4cd-46b8-b24d-dd8ef8bc60bf", "embedding": null, "doc_hash": "60e4405d9eca86ab7f3deba709afbf0e05732764ac95924f1b90729ef4e6e584", "extra_info": {"page_label": "151"}, "node_info": {"start": 0, "end": 2393}, "relationships": {"1": "6788e0d2-1577-41df-9097-5ea46400bb47"}}, "__type__": "1"}, "6ea95163-09e6-484e-a46d-2734fc121709": {"__data__": {"text": "Chapter 5: Working with Text Files\n121\n5Using locate to find files by name\nOn most Linux systems (Fedora and RHEL included), the updatedb  command runs once per \nday to gather the names of files throughout your Linux system into a database. By running \nthe locate  command, you can search that database to find the location of files stored in it.\nHere are a few things that you should know about searching for files using the \nlocate  command:\n\u25a0\u25a0There are advantages and disadvantages to using locate  to find filenames instead \nof the find  command. A locate  command finds files faster because it searches a \ndatabase instead of having to search the whole filesystem live. A disadvantage is \nthat the locate  command cannot find any files added to the system since the pre -\nvious time the database was updated.\n\u25a0\u25a0Not every file in your filesystem is stored in the database. The contents of the  \n/etc/updatedb.conf  file limit which filenames are collected by pruning out \nselect mount types, filesystem types, file types, and mount points. For example, \nfilenames are not gathered from remotely mounted filesystems ( cifs , nfs , and so \non) or locally mounted CDs or DVDs ( iso9660 ). Paths containing temporary files  \n(/tmp ) and spool files ( /var/spool/cups ) are also pruned. You can add items to \nprune (or remove some items that you don\u2019t want pruned) the locate database to \nyour needs. In RHEL 8, the updatedb.conf  file contains the following:\nPRUNE_BIND_MOUNTS = \"yes\"\nPRUNEFS = \"9p afs anon_inodefs auto autofs bdev binfmt_misc cgroup \ncifs coda configfs cpuset debugfs devpts ecryptfs exofs fuse fuse  \n.sshfs fusectl gfs gfs2 gpfs hugetlbfs inotifyfs iso9660 jffs2 \nlustre mqueue ncpfs nfs nfs4 nfsd pipefs proc ramfs rootfs rpc_\npipefs securityfs selinuxfs sfs sockfs sysfs tmpfs ubifs udf usbfs \nceph fuse.ceph\"\nPRUNENAMES = \".git .hg .svn .bzr .arch-ids {arch} CVS\"\nPRUNEPATHS = \"/afs /media /mnt /net /sfs /tmp /udev /var/cache/\nccache /var/lib/yum/yumdb /var/lib/dnf/yumdb /var/spool/cups /var/\nspool/squid /var/tmp /var/lib/ceph\"\n \nAs a regular user, you can't see any files from the locate database that you can't see in the \nfilesystem normally. For example, if you can't type ls  to view files in the /root  directory, \nyou can't locate files stored in that directory.\n\u25a0\u25a0When you search for a string, the string can appear anywhere in a file\u2019s path. For \nexample, if you search for passwd , you could turn up /etc/passwd , /usr/bin/\npasswd , /home/chris/passwd/pwdfiles.txt , and many other files with \npasswd  in the path.\n\u25a0\u25a0If you add files to your system after updatedb  runs, you can\u2019t locate those files \nuntil updatedb  runs again (probably that night). To get the database to con -\ntain all files up to the current moment, you can simply run updatedb  from the \nshell as root.", "doc_id": "6ea95163-09e6-484e-a46d-2734fc121709", "embedding": null, "doc_hash": "19daa3ac7f155e79d3472d104bfac884b5b50448372202b67689522cde717a3a", "extra_info": {"page_label": "152"}, "node_info": {"start": 0, "end": 2811}, "relationships": {"1": "df147337-9cbd-497d-9ea8-a25c43e7c130"}}, "__type__": "1"}, "00434ed3-00ad-44f1-858a-11542574fb52": {"__data__": {"text": "Part II: Becoming a Linux Power User122Here are some examples of using the locate  command to search for files:\n$ locate .bashrc\n/etc/skel/.bashrc\n/home/cnegus/.bashrc\n# locate .bashrc\n/etc/skel/.bashrc\n/home/bill/.bashrc\n/home/joe/.bashrc\n/root/.bashrc\nWhen run as a regular user, locate  only finds .bashrc  in /etc/skel  and the user\u2019s own \nhome directory. Run as root, the same command locates .bashrc  files in everyone\u2019s home \ndirectory.\n$ locate dir_color\n/usr/share/man/man5/dir_colors.5.gz\n...\n$ locate -i dir_color\n/etc/DIR_COLORS\n/etc/DIR_COLORS.256color\n/etc/DIR_COLORS.lightbgcolor\n/usr/share/man/man5/dir_colors.5.gz\n \n \nUsing locate -i , filenames are found regardless of case. So in the previous example, DIR_\nCOLORS  was found with -i  whereas it wasn't found without the -i  option. \n$ locate services\n/etc/services\n/usr/share/services/bmp.kmgio\n/usr/share/services/data.kmgio\nUnlike the find  command, which uses the -name  option to find filenames, the locate  \ncommand locates the string you enter if it exists in any part of the file\u2019s path. In this \nexample, searching for services  using the locate  command finds files and directories \ncontaining the services  text string.\nSearching for files with find\nThe find  command is the best one for searching your filesystem for files based on a variety \nof attributes. After files are found, you can act on those files as well (using the -exec  or \n-okay  option) by running any commands you want on them.\nWhen you run find , it searches your filesystem live, which causes it to run slower than \nlocate , but it gives you an up-to-the-moment view of the files on your Linux system. \nHowever, you can also tell find  to start at a particular point in the filesystem so that the \nsearch can go faster by limiting the area of the filesystem being searched.", "doc_id": "00434ed3-00ad-44f1-858a-11542574fb52", "embedding": null, "doc_hash": "cca1195795aa0275a0f7ff5577d2c49bf493ebf2fe909cf3d8a13d6630e5ebcf", "extra_info": {"page_label": "153"}, "node_info": {"start": 0, "end": 1822}, "relationships": {"1": "0f198057-c119-444b-93c4-e2b61c0cb234"}}, "__type__": "1"}, "9d88c518-b8b3-4883-b501-4a0644aec170": {"__data__": {"text": "Chapter 5: Working with Text Files\n123\n5Nearly any file attribute that you can think of can be used as a search option. You can \nsearch for filenames, ownership, permission, size, modification times, and other attributes. \nYou can even use combinations of attributes. Here are some basic examples of using the \nfind  command:\n$ find\n$ find /etc\n# find /etc\n$ find $HOME -ls\nRun on a line by itself, the find  command finds all files and directories below the current \ndirectory. If you want to search from a particular point in the directory tree, just add the \nname of the directory you want to search (such as /etc) . As a regular user, find  does not \ngive you special permission to find files that have permissions that make them readable \nonly by the root user. So, find  produces a bunch of error messages. Run as the root user, \nfind /etc  finds all files under /etc .\nA special option to the find  command is -ls . A long listing (ownership, permission, size, \nand so on) is printed with each file when you add -ls  to the find  command (similar to \noutput of the ls -l  command). This option helps you in later examples when you want to \nverify that you have found files that contain the ownership, size, modification times, or \nother attributes that you are trying to find.\nFinding files by name\nTo find files by name, you can use the -name  and -iname  options. The search is done by \nbase name of the file; the directory names are not searched by default. To make the search \nmore flexible, you can use file-matching characters, such as asterisks ( *) and question \nmarks (?), as in the following examples:\n# find /etc -name passwd\n/etc/pam.d/passwd\n/etc/passwd\n# find /etc -iname '*passwd*'\n/etc/pam.d/passwd\n/etc/passwd-\n/etc/passwd.OLD\n/etc/passwd\n/etc/MYPASSWD\n/etc/security/opasswdNote\nIf, as a regular user, you are searching an area of the filesystem where you don\u2019t have full permission to access all \nof the files it contains (such as the /etc  directory), you might receive lots of error messages when you search with \nfind . To get rid of those messages, direct standard errors to /dev/null . To do that, add the following to the \nend of the command line: 2> /dev/null . The 2>  redirects standard error to the next option (in this case /dev/\nnull , where the output is discarded).", "doc_id": "9d88c518-b8b3-4883-b501-4a0644aec170", "embedding": null, "doc_hash": "f7410c60093a013f1f59529e1ec2fc3d86a29209d0889dcd08ade5e3be99bb59", "extra_info": {"page_label": "154"}, "node_info": {"start": 0, "end": 2304}, "relationships": {"1": "6a9a27d8-a5af-4a4f-914d-a061afab9820"}}, "__type__": "1"}, "8e0f801f-634c-4ba3-8014-8e13fcac0f9c": {"__data__": {"text": "Part II: Becoming a Linux Power User124Using the -name  option and no asterisks, the first example above lists any files in the /\netc directory that are named passwd  exactly. By using -iname  instead, you can match \nany combination of upper- and lowercase. Using asterisks, you can match any filename that \nincludes the word passwd .\nFinding files by size\nIf your disk is filling up and you want to find out where your biggest files are located, \nyou can search your system by file size. The -size  option enables you to search for files \nthat are exactly, smaller than, or larger than a selected size, as you can see in the follow -\ning examples:\n$ find /usr/share/ -size +10M\n$ find /mostlybig -size -1M\n$ find /bigdata -size +500M -size -5G -exec du -sh {} \\;\n4.1G   /bigdata/images/rhel6.img\n606M   /bigdata/Fedora-16-i686-Live-Desktop.iso\n560M   /bigdata/dance2.avi\nThe first example in the preceding code finds files larger than 10MB. The second finds files \nless than 1MB. In the third example, I\u2019m searching for files that are between 500MB and \n5GB. This includes an example of the -exec  option (which I describe later) to run the du  \ncommand on each file to see its size.\nFinding files by user\nYou can search for a particular owner ( -user ) or group ( -group ) when you try to find \nfiles. By using -not  and -or , you can refine your search for files associated with specific \nusers and groups, as you can see in the following examples:\n$ find /home -user chris -ls\n131077     4    -rw-r--r--  1 chris   chris 379 Jun 29  2014 ./.bashrc\n# find /home \\( -user chris -or -user joe \\) -ls\n131077      4    -rw-r--r--  1 chris   chris 379 Jun 29  2014 ./.bashrc\n181022      4    -rw-r--r--  1 joe     joe    379 Jun 15  2014 ./.bashrc\n# find /etc -group ntp -ls\n131438      4 drwxrwsr-x  3 root    ntp   4096 Mar  9 22:16 /etc/ntp\n# find /var/spool -not -user root -ls\n262100    0 -rw-rw----   1 rpc      mail    0 Jan 27  2014 /var/spool/mail/rpc\n278504    0 -rw-rw----   1 joe      mail    0 Apr  3  2014 /var/spool/mail/joe\n261230    0 -rw-rw----   1 bill     mail    0 Dec 18 14:17 /var/spool/mail/bill\n277373 2848 -rw-rw----   1 chris    mail 8284 Mar 15  2014 /var/spool/mail/chris\nThe first example outputs a long listing of all of the files under the /home  directory that \nare owned by the user chris . The next lists files owned by chris  or joe . The find  \ncommand of /etc  turns up all files that have ntp  as their primary group assignment. The \nlast example shows all files under /var/spool  that are not owned by root. You can see \nfiles owned by other users in the sample output.", "doc_id": "8e0f801f-634c-4ba3-8014-8e13fcac0f9c", "embedding": null, "doc_hash": "b2df0a3373538402f2ae22aea65c283955c8e556f222a172615265608563e22a", "extra_info": {"page_label": "155"}, "node_info": {"start": 0, "end": 2607}, "relationships": {"1": "9c041abd-493e-4417-92b5-460359648258"}}, "__type__": "1"}, "1bfdd6d3-8edf-433c-b36d-a10b6fa38249": {"__data__": {"text": "Chapter 5: Working with Text Files\n125\n5Finding files by permission\nSearching for files by permission is an excellent way to turn up security issues on your \nsystem or uncover access issues. Just as you changed permissions on files using numbers or \nletters (with the chmod  command), you can likewise find files based on number or letter \npermissions along with the -perm  options. (Refer to Chapter\u00a04, \u201cMoving Around the File -\nsystem,\u201d to see how to use numbers and letters with chmod  to reflect file permissions.)\nIf you use numbers for permission, as I do below, remember that the three numbers repre -\nsent permissions for the user, group, and other. Each of those three numbers varies from \nno permission (0) to full read/write/execute permission (7) by adding read (4), write (2), \nand execute (1) bits together. With a hyphen ( -) in front of the number, all three of the bits \nindicated must match; with a forward slash (/) in front of it, any of the numbers can match \nfor the search to find a file. The full, exact numbers must match if neither a hyphen nor a \nforward slash is used.\nConsider the following examples:\n$ find /usr/bin -perm 755 -ls\n788884   28 -rwxr-xr-x   1 root     root        28176 Mar 10  2014 /bin/echo\n \n$ find /home/chris/ -perm -222 -type d -ls\n144503    4 drwxrwxrwx   8 chris  chris 4096 Jun 23  2014 /home/chris/OPENDIR\nBy searching for -perm 755 , any files or directories with exactly rwxr-xr-x  permission \nare matched. By using -perm -222 , only files that have write permission for user, group, \nand other are matched. Notice that, in this case, the -type d  is added to match only \ndirectories.\n$ find /myreadonly -perm /222 -type f\n685035    0 -rw-rw-r--  1 chris   chris      0 Dec 30 16:34 /myreadonly/abc\n \n$ find . -perm -002 -type f -ls\n266230    0 -rw-rw-rw-   1 chris   chris      0 Dec 30 16:28 ./LINUX_BIBLE/abc\nUsing -perm /222 , you can find any file ( -type f ) that has write permission turned on \nfor the user, group, or other. You might do that to make sure that all files are read-only in \na particular part of the filesystem (in this case, beneath the /myreadonly  directory). The \nlast example, -perm /002 , is very useful for finding files that have open write permission \nfor \u201cother,\u201d regardless of how the other permission bits are set.\nFinding files by date and time\nDate and time stamps are stored for each file when it is created, when it is accessed, when \nits content is modified, or when its metadata is changed. Metadata includes owner, group, \ntime stamp, file size, permissions, and other information stored in the file\u2019s inode. You \nmight want to search for file data or metadata changes for any of the following reasons:\n\u25a0\u25a0You just changed the contents of a configuration file, and you can\u2019t remember \nwhich one. So, you search /etc  to see what has changed in the past 10 minutes:\n        $ find /etc/ -mmin -10", "doc_id": "1bfdd6d3-8edf-433c-b36d-a10b6fa38249", "embedding": null, "doc_hash": "d1924090e64b4457743c012ffd049c1325d11de19d335e9592dc364211a44bdd", "extra_info": {"page_label": "156"}, "node_info": {"start": 0, "end": 2891}, "relationships": {"1": "61fcfe35-589e-4020-8f85-87c972572faa"}}, "__type__": "1"}, "3b610170-ef75-4aad-9d59-185865c4af1b": {"__data__": {"text": "Part II: Becoming a Linux Power User126\u25a0\u25a0You suspect that someone hacked your system three days ago. So, you search the \nsystem to see if any commands have had their ownership or permissions changed in \nthe past three days:\n        $ find /bin /usr/bin /sbin /usr/sbin -ctime -3\n\u25a0\u25a0You want to find files in your FTP server ( /var/ftp ) and web server ( /var/www ) \nthat have not been accessed in more than 300 days so that you can see if any need \nto be deleted:\n        $ find /var/ftp /var/www -atime +300\nAs you can glean from the examples, you can search for content or metadata changes over \na certain number of days or minutes. The time options ( -atime , -ctime , and -mtime ) \nenable you to search based on the number of days since each file was accessed, changed, \nor had its metadata changed. The min  options (-amin , -cmin , and -mmin) do the same \nin minutes.\nNumbers that you give as arguments to the min  and time  options are preceded by a \nhyphen (to indicate a time from the current time to that number of minutes or days ago) or \na plus (to indicate time from the number of minutes or days ago and older). With no hyphen \nor plus, the exact number is matched.\nUsing \u2018not\u2019 and \u2018or\u2019 when finding files\nWith the -not  and -or  options, you can further refine your searches. There may be times \nwhen you want to find files owned by a particular user but not assigned to a particular \ngroup. You may want files larger than a certain size but smaller than another size. Or you \nmight want to find files owned by any of several users. The -not  and -or  options can help \nyou do that. Consider the following examples:\n\u25a0\u25a0There is a shared directory called /var/allusers . This command line enables you \nto find files that are owned by either joe  or chris .\n        $ find /var/allusers \\( -user joe -o -user chris \\) -ls\n        679967    0 -rw-r--r-- 1 chris chris    0 Dec 31 12:57\n          /var/allusers/myjoe\n        679977 1812 -rw-r--r-- 1 joe   joe   4379 Dec 31 13:09\n          /var/allusers/dict.dat\n        679972    0 -rw-r--r-- 1 joe   sales    0 Dec 31 13:02\n          /var/allusers/one\n\u25a0\u25a0This command line searches for files owned by the user joe , but only those that \nare not assigned to the group joe :\n        $ find /var/allusers/ -user joe -not -group joe -ls\n        679972 0 -rw-r--r-- 1 joe sales  0 Dec 31 13:02 /var/allusers/one", "doc_id": "3b610170-ef75-4aad-9d59-185865c4af1b", "embedding": null, "doc_hash": "5551ca37f2cd46d5f75e432e080bd029a7b12f616580f58ceb90ec2c428a9bf4", "extra_info": {"page_label": "157"}, "node_info": {"start": 0, "end": 2366}, "relationships": {"1": "00b5ae46-3e4f-4aba-bd74-56efcf6b2e50"}}, "__type__": "1"}, "c286eb77-ddb8-41f3-a9cb-1e629d0f58c1": {"__data__": {"text": "Chapter 5: Working with Text Files\n127\n5\u25a0\u25a0You can also add multiple requirements on your searches. Here, a file must be \nowned by the user joe  and must also be more than 1MB in size:\n $ find /var/allusers/ -user joe -and -size +1M -ls\n 679977 1812 -rw-r--r-- 1 joe root 1854379 Dec 31 13:09\n   /var/allusers/dict.dat\nFinding files and executing commands\nOne of the most powerful features of the find  command is the capability to execute com-\nmands on any files that you find. With the -exec  option, the command you use is exe -\ncuted on every file found, without stopping to ask if that\u2019s okay. The -ok  option stops at \neach matched file and asks whether you want to run the command on it.\nThe advantage of using -ok  is that, if you are doing something destructive, you can make \nsure that you okay each file individually before the command is run on it. The syntax for \nusing -exec  and -ok  is the same:\n$ find [options] -exec command {} \\;\n$ find [options] -ok command {} \\;\nWith -exec  or -ok , you run find  with any options you like in order to find the files you \nare seeking. Then you enter the -exec  or -ok  option followed by the command you want \nto run on each file. The set of curly braces indicates where on the command line to read \nin each file that is found. Each file can be included in the command line multiple times \nif you like. To end the line, you need to add a backslash and semicolon ( \\;). Here are \nsome examples:\n\u25a0\u25a0This command finds any file named passwd  under the /etc  directory and includes \nthat name in the output of an echo  command:\n        $ find /etc -iname passwd -exec echo \"I found {}\" \\;\n        I found /etc/pam.d/passwd\n        I found /etc/passwd\n\u25a0\u25a0The following command finds every file under the /usr/share  directory that is \nmore than 5MB in size. Then it lists the size of each file with the du  command. \nThe output of find  is then sorted by size, from largest to smallest. With -exec  \nentered, all entries found are processed, without prompting:\n        $ find /usr/share -size +5M -exec du {} \\; | sort -nr\n        116932  /usr/share/icons/HighContrast/icon-theme.cache\n        69048   /usr/share/icons/gnome/icon-theme.cache\n        20564   /usr/share/fonts/cjkuni-uming/uming.ttc\n\u25a0\u25a0The -ok  option enables you to choose, one at a time, whether each file found is \nacted upon by the command you enter. For example, you want to find all files that \nbelong to joe  in the /var/allusers  directory (and its subdirectories) and move \nthem to the /tmp/joe  directory:\n        # find /var/allusers/ -user joe -ok mv {} /tmp/joe/ \\;\n        < mv ... /var/allusers/dict.dat > ? y\n        < mv ... /var/allusers/five > ? y", "doc_id": "c286eb77-ddb8-41f3-a9cb-1e629d0f58c1", "embedding": null, "doc_hash": "7c94df1881d9003b07fb1bc1bca1503daed9df21b63076bb29ca092b08abaed8", "extra_info": {"page_label": "158"}, "node_info": {"start": 0, "end": 2677}, "relationships": {"1": "25f52ac5-9a40-4017-8c34-1a7b10806aa5"}}, "__type__": "1"}, "1de42d96-edcb-4b76-b656-759556741c2d": {"__data__": {"text": "Part II: Becoming a Linux Power User128Notice in the preceding code that you are prompted for each file that is found before it is \nmoved to the /tmp/joe  directory. You would simply type y and press Enter at each line to \nmove the file, or just press Enter to skip it.\nFor more information on the find  command, enter man find .\nSearching in files with grep\nIf you want to search for files that contain a certain search term, you can use the grep  \ncommand. With grep , you can search a single file or search a whole directory structure of \nfiles recursively.\nWhen you search, you can have every line containing the term printed on your screen (stan -\ndard output) or just list the names of the files that contain the search term. By default, grep  \nsearches text in a case-sensitive way, although you can do case-insensitive searches as well.\nInstead of just searching files, you can also use grep  to search standard output. So, if a \ncommand turns out lots of text and you want to find only lines that contain certain text, \nyou can use grep  to filter just want you want.\nHere are some examples of grep  command lines used to find text strings in one or \nmore files:\n$ grep desktop /etc/services\ndesktop-dna     2763/tcp               # Desktop DNA\ndesktop-dna     2763/udp               # Desktop DNA\n \n$ grep -i desktop /etc/services\nsco-dtmgr       617/tcp                 # SCO Desktop Administration Server\nsco-dtmgr       617/udp                 # SCO Desktop Administration Server\nairsync         2175/tcp                # Microsoft Desktop AirSync Protocol\n...\nIn the first example, a grep  for the word desktop  in the /etc/services  file turned up \ntwo lines. Searching again, using the -i  to be case-insensitive (as in the second example), \nthere were 29 lines of text produced.\nTo search for lines that don\u2019t contain a selected text string, use the -v  option. In the fol -\nlowing example, all lines from the /etc/services  file are displayed except those contain -\ning the text tcp  (case-insensitive):\n$ grep -vi tcp /etc/services\nTo do recursive searches, use the -r  option and a directory as an argument. The following \nexample includes the -l  option, which just lists files that include the search text, without \nshowing the actual lines of text. That search turns up files that contain the text peerdns  \n(case-insensitive).\n$ grep -rli peerdns /usr/share/doc/\n/usr/share/doc/dnsmasq-2.66/setup.html\n/usr/share/doc/initscripts-9.49.17/sysconfig.txt\n...", "doc_id": "1de42d96-edcb-4b76-b656-759556741c2d", "embedding": null, "doc_hash": "c7dbef35ed37c3e1d9c235e568f2c068cae305bdec97edc037488c038db16cc7", "extra_info": {"page_label": "159"}, "node_info": {"start": 0, "end": 2478}, "relationships": {"1": "d6ec7922-abe0-490f-89ce-86ec617ea33b"}}, "__type__": "1"}, "77e21318-de82-4aad-8e66-b8f3eda13674": {"__data__": {"text": "Chapter 5: Working with Text Files\n129\n5The next example recursively searches the /etc/sysconfig  directory for the term root . \nIt lists every line in every file beneath the directory that contains that text. To make it \neasier to have the term root  stand out on each line, the --color  option is added. By \ndefault, the matched term appears in red.\n$ grep -ri --color root /etc/sysconfig/\nTo search the output of a command for a term, you can pipe the output to the grep  \ncommand. In this example, I know that IP addresses are listed on output lines from the ip  \ncommand that include the string inet , so I use grep  to display just those lines:\n$ ip addr show | grep inet\ninet 127.0.0.1/8 scope host lo\ninet 192.168.1.231/24 brd 192.168.1.255 scope global wlan0\nSummary\nBeing able to work with plain-text files is a critical skill for using Linux. Because so many \nconfiguration files and document files are in plain-text format, you need to become profi -\ncient with a text editor to use Linux effectively. Finding filenames and content in files are \nalso critical skills. In this chapter, you learned to use the locate  and find  commands for \nfinding files and grep  for searching files.\nThe next chapter covers a variety of ways to work with processes. There, you learn how \nto see what processes are running, run processes in the foreground and background, and \nchange processes (send signals).\nExercises\nUse these exercises to test your knowledge of using the vi  (or vim)  text editor, commands \nfor finding files ( locate  and find ), and commands for searching files ( grep ). These tasks \nassume that you are running a Fedora or Red Hat Enterprise Linux system (although some \ntasks work on other Linux systems as well). If you are stuck, solutions to the tasks are \nshown in Appendix B (although in Linux, there are often multiple ways to complete a task).\n1. Copy the /etc/services  file to the /tmp  directory. Open the /tmp/ser -\nvices  file in vim , and search for the term WorldWideWeb . Change that to read \nWorld Wide Web .\n2. Find the following paragraph in your /tmp/services  file (if it is not there, \nchoose a different paragraph) and move it to the end of that file.\n# Note that it is presently the policy of IANA to assign a single well-known\n# port number for both TCP and UDP; hence, most entries here have two entries\n# even if the protocol doesn't support UDP operations.\n# Updated from RFC 1700, \"Assigned Numbers\" (October 1994). Not all ports\n# are included, only the more common ones.", "doc_id": "77e21318-de82-4aad-8e66-b8f3eda13674", "embedding": null, "doc_hash": "e606f00ac5717036074142bcb32c8af775ec591c9fdf3cf98b81213beddd8b51", "extra_info": {"page_label": "160"}, "node_info": {"start": 0, "end": 2523}, "relationships": {"1": "614dd2dd-d88c-4fce-b7ff-f651e20d5c92"}}, "__type__": "1"}, "3815c333-bf82-48ec-a322-bd701e852689": {"__data__": {"text": "Part II: Becoming a Linux Power User1303. Using ex  mode, search for every occurrence of the term tcp  (case-sensitive) in \nyour /tmp/services  file and change it to WHATEVER .\n4. As a regular user, search the /etc  directory for every file named passwd . Redirect \nerror messages from your search to /dev/null .\n5. Create a directory in your home directory called TEST . Create files in that directory \nnamed one , two , and three  that have full read/write/execute permissions on for \neveryone (user, group, and other). Construct a find  command to find those files \nand any other files that have write permission open to \u2033 others \u2033 from your home \ndirectory and below.\n6. Find files under the /usr/share/doc  directory that have not been modified in \nmore than 300 days.\n7. Create a /tmp/FILES  directory. Find all files under the /usr/share  directory \nthat are more than 5MB and less than 10MB and copy them to the /tmp/FILES  \ndirectory.\n8. Find every file in the /tmp/FILES  directory, and make a backup copy of each file \nin the same directory. Use each file\u2019s existing name, and just append .mybackup  \nto create each backup file.\n9. Install the kernel-doc  package in Fedora or Red Hat Enterprise Linux. Using \ngrep , search inside the files contained in the /usr/share/doc/kernel-doc*  \ndirectory for the term e1000  (case-insensitive) and list the names of the files that \ncontain that term.\n10. Search for the e1000  term again in the same location, but this time list every line \nthat contains the term and highlight the term in color.", "doc_id": "3815c333-bf82-48ec-a322-bd701e852689", "embedding": null, "doc_hash": "778239e547a151d6e1de8dd00ba628c45dbc2f9af3dfa90501ff9c19b7b70b85", "extra_info": {"page_label": "161"}, "node_info": {"start": 0, "end": 1549}, "relationships": {"1": "88fe5139-26cc-42bc-aca4-03e7b65c3255"}}, "__type__": "1"}, "36614cf7-3135-4930-8386-4c1b311fa7d3": {"__data__": {"text": "131\nIN THIS CHAPTER\nDisplaying processes\nRunning processes in the foreground and background\nKilling and renicing processes\nIn addition to being a multiuser operating system, Linux is a multitasking system. Multitasking  \nmeans that many programs can be running at the same time. An instance of a running program \nis referred to as a process . Linux provides tools for listing running processes, monitoring system \nusage, and stopping (or killing) processes when necessary.\nFrom a shell, you can launch processes and then pause, stop, or kill them. You can also put them \nin the background and bring them to the foreground. This chapter describes tools such as ps , top, \nkill , jobs , and other commands for listing and managing processes.\nUnderstanding Processes\nA process is a running instance of a command. For example, there may be one vi  command on the \nsystem. But if vi  is currently being run by 15 different users, that command is represented by 15 \ndifferent running processes.\nA process is identified on the system by what is referred to as a process ID (PID) . That PID is unique for \nthe current system. In other words, no other process can use that number as its process ID while that \nfirst process is still running. However, after a process has ended, another process can reuse that number.\nAlong with a process ID number, other attributes are associated with a process. Each process, when \nit is run, is associated with a particular user account and group account. That account information \nhelps determine what system resources the process can access. For example, a process run as the root \nuser has much more access to system files and resources than a process running as a regular user.\nThe ability to manage processes on your system is critical for a Linux system administrator. Some -\ntimes, runaway processes may be killing your system\u2019s performance. Finding and dealing with \nprocesses, based on attributes such as memory and CPU usage, are covered in this chapter.Managing Running ProcessesCHAPTER6\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "36614cf7-3135-4930-8386-4c1b311fa7d3", "embedding": null, "doc_hash": "ced59ee7921863c612835cf79b29b3cfd7aa8d751272e37ba5b228ca2c6fbf74", "extra_info": {"page_label": "162"}, "node_info": {"start": 0, "end": 2148}, "relationships": {"1": "8ec08bba-5d16-41ed-bf0f-0ff69564fb47"}}, "__type__": "1"}, "0d7e9987-a2e3-40d7-bb22-c67dc07e3d2a": {"__data__": {"text": "Part II: Becoming a Linux Power User132Listing Processes\nFrom the command line, the ps  command is the oldest and most common command for list -\ning processes currently running on your system. The Linux version of ps  contains a variety \nof options from old UNIX and BSD systems, some of which are conflicting and implemented \nin nonstandard ways. See the ps  man page for descriptions of those different options.\nThe top  command provides a more screen-oriented approach to listing processes, and it can \nalso be used to change the status of processes. If you are using the GNOME desktop, you can \nuse the System Monitor tool ( gnome-system-monitor ) to provide a graphical means of \nworking with processes. These commands are described in the following sections.\nListing processes with ps\nThe most common utility for checking running processes is the ps  command. Use it to see \nwhich programs are running, the resources they are using, and who is running them. The \nfollowing is an example of the ps  command:\n$ ps u\nUSER   PID %CPU %MEM  VSZ    RSS   TTY    STAT  START  TIME  COMMAND\njake   2147 0.0  0.7 1836   1020   tty1   S+    14:50  0:00  -bash\njake   2310 0.0  0.7 2592    912   tty1   R+    18:22  0:00  ps u\nIn this example, the u option (equivalent to -u ) asks that usernames be shown, as well \nas other information such as the time the process started and memory and CPU usage for \nprocesses associated with the current user. The processes shown are associated with the \ncurrent terminal ( tty1 ). The concept of a terminal comes from the old days when people \nworked exclusively from character terminals, so a terminal typically represented a single \nperson at a single screen. Nowadays, you can have many \u201cterminals\u201d on one screen by \nopening multiple virtual terminals or Terminal windows on the desktop.\nIn this shell session, not much is happening. The first process shows that the user named \njake  opened a bash shell after logging in. The next process shows that jake  has run the \nps u  command. The terminal device tty1  is being used for the login session. The STAT  \ncolumn represents the state of the process, with R indicating a currently running process \nand S representing a sleeping process.Note\nCommands that display information about running processes get most of that information from raw data stored in \nthe /proc  file system. Each process stores its information in a subdirectory of /proc , named after the process \nID of that process. You can view some of that raw data by displaying the contents of files in one of those directories \n(using cat  or less  commands).", "doc_id": "0d7e9987-a2e3-40d7-bb22-c67dc07e3d2a", "embedding": null, "doc_hash": "f8ba28ee90fb3feea55f6d0335b3a22e5b9fed13ec5215ca283f7555f861a765", "extra_info": {"page_label": "163"}, "node_info": {"start": 0, "end": 2607}, "relationships": {"1": "fc702246-b694-4660-8d45-870210082e27"}}, "__type__": "1"}, "49467157-d072-4769-a7f0-88a20209fa62": {"__data__": {"text": "Chapter 6: Managing Running Processes\n133\n6The USER  column shows the name of the user who started the process. Each process is \nrepresented by a unique ID number referred to as a process ID, or PID. You can use the PID \nif you ever need to kill a runaway process or send another kind of signal to a process. The \n%CPU  and %MEM  columns show the percentages of the processor and random access memory, \nrespectively, that the process is consuming.\nVSZ (virtual set size) shows the size of the image process (in kilobytes), and RSS (resident \nset size)  shows the size of the program in memory. The VSZ and RSS sizes may be differ -\nent because VSZ is the amount of memory allocated for the process, whereas RSS is the \namount that is actually being used. RSS memory represents physical memory that cannot \nbe swapped.\nSTART  shows the time the process began running, and TIME  shows the cumulative \nsystem time used. (Many commands consume very little CPU time, as reflected by 0:00 for \nprocesses that haven\u2019t even used a whole second of CPU time.)\nMany processes running on a computer are not associated with a terminal. A normal Linux \nsystem has many processes running in the background. Background system processes per -\nform such tasks as logging system activity or listening for data coming in from the net -\nwork. They are often started when Linux boots up and run continuously until the system \nshuts down. Likewise, logging into a Linux desktop causes many background processes to \nkick off, such as processes for managing audio, desktop panels, authentication, and other \ndesktop features.\nTo page through all of the processes running on your Linux system for the current user, add \nthe pipe (|)  and the less  command to ps ux :\n$ ps ux | less\nTo page through all processes running for all users on your system, use the ps aux  \ncommand as follows:\n$ ps aux | less\nA pipe (located above the backslash character on the keyboard) enables you to direct the \noutput of one command to be the input of the next command. In this example, the output \nof the ps  command (a list of processes) is directed to the less  command, which enables \nyou to page through that information. Use the spacebar to page through and type q to end \nthe list. You can also use the arrow keys to move one line at a time through the output.\nThe ps  command can be customized to display selected columns of information and to \nsort information by one of those columns. Using the -o  option, you can use keywords to \nindicate the columns you want to list with ps . For example, the next example lists every Note\nSeveral other values can appear under the STAT  column. For example, a plus sign ( +) indicates that the process is \nassociated with the foreground operations.", "doc_id": "49467157-d072-4769-a7f0-88a20209fa62", "embedding": null, "doc_hash": "414263626be3eb80fb9c1eaaf3e5c3bcdb025a168704fd5cfdb59795f1f52993", "extra_info": {"page_label": "164"}, "node_info": {"start": 0, "end": 2752}, "relationships": {"1": "fd9ca423-c1c5-4b17-99f9-43a1a606bca7"}}, "__type__": "1"}, "005829e2-dc17-460d-8384-923caa055421": {"__data__": {"text": "Part II: Becoming a Linux Power User134running process ( -e) and then follows the -o  option with every column of information I \nwant to display, including the process ID ( pid), username ( user ), user ID ( uid), group \nname (group ), group ID ( gid), virtual memory allocated ( vsz), resident memory used \n(rss), and the full command line that was run ( comm ). By default, output is sorted by pro -\ncess ID number.\n$ ps -eo pid,user,uid,group,gid,vsz,rss,comm | less\n  PID  USER       UID GROUP      GID    VSZ   RSS COMMAND\n  1    root         0 root         0 187660 13296 systemd\n  2    root         0 root         0      0     0 kthreadd\n \nIf you want to sort by a specific column, you can use the sort=  option. For example, to see \nwhich processes are using the most memory, I sort by the vsz  field. That sorts from lowest \nmemory use to highest. Because I want to see the highest ones first, I put a hyphen in front \nof that option to sort ( sort=-vsz ).\n$ ps -eo pid,user,group,gid,vsz,rss,comm --sort=-vsz | head\n    PID USER     GROUP      GID    VSZ   RSS COMMAND\n 2366 chris    chris     1000 3720060 317060 gnome-shell\n 1580 gdm      gdm         42 3524304 205796 gnome-shell\n 3030 chris    chris     1000 2456968 248340 firefox\n 3233 chris    chris     1000 2314388 316252 Web Content\n \nRefer to the ps  man page for information on other columns of information by which you \ncan display and sort.\nListing and changing processes with top\nThe top  command provides a screen-oriented means of displaying processes running on \nyour system. With top, the default is to display processes based on how much CPU time \nthey are currently consuming. However, you can sort by other columns as well. After you \nidentify a misbehaving process, you can also use top  to kill (completely end) or renice \n(reprioritize) that process.\nIf you want to be able to kill or renice any processes, you need to run top  as the root user. \nIf you just want to display processes and possibly kill or change your own processes, you \ncan do that as a regular user. Figure\u00a06.1 shows an example of the top  window.\nGeneral information about your system appears at the top of the top  output, followed by \ninformation about each running process (or at least as many as will fit on your screen). At \nthe top, you can see how long the system has been up, how many users are currently logged \nin to the system, and how much demand there has been on the system for the past 1, 5, \nand 10 minutes.\nOther general information includes how many processes (tasks) are currently running, \nhow much CPU is being used, and how much RAM and swap are available and being used. ", "doc_id": "005829e2-dc17-460d-8384-923caa055421", "embedding": null, "doc_hash": "1ad9cf578a38dacac778ea6fca287bf29e988e1749a312bb595808a994f22ae0", "extra_info": {"page_label": "165"}, "node_info": {"start": 0, "end": 2649}, "relationships": {"1": "ec697b00-2b4c-4804-9915-18c4073da741"}}, "__type__": "1"}, "b5e2eb9c-6674-47f8-ba37-ccf4360865c0": {"__data__": {"text": "Chapter 6: Managing Running Processes\n135\n6Following the general information are listings of each process, sorted by what percent of the \nCPU is being used by each process. All of this information is redisplayed every 5 seconds, \nby default.\nThe following list includes actions that you can do with top  to display information in dif -\nferent ways and modify running processes:\n\u25a0\u25a0Press h to see help options, and then press any key to return to the top  display.\n\u25a0\u25a0Press M to sort by memory usage instead of CPU, and then press P to return to sort -\ning by CPU.\n\u25a0\u25a0Press the number 1 to toggle showing CPU usage of all your CPUs if you have more \nthan one CPU on your system.\n\u25a0\u25a0Press R to reverse sort your output.\n\u25a0\u25a0Press u and enter a username to display processes only for a particular user.\nA common practice is to use top  to find processes that are consuming too much memory \nor processing power and then act on those processes in some way. A process consuming too \nmuch CPU can be reniced to give it less priority to the processors. A process consuming too \nmuch memory can be killed. With top  running, here\u2019s how to renice or kill a process:\nRenicing a process Note the process ID of the process you want to renice and press r . \nWhen the PID to renice message appears, type the process ID of the process you \nwant to renice. When prompted to Renice PID to value , type in a number from \n\u201320 to 19. (See \u201cSetting processor priority with nice and renice\u201d later in this chapter \nfor information on the meanings of different renice values.)\nKilling a process  Note the process ID of the process you want to kill and press k . \nType 15  to terminate cleanly or 9 to just kill the process outright. (See \u201cKilling \nprocesses with kill and killall\u201d later in this chapter for more information on using \ndifferent signals you can send to processes.)\nFIGURE 6.1\nDisplaying running processes with top", "doc_id": "b5e2eb9c-6674-47f8-ba37-ccf4360865c0", "embedding": null, "doc_hash": "719f51fbcedfc0617bc67a83e64fb5f2abbb97c4a69a72e5f5022b1f9230e868", "extra_info": {"page_label": "166"}, "node_info": {"start": 0, "end": 1897}, "relationships": {"1": "e00fdc5c-618e-4d28-9990-da185dbb877d"}}, "__type__": "1"}, "21035f52-4491-4b4b-a068-5bdcefff2532": {"__data__": {"text": "Part II: Becoming a Linux Power User136Listing processes with System Monitor\nIf you have GNOME desktop available on your Linux system, System Monitor ( gnome-sys -\ntem-monitor ) is available to provide a more graphical way of displaying processes on your \nsystem. You sort processes by clicking columns. You can right-click processes to stop, kill, \nor renice them.\nTo start System Monitor from the GNOME desktop, press the Windows key and then type \nSystem Monitor and press Enter. Then select the Processes tab. Figure\u00a06.2 shows an example of \nthe System Monitor window, displaying processes for the current user in order by memory use.\nBy default, only running processes associated with your user account are displayed. Those \nprocesses are listed alphabetically at first. You can resort the processes by clicking any of \nthe field headings (forward and reverse). For example, click the %CPU heading to see which \nprocesses are consuming the most processing power. Click the Memory heading to see which \nprocesses consume the most memory.\nYou can change your processes in various ways by right-clicking a process name and select -\ning from the menu that appears (see Figure\u00a06.3 for an example).\nHere are some of the things you can do to a process from the menu you clicked:\nStop: Pauses the process so that no processing occurs until you select Continue Process. \n(This is the same as pressing Ctrl+Z on a process from the shell.)\nContinue: Continues running a paused process.\nEnd: Sends a Terminate signal (15) to a process. In most cases, this terminates the pro -\ncess cleanly.\nKill: Sends a Kill signal (9) to a process. This should kill a process immediately, regard -\nless of whether it can be done cleanly.\nFIGURE 6.2\nUse the System Monitor window to view and change running processes.", "doc_id": "21035f52-4491-4b4b-a068-5bdcefff2532", "embedding": null, "doc_hash": "852f28bdb62e1450ff03a3ef2d50d8c577e22b315fdd0ce165f9ab44c4cc4c70", "extra_info": {"page_label": "167"}, "node_info": {"start": 0, "end": 1795}, "relationships": {"1": "bddfff1a-5f59-4d63-a934-9c14e018b1f8"}}, "__type__": "1"}, "c62f6a66-ac2b-4a4d-a1e6-e52b4bf73e50": {"__data__": {"text": "Chapter 6: Managing Running Processes\n137\n6Change Priority: Presents a list of priorities from Very Low to Very High. Select Custom \nto see a slider bar from which you can renice a process. Normal priority is 0. To get \nbetter processor priority, use a negative number from \u20131 to \u201320. To have a lower pro -\ncessor priority, use a positive number (0 to 19). Only the root user can assign neg -\native priorities, so when prompted you need to provide the root password to set a \nnegative nice value.\nMemory Maps: Lets you view the system memory map to see which libraries and other \ncomponents are being held in memory for the process.\nOpen Files: Lets you view which files are currently being held open by the process.\nProperties: Lets you see other settings associated with the process (such as security \ncontext, memory usage, and CPU use percentages).\nYou can display running processes associated with users other than yourself. To do that, \nhighlight any process in the display (just click it). Then, from the menu button (the button \nwith three bars on it), select All Processes. You can modify processes you don\u2019t own only \nif you are the root user or if you can provide the root password when prompted after you \ntry to change a process. Sometimes, you won\u2019t have the luxury of working with a graphical \ninterface. To change processes without a graphical interface, you can use a set of com-\nmands and keystrokes to change, pause, or kill running processes. Some of those are \ndescribed next.\nManaging Background and Foreground Processes\nIf you are using Linux over a network or from a dumb terminal (a monitor that allows only \ntext input with no GUI support), your shell may be all that you have. You may be used to a \nFIGURE 6.3\nRenice, kill, or pause a process from the System Monitor window.", "doc_id": "c62f6a66-ac2b-4a4d-a1e6-e52b4bf73e50", "embedding": null, "doc_hash": "6548b85745735eca918566844dd89fe3084611922007efb979ab75db87561107", "extra_info": {"page_label": "168"}, "node_info": {"start": 0, "end": 1801}, "relationships": {"1": "d4f680cd-7823-48e7-9cb3-60cd57020ec8"}}, "__type__": "1"}, "7d12f870-885d-4f1a-85c1-79df89e787c2": {"__data__": {"text": "Part II: Becoming a Linux Power User138graphical environment in which you have lots of programs active at the same time so that \nyou can switch among them as needed. This shell thing can seem pretty limited.\nAlthough the bash shell doesn\u2019t include a GUI for running many programs at once, it does \nlet you move active programs between the background and foreground. In this way, you \ncan have lots of stuff running and selectively choose the one you want to deal with at \nthe moment.\nYou can place an active program in the background in several ways. One is to add an amper -\nsand (&) to the end of a command line when you first run the command. You can also use \nthe at  command to run commands in such a way that they are not connected to the shell.\nTo stop a running command and put it in the background, press Ctrl+Z. After the command \nis stopped, you can either bring it back into the foreground to run (the fg  command) or \nstart it running in the background (the bg  command). Keep in mind that any command \nrunning in the background might spew output during commands that you run subsequently \nfrom that shell. For example, if output appears from a command running in the background \nduring a vi  session, simply press Ctrl+L to redraw the screen to get rid of the output.\nStarting background processes\nIf you have programs that you want to run while you continue to work in the shell, you can \nplace the programs in the background. To place a program in the background at the time \nyou run the program, type an ampersand ( &) at the end of the command line, like this:\n$ find /usr > /tmp/allusrfiles &\n[3] 15971\nThis example command finds all files on your Linux system (starting from /usr ), prints \nthose filenames, and puts those names in the file /tmp/allusrfiles . The ampersand ( &) \nruns that command line in the background. Notice that the job number, [3] , and process ID \nnumber, 15971 , are displayed when the command is launched. To check which commands \nyou have running in the background, use the jobs  command, as follows:\n$ jobs\n[1]  Stopped (tty output)  vi /tmp/myfile\n[2]  Running        find /usr -print > /tmp/allusrfiles &\n[3]  Running        nroff -man /usr/man2/* >/tmp/man2 &\n[4]- Running        nroff -man /usr/man3/* >/tmp/man3 &\n[5]+ Stopped        nroff -man /usr/man4/* >/tmp/man4\nThe first job shows a text-editing command ( vi) that I placed in the background and \nstopped by pressing Ctrl+Z while I was editing. Job 2 shows the find  command I just ran. tip\nTo avoid having the output appear, you should have any process running in the background send its output to a file or \nto null (add 2> /dev/null  to the end of the command line).", "doc_id": "7d12f870-885d-4f1a-85c1-79df89e787c2", "embedding": null, "doc_hash": "094bd0eaaf3dbebd5fd7e3cd4bcdac9d02f503adb395b5fb550ed59f442d8044", "extra_info": {"page_label": "169"}, "node_info": {"start": 0, "end": 2679}, "relationships": {"1": "912a671a-11fe-4618-99ea-99d7d12b6814"}}, "__type__": "1"}, "0d29e8ef-8703-46a9-8e56-31bce62649c3": {"__data__": {"text": "Chapter 6: Managing Running Processes\n139\n6Jobs 3 and 4 show nroff  commands currently running in the background. Job 5 had been \nrunning in the shell (foreground) until I decided too many processes were running and \npressed Ctrl+Z to stop job 5 until a few processes had completed.\nThe plus sign ( +) next to number 5 shows that it was most recently placed in the \nbackground. The minus sign ( -) next to number 4 shows that it was placed in the \nbackground just before the most recent background job. Because job 1 requires terminal \ninput, it cannot run in the background. As a result, it is Stopped  until it is brought to the \nforeground again.\nUsing foreground and background commands\nContinuing with the example, you can bring any of the commands on the jobs list to the \nforeground. For example, to edit myfile  again, enter the following:\n$ fg %1\nAs a result, the vi  command opens again. All text is as it was when you stopped \nthe vi  job.\nTo refer to a background job (to cancel or bring it to the foreground), use a percent sign ( %) \nfollowed by the job number. You can also use the following to refer to a background job:\n% Refers to the most recent command put into the background (indicated by the \nplus sign when you type the jobs  command). This action brings the command to \nthe foreground.\n%string Refers to a job where the command begins with a particular string of characters. \nThe string must be unambiguous. (In other words, typing %vi  when there are two \nvi commands in the background results in an error message.)\n%?string Refers to a job where the command line contains a string at any point. The string \nmust be unambiguous or the match fails.\n%-- Refers to the job stopped before the one most recently stopped.tip\nTo see the process ID for the background job, add a -l  (the lowercase letter L ) option to the jobs command. If you \ntype ps , you can use the process ID to figure out which command is for a particular background job.\nCautio N\nBefore you put a text processor, word processor, or similar program in the background, make sure that you save your \nfile. It\u2019s easy to forget that you have a program in the background, and you will lose your data if you log out or the \ncomputer reboots.", "doc_id": "0d29e8ef-8703-46a9-8e56-31bce62649c3", "embedding": null, "doc_hash": "71d02299aebdd3b73d3c7427209c80670f2deb797c52cebfbbf40cf7224259f1", "extra_info": {"page_label": "170"}, "node_info": {"start": 0, "end": 2227}, "relationships": {"1": "072331f2-0b5c-4e53-b6d9-6e83fc34a8d4"}}, "__type__": "1"}, "cd00d081-72da-4fba-80b4-2187ea581aea": {"__data__": {"text": "Part II: Becoming a Linux Power User140If a command is stopped, you can start it running again in the background using the bg  \ncommand. For example, refer back to job 5 from the jobs list in a previous example:\n[5]+ Stopped nroff -man /usr/man4/* >/tmp/man4 \nEnter the following:\n$ bg %5\nAfter that, the job runs in the background. Its jobs  entry appears as follows:\n[5] Running nroff -man /usr/man4/* >/tmp/man4 &\nKilling and Renicing Processes\nJust as you can change the behavior of a process using graphical tools such as System Mon -\nitor (described earlier in this chapter), you can also use command-line tools to kill a pro -\ncess or change its CPU priority. The kill  command can send a kill signal to any process to \nend it, assuming you have permission to do so. It can also send different signals to a pro -\ncess to otherwise change its behavior. The nice  and renice  commands can be used to set \nor change the processor priority of a process.\nKilling processes with kill and killall\nAlthough usually used for ending a running process, the kill  and killall  commands \ncan actually be used to send any valid signal to a running process. Besides telling a process \nto end, a signal might tell a process to reread configuration files, pause (stop), or continue \nafter being paused, just to name a few possibilities.\nSignals are represented by both numbers and names. Signals that you might send most \ncommonly from a command include SIGKILL  (9), SIGTERM  (15), and SIGHUP  (1). The \ndefault signal is SIGTERM , which tries to terminate a process cleanly. To kill a process \nimmediately, you can use SIGKILL . The SIGHUP  signal can, depending on the program, \ntell a process to reread its configuration files. SIGSTOP  pauses a process, while SIGCONT  \ncontinues a stopped process.\nDifferent processes respond to different signals. Processes cannot block SIGKILL  and SIG-\nSTOP  signals, however. Table\u00a06.1 shows examples of some signals (enter man 7 signal to \nread about other available signals).\nNotice that there are multiple possible signal numbers for SIGCONT  and SIGSTOP  because \ndifferent numbers are used in different computer architectures. For most x86 and Power \narchitectures, use the middle value. The first value usually works for Alpha and SPARC, \nwhile the last one is for MIPS architecture.\nUsing kill to signal processes by PID\nUsing commands such as ps  and top, you can find processes to which you want to send a \nsignal. Then you can use the process ID of that process as an option to the kill  command, \nalong with the signal you want to send.", "doc_id": "cd00d081-72da-4fba-80b4-2187ea581aea", "embedding": null, "doc_hash": "c599e47a8dc435526bb98509a78a2df85956b2be46ade3ad79d0038725d71032", "extra_info": {"page_label": "171"}, "node_info": {"start": 0, "end": 2580}, "relationships": {"1": "b1a72393-7d01-4758-a88e-b0ebc4165b97"}}, "__type__": "1"}, "fa73bef8-f1dd-47d8-90c2-e4c2b904649f": {"__data__": {"text": "Chapter 6: Managing Running Processes\n141\n6For example, you run the top  command and see that the bigcommand  process is con -\nsuming most of your processing power:\n  PID USER     PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND\n10432 chris       20   0     471m    121m  18m S 99.9  3.2  77:01.76        bigcommand\nHere, the bigcommand  process is consuming 99.9 percent of the CPU. You decide that you \nwant to kill it so that other processes have a shot at the CPU. If you use the process ID of \nthe running bigcommand  process, here are some examples of the kill  command that you \ncan use to kill that process:\n$ kill 10432\n$ kill -15 10432\n$ kill -SIGKILL 10432\nThe default signal sent by kill is 15  (SIGTERM ), so the first two examples have exactly the \nsame results. On occasion, a SIGTERM  doesn\u2019t kill a process, so you may need a SIGKILL  to \nkill it. Instead of SIGKILL , you can use \u20139  to get the same result.\nAnother useful signal is SIGHUP . If, for example, something on your GNOME desktop were \ncorrupted, you could send the gnome-shell  a SIGHUP  signal to reread its configuration \nfiles and restart the desktop. If the process ID for gnome-shell  were 1833, here are two \nways you could send it a SIGHUP  signal:\n# kill -1 1833\n# killall -HUP gnome-shell\nUsing killall to signal processes by name\nWith the killall command, you can signal processes by name instead of by process ID. The \nadvantage is that you don\u2019t have to look up the process ID of the process that you want to \nkill. The potential downside is that you can kill more processes than you mean to if you are \nnot careful. (For example, typing killall bash may kill a bunch of shells that you don\u2019t \nmean to kill.)TABLE 6.1  Signals Available in Linux\nSignal Number Description\nSIGHUP 1 Hang-up detected on controlling terminal or death of controlling  \nprocess.\nSIGINT 2 Interrupt from keyboard.\nSIGQUIT 3 Quit from keyboard.\nSIGABRT 6 Abort signal from abort(3).\nSIGKILL 9 Kill signal.\nSIGTERM 15 Termination signal.\nSIGCONT 19,18,25 Continue if stopped.\nSIGSTOP 17,19,23 Stop process.", "doc_id": "fa73bef8-f1dd-47d8-90c2-e4c2b904649f", "embedding": null, "doc_hash": "3390dccca6434aad809d7e35763df7b138913046d203f793c5a91856412bfaa4", "extra_info": {"page_label": "172"}, "node_info": {"start": 0, "end": 2077}, "relationships": {"1": "583cfe08-0496-4658-885b-9e781300a4fa"}}, "__type__": "1"}, "b0745ae3-d77e-4239-8458-db638932f8e9": {"__data__": {"text": "Part II: Becoming a Linux Power User142Like the kill  command, killall  uses SIGTERM  (signal 15) if you don\u2019t explicitly enter \na signal number. Also as with kill , you can send any signal you like to the process you \nname with killall . For example, if you see a process called testme  running on your \nsystem and you want to kill it, you can simply enter the following:\n$ killall -9 testme\nThe killall  command can be particularly useful if you want to kill a bunch of commands \nof the same name.\nSetting processor priority with nice and renice\nWhen the Linux kernel tries to decide which running processes get access to the CPUs on \nyour system, one of the things it takes into account is the nice value set on the process. \nEvery process running on your system has a nice value between \u201320 and 19. By default, the \nnice value is set to 0. Here are a few facts about nice values:\n\u25a0\u25a0The lower the nice value, the more access to the CPUs the process has. In other \nwords, the nicer a process is, the less CPU attention it gets. So, a \u201320 nice value \ngets more attention than a process with a 19 nice value.\n\u25a0\u25a0A regular user can set nice values only from 0 to 19. No negative values are allowed. \nSo a regular user can\u2019t ask for a value that gives a process more attention than most \nprocesses get by default.\n\u25a0\u25a0A regular user can set the nice value higher, not lower. So, for example, if a user \nsets the nice value on a process to 10 and then later wants to set it back to 5, that \naction will fail. Likewise, any attempt to set a negative value will fail.\n\u25a0\u25a0A regular user can set the nice value only on the user\u2019s own processes.\n\u25a0\u25a0The root user can set the nice value on any process to any valid value, up or down.\nYou can use the nice  command to run a command with a particular nice value. When a \nprocess is running, you can change the nice value using the renice  command, along with \nthe process ID of the process, as in the example that follows:\n# nice -n +5 updatedb &\nThe updatedb  command is used to generate the locate database manually by gathering \nnames of files throughout the filesystem. In this case, I just wanted updatedb  to run in \nthe background ( &) and not interrupt work being done by other processes on the system. I \nran the top  command to make sure that the nice value was set properly:\nPID USER        PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND\n20284 root      25   5 98.7m  932  644 D  2.7  0.0   0:00.96 updatedb\nNotice that under the NI  column, the nice value is set to 5. Because the command was run \nas the root user, the root user can lower the nice value later by using the renice  command. \n(Remember that a regular user can\u2019t reduce the nice value or ever set it to a negative number.) \nHere\u2019s how you would change the nice value for the updatedb  command just run to \u20135 :\n# renice -n -5 20284", "doc_id": "b0745ae3-d77e-4239-8458-db638932f8e9", "embedding": null, "doc_hash": "e1683e8820b021954663324a629b5ce4a7767f5bdfe360286081092d2b44f025", "extra_info": {"page_label": "173"}, "node_info": {"start": 0, "end": 2847}, "relationships": {"1": "4314dfb3-f9f2-470f-94b7-f18a71f9dc17"}}, "__type__": "1"}, "5b59a6b6-c876-4fed-b14b-2a08ad755686": {"__data__": {"text": "Chapter 6: Managing Running Processes\n143\n6If you ran the top  command again, you might notice that the updatedb  command is now \nat or near the top of the list of processes consuming CPU time because you gave it priority \nto get more CPU attention.\nLimiting Processes with cgroups\nYou can use a feature like \u201cnice\u201d to give a single process more or less access to CPU time. \nSetting the nice value for one process, however, doesn\u2019t apply to child processes that a pro -\ncess might start up or any other related processes that are part of a larger service. In other \nwords, \u201cnice\u201d doesn\u2019t limit the total amount of resources a particular user or application \ncan consume from a Linux system.\nAs cloud computing takes hold, many Linux systems will be used more as hypervisors than \nas general-purpose computers. Their memory, processing power, and access to storage will \nbecome commodities to be shared by many users. In that model, more needs to be done to \ncontrol the amount of system resources to which a particular user, application, container, \nor virtual machine running on a Linux system has access.\nThat\u2019s where cgroups  come in.\nCgroups can be used to identify a process as a task, belonging to a particular control group. \nTasks can be set up in a hierarchy where, for example, there may be a task called daemons \nthat sets default limitations for all daemon server processes, then subtasks that may set \nspecific limits on a web server daemon ( httpd ) for FTP service daemon ( vsftpd ).\nAs a task launches a process, other processes that the initial process launches (called child \nprocesses) inherit the limitations set for the parent process. Those limitations might say \nthat all the processes in a control group only have access to particular processors and cer -\ntain sets of RAM. Or they may only allow access to up to 30 percent of the total processing \npower of a machine.\nThe types of resources that can be limited by cgroups include the following:\nStorage (blkio ): Limits total input and output access to storage devices (such as hard \ndisks, USB drives, and so on).\nProcessor scheduling ( cpu): Assigns the amount of access a cgroup has to be sched -\nuled for processing power.\nProcess accounting ( cpuacct ): Reports on CPU usage. This information can be lever -\naged to charge clients for the amount of processing power they use.\nCPU assignment ( cpuset ): On systems with multiple CPU cores, assigns a task to a \nparticular set of processors and associated memory.\nDevice access ( devices ): Allows tasks in a cgroup to open or create ( mknod ) selected \ndevice types.\nSuspend/resume ( freezer ): Suspends and resumes cgroup tasks.", "doc_id": "5b59a6b6-c876-4fed-b14b-2a08ad755686", "embedding": null, "doc_hash": "24fd7fa75b12f40df292ad7d69c40fc10852d06bfc591948fabb4aaa1ca4f5ca", "extra_info": {"page_label": "174"}, "node_info": {"start": 0, "end": 2658}, "relationships": {"1": "2e48c3e3-c09e-469f-9932-9c13c76d847e"}}, "__type__": "1"}, "059c7af9-2d3d-4e7b-aa49-12758431e88d": {"__data__": {"text": "Part II: Becoming a Linux Power User144Memory usage ( memory ): Limits memory usage by task. It also creates reports on \nmemory resources used.\nNetwork bandwidth ( net_cls ): Limits network access to selected cgroup tasks. This \nis done by tagging network packets to identify the cgroup task that originated the \npacket and having the Linux traffic controller monitor and restrict packets coming \nfrom each cgroup.\nNetwork traffic ( net_prio ): Sets priorities of network traffic coming from selected \ncgroups and lets administrators change these priorities on the fly.\nName spaces ( ns): Separates cgroups into namespaces, so processes in one cgroup can \nonly see the namespaces associated with the cgroup. Namespaces can include sepa -\nrate process tables, mount tables, and network interfaces.\nAt its most basic level, creating and managing cgroups is generally not a job for new Linux \nsystem administrators. It can involve editing configuration files to create your own cgroups \n(/etc/cgconfig.conf ) or set up limits for particular users or groups ( /etc/cgrules  \n.conf ). Or you can use the cgcreate  command to create cgroups, which results in those \ngroups being added to the /sys/fs/cgroup  hierarchy. Setting up cgroups can be tricky \nand, if done improperly, can make your system unbootable.\nThe reason I bring up the concept of cgroups here is to help you understand some of the \nunderlying features in Linux that can be used to limit and monitor resource usage. In the \nfuture, you will probably run into these features from controllers that manage your cloud \ninfrastructure. You will be able to set rules like \u201cAllow the Marketing department\u2019s virtual \nmachines to consume up to 40 percent of the available memory\u201d or \u201cPin the database appli-\ncation to a particular CPU and memory set.\u201d\nKnowing how Linux can limit and contain the resource usage by the set of processes \nassigned to a task will ultimately help you manage your computing resources better. If you \nare interested in learning more about cgroups, you can refer to the following:\n\u25a0\u25a0Red Hat Enterprise Linux Resource Management and Linux Containers Guide :\nhttps://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/\nhtml-single/resource_management_ guide/index\n\u25a0\u25a0Kernel documentation on cgroups : Refer to files in the /usr/share/doc/\nkernel-doc-*/Documentation/cgroups  directory after installing the kernel-\ndoc package.\nSummary\nEven on a Linux system where there isn\u2019t much activity, typically dozens or even hundreds \nof processes are running in the background. Using the tools described in this chapter, you \ncan view and manage the processes running on your system.", "doc_id": "059c7af9-2d3d-4e7b-aa49-12758431e88d", "embedding": null, "doc_hash": "21567a7604925438c90c38ece2a3c57d9c7fadcaef404d1ed7447a929f5075c4", "extra_info": {"page_label": "175"}, "node_info": {"start": 0, "end": 2664}, "relationships": {"1": "36f27ac3-e090-4c77-aecd-743c598043b5"}}, "__type__": "1"}, "a74bc16d-db74-45cc-8dd7-0e2e1146e34a": {"__data__": {"text": "Chapter 6: Managing Running Processes\n145\n6Managing processes includes viewing processes in different ways, running them in the fore -\nground or background, and killing or renicing them. More advanced features for limiting \nresource usage by selected processes are available using the cgroups feature.\nIn the next chapter, you learn how to combine commands and programming functions into \nfiles that can be run as shell scripts.\nExercises\nUse these exercises to test your knowledge of viewing running processes and then changing \nthem later by killing them or changing processor priority (nice value). These tasks assume \nthat you are running a Fedora or Red Hat Enterprise Linux system (although some tasks \nwork on other Linux systems as well). If you are stuck, solutions to the tasks are shown in \nAppendix B (although in Linux, you can often use multiple ways to complete a task).\n1. List all processes running on your system, showing a full set of columns. Pipe that \noutput to the less  command so that you can page through the list of processes.\n2. List all processes running on the system and sort those processes by the name of \nthe user running each process.\n3. List all processes running on the system, and display the following columns of \ninformation: process ID, username, group name, virtual memory size, resident mem-\nory size, and the command.\n4. Run the top  command to view processes running on your system. Go back and \nforth between sorting by CPU usage and memory consumption.\n5. Start the gedit process from your desktop. Make sure that you run it as the user \nyou are logged in as. Use the System Monitor window to kill that process.\n6. Run the gedit process again. This time, using the kill command, send a signal \nto the gedit process that causes it to pause (stop). Try typing some text into the \ngedit window and make sure that no text appears yet.\n7. Use the killall  command to tell the gedit command that you paused in the \nprevious exercise to continue working. Make sure that the text you type in after \ngedit was paused now appears on the window.\n8. Install the xeyes  command (in Fedora, it is in the xorg-x11-apps  package). Run \nthe xeyes  command about 20 times in the background so that 20 xeyes  win-\ndows appear on the screen. Move the mouse around and watch the eyes watch your \nmouse pointer. When you have had enough fun, kill all xeyes  processes in one \ncommand using killall .\n9. As a regular user, run the gedit command so that it starts with a nice value of 5.\n10. Using the renice  command, change the nice value of the gedit command you \njust started to 7 . Use any command you like to verify that the current nice value \nfor the gedit command is now set to 7 .", "doc_id": "a74bc16d-db74-45cc-8dd7-0e2e1146e34a", "embedding": null, "doc_hash": "e78dcdbf248a676e0cb8e082506394f8d245aaabc325c28ffec522f0d0d3a43d", "extra_info": {"page_label": "176"}, "node_info": {"start": 0, "end": 2713}, "relationships": {"1": "36452ef8-c91e-44c1-a414-3aa45078be00"}}, "__type__": "1"}, "05e96bc0-9cab-407d-9fa0-22545bb7631e": {"__data__": {"text": "147\nCHAPTER7\nWriting Simple Shell Scripts\nIN THIS CHAPTER\nWorking with shell scripts\nDoing arithmetic in shell scripts\nRunning loops and cases in shell scripts\nCreating simple shell scripts\nYou\u2019d never get any work done if you typed every command that needs to be run on your Linux \nsystem when it starts. Likewise, you could work more efficiently if you grouped together sets \nof commands that you run all the time. Shell scripts can handle these tasks.\nA shell script is a group of commands, functions, variables, or just about anything else you can use \nfrom a shell. These items are typed into a plain-text file. That file can then be run as a command. \nLinux systems have traditionally used system initialization shell scripts during system startup to run \ncommands needed to get services going. You can create your own shell scripts to automate the tasks \nthat you need to do regularly.\nFor decades, building shell scripts was the primary skill needed to join together sets of tasks in UNIX \nand Linux systems. As demands for configuring Linux systems grew beyond single-system setups to \ncomplex, automated cluster configurations, more structured methods have arisen. These methods \ninclude Ansible playbooks and Kubernetes YAML files, described later in cloud-related chapters. That \nsaid, writing shell scripts is still the best next step from running individual commands to building \nrepeatable tasks in Linux systems.\nThis chapter provides a rudimentary overview of the inner workings of shell scripts and how they can \nbe used. You learn how simple scripts can be harnessed to a scheduling facility (such as cron  or at ) \nto simplify administrative tasks or just run on demand as they are needed.\nUnderstanding Shell Scripts\nHave you ever had a task that you needed to do over and over that took lots of typing on the \ncommand line? Do you ever think to yourself, \u201cWow, I wish I could just type one command to do all \nthis\u201d? Maybe a shell script is what you\u2019re after.\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "05e96bc0-9cab-407d-9fa0-22545bb7631e", "embedding": null, "doc_hash": "41814ae73ed4dbe348a515a2bdefd2a81ff3d275a88992d8a8c067ed91d574f8", "extra_info": {"page_label": "177"}, "node_info": {"start": 0, "end": 2103}, "relationships": {"1": "c8c42fa9-54df-479c-abe6-a43454fdc781"}}, "__type__": "1"}, "7bf03655-62db-4115-b539-4b32dee0480f": {"__data__": {"text": "Part II: Becoming a Linux Power User148Shell scripts are the equivalent of batch files in Windows and can contain long lists of com-\nmands, complex flow control, arithmetic evaluations, user-defined variables, user-defined \nfunctions, and sophisticated condition testing. Shell scripts are capable of handling every -\nthing from simple one-line commands to something as complex as starting up a Linux \nsystem. Although dozens of different shells are available in Linux, the default shell for \nmost Linux systems is called bash, the B ourne A gain SH ell.\nExecuting and debugging shell scripts\nOne of the primary advantages of shell scripts is that they can be opened in any text editor \nto see what they do. A big disadvantage is that large or complex shell scripts often execute \nmore slowly than compiled programs. You can execute a shell script in two basic ways:\n\u25a0\u25a0The filename is used as an argument to the shell (as in bash myscript ). In this \nmethod, the file does not need to be executable; it just contains a list of shell com-\nmands. The shell specified on the command line is used to interpret the commands \nin the script file. This is most common for quick, simple tasks.\n\u25a0\u25a0The shell script may also have the name of the interpreter placed in the first line \nof the script preceded by #!  (as in #!/bin/bash ) and have the execute bit of the \nfile containing the script set (using chmod +x filename ). You can then run your \nscript just as you would any other program in your path simply by typing the name \nof the script on the command line.\nWhen scripts are executed in either manner, options for the program may be specified on \nthe command line. Anything following the name of the script is referred to as a command-\nline argument .\nAs with writing any software, there is no substitute for clear and thoughtful design and \nlots of comments. The pound sign ( #) prefaces comments and can take up an entire line or \nexist on the same line after script code. It is best to implement more complex shell scripts \nin stages, making sure that the logic is sound at each step before continuing. Here are a \nfew good, concise tips to make sure that things are working as expected during testing:\n\u25a0\u25a0In some cases, you can place an echo  statement at the beginning of lines within \nthe body of a loop and surround the command with quotes. That way, rather than \nexecuting the code, you can see what will be executed without making any perma -\nnent changes.\n\u25a0\u25a0To achieve the same goal, you can place dummy echo  statements throughout the \ncode. If these lines get printed, you know the correct logic branch is being taken.\n\u25a0\u25a0You can use set -x  near the beginning of the script to display each command that \nis executed or launch your scripts using\n        $ bash -x myscript\n\u25a0\u25a0Because useful scripts have a tendency to grow over time, keeping your code read -\nable as you go along is extremely important. Do what you can to keep the logic of \nyour code clean and easy to follow.", "doc_id": "7bf03655-62db-4115-b539-4b32dee0480f", "embedding": null, "doc_hash": "ff770e00fb2fbec35b487b4741a4f2cef84205c2b7cd2a3090fe39509321ab4d", "extra_info": {"page_label": "178"}, "node_info": {"start": 0, "end": 2984}, "relationships": {"1": "fb2db519-a8ba-42a6-859d-28060be41a4c"}}, "__type__": "1"}, "43f7fbc8-ee6c-47f7-8431-261b9bf73d71": {"__data__": {"text": "Chapter 7: Writing Simple Shell Scripts\n149\n7Understanding shell variables\nOften within a shell script, you want to reuse certain items of information. During the \ncourse of processing the shell script, the name or number representing this information \nmay change. To store information used by a shell script in such a way that it can be easily \nreused, you can set variables . Variable names within shell scripts are case sensitive and can \nbe defined in the following manner:\nNAME=value\nThe first part of a variable is the variable name, and the second part is the value set for \nthat name. Be sure that the NAME  and value  touch the equal sign, without any spaces. \nVariables can be assigned from constants, such as text, numbers, and underscores. This \nis useful for initializing values or saving lots of typing for long constants. The following \nexamples show variables set to a string of characters ( CITY ) and a numeric value ( PI):\nCITY=\"Springfield\"\nPI=3.14159265\nVariables can contain the output of a command or command sequence. You can accomplish \nthis by preceding the command with a dollar sign and open parenthesis, following it with \na closing parenthesis. For example, MYDATE=$(date) assigns the output from the date  \ncommand to the MYDATE  variable. Enclosing the command in back-ticks (`)  can have the \nsame effect. In this case, the date  command is run when the variable is set and not each \ntime the variable is read.\nEscaping Special Shell Characters\nKeep in mind that characters such as the dollar sign ( $), back-tick ( `), asterisk ( *), exclamation point ( !), \nand others have special meaning to the shell, which you will see as you proceed through this chapter. \nOn some occasions, you want the shell to use these characters\u2019 special meaning and other times you \ndon\u2019t. For example, if you typed echo $HOME , the shell would think that you meant to display the name \nof your home directory (stored in the $HOME  variable) to the screen (such as /home/chris ) because a \n$ indicates a variable name follows that character.\nIf you wanted literally to show $HOME , you would need to escape the $ . Typing echo  \u2019$HOME' or echo \n\\$HOME  would literally show $HOME  on the screen. So, if you want to have the shell interpret a single \ncharacter literally, precede it with a backslash ( \\). To have a whole set of characters interpreted literally, \nsurround those characters with single quotes ( ').\nUsing double quotes is a bit trickier. Surround a set of text with double quotes if you want all but a few \ncharacters used literally. For example, with text surrounded with double quotes, dollar signs ( $), back-\nticks (`), and exclamation points ( !) are interpreted specially, but other characters (such as an asterisk) \nare not. Type these three lines to see the different output (shown on the right):\n    echo '$HOME * `date`'   $HOME * `date`\n    echo \u2033$HOME * `date`\u2033   /home/chris * Tue Jan 21 16:56:52 EDT 2020\n    echo $HOME * `date`     /home/chris file1 file2 Tue Jan 21 16:56:52 EDT 2020", "doc_id": "43f7fbc8-ee6c-47f7-8431-261b9bf73d71", "embedding": null, "doc_hash": "2fb2a149b0d90cb14461bc21557706676cba20326e0772963dca652e806de7c9", "extra_info": {"page_label": "179"}, "node_info": {"start": 0, "end": 3027}, "relationships": {"1": "2e366c1b-2ab0-4c1a-a8e6-79b86100499b"}}, "__type__": "1"}, "92b2a89b-c831-4d28-a426-2020333bedff": {"__data__": {"text": "Part II: Becoming a Linux Power User150Using variables is a great way to get information that can change from computer to \ncomputer or from day to day. The following example sets the output of the uname -n  \ncommand to the MACHINE  variable. Then I use parentheses to set NUM_FILES  to the \nnumber of files in the current directory by piping ( |) the output of the ls  command to the \nword count command ( wc -l ):\nMACHINE=`uname -n`\nNUM_FILES=$(/bin/ls | wc -l)\nVariables can also contain the value of other variables. This is useful when you have to pre -\nserve a value that will change so that you can use it later in the script. Here, BALANCE  is \nset to the value of the CurBalance  variable:\nBALANCE=\"$CurBalance\"\nSpecial shell positional parameters\nThere are special variables that the shell assigns for you. One set of commonly used vari-\nables is called positional parameters  or command-line arguments , and it is referenced as $0, \n$1, $2, $3.\u00a0.\u00a0.$ n. $0 is special, and it is assigned the name used to invoke your script; the \nothers are assigned the values of the parameters passed on the command line in the order \nthey appeared. For instance, let\u2019s say that you had a shell script named myscript  which \ncontained the following:\n#!/bin/bash\n# Script to echo out command-line arguments\necho \"The first argument is $1, the second is $2.\"\necho \"The command itself is called $0.\"\necho \"There are $# parameters on your command line\"\necho \"Here are all the arguments: $@\"\nAssuming that the script is executable and located in a directory in your $PATH , the \nfollowing shows what would happen if you ran that command with foo  and bar  as \narguments:\n$ chmod 755 /home/chris/bin/myscript\n$ myscript foo bar\nThe first argument is foo, the second is bar.\nThe command itself is called /home/chris/bin/myscript.\nThere are 2 parameters on your command line\nHere are all the arguments: foo barNote\nWhen assigning variables, use only the variable name (for example, BALANCE ). When you reference a variable, \nmeaning that you want the value  of the variable, precede it with a dollar sign (as in $CurBalance ). The result of \nthe latter is that you get the value of the variable, not the variable name itself.", "doc_id": "92b2a89b-c831-4d28-a426-2020333bedff", "embedding": null, "doc_hash": "fcac0397f6461e28ef6d1f40db5e451e01a6ef9cfd44c99f2d256818ea6bed27", "extra_info": {"page_label": "180"}, "node_info": {"start": 0, "end": 2211}, "relationships": {"1": "b014570c-807c-4087-a1de-ad12c5853ae2"}}, "__type__": "1"}, "573e6b23-1ec1-4382-aab8-97105ecb392b": {"__data__": {"text": "Chapter 7: Writing Simple Shell Scripts\n151\n7As you can see, the positional parameter $0  is the full path or relative path to myscript , \n$1 is foo , and $2  is bar .\nAnother variable, $# , tells you how many parameters your script was given. In the example, \n$# would be 2. The $@  variable holds all of the arguments entered at the command line. \nAnother particularly useful special shell variable is $?, which receives the exit status of the \nlast command executed. Typically, a value of zero means that the command exited success -\nfully, and anything other than zero indicates an error of some kind. For a complete list of \nspecial shell variables, refer to the bash  man page.\nReading in parameters\nUsing the read  command, you can prompt the user for information and store that informa -\ntion to use later in your script. Here\u2019s an example of a script that uses the read  command:\n#!/bin/bash\nread -p \"Type in an adjective, noun and verb (past tense): \" adj1 noun1 verb1\necho \"He sighed and $verb1 to the elixir. Then he ate the $adj1 $noun1.\"\nIn this script, after the script prompts for an adjective, noun, and verb, the user is \nexpected to enter words that are then assigned to the adj1 , noun1 , and verb1  vari-\nables. Those three variables are then included in a silly sentence, which is displayed on the \nscreen. If the script were called sillyscript , here\u2019s an example of how it might run:\n$ chmod 755 /home/chris/bin/sillyscript\n$ sillyscript\nType in an adjective, noun and verb (past tense): hairy football danced\nHe sighed and danced to the elixir. Then he ate the hairy football.\nParameter expansion in bash\nAs mentioned earlier, if you want the value of a variable, you precede it with a $  (for exam -\nple, $CITY ). This is really just shorthand for the notation ${CITY} ; curly braces are used \nwhen the value of the parameter needs to be placed next to other text without a space. \nBash has special rules that allow you to expand the value of a variable in different ways. \nGoing into all of the rules is probably overkill for a quick introduction to shell scripts, but \nthe following list presents some common constructs you\u2019re likely to see in bash scripts that \nyou find on your Linux system.\n${var:-value}: If variable is unset or empty, expand this to value .\n${var#pattern}: Chop the shortest match for pattern  from the front of var \u2019s value.\n${var##pattern}: Chop the longest match for pattern  from the front of var \u2019s value.\n${var%pattern}: Chop the shortest match for pattern  from the end of var \u2019s value.\n${var%%pattern}: Chop the longest match for pattern  from the end of var \u2019s value.", "doc_id": "573e6b23-1ec1-4382-aab8-97105ecb392b", "embedding": null, "doc_hash": "fcb72edee3cb52cac4c9a774575706d29ac2da67b15899a9fc6d9cfeda21e01e", "extra_info": {"page_label": "181"}, "node_info": {"start": 0, "end": 2626}, "relationships": {"1": "89e9ee3a-f52a-4c91-be53-186124424271"}}, "__type__": "1"}, "99f98855-6912-4860-92f1-e9ced9713b1b": {"__data__": {"text": "Part II: Becoming a Linux Power User152Try typing the following commands from a shell to test how parameter expansion works:\n$ THIS=\"Example\"\n$ THIS=${THIS:-\"Not Set\"}\n$ THAT=${THAT:-\"Not Set\"}\n$ echo $THIS\nExample\n$ echo $THAT\nNot Set\nIn the examples here, the THIS  variable is initially set to the word Example . In the next \ntwo lines, the THIS  and THAT  variables are set to their current values or to Not Set , \nif they are not currently set. Notice that because I just set THIS  to the string Example , \nwhen I echo the value of THIS  it appears as Example . However, because THAT  was not set, \nit appears as Not Set .\nIn the following example, MYFILENAME  is set to /home/digby/myfile.txt . Next, the \nFILE  variable is set to myfile.txt  and DIR  is set to /home/digby . In the NAME  vari-\nable, the filename is cut down simply to myfile ; then, in the EXTENSION  variable, the file \nextension is set to txt . (To try these out, you can type them at a shell prompt as in the \nprevious example and echo the value of each variable to see how it is set.) Type the code on \nthe left. The material on the right side describes the action.\nMYFILENAME=/home/digby/myfile.txt : Sets the value of MYFILENAME\nFILE=${MYFILENAME##*/} : FILE  becomes myfile.txt\nDIR=${MYFILENAME%/*} : DIR  becomes /home/digby\nNAME=${FILE%.*} : NAME  becomes myfile\nEXTENSION=${FILE##*.} : EXTENSION  becomes txt\nPerforming arithmetic in shell scripts\nBash uses untyped variables , meaning it normally treats variables as strings of text, but you \ncan change them on the fly if you want it to.\nBash uses untyped variables , meaning that you are not required to specify whether a vari-\nable is text or numbers. It normally treats variables as strings of text, so unless you tell it \notherwise with declare , your variables are just a bunch of letters to bash. However, when \nyou start trying to do arithmetic with them, bash converts them to integers if it can. This \nmakes it possible to do some fairly complex arithmetic in bash.\nInteger arithmetic can be performed using the built-in let  command or through the \nexternal expr  or bc  commands. After setting the variable BIGNUM  value to 1024 , the Note\nFor the rest of this section, I show how variables and commands may appear in a shell script. To try out any of those \nexamples, however, you can simply type them into a shell, as shown in the previous example.", "doc_id": "99f98855-6912-4860-92f1-e9ced9713b1b", "embedding": null, "doc_hash": "3a7a0d8bb82784b7518e7708f4c68e066bc11b8e75e43f1f15c7c30464e7c008", "extra_info": {"page_label": "182"}, "node_info": {"start": 0, "end": 2397}, "relationships": {"1": "2c2bb521-9736-4b75-8ef1-1caf5f928483"}}, "__type__": "1"}, "b03af0db-db8a-45f1-955b-b50405bc530c": {"__data__": {"text": "Chapter 7: Writing Simple Shell Scripts\n153\n7three commands that follow would all store the value 64  in the RESULT  variable. The bc  \ncommand is a calculator application that is available in most Linux distributions. The last \ncommand gets a random number between 0 and 10 and echoes the results back to you.\nBIGNUM=1024\nlet RESULT=$BIGNUM/16\nRESULT=`expr $BIGNUM / 16`\nRESULT=`echo \"$BIGNUM / 16\" | bc`\nlet foo=$RANDOM; echo $foo\nAnother way to grow a variable incrementally is to use $(())  notation with ++I  added to \nincrement the value of I . Try typing the following:\n$ I=0\n$ echo \"The value of I after increment is $((++I))\"\nThe value of I after increment is 1\n \n$ echo \"The value of I before and after increment is $((I++)) and $I\"\nThe value of I before and after increment is 1 and 2\nRepeat either of those commands to continue to increment the value of $I .\nTo see a complete list of the kinds of arithmetic that you can perform using the let  \ncommand, type help let  at the bash prompt.\nUsing programming constructs in shell scripts\nOne of the features that makes shell scripts so powerful is that their implementation of \nlooping and conditional execution constructs is similar to those found in more complex \nscripting and programming languages. You can use several different types of loops, depend -\ning on your needs.\nThe \u2033 if.\u00a0.\u00a0.then \u2033 statements\nThe most commonly used programming construct is conditional execution, or the if  state -\nment. It is used to perform actions only under certain conditions. There are several varia -\ntions of if  statements for testing various types of conditions.\nThe first if...then  example tests if VARIABLE  is set to the number 1 . If it is, then the \necho  command is used to say that it is set to 1 . The fi  statement then indicates that the \nif statement is complete, and processing can continue.Note\nAlthough most elements of shell scripts are relatively freeform (where white space, such as spaces or tabs, is insig -\nnificant), both let  and expr  are particular about spacing. The let  command insists on no spaces between each \noperand and the mathematical operator, whereas the syntax of the expr  command requires white space between \neach operand and its operator. In contrast to those, bc  isn\u2019t picky about spaces, but it can be trickier to use \nbecause it does floating-point arithmetic.", "doc_id": "b03af0db-db8a-45f1-955b-b50405bc530c", "embedding": null, "doc_hash": "4fbc09b71e3cf4f54eeedfe99d40842e8560e6a1aa65b241003e638bd9580b7d", "extra_info": {"page_label": "183"}, "node_info": {"start": 0, "end": 2359}, "relationships": {"1": "42a81c54-449f-4ae8-9606-7a5453b8e8c0"}}, "__type__": "1"}, "a6ddbe78-8c66-4b99-8f26-f147ceb9360b": {"__data__": {"text": "Part II: Becoming a Linux Power User154VARIABLE=1\nif [ $VARIABLE -eq 1 ] ; then\necho \"The variable is 1\"\nfi\nInstead of using -eq , you can use the equal sign ( =), as shown in the following example. \nThe =  works best for comparing string values, while -eq  is often better for comparing num-\nbers. Using the else  statement, different words can be echoed if the criterion of the if  \nstatement isn\u2019t met ( $STRING = \u2033 Friday \u2033). Keep in mind that it\u2019s good practice to put \nstrings in double quotes.\nSTRING=\"Friday\"\nif [ $STRING = \"Friday\" ] ; then\necho \"WhooHoo.  Friday.\"\nelse\necho \"Will Friday ever get here?\"\nfi\nYou can also reverse tests with an exclamation mark ( !). In the following example, if \nSTRING  is not Monday , then \u2033At least it's not Monday \u2033 is echoed.\nSTRING=\"FRIDAY\"\nif [ \"$STRING\" != \"Monday\" ] ; then\n   echo \"At least it's not Monday\"\nfi\nIn the following example, elif  (which stands for \u201celse if\u201d) is used to test for an additional \ncondition (for example, whether filename  is a file or a directory).\nfilename=\"$HOME\"\nif [ -f \"$filename\" ] ; then\n   echo \"$filename is a regular file\"\nelif [ -d \"$filename\" ] ; then\n   echo \"$filename is a directory\"\nelse\n   echo \"I have no idea what $filename is\"\nfi\nAs you can see from the preceding examples, the condition you are testing is placed \nbetween square brackets [ ] . When a test expression is evaluated, it returns either a value \nof 0, meaning that it is true, or a 1, meaning that it is false. Notice that the echo  lines are \nindented. The indentation is optional and done only to make the script more readable.\nTable\u00a07.1 lists the conditions that are testable and is quite a handy reference. (If you\u2019re in a \nhurry, you can type help test  on the command line to get the same information.)", "doc_id": "a6ddbe78-8c66-4b99-8f26-f147ceb9360b", "embedding": null, "doc_hash": "f671b3d4f3bd1444e6f7fe02b4bb2579b3cef4654e213e3ba73b6e3074f084c2", "extra_info": {"page_label": "184"}, "node_info": {"start": 0, "end": 1770}, "relationships": {"1": "e644cf85-40d6-4555-a8ce-1a7555ccbcab"}}, "__type__": "1"}, "273d6719-1355-4b83-947b-26128dc77d67": {"__data__": {"text": "Chapter 7: Writing Simple Shell Scripts\n155\n7TABLE 7.1  Operators for Test Expressions\nOperator What Is Being Tested?\n-a file Does the file exist? (same as -e)\n-b file Is the file a block special device?\n-c file Is the file character special (for example, a character device)? Used to \nidentify serial lines and terminal devices.\n-d file Is the file a directory?\n-e file Does the file exist? (same as -a)\n-f file Does the file exist, and is it a regular file (for example, not a directory, \nsocket, pipe, link, or device file)?\n-g file Does the file have the set group id (SGID) bit set?\n-h file Is the file a symbolic link? (same as -L)\n-k file Does the file have the sticky bit set?\n-L file Is the file a symbolic link?\n-n string Is the length of the string greater than 0 bytes?\n-O file Do you own the file?\n-p file Is the file a named pipe?\n-r file Is the file readable by you?\n-s file Does the file exist, and is it larger than 0 bytes?\n-S file Does the file exist, and is it a socket?\n-t fd Is the file descriptor connected to a terminal?\n-u file Does the file have the set user id (SUID) bit set?\n-w file Is the file writable by you?\n-x file Is the file executable by you?\n-z string Is the length of the string 0 (zero) bytes?\nexpr1  -a expr2 Are both the first expression and the second expression true?\nexpr1  -o expr2 Is either of the two expressions true?\nfile1  -nt file2 Is the first file newer than the second file (using the modification \ntime stamp)?\nfile1  -ot file2 Is the first file older than the second file (using the modification \ntime stamp)?\nfile1  -ef file2 Are the two files associated by a link (a hard link or a symbolic link)?\nvar1  = var2 Is the first variable equal to the second variable?\nvar1  -eq  var2 Is the first variable equal to the second variable?\nvar1  -ge  var2 Is the first variable greater than or equal to the second variable?\nContinues", "doc_id": "273d6719-1355-4b83-947b-26128dc77d67", "embedding": null, "doc_hash": "44d262a5a541458b785a2ef7a46279e9f30d19c3899ff6592acabf2bcd312e65", "extra_info": {"page_label": "185"}, "node_info": {"start": 0, "end": 1883}, "relationships": {"1": "ab4f56f2-abc5-456b-ba51-c2e060295d05"}}, "__type__": "1"}, "ca097ea6-c6a6-44d8-8898-79a471e99efd": {"__data__": {"text": "Part II: Becoming a Linux Power User156There is also a special shorthand method of performing tests that can be useful for simple \none-command actions . In the following example, the two pipes ( ||) indicate that if the \ndirectory being tested for doesn\u2019t exist ( -d dirname ), then make the directory ( mkdir \n$dirname ):\n# [ test ] || action\n# Perform simple single command if test is false\ndirname=\"/tmp/testdir\"\n[ -d \"$dirname\" ] || mkdir \"$dirname\"\nInstead of pipes, you can use two ampersands to test if something is true. In the follow -\ning example, a command is being tested to see if it includes at least three command-line \narguments:\n# [ test ] && {action}\n# Perform simple single action if test is true\n[ $# -ge 3 ] && echo \"There are at least 3 command line arguments.\"\nYou can combine the &&  and ||  operators to make a quick, one-line if...then...else . \nThe following example tests that the directory represented by $dirname  already exists. If \nit does, a message says the directory already exists. If it doesn\u2019t, the statement creates the \ndirectory:\n# dirname=mydirectory\n[ -e $dirname ] && echo $dirname already exists || mkdir $dirname\n \nThe case command\nAnother frequently used construct is the case  command. Similar to a switch  statement in \nprogramming languages, this can take the place of several nested if  statements. The fol -\nlowing is the general form of the case  statement:\ncase \"VAR\" in\n   Result1)\n      { body };;\n   Result2)\n      { body };;Operator What Is Being Tested?\nvar1  -gt  var2 Is the first variable greater than the second variable?\nvar1  -le var2 Is the first variable less than or equal to the second variable?\nvar1  -lt var2 Is the first variable less than the second variable?\nvar1  != var2 Is the first variable not equal to the second variable?\nvar1  -ne  var2 Is the first variable not equal to the second variable?TABLE 7.1  (continued)", "doc_id": "ca097ea6-c6a6-44d8-8898-79a471e99efd", "embedding": null, "doc_hash": "fda5a333a105c3ef730defbe34533c932b27794baa8b5426200001e3e6a718e9", "extra_info": {"page_label": "186"}, "node_info": {"start": 0, "end": 1896}, "relationships": {"1": "983dff8f-8f64-4a3a-8c0a-0897b52e2f68"}}, "__type__": "1"}, "75deb755-9a66-4614-81b0-51dea63714c6": {"__data__": {"text": "Chapter 7: Writing Simple Shell Scripts\n157\n7   *)\n      { body } ;;\nesac\nAmong other things, you can use the case  command to help with your backups. The fol -\nlowing case  statement tests for the first three letters of the current day ( case 'date \n+%a' in ). Then, depending on the day, a particular backup directory ( BACKUP ) and tape \ndrive (TAPE ) are set.\n# Our VAR doesn't have to be a variable,\n# it can be the output of a command as well\n# Perform action based on day of week\ncase `date +%a` in\n   \"Mon\")\n         BACKUP=/home/myproject/data0\n         TAPE=/dev/rft0\n# Note the use of the double semi-colon to end each option\n         ;;\n# Note the use of the \"|\" to mean \"or\"\n   \"Tue\" | \"Thu\")\n         BACKUP=/home/myproject/data1\n         TAPE=/dev/rft1\n         ;;\n   \"Wed\" | \"Fri\")\n         BACKUP=/home/myproject/data2\n         TAPE=/dev/rft2\n         ;;\n# Don't do backups on the weekend.\n   *)\n \nBACKUP=\"none\"\n         TAPE=/dev/null\n         ;;\nesac\nThe asterisk ( *) is used as a catchall, similar to the default  keyword in the C program-\nming language. In this example, if none of the other entries are matched on the way down \nthe loop, the asterisk is matched and the value of BACKUP  becomes none . Note the use of \nesac , or case  spelled backwards, to end the case  statement.\nThe \u2033 for.\u00a0.\u00a0.do \u2033 loop\nLoops are used to perform actions over and over again until a condition is met or until all \ndata has been processed. One of the most commonly used loops is the for...do  loop. It \niterates through a list of values, executing the body of the loop for each element in the list. \nThe syntax and a few examples are presented here:\nfor VAR in LIST\ndo\n    { body }\ndone", "doc_id": "75deb755-9a66-4614-81b0-51dea63714c6", "embedding": null, "doc_hash": "88ea35f9d6f11c6ec81803a0cac4b910bfd901bd5ebcb255987bb792e7b7fd39", "extra_info": {"page_label": "187"}, "node_info": {"start": 0, "end": 1693}, "relationships": {"1": "52511555-1670-4f40-8690-0f1aa4a48d96"}}, "__type__": "1"}, "4296237c-de48-42f1-9d56-131b5e5069fe": {"__data__": {"text": "Part II: Becoming a Linux Power User158The for  loop assigns the values in LIST  to VAR  one at a time. Then, for each value, the \nbody  in braces between do  and done  is executed. VAR  can be any variable name, and \nLIST  can be composed of pretty much any list of values or anything that generates a list.\nfor NUMBER in 0 1 2 3 4 5 6 7 8 9\ndo\n   echo The number is $NUMBER\ndone\n \nfor FILE in `/bin/ls`\ndo\n   echo $FILE\ndone\nYou can also write it this way, which is somewhat cleaner:\nfor NAME in John Paul Ringo George ; do\n   echo $NAME is my favorite Beatle\ndone\nEach element in the LIST  is separated from the next by white space. This can cause trouble \nif you\u2019re not careful because some commands, such as ls -l , output multiple fields per \nline, each separated by white space. The string done  ends the for  statement.\nIf you\u2019re a die-hard C programmer, bash allows you to use C syntax to control your loops:\nLIMIT=10\n# Double parentheses, and no $ on LIMIT even though it's a variable!\nfor ((a=1; a <= LIMIT ; a++)) ; do\n  echo  \"$a\"\ndone\nThe \u2033 while.\u00a0.\u00a0.do \u2033 and \u2033 until.\u00a0.\u00a0.do \u2033 loops\nTwo other possible looping constructs are the while...do  loop and the until...do  loop. \nThe structure of each is presented here:\nwhile condition      until condition\ndo                   do\n   { body }            { body }\ndone                 done\nThe while  statement executes while the condition is true. The until  statement executes \nuntil the condition is true\u2014in other words, while the condition is false.\nHere is an example of a while  loop that outputs the number 0123456789:\nN=0\nwhile [ $N -lt 10 ] ; do\n   echo -n $N\n   let N=$N+1\ndone", "doc_id": "4296237c-de48-42f1-9d56-131b5e5069fe", "embedding": null, "doc_hash": "1515095f14f5bb7e533ea29bb099973f52004e99444ea87b648bcbf53c01dcaf", "extra_info": {"page_label": "188"}, "node_info": {"start": 0, "end": 1644}, "relationships": {"1": "1aadcf45-f101-4b2f-b81a-e019c1dffef5"}}, "__type__": "1"}, "51cc7534-84e4-496a-8c2a-e1d9e5734e9c": {"__data__": {"text": "Chapter 7: Writing Simple Shell Scripts\n159\n7Another way to output the number 0123456789 is to use an until  loop as follows:\nN=0\nuntil [ $N -eq 10 ] ; do\n   echo -n $N\n   let N=$N+1\ndone\nTrying some useful text manipulation programs\nBash is great and has lots of built-in commands, but it usually needs some help to do any -\nthing really useful. Some of the most common useful programs you\u2019ll see used are grep , \ncut, tr, awk , and sed . As with all of the best UNIX tools, most of these programs are \ndesigned to work with standard input and standard output, so you can easily use them with \npipes and shell scripts.\nThe general regular expression parser\nThe name general regular expression print  (grep ) sounds intimidating, but grep  is just a \nway to find patterns in files or text. Think of it as a useful search tool. Gaining expertise \nwith regular expressions is quite a challenge, but after you master it, you can accomplish \nmany useful things with just the simplest forms.\nFor example, you can display a list of all regular user accounts by using grep  to search for \nall lines that contain the text /home  in the /etc/passwd  file as follows:\n$ grep /home /etc/passwd\nOr you could find all environment variables that begin with HO  using the follow -\ning command:\n$ env | grep ^HO\nTo find a list of options to use with the grep  command, type man grep .\nRemove sections of lines of text (cut)\nThe cut  command can extract fields from a line of text or from files. It is very useful for \nparsing system configuration files into easy-to-digest chunks. You can specify the field sep -\narator you want to use and the fields you want, or you can break up a line based on bytes.\nThe following example lists all home directories of users on your system. This grep  \ncommand line pipes a list of regular users from the /etc/passwd  file and displays the \nsixth field ( -f6) as delimited by a colon ( -d':' ). The hyphen at the end tells cut  to read \nfrom standard input (from the pipe).Note\nThe ^  in the preceding code is the actual caret character, ^ , not what you\u2019ll commonly see for a backspace, ^H . Type \n^, H, and O (the uppercase letter) to see what items start with the uppercase characters HO.", "doc_id": "51cc7534-84e4-496a-8c2a-e1d9e5734e9c", "embedding": null, "doc_hash": "e84d2ed9c3e7e93db22cbb59af2bce5dfddf2d578c3a6d882e33ef2a53ed949b", "extra_info": {"page_label": "189"}, "node_info": {"start": 0, "end": 2212}, "relationships": {"1": "bccd5b63-36a4-4c5c-90b4-2c5dee99db12"}}, "__type__": "1"}, "363ff23e-6f93-4a30-9e49-5550ef79b0ee": {"__data__": {"text": "Part II: Becoming a Linux Power User160$ grep /home /etc/passwd | cut  -d':' -f6 -\n/home/chris\n/home/joe\nTranslate or delete characters (tr)\nThe tr  command is a character-based translator that can be used to replace one character \nor set of characters with another or to remove a character from a line of text.\nThe following example translates all uppercase letters to lowercase letters and displays the \nwords mixed upper and lower case as a result:\n$ FOO=\"Mixed UPpEr aNd LoWeR cAsE\"\n$ echo $FOO | tr [A-Z] [a-z]\nmixed upper and lower case\nIn the next example, the tr  command is used on a list of filenames to rename any files \nin that list so that any tabs or spaces (as indicated by the [:blank:]  option) contained \nin a filename are translated into underscores. Try running the following code in a test \ndirectory:\nfor file in * ; do\n   f=`echo $file | tr [:blank:] [_]`\n   [ \"$file\" = \"$f\" ] || mv -i -- \"$file\" \"$f\"\ndone\nThe stream editor (sed)\nThe sed  command is a simple scriptable editor, so it can perform only simple edits, such as \nremoving lines that have text matching a certain pattern, replacing one pattern of charac -\nters with another, and so on. To get a better idea of how sed  scripts work, there\u2019s no sub -\nstitute for the online documentation, but here are some examples of common uses.\nYou can use the sed  command essentially to do what I did earlier with the grep  example: \nsearch the /etc/passwd  file for the word home . Here the sed  command searches the \nentire /etc/passwd  file, searches for the word home , and prints any line containing the \nword home :\n$ sed -n '/home/p' /etc/passwd\nchris:x:1000:1000:Chris Negus:/home/chris:/bin/bash\njoe:x:1001:1001:Joe Smith:/home/joe:/bin/bash\nIn this next example, sed  searches the file somefile.txt  and replaces every instance of \nthe string Mac  with Linux . Notice that the letter g  is needed at the end of the substitu -\ntion command to cause every occurrence of Mac  on each line to be changed to Linux . \n(Otherwise, only the first instance of Mac  on each line is changed.) The output is then sent \nto the fixed_file.txt file. The output from sed  goes to stdout , so this command redi-\nrects the output to a file for safekeeping.\n$ sed 's/Mac/Linux/g' somefile.txt > fixed_file.txt", "doc_id": "363ff23e-6f93-4a30-9e49-5550ef79b0ee", "embedding": null, "doc_hash": "6a35bfb923af9c5877079fb51eac49412c04713c1c8d59b9e97a5ff1df287190", "extra_info": {"page_label": "190"}, "node_info": {"start": 0, "end": 2273}, "relationships": {"1": "75258f05-29d7-45e0-b1a4-71ccf39d5908"}}, "__type__": "1"}, "e6076e74-e729-40a7-b572-23481fec1f20": {"__data__": {"text": "Chapter 7: Writing Simple Shell Scripts\n161\n7You can get the same result using a pipe:\n$ cat somefile.txt | sed 's/Mac/Linux/g' > fixed_file.txt\nBy searching for a pattern and replacing it with a null pattern, you delete the original \npattern. This example searches the contents of the somefile.txt  file and replaces extra \nblank spaces at the end of each line ( s/ *$ ) with nothing ( //). Results go to the fixed_\nfile.txt  file.\n$ cat somefile.txt | sed 's/ *$//' > fixed_file.txt\nUsing simple shell scripts\nSometimes, the simplest of scripts can be the most useful. If you type the same sequence \nof commands repetitively, it makes sense to store those commands (once!) in a file. The fol -\nlowing sections offer a couple of simple, but useful, shell scripts.\nTelephone list\nThis idea has been handed down from generation to generation of old UNIX hacks. It\u2019s \nreally quite simple, but it employs several of the concepts just introduced.\n#!/bin/bash\n# (@)/ph\n# A very simple telephone list\n# Type \"ph new name number\" to add to the list, or\n# just type \"ph name\" to get a phone number\n \nPHONELIST=~/.phonelist.txt\n \n# If no command line parameters ($#), there\n# is a problem, so ask what they're talking about.\nif [ $# -lt 1 ] ; then\n  echo \"Whose phone number did you want? \"\n   exit 1\nfi\n \n# Did you want to add a new phone number?\nif [ $1 = \"new\" ] ; then\n  shift\n  echo $* >> $PHONELIST\n  echo $* added to database\n  exit 0\nfi\n \n# Nope. But does the file have anything in it yet?\n# This might be our first time using it, after all.\nif [ ! -s $PHONELIST ] ; then\n  echo \"No names in the phone list yet! \"\n  exit 1", "doc_id": "e6076e74-e729-40a7-b572-23481fec1f20", "embedding": null, "doc_hash": "f9d5874da4cd3eb58ab3a5353e010ba020371dacd19bd5a03d6033d189ee780d", "extra_info": {"page_label": "191"}, "node_info": {"start": 0, "end": 1621}, "relationships": {"1": "0c3b6d96-7e52-4a04-ad2b-f085d2791aff"}}, "__type__": "1"}, "957adf60-7664-4594-95e6-be32fb2fab6f": {"__data__": {"text": "Part II: Becoming a Linux Power User162else\n  grep -i -q \"$*\" $PHONELIST     # Quietly search the file\n  if [ $? -ne 0 ] ; then         # Did we find anything?\n    echo \"Sorry, that name was not found in the phone list\"\n    exit 1\n  else\n    grep -i \"$*\" $PHONELIST\n  fi\nfi\nexit 0\nSo, if you created the telephone list file as ph  in your current directory, you could type the \nfollowing from the shell to try out your ph  script:\n$ chmod 755 ph\n$ ./ph new \"Mary Jones\" 608-555-1212\nMary Jones 608-555-1212 added to database\n$ ./ph Mary\nMary Jones 608-555-1212\nThe chmod  command makes the ph  script executable. The ./ph  command runs the ph  \ncommand from the current directory with the new  option. This adds Mary Jones as the \nname and 608-555-1212 as the phone number to the database ( $HOME/.phonelist.txt ). \nThe next ph  command searches the database for the name Mary and displays the phone \nentry for Mary. If the script works, add it to a directory in your path (such as $HOME/bin ).\nBackup script\nBecause nothing works forever and mistakes happen, backups are just a fact of life when \ndealing with computer data. This simple script backs up all of the data in the home direc -\ntories of all of the users on your Fedora or RHEL system.\n#!/bin/bash\n# (@)/my_backup\n# A very simple backup script\n#\n \n# Change the TAPE device to match your system.\n# Check /var/log/messages to determine your tape device.\n \nTAPE=/dev/rft0\n \n# Rewind the tape device $TAPE\nmt $TAPE rew\n# Get a list of home directories\nHOMES=`grep /home /etc/passwd | cut -f6 -d':'`\n# Back up the data in those directories\ntar cvf $TAPE $HOMES\n# Rewind and eject the tape.\nmt $TAPE rewoffl", "doc_id": "957adf60-7664-4594-95e6-be32fb2fab6f", "embedding": null, "doc_hash": "e345800368a30ff3ecd8ef10069eb68a2091734803a6a4930dc3331812b25786", "extra_info": {"page_label": "192"}, "node_info": {"start": 0, "end": 1663}, "relationships": {"1": "7984fd7f-16a8-4a8f-9b56-611a78b0f025"}}, "__type__": "1"}, "1a334e0c-3c4e-461f-8fba-fabb92bd9b35": {"__data__": {"text": "Chapter 7: Writing Simple Shell Scripts\n163\n7Summary\nWriting shell scripts gives you the opportunity to automate many of your most common \nsystem administration tasks. This chapter covered common commands and functions that \nyou can use in scripting with the bash shell. It also provided some concrete examples of \nscripts for doing backups and other procedures.\nIn the next chapter, you transition from learning about user features into examining \nsystem administration topics. Chapter\u00a08, \u201cLearning System Administration,\u201d covers how \nto become the root user, as well as how to use administrative commands, monitor log files, \nand work with configuration files.\nExercises\nUse these exercises to test your knowledge of writing simple shell scripts. These tasks \nassume you are running a Fedora or Red Hat Enterprise Linux system (although some tasks \nwork on other Linux systems as well). If you are stuck, solutions to the tasks are shown in \nAppendix B (although in Linux, there are often multiple ways to complete a task).\n1. Create a script in your $HOME/bin  directory called myownscript . When the script \nruns, it should output information that appears as follows:\n        Today is Sat Jan 4 15:45:04 EST 2020.\n        You are in /home/joe and your host is abc.example.com.\nOf course, you need to read in your current date/time, current working directory, \nand hostname. Also, include comments about what the script does and indicate \nthat the script should run with the /bin/bash  shell.\n2. Create a script that reads in three positional parameters from the command line, \nassigns those parameters to variables named ONE , TWO , and THREE , respectively, \nand outputs that information in the following format:\n        There are X parameters that include Y.\n        The first is A, the second is B, the third is C.\nReplace X with the number of parameters and Y with all parameters entered. Then \nreplace A with the contents of variable ONE , B with variable TWO , and C with vari-\nable THREE .\n3. Create a script that prompts users for the name of the street and town where they \ngrew up. Assign town and street to variables called mytown  and mystreet , and \noutput them with a sentence that reads as shown below (of course, $mystreet  and \n$mytown  will appear with the actual town and street the user enters):\n        The street I grew up on was $mystreet and the town was \n$mytown", "doc_id": "1a334e0c-3c4e-461f-8fba-fabb92bd9b35", "embedding": null, "doc_hash": "b9de7334b427914cb1fdca32fc097cdd5d3c36e6b2f538fa74e00dd0b2265d71", "extra_info": {"page_label": "193"}, "node_info": {"start": 0, "end": 2391}, "relationships": {"1": "457bca46-30a6-48ab-85e3-8a92a227c9b8"}}, "__type__": "1"}, "f35676ad-b0f1-4f1c-ac64-79084cdd0e3a": {"__data__": {"text": "Part II: Becoming a Linux Power User1644. Create a script called myos  that asks the user, \u201cWhat is your favorite operating \nsystem?\u201d Output an insulting sentence if the user types \u201cWindows\u201d or \u201cMac.\u201d \nRespond \u201cGreat choice!\u201d if the user types \u201cLinux.\u201d For anything else, say \u201cIs < what \nis typed in > an operating system?\u201d\n5. Create a script that runs through the words moose , cow, goose , and sow  through a \nfor loop. Have each of those words appended to the end of the line \u201cI have a.\u00a0.\u00a0.\u00a0.\u201d", "doc_id": "f35676ad-b0f1-4f1c-ac64-79084cdd0e3a", "embedding": null, "doc_hash": "49f1e6435a0477ee68aa8a48be0196d7003afd4c97a3a3690b67fe4d56c7d917", "extra_info": {"page_label": "194"}, "node_info": {"start": 0, "end": 496}, "relationships": {"1": "5204de31-ae40-426a-9bff-9721945d5e71"}}, "__type__": "1"}, "bd31b1a6-96e1-4d8e-b2c7-f8ba1d5391ad": {"__data__": {"text": "Part IIIIN THIS PART\nChapter\u00a08 \nLearning System Administration\nChapter\u00a09 \nInstalling Linux\nChapter\u00a010 \nGetting and Managing Software\nChapter\u00a011 \nManaging User Accounts\nChapter\u00a012 \nManaging Disks and FilesystemsBecoming a Linux System \nAdministrator\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "bd31b1a6-96e1-4d8e-b2c7-f8ba1d5391ad", "embedding": null, "doc_hash": "432d789a7101a993a6e99030ffbaea85e626e4aedeeecac74aceeec8eaca1c40", "extra_info": {"page_label": "195"}, "node_info": {"start": 0, "end": 371}, "relationships": {"1": "cacd28ea-beb3-4626-9509-a1e0f4534dd2"}}, "__type__": "1"}, "20cd8e76-b65b-4706-9b60-3b15ab0e48d8": {"__data__": {"text": "167\nCHAPTER8\nLearning System Administration\nIN THIS CHAPTER\nDoing graphical administration\nUsing the root loginUnderstanding administrative commands, config files, and log filesWorking with devices and filesystems\nLinux, like other UNIX-based systems, was intended for use by more than one person at a time.  \nMultiuser features  enable many people to have accounts on a single Linux system with their \ndata kept secure from others. Multitasking  enables many people to run many programs on the \ncomputer at the same time, with each person able to run more than one program. Sophisticated networking protocols and applications make it possible for a Linux system to extend its capabilities to network users and computers around the world. The person assigned to manage all of a Linux system\u2019s resources is called the system administrator .\nEven if you are the only person using a Linux system, system administration is still set up to be separate from other computer use. To do most administrative tasks, you need to be logged in as the root user  (also called the superuser ) or to get root permission temporarily (usually using the sudo  \ncommand). Regular users who don\u2019t have root permission cannot change, or in some cases cannot even see, some of the configuration information for a Linux system. In particular, security features such as stored passwords are protected from general view.\nBecause Linux system administration is such a huge topic, this chapter focuses on the general prin -\nciples of Linux system administration. In particular, it examines some of the basic tools that you \nn\need to administer a Linux system for a personal desktop or on a small server. Beyond the basics, \nthis chapter also teaches you how to work with filesystems and monitor the setup and performance of your Linux system.\nUnderstanding System Administration\nSeparating the role of system administrator from that of other users has several effects. For a system that has many people using it, limiting who can manage it enables you to keep it more \nLinux\u00ae Bible , Tenth Edition. Christopher Negus.\n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "20cd8e76-b65b-4706-9b60-3b15ab0e48d8", "embedding": null, "doc_hash": "729d84084f74d3dde77340b2c41e4289726e3250e4addc49b2ba1e10433842e6", "extra_info": {"page_label": "196"}, "node_info": {"start": 0, "end": 2161}, "relationships": {"1": "bc74650d-bc92-4280-bc32-be1930fc7eeb"}}, "__type__": "1"}, "1c882041-a8fc-4a35-8799-55d08a4e3c4b": {"__data__": {"text": "Part III: Becoming a Linux System Administrator168secure. A separate administrative role also prevents others from casually harming your \nsystem when they are just using it to write a document or browse the Internet.\nIf you are the system administrator of a Linux system, you generally log in as a regular \nuser account and then ask for administrative privileges when you need them. This is often \ndone with one of the following:\nsu command : Often, su  is used to open a shell as root user. After the shell is open, \nthe administrator can run multiple commands and then exit to return to a shell as a \nregular user.\nsudo  command : With sudo , a regular user is given root privileges, but only when \nthat user runs the sudo  command to run another command. After running that one \ncommand with sudo , the user is immediately returned to a shell and acts as the \nregular user again. Ubuntu and Fedora by default assign sudo  privilege to the first \nuser account when those systems are installed. This is not done by default in RHEL, \nalthough during RHEL installation, you can choose for your first user to have sudo  \nprivilege if you\u2019d like.\nCockpit browser-based administration : RHEL, Fedora, and other Linux distributions \nhave committed to Cockpit as their primary browser-based system administration \nfacility. With Cockpit enabled, you can monitor and change your system\u2019s general \nactivities, storage, networking, accounts, services, and other features.\nGraphical windows : Before Cockpit was widely available, RHEL, Fedora, and other \nLinux distributions offered individual graphical administration tools that were \nlaunched by commands beginning with system-config-* . Although most of these \nadministration tools are not being offered in the latest release of RHEL and Fedora, \nthey are noted here because they are still available in older Linux releases.\nTasks that can be done only by the root user tend to be those that affect the system as a \nwhole or impact the security or health of the system. Following is a list of common features \nthat a system administrator is expected to manage:\nFilesystems : When you first install Linux, the directory structure is set up to make \nthe system usable. However, if users later want to add extra storage or change the \nfilesystem layout outside of their home directory, they need administrative priv -\nileges to do that. Also, the root user has permission to access files owned by any \nuser. As a result, the root user can copy, move, or change any other user\u2019s files\u2014a \nprivilege needed to make backup copies of the filesystem for safekeeping.\nSoftware installation : Because malicious software can harm your system or make it \ninsecure, you need root privilege to install software so that it is available to all \nusers on your system. Regular users can still install some software in their own \ndirectories and can list information about installed system software.\nUser accounts : Only the root user can add and remove user accounts and \ngroup accounts.", "doc_id": "1c882041-a8fc-4a35-8799-55d08a4e3c4b", "embedding": null, "doc_hash": "d5be37da17db6cf1735540e7ec26fbfdff07bfdda90635a81d73ad1ab52328b3", "extra_info": {"page_label": "197"}, "node_info": {"start": 0, "end": 3011}, "relationships": {"1": "2bb184bd-d85a-4720-885d-aa1158654ea1"}}, "__type__": "1"}, "a67effab-4441-4753-ab89-733a6c1b3c2c": {"__data__": {"text": "Chapter 8: Learning System Administration\n169\n8Network interfaces : In the past, the root user had to configure network interfaces and \nstart and stop those interfaces. Now, many Linux desktops allow regular users to \nstart and stop network interfaces from their desktop using Network Manager. This is \nparticularly true for wireless network interfaces, which can come and go by location \nas you move your Linux laptop or handheld device around.\nServers : Configuring web servers, file servers, domain name servers, mail servers, and \ndozens of other servers requires root privilege, as does starting and stopping those \nservices. Content, such as web pages, can be added to servers by non-root users if \nyou configure your system to allow that. Services are often run as special admin -\nistrative user accounts, such as apache  (for the httpd  service) and rpc  (for the \nrpcbind  service). So, if someone cracks a service, they can\u2019t get root privilege to \nother services or system resources.\nSecurity features : Setting up security features, such as firewalls and user access lists, \nis usually done with root privilege. It\u2019s also up to the root user to monitor how the \nservices are being used and to make sure that server resources are not exhausted \nor abused.\nThe easiest way to begin system administration is to use some graphical administration  \ntools.\nUsing Graphical Administration Tools\nMost system administration for the first Linux systems was done from the command line. \nAs Linux became more popular, however, both graphical and command-line interfaces began \nto be offered for most common Linux administrative tasks.\nThe following sections describe some of the point-and-click types of interfaces that are \navailable for doing system administration in Linux.\nUsing Cockpit browser-based administration\nCockpit  is the best browser-based Linux system administration tool that I have ever seen. It \nbrings together a range of Linux administrative activities into one interface and taps into \na diverse set of Linux APIs using cockpit-bridge. As someone doing Linux administration, \nhowever, you just need to know that you will get a consistent and stable way of adminis -\ntering your systems with Cockpit.\nGetting started with Cockpit is as simple as enabling the cockpit socket and pointing a \nweb browser at the Cockpit service. Because of Cockpit\u2019s plug-in design, there are new tools \nbeing created all the time that you can add to your system\u2019s Cockpit interface.\nIf you are starting with the latest RHEL or Fedora systems, performing the following proce -\ndure lets you enable and start using Cockpit on your system.", "doc_id": "a67effab-4441-4753-ab89-733a6c1b3c2c", "embedding": null, "doc_hash": "515cad551fc4a7f5d14b39f2ff8ff7dc1bcab986495b91f82ef07a899b1b6a0b", "extra_info": {"page_label": "198"}, "node_info": {"start": 0, "end": 2638}, "relationships": {"1": "ea6290d9-e146-4566-9beb-b77b3db2699b"}}, "__type__": "1"}, "70f33f55-233a-47fa-9690-072457f46a9b": {"__data__": {"text": "Part III: Becoming a Linux System Administrator1701. If Cockpit is not already installed, do the following:\n        # dnf install cockpit\n2. Log in as root user, and enable the Cockpit socket:\n        # systemctl enable --now cockpit.socket\n        Created symlink /etc/systemd/system/sockets.target.wants/\ncockpit.socket\n           \u2192 /usr/lib/systemd/system/cockpit.socket.\n3. Open your web browser to port 9090 on the system where you just enabled Cockpit. \nYou can use the hostname or IP address. Port 9090 is configured for https by \ndefault, although you can reconfigure that if you like to use http. Here are exam-\nples of addresses to type into your browser\u2019s address bar:\n        https://host1.example.com:9090/\n        https://192.168.122.114:9090/\n4. Assuming you didn\u2019t replace the self-signed certificate for Cockpit, you are warned \nthat the connection is not safe. To accept it anyway, and depending on your \nbrowser, you must select Advanced and agree to an exception to allow the browser \nto use the Cockpit service.\n5. Enter your username and password. Use the root user or a user with sudo  privi -\nleges if you want to change your system configuration. A regular user can see but \nnot change most settings. Figure\u00a08.1 shows an example of this window.\n6. Begin using Cockpit. The Cockpit dashboard contains a good set of features by \ndefault (you can add more later) on RHEL and Fedora systems. Figure\u00a08.2 shows an \nexample of the System area of the Cockpit dashboard:\nImmediately after logging in to Cockpit, you begin seeing system activity related to CPU \nusage, memory and swap, disk input/output, and network traffic. Selections in the left \nnavigation pane let you begin working with logs, storage, networking, user and group \naccounts, services, and many other features on your system.\nAs you proceed through the rest of this book, you will see descriptions of how to use the \ndifferent features of Cockpit in the appropriate section. To dive deeper into any of the \ntopics that you encounter with Cockpit, I recommend checking out the Cockpit project web -\nsite: https://cockpit-project.org .Note\nNo configuration is required to start this procedure. However, you can configure Cockpit to use your own OpenSSL \ncertificate instead of the self-signed one used by default. This lets you avoid having to accept the unverified self-\nsigned certificate when you open the Cockpit interface from your browser.", "doc_id": "70f33f55-233a-47fa-9690-072457f46a9b", "embedding": null, "doc_hash": "ef8decd5435f411411892efb2bd593dbac10c4f155ace6b5b03293f3807b7361", "extra_info": {"page_label": "199"}, "node_info": {"start": 0, "end": 2428}, "relationships": {"1": "768123eb-8a71-41b8-b233-99de00329cd1"}}, "__type__": "1"}, "c2d64453-8fbe-4c45-9774-fd3d5fe76de9": {"__data__": {"text": "Chapter 8: Learning System Administration\n171\n8Using system-config-* tools\nOn Fedora and RHEL systems prior to the release of Cockpit, a set of graphical tools was \navailable from the Administration submenu of the System menu (GNOME 2), from the \nFIGURE 8.1\nLogging in to Cockpit\nFIGURE 8.2\nView system activity and other topics from the Cockpit dashboard.", "doc_id": "c2d64453-8fbe-4c45-9774-fd3d5fe76de9", "embedding": null, "doc_hash": "0556fbfbdaf49c737502995de2741a83ca991d32ff975106afd6c5c9b6dc92c9", "extra_info": {"page_label": "200"}, "node_info": {"start": 0, "end": 356}, "relationships": {"1": "36a9c1e3-6cb9-426c-bc35-39417706362a"}}, "__type__": "1"}, "253fd818-3eb4-4122-b8c6-85a22cc23498": {"__data__": {"text": "Part III: Becoming a Linux System Administrator172Activities screen (GNOME 3), or from the command line. On these older Fedora and RHEL \nsystems, you could operate these tools from the command line by running a set of com-\nmands that began with the system-config*  string (such as system-config-network ).\nThese system-config*  tools require root permission. If you are logged in as a regular \nuser, you must enter the root password before the graphical user interface (GUI) applica -\ntion\u2019s window opens or, in some cases, when you request to do some special activity.\nThe following list describes many of the graphical tools available in earlier Fedora or RHEL \nsystems. (Some were only in Fedora and many are not installed by default.) The command \nthat you would launch to get the feature is shown in parentheses (often, it is the same as \nthe package name). The following graphical tools were available in Fedora:\nDomain Name System ( system-config-bind ): Create and configure zones if your \ncomputer is acting as a DNS server.\nHTTP  (system-config-httpd ): Configure your computer as an Apache web server.\nNFS (system-config-nfs ): Set up directories from your system to be shared with \nother computers on your network using the NFS service.\nRoot Password  (system-config-rootpassword ): Change the root password.\nSamba NFS ( system-config-samba ): Configure Windows (SMB) file sharing. (To  \nconfigure other Samba features, you can use the SWAT window.)\nThe following graphical tools were available in both Fedora and RHEL systems prior \nto RHEL 8:\nServices  (system-config-services ): Display and change which services are \nrunning on your Fedora system at different runlevels from the Service Configura -\ntion window.\nAuthentication  (system-config-authentication ): Change how users are authenti-\ncated on your system. Typically, shadow passwords and MD5 passwords are selected. \nHowever, if your network supports LDAP, Kerberos, SMB, NIS, or Hesiod authentica -\ntion, you can select to use any of those authentication types.\nDate & Time ( system-config-date ): Set the date and time or choose to have an NTP \nserver keep system time in sync.\nFirewall (system-config-firewall ): Configure your firewall to allow or deny  \nservices to computers from the network.\nLanguage  (system-config-language ): Select the default language used for \nthe system.\nPrinting  (system-config-printer ): Configure local and network printers.\nSELinux Management  (system-config-selinux ): Set SELinux enforcing modes and \ndefault policy.\nUsers & Groups ( system-config-users ): Add, display, and change user and group \naccounts for your Fedora system.", "doc_id": "253fd818-3eb4-4122-b8c6-85a22cc23498", "embedding": null, "doc_hash": "f0e22dad3c46200d2337591400371b955db31f89abcfb3c6869a8f893ea89398", "extra_info": {"page_label": "201"}, "node_info": {"start": 0, "end": 2642}, "relationships": {"1": "b163df89-06f2-4910-9f63-800a2f9ab160"}}, "__type__": "1"}, "be234742-fa94-496f-b6fc-7b4a6d29a44b": {"__data__": {"text": "Chapter 8: Learning System Administration\n173\n8Other administrative utilities were available from the Applications menu on the top panel. \nSelect the System Tools submenu (in GNOME 2) or go to the Activities screen (in GNOME 3) \nto choose some of the following tools (if installed):\nConfiguration Editor ( gconf-editor ): Directly edit the GNOME configura -\ntion database.\nDisk Usage Analyzer ( gnome-utils ): Display detailed information about your hard \ndisks and removable storage devices.\nDisk Utility  (gnome-disks ): Manage disk partitions and add filesystems ( gnome-\ndisk-utility  package).\nKickstart  (system-config-kickstart ): Create a kickstart configuration file that \ncan be used to install multiple Linux systems without user interaction.\nDescriptions from previous editions of this book of most of these tools have been replaced \nby procedures using Cockpit instead.\nUsing other browser-based admin tools\nTo simplify the management of many enterprise-quality open source projects, those pro -\njects have begun offering browser-based graphical management tools. In most cases, com-\nmand-line tools are offered for managing these projects as well.\nFor example, if you are using Red Hat Enterprise Linux, there are browser-based interfaces \nfor managing the following projects:\nRed Hat OpenShif t: OpenShift , based on the Kubernetes project, offers a browser-based \ninterface for deploying and managing a cluster of control plane and worker nodes \nas well as features for deploying and managing containers in what are referred to as \npods. See the Red Hat OpenShift site at www.openshift.com  or the upstream OKD \nsite at www.okd.io  for details.\nRed Hat Enterprise Linux OpenStack Platform (RHELOSP) : The OpenStack platform-\nas-a-service project lets you manage your own private, hybrid cloud through your \nbrowser. This includes the OpenStack dashboard from the OpenStack Horizon project \n(http://horizondocs.openstack.org/horizon/latest ). That interface lets \nyou launch and manage virtual machines and all of the resources around them: \nstorage, networking, authentication, processing allocations, and so on. Refer to \nChapter\u00a027, \u201cUsing Linux for Cloud Computing,\u201d for a description of how to use the \nOpenStack Dashboard.\nRed Hat Virtualization (RHV) : With RHEV, the RHV manager provides the browser-\nbased interface for managing virtual machines, including allocating storage and \nuser access to resources. Many other examples of browser-based graphical admin -\nistration tools are available with open source projects. If you are new to Linux, it \ncan be easier to get started with these interfaces. However, keep in mind that often \nyou need to use command-line tools if you need to troubleshoot problems because \ngraphical tools are often limited in that area.", "doc_id": "be234742-fa94-496f-b6fc-7b4a6d29a44b", "embedding": null, "doc_hash": "9d9b85daef24e4e5ed6f53277974752e310b064a91ffc80341d67ca7f94c7d5d", "extra_info": {"page_label": "202"}, "node_info": {"start": 0, "end": 2786}, "relationships": {"1": "49233044-c547-4e66-861e-bdc3cfb4e920"}}, "__type__": "1"}, "7b3067e7-0ba9-4a9f-8493-5e670de80bd1": {"__data__": {"text": "Part III: Becoming a Linux System Administrator174Using the root User Account\nEvery Linux system starts out with at least one administrative user account (the root user) \nand possibly one or more regular user accounts (given a name that you choose, or a name \nassigned by your Linux distribution). In most cases, you log in as a regular user and become \nthe root user to do an administrative task.\nThe root user has complete control of the operation of your Linux system. That user can \nopen any file or run any program. The root user also installs software packages and adds \naccounts for other people who use the system.\ntip\nThink of the root user in Linux as similar to the Administrator user in Windows.\nWhen you first install most Linux systems (although not all systems), you add a password \nfor the root user. You must remember and protect this password; you need it to log in as \nroot or to obtain root permission while you are logged in as some other user.\nTo become familiar with the root user account, you can simply log in as the root user. I \nrecommend trying this from a virtual console. To do so, press Ctrl+Alt+F3. When you see \nthe login prompt, type root  (press Enter) and enter the password. A login session for root \nopens. When you are finished, type exit , and then press Ctrl+Alt+F1 to return to the reg -\nular desktop login.\nAfter you have logged in as root, the home directory for the root user is typically /root . \nThe home directory and other information associated with the root user account are located \nin the /etc/passwd  file. Here\u2019s what the root entry looks like in the /etc/passwd  file:\nroot:x:0:0:root:/root:/bin/bash\nThis shows that for the user named root , the user ID is set to 0  (root user), the group ID \nis set to 0  (root group), the home directory is /root , and the shell for that user is /bin/\nbash . (Linux uses the /etc/shadow  file to store encrypted password data, so the password \nfield here contains an x .) You can change the home directory or the shell used by editing \nthe values in this file. A better way to change these values, however, is to use the user -\nmod command (see the section \u201cModifying Users with usermod\u201d in Chapter\u00a011 for further \ninformation).\nAt this point, any command that you run from your shell is run with root privilege. So be \ncareful. You have much more power to change (and damage) the system than you did as a \nregular user. Again, type exit  when you are finished. If you are on a virtual console and \nhave a desktop interface running on another console, press Ctrl+Alt+F1 to return to the \ngraphical login screen if you are using a Linux desktop system.", "doc_id": "7b3067e7-0ba9-4a9f-8493-5e670de80bd1", "embedding": null, "doc_hash": "ce9cc1aafb401dab34be4b4e15bf7b6a75566ec91b9ae14fb3b5e678f49c3d82", "extra_info": {"page_label": "203"}, "node_info": {"start": 0, "end": 2644}, "relationships": {"1": "d6cb4dba-90de-48fb-9fe2-d8b342b929ab"}}, "__type__": "1"}, "d66095f0-2e6f-410e-8af8-2f0521639be2": {"__data__": {"text": "Chapter 8: Learning System Administration\n175\n8Becoming root from the shell (su command)\nAlthough you can become the superuser by logging in as root, sometimes that is not \nconvenient.\nFor example, you may be logged in to a regular user account and just want to make a quick \nadministrative change to your system without having to log out and log back in. You may \nneed to log in over the network to make a change to a Linux system but find that the \nsystem doesn\u2019t allow root users in from over the network (a common practice for secure \nLinux systems). One solution is to use the su  command. From any Terminal window or \nshell, you can simply type the following:\n$ su\nPassword: ******\n#\nWhen you are prompted, type the root user\u2019s password. The prompt for the regular user ( $) \nchanges to the superuser prompt ( #). At this point, you have full permission to run any \ncommand and use any file on the system. However, one thing that the su  command doesn\u2019t \ndo when used this way is read in the root user\u2019s environment. As a result, you may type a \ncommand that you know is available and get the message Command Not Found . To fix \nthis problem, use the su  command with the dash ( -) option instead like this:\n$ su -\nPassword: ******\n#\nYou still need to type the password, but after that everything that normally happens at \nlogin for the root user happens after the su  command is completed. Your current directory \nwill be root\u2019s home directory (probably /root ), and things such as the root user\u2019s PATH  \nvariable are used. If you become the root user by just typing su , rather than su - , you \ndon\u2019t change directories or the environment of the current login session.\nYou can also use the su  command to become a user other than root. This is useful for trou -\nbleshooting a problem that is being experienced by a particular user but not by others on \nthe computer (such as an inability to print or send email). For example, to have the permis -\nsions of a user named jsmith , you\u2019d type the following:\n$ su - jsmithNote\nBy default, the root account has no password set in Ubuntu. This means that even though the account exists, you \ncannot log in using it or use su  to become the root user. This adds an additional level of security to Ubuntu and \nrequires you to use sudo  before each command that you want to execute as the root user.", "doc_id": "d66095f0-2e6f-410e-8af8-2f0521639be2", "embedding": null, "doc_hash": "bc0cd2116cc5221a45ef0512437c1ffa33f2b2c5156ef01c82f847de5e1797b8", "extra_info": {"page_label": "204"}, "node_info": {"start": 0, "end": 2347}, "relationships": {"1": "849e745a-ea74-4757-b4d2-a9c1b89bf16b"}}, "__type__": "1"}, "817c9c4d-02f7-460e-81d6-f453ae0cad65": {"__data__": {"text": "Part III: Becoming a Linux System Administrator176Even if you were root user before you typed this command, afterward you would have only \nthe permissions to open files and run programs that are available to jsmith. As root user, \nhowever, after you type the su  command to become another user, you don\u2019t need a pass -\nword to continue. If you type that command as a regular user, you must type the new \nuser\u2019s password.\nWhen you are finished using superuser permissions, return to the previous shell by exiting \nthe current shell. Do this by pressing Ctrl+D or by typing exit . If you are the adminis -\ntrator for a computer that is accessible to multiple users, don\u2019t leave a root shell open on \nsomeone else\u2019s screen unless you want to give that person freedom to do anything he or she \nwants to the computer!\nAllowing administrative access via the GUI\nAs mentioned earlier, when you run GUI tools as a regular user (from Fedora, Red Hat Enter -\nprise Linux, or some other Linux systems), you are prompted for the root password before \nyou are able to access the tool. By entering the root password, you are given root privilege \nfor that task.\nFor Linux systems using the GNOME 2 desktop, after you enter the password, a yellow badge \nicon appears in the top panel, indicating that root authorization is still available for other \nGUI tools to run from that desktop session. For GNOME 3 desktops, you must enter the root \npassword each time you start any of the system-config tools.\nGaining administrative access with sudo\nParticular users can also be given administrative permissions for particular tasks or any \ntask by typing sudo  followed by the command they want to run, without being given the \nroot password. The sudoers  facility is the most common way to provide such privilege. \nUsing sudoers  for any users or groups on the system, you can do the following:\n\u25a0\u25a0Assign root privilege for any command they run with sudo .\n\u25a0\u25a0Assign root privilege for a select set of commands.\n\u25a0\u25a0Give users root privilege without telling them the root password because they only \nhave to provide their own user password to gain root privilege.\n\u25a0\u25a0Allow users, if you choose, to run sudo  without entering a password at all.\n\u25a0\u25a0Track which users have run administrative commands on your system. (Using su , \nall you know is that someone with the root password logged in, whereas the sudo  \ncommand logs which user runs an administrative command.)\nWith the sudoers  facility, giving full or limited root privileges to any user simply entails \nadding the user to /etc/sudoers  and defining what privilege you want that user to have. \nThen the user can run any command they are privileged to use by preceding that command \nwith the sudo  command.\nHere\u2019s an example of how to use the sudo  facility to cause the user named joe  to have full \nroot privilege.", "doc_id": "817c9c4d-02f7-460e-81d6-f453ae0cad65", "embedding": null, "doc_hash": "bf0cf53685a42beded5ae0f5e20b05dc66ebbc7384341ea90b3bafb91285627e", "extra_info": {"page_label": "205"}, "node_info": {"start": 0, "end": 2845}, "relationships": {"1": "ca8ac6f2-9a5a-492f-801f-2fdf43e94744"}}, "__type__": "1"}, "0d3df119-995e-4cfe-b023-6e1b6da8cc5f": {"__data__": {"text": "Chapter 8: Learning System Administration\n177\n81. As the root user, edit the /etc/sudoers  file by running the visudo  command:\n        # /usr/sbin/visudo\nBy default, the file opens in vi , unless your EDITOR  variable happens to be set to \nsome other editor acceptable to visudo  (for example, export EDITOR=gedit ). \nThe reason for using visudo  is that the command locks the /etc/sudoers  file \nand does some basic sanity checking of the file to ensure that it has been edited \ncorrectly.\nNote\nIf you are stuck here, try running the vimtutor  command for a quick tutorial on using vi  and vim .\n2. Add the following line to allow joe to have full root privileges on the computer:\n        joe     ALL=(ALL)     ALL\nThis line causes joe to provide a password (his own password, not the root pass -\nword) in order to use administrative commands. To allow joe to have that privilege \nwithout using a password, type the following line instead:\n        joe    ALL=(ALL)     NOPASSWD: ALL\n3. Save the changes to the /etc/sudoers  file (in vi , type Esc  and then :wq ). The \nfollowing is an example of a session by the user joe after he has been assigned \nsudo  privileges:\n        [joe]$ sudo touch /mnt/testfile.txt\n          We trust you have received the usual lecture\n          from the local System Administrator. It usually\n          boils down to these two things:\n            #1) Respect the privacy of others.\n            #2) Think before you type.\n        Password: *********\n        [joe]$ ls -l /mnt/testfile.txt\n        -rw-r--r--. 1 root root 0 Jan  7 08:42 /mnt/testfile.txt\n        [joe]$ rm /mnt/testfile.txt\n        rm: cannot remove \u2018/mnt/testfile.txt': Permission denied\n        [joe]$ sudo rm /mnt/textfile.txt\n        [joe]$tip\nIf you look at the sudoers  file in Ubuntu, you see that the initial user on the system already has privilege, by \ndefault, for the sudo  group members. To give any other user the same privilege, you could simply add the additional \nuser to the admin group when you run visudo .", "doc_id": "0d3df119-995e-4cfe-b023-6e1b6da8cc5f", "embedding": null, "doc_hash": "657fdfd1a6dbade8c4696bc595296ce0fb716050627f330ba010eb28ff9f8f4a", "extra_info": {"page_label": "206"}, "node_info": {"start": 0, "end": 2025}, "relationships": {"1": "8365b330-c9f8-4a08-a2b8-c5c1d7a9782b"}}, "__type__": "1"}, "2b1d89a6-3bc6-4062-bc75-68232a5ad87f": {"__data__": {"text": "Part III: Becoming a Linux System Administrator178In this session, the user joe runs the sudo  command to create a file ( /mnt/textfile.\ntxt) in a directory for which he doesn\u2019t have write permission. He is given a warning and \nasked to provide his password (this is joe\u2019s password, not  the root password).\nEven after joe has entered the password, he must still use the sudo  command to run sub -\nsequent administrative commands as root (the rm  fails, but the sudo rm  succeeds). Notice \nthat he is not prompted for a password for the second sudo . That\u2019s because after entering \nhis password successfully, he can enter as many sudo  commands as he wants for the next \nfive minutes, on RHEL and Fedora systems, without having to enter it again. For Ubuntu, \nthis is set to zero, for no time-out. (You can change the time-out value from five min -\nutes to any length of time you want by setting the passwd_timeout  value in the /etc/\nsudoers  file.)\nThe preceding example grants a simple all-or-nothing administrative privilege to joe. \nHowever, the /etc/sudoers  file gives you an incredible amount of flexibility in per -\nmitting individual users and groups to use individual applications or groups of applica -\ntions. Refer to the sudoers  and sudo  man pages for information about how to tune your \nsudo  facility.\nExploring Administrative Commands, Configuration \nFiles, and Log Files\nYou can expect to find many commands, configuration files, and log files in the same places \nin the filesystem, regardless of which Linux distribution you are using. The following sec -\ntions give you some pointers on where to look for these important elements.\nNote\nIf GUI administrative tools for Linux have become so good, why do you need to know about administrative files? For \none thing, while GUI tools differ among Linux versions, many underlying configuration files are the same. So if you \nlearn to work with them, you can work with almost any Linux system. Also, if a feature is broken, or if you need to do \nsomething that\u2019s not supported by the GUI, when you ask for help, Linux experts almost always tell you how to run \ncommands or change the configuration file directly.\nAdministrative commands\nOnly the root user is intended to use many administrative commands. When you log in \nas root (or use su -  from the shell to become root), your $PATH  variable is set to include \nsome directories that contain commands for the root user. In the past, these have included \nthe following:\n/sbin : Originally contained commands needed to boot your system, including com-\nmands for checking filesystems ( fsck ) and turning on swap devices ( swapon ).", "doc_id": "2b1d89a6-3bc6-4062-bc75-68232a5ad87f", "embedding": null, "doc_hash": "80c7727bb011cf3a32c225cec57122a0b46b1c263a54f97dcbbc0cbdc9cf0990", "extra_info": {"page_label": "207"}, "node_info": {"start": 0, "end": 2648}, "relationships": {"1": "fb899527-b1d5-4bb0-bcd4-38aa69cefacb"}}, "__type__": "1"}, "a69ce5c7-3d27-42ea-a9f2-cc97879321b2": {"__data__": {"text": "Chapter 8: Learning System Administration\n179\n8/usr/sbin : Originally contained commands for such things as managing user \naccounts (such as useradd ) and checking processes that are holding files open \n(such as lsof ). Commands that run as daemon processes are also contained in this \ndirectory. Daemon processes are processes that run in the background, waiting for \nservice requests such as those to access a printer or a web page. (Look for commands \nthat end in d , such as sshd , pppd , and cupsd .)\nFor the latest Ubuntu, RHEL and Fedora releases, all administrative commands from the \ntwo directories are stored in the /usr/sbin  directory (which is symbolically linked from /\nsbin ). Also, only /usr/sbin  is added to the PATH of the root user, as well as the PATH of \nall regular users.\nSome administrative commands are contained in regular user directories (such as /bin  \nand /usr/bin ). This is especially true of commands that have some options available to \neveryone. An example is the /bin/mount  command, which anyone can use to list mounted \nfilesystems but only root can use to mount filesystems. (Some desktops, however, are con -\nfigured to let regular users use mount  to mount CDs, DVDs, or other removable media.)\nNote\nSee the section \u2033 Mounting Filesystems \u2033 in Chapter\u00a012 for instructions on how to mount a filesystem.\nTo find commands intended primarily for the system administrator, check out the section\u00a08 \nmanual pages (usually in /usr/share/man/man8 ). They contain descriptions and options \nfor most Linux administrative commands. If you want to add commands to your system, \nconsider adding them to directories such as /usr/local/bin  or /usr/local/sbin . Some \nLinux distributions automatically add those directories to your PATH, usually before your \nstandard bin  and sbin  directories. In that way, commands installed to those directories \nare not only accessible, but can also override commands of the same name in other direc -\ntories. Some third-party applications that are not included with Linux distributions are \nsometimes placed in the /usr/local/bin , /opt/bin , or /usr/local/sbin  directory.\nAdministrative configuration files\nConfiguration files are another mainstay of Linux administration. Almost everything that \nyou set up for your particular computer\u2014user accounts, network addresses, or GUI prefer -\nences\u2014results in settings being stored in plain-text files. This has some advantages and \nsome disadvantages.\nThe advantage of plain-text files is that it\u2019s easy to read and change them. Any text editor \nwill do. The downside, however, is that as you edit configuration files, traditionally no error \nchecking is done. You sometimes have to run the program that reads these files (such as a \nnetwork daemon or the X desktop) to find out whether you set up the files correctly.\nWhile some configuration files use standard structures, such as XML for storing informa -\ntion, many do not. So, you need to learn the specific structure rules for each configuration ", "doc_id": "a69ce5c7-3d27-42ea-a9f2-cc97879321b2", "embedding": null, "doc_hash": "b89fdf5366847f2eb1ee3fc960e9b1f80a5bc9426936c71b5edbf5c3448d2fc9", "extra_info": {"page_label": "208"}, "node_info": {"start": 0, "end": 3015}, "relationships": {"1": "d7ebe0a1-9913-4bd2-a19d-bccfa9a7bee0"}}, "__type__": "1"}, "d08bdf9b-2458-4520-8fd4-96b5f367b9dc": {"__data__": {"text": "Part III: Becoming a Linux System Administrator180file. A comma or a quote in the wrong place can sometimes cause an entire interface to fail. \nYou can check in many ways that the structure of many configuration files is correct.\nSome software packages offer a command to test the sanity of the configuration file tied \nto a package before you start a service. For example, the testparm  command is used with \nSamba to check the sanity of your smb.conf  file. Other times, the daemon process provid -\ning a service offers an option for checking your config file. For example, run httpd -t  to \ncheck your Apache web server configuration before starting your web server.\nNote\nSome text editors, such as the vim  command (not vi ), understand the structure of some types of configuration \nfiles. If you open such a configuration file in vim , notice that different elements of the file are shown in different \ncolors. In particular, you can see comment lines in a different color than data.\nThroughout this book, you\u2019ll find descriptions of the configuration files that you need to \nset up the different features that make up Linux systems. The two major locations of con -\nfiguration files are your home directory (where your personal configuration files are kept) \nand the /etc  directory (which holds system-wide configuration files).\nFollowing are descriptions of directories (and subdirectories) that contain useful configura -\ntion files. The descriptions are followed by some individual configuration files in /etc  that \nare of particular interest. Viewing the contents of Linux configuration files can teach you a \nlot about administering Linux systems.\n$HOME : All users store in their home directories information that directs how their \nlogin accounts behave. Many configuration files are stored directly in each user\u2019s \nhome directory (such as /home/joe ) and begin with a dot ( .), so they don\u2019t appear \nin a user\u2019s directory when you use a standard ls  command (you need to type ls -a  \nto see them). Likewise, dot files and directories won\u2019t show up in most file manager \nwindows by default. There are dot files that define the behavior of each user\u2019s shell, \nthe desktop look-and-feel, and options used with your text editor. There are even \nfiles such as those in each user\u2019s $HOME/.ssh  directory that configure permissions \nfor logging into remote systems. (To see the name of your home directory, type \necho $HOME  from a shell.)\n/etc : This directory contains most of the basic Linux system configuration files.\n/etc/cron* : Directories in this set contain files that define how the crond  utility \nruns applications on a daily ( cron.daily ), hourly (cron.hourly ), monthly ( cron.\nmonthly ), or weekly ( cron.weekly ) schedule.\n/etc/cups : Contains files used to configure the CUPS printing service.\n/etc/default : Contains files that set default values for various utilities. For example, \nthe file for the useradd  command defines the default group number, home direc -\ntory, password expiration date, shell, and skeleton directory ( /etc/skel ) used \nwhen creating a new user account.", "doc_id": "d08bdf9b-2458-4520-8fd4-96b5f367b9dc", "embedding": null, "doc_hash": "8742affb9eac5822bdb2cb495bc565a0ee0a1b615c4ef81e3834054595331b2f", "extra_info": {"page_label": "209"}, "node_info": {"start": 0, "end": 3109}, "relationships": {"1": "284f3ece-df66-457e-a513-b8d6e3c1f4bc"}}, "__type__": "1"}, "c68b3f8f-4541-4dc0-b3d2-805d624b6274": {"__data__": {"text": "Chapter 8: Learning System Administration\n181\n8/etc/httpd : Contains a variety of files used to configure the behavior of your Apache \nweb server (specifically, the httpd  daemon process). (On Ubuntu and other Linux \nsystems, /etc/apache  or /etc/apache2  is used instead.)\n/etc/mail : Contains files used to configure your sendmail  mail transport agent.\n/etc/postfix : Contains configuration files for the postfix  mail transport agent.\n/etc/ppp : Contains several configuration files used to set up Point-to-Point Protocol \n(PPP) so that you can have your computer dial out to the Internet. (PPP was more \ncommonly used when dial-up modems were popular.)\n/etc/rc?.d : There is a separate rc?.d  directory for each valid system state: rc0.d  \n(shutdown state), rc1.d  (single-user state), rc2.d  (multiuser state), rc3.d  (mul-\ntiuser plus networking state), rc4.d  (user-defined state), rc5.d  (multiuser, net -\nworking, plus GUI login state), and rc6.d  (reboot state). These directories are \nmaintained for compatibility with old UNIX SystemV init services.\n/etc/security : Contains files that set a variety of default security conditions for \nyour computer, basically defining how authentication is done. These files are part of \nthe pam  (pluggable authentication modules) package.\n/etc/skel : Any files contained in this directory are automatically copied to a user\u2019s \nhome directory when that user is added to the system. By default, most of these \nfiles are dot ( .) files, such as .kde  (a directory for setting KDE desktop defaults) and \n.bashrc  (for setting default values used with the bash shell).\n/etc/sysconfig : Contains important system configuration files that are created \nand maintained by various services (including firewalld , samba , and most net -\nworking services). These files are critical for Linux distributions, such as Fedora \nand RHEL, that use GUI administration tools but are not used on other Linux sys -\ntems at all.\n/etc/systemd : Contains files associated with the systemd  facility, for managing \nthe boot process and system services. In particular, when you run systemctl  com-\nmands to enable and disable services, files that make that happen are stored in sub -\ndirectories of the /etc/systemd system  directory.\n/etc/xinetd.d : Contains a set of files, each of which defines an on-demand network \nservice that the xinetd  daemon listens for on a particular port. When the xinetd  \ndaemon process receives a request for a service, it uses the information in these files \nto determine which daemon processes to start to handle the request.\nThe following are some interesting configuration files in /etc :\naliases : Can contain distribution lists used by the Linux mail services. (This file is \nlocated in /etc/mail  in Ubuntu when you install the sendmail  package.)\nbashrc : Sets system-wide defaults for bash shell users. (This may be called bash.\nbashrc  on some Linux distributions.)", "doc_id": "c68b3f8f-4541-4dc0-b3d2-805d624b6274", "embedding": null, "doc_hash": "de93dd864076b8edf60ba75e8e4f99a510f57e43790b09fc559995211ea3b2db", "extra_info": {"page_label": "210"}, "node_info": {"start": 0, "end": 2931}, "relationships": {"1": "6416c85f-ffcd-4f96-a539-25f849b78008"}}, "__type__": "1"}, "1ba8e81a-5d85-4f1e-a256-f8ab38a494f5": {"__data__": {"text": "Part III: Becoming a Linux System Administrator182crontab : Sets times for running automated tasks and variables associated with the \ncron  facility (such as the SHELL  and PATH  associated with cron ).\ncsh.cshrc  (or cshrc ): Sets system-wide defaults for csh  (C shell) users.\nexports : Contains a list of local directories that are available to be shared by remote \ncomputers using the Network File System (NFS).\nfstab : Identifies the devices for common storage media (hard disk, DVD, CD-ROM, \nand so on) and locations where they are mounted in the Linux system. This is used \nby the mount  command to choose which filesystems to mount when the system \nfirst boots.\ngroup : Identifies group names and group IDs (GIDs) that are defined on the system. \nGroup permissions in Linux are defined by the second of three sets of rwx  (read, \nwrite, execute) bits associated with each file and directory.\ngshadow : Contains shadow passwords for groups.\nhost.conf : Used by older applications to set the locations in which domain names \n(for example, redhat.com ) are searched for on TCP/IP networks (such as the Inter -\nnet). By default, the local hosts file is searched and then any name server entries in \nresolv.conf .\nhostname : Contains the hostname for the local system (beginning in RHEL 7 and \nrecent Fedora and Ubuntu systems).\nhosts : Contains IP addresses and hostnames that you can reach from your computer. \n(Usually this file is used just to store names of computers on your LAN or small pri-\nvate network.)\ninittab : On earlier Linux systems, contained information that defined which pro -\ngrams start and stop when Linux boots, shuts down, or goes into different states in \nbetween. This configuration file was the first one read when Linux started the init  \nprocess. This file is no longer used on Linux systems that support systemd .\nmtab : Contains a list of filesystems that are currently mounted.\nmtools.conf : Contains settings used by DOS tools in Linux.\nnamed.conf : Contains DNS settings if you are running your own DNS server ( bind  or \nbind9  package).\nnsswitch.conf : Contains name service switch settings, for identifying where criti-\ncal system information (user accounts, hostname-to-address mappings, and so on) \ncomes from (local host or via network services).\nntp.conf : Includes information needed to run the Network Time Protocol (NTP).\npasswd : Stores account information for all valid users on the local system. Also \nincludes other information, such as the home directory and default shell. (Rarely \nincludes the user passwords themselves, which are typically stored in the /etc/\nshadow  file.)", "doc_id": "1ba8e81a-5d85-4f1e-a256-f8ab38a494f5", "embedding": null, "doc_hash": "ab031736951de6ea77237de9c9676a3223455566280c3bcd26a6738b72924a29", "extra_info": {"page_label": "211"}, "node_info": {"start": 0, "end": 2630}, "relationships": {"1": "c2e127d8-8993-41f5-b75c-ce3264419683"}}, "__type__": "1"}, "6805b77a-278e-499e-b483-c21227b59e5d": {"__data__": {"text": "Chapter 8: Learning System Administration\n183\n8printcap : Contains definitions for the printers configured for your computer. (If \nthe printcap  file doesn\u2019t exist, look for printer information in the /etc/cups  \ndirectory.)\nprofile : Sets system-wide environment and startup programs for all users. This file is \nread when the user logs in.\nprotocols : Sets protocol numbers and names for a variety of Internet services.\nrpc: Defines remote procedure call names and numbers.\nservices : Defines TCP/IP and UDP service names and their port assignments.\nshadow : Contains encrypted passwords for users who are defined in the passwd  file. \n(This is viewed as a more secure way to store passwords than the original encrypted \npassword in the passwd  file. The passwd  file needs to be publicly readable, \nwhereas the shadow  file can be unreadable by all but the root user.)\nshells : Lists the shell command-line interpreters ( bash , sh, csh, and so on) that are \navailable on the system as well as their locations.\nsudoers : Sets commands that can be run by users, who may not otherwise have per -\nmission to run the command, using the sudo  command. In particular, this file is \nused to provide selected users with root permission.\nrsyslog.conf : Defines what logging messages are gathered by the rsyslogd  \ndaemon and in which files they are stored. (Typically, log messages are stored in \nfiles contained in the /var/log  directory.)\nxinetd.conf : Contains simple configuration information used by the xinetd  \ndaemon process. This file mostly points to the /etc/xinetd.d  directory for infor -\nmation about individual services.\nAnother directory, /etc/X11 , includes subdirectories that each contain system-wide con -\nfiguration files used by X and different X window managers available for Linux. The xorg.\nconf  file (configures your computer and monitor to make it usable with X) and configura -\ntion directories containing files used by xdm  and xinit  to start X are in here.\nDirectories relating to window managers contain files that include the default values that \na user will get if that user starts one of these window managers on your system. The twm \nwindow manager may have system-wide configuration files in these directories.\nAdministrative log files and systemd journal\nOne of the things that Linux does well is keep track of itself. This is a good thing when you \nconsider how much is going on in a complex operating system.\nSometimes you are trying to get a new facility to work and it fails without giving you the \nfoggiest reason why. Other times, you want to monitor your system to see whether people \nare trying to access your computer illegally. In any of those cases, you want to be able to \nrefer to messages coming from the kernel and services running on the system.", "doc_id": "6805b77a-278e-499e-b483-c21227b59e5d", "embedding": null, "doc_hash": "0f37282a676cd99fade3965c85b581cfb522bf8929d18c85a617c7c15f26464b", "extra_info": {"page_label": "212"}, "node_info": {"start": 0, "end": 2795}, "relationships": {"1": "61c7f514-183e-4bc7-af71-24af9d35c943"}}, "__type__": "1"}, "346eac7f-1350-4934-a76b-95cdbf3b1d3d": {"__data__": {"text": "Part III: Becoming a Linux System Administrator184For Linux systems that don\u2019t use the systemd  facility, the main utility for logging error \nand debugging messages is the rsyslogd  daemon. (Some older Linux systems use sys -\nlogd  and syslogd  daemons.) Although you can still use rsyslogd  with systemd  \nsystems, systemd  has its own method of gathering and displaying messages called the \nsystemd  journal (journalctl  command).\nUsing journalctl to view the systemd journal\nThe primary command for viewing messages from the systemd  journal is the journalctl  \ncommand. The boot process, the kernel, and all systemd -managed services direct their \nstatus and error messages to the systemd  journal.\nUsing the journalctl  command, you can display journal messages in many different \nways. Here are some examples:\n# journalctl\n# journalctl --list-boots | head\n-2 93bdb6164... Sat 2020-01-04 21:07:28 EST\u2014Sat 2020-01-04 21:19:37 EST\n-1 7336cb823... Sun 2020-01-05 10:38:27 EST\u2014Mon 2020-01-06 09:29:09 EST\n 0 eaebac25f... Sat 2020-01-18 14:11:41 EST\u2014Sat 2020-01-18 16:03:37 EST\n# journalctl -b 488e152a3e2b4f6bb86be366c55264e7\n# journalctl -k\nIn these examples, the journalctl  command with no options lets you page through all \nmessages in the systemd  journal. To list the boot IDs for each time the system was booted, \nuse the \u2013list-boots  option. To view messages associated with a particular boot instance, \nuse the -b  option with one of the boot instances. To see only kernel messages, use the -k  \noption. Here are some more examples:\n# journalctl _SYSTEMD_UNIT=sshd.service\n# journalctl PRIORITY=0\n# journalctl -a -f\nUse the _SYSTEMD_UNIT= options to show messages for specific services (here, the sshd  \nservice) or for any other systemd  unit file (such as other services or mounts). To see mes -\nsages associated with a particular syslog log level, set PRIORITY=  to a value from 0  to 7. \nIn this case, only emergency ( 0) messages are shown. To follow messages as they come in, \nuse the -f  option; to show all fields, use the -a  option.\nManaging log messages with rsyslogd\nThe rsyslogd  facility, and its predecessor syslogd , gather log messages and direct them \nto log files or remote log hosts. Logging is done according to information in the /etc/\nrsyslog.conf  file. Messages are typically directed to log files that are usually in the /", "doc_id": "346eac7f-1350-4934-a76b-95cdbf3b1d3d", "embedding": null, "doc_hash": "d00dd6951039b83c0f2593b510460bfa54aa3fa444214c7bb6266a948cd162f6", "extra_info": {"page_label": "213"}, "node_info": {"start": 0, "end": 2358}, "relationships": {"1": "8a5f2dd0-e095-46b1-afe8-776c6f0812bc"}}, "__type__": "1"}, "324695a1-07b2-4d4f-9581-cfcf72d1b4fb": {"__data__": {"text": "Chapter 8: Learning System Administration\n185\n8var/log  directory, but they can also be directed to log hosts for additional security. Here \nare a few common log files:\nboot.log : Contains boot messages about services as they start up.\nmessages : Contains many general informational messages about the system.\nsecure : Contains security-related messages, such as login activity or any other act \nthat authenticates users.\nRefer to Chapter\u00a013, \u201cUnderstanding Server Administration,\u201d for information on config -\nuring the rsyslogd  facility.\nUsing Other Administrative Accounts\nYou don\u2019t hear much about logging in with other administrative user accounts (besides \nroot) on Linux systems. It was a fairly common practice in UNIX systems to have several \ndifferent administrative logins that allowed administrative tasks to be split among several \nusers. For example, people sitting near a printer could have lp  permissions to move print \njobs to another printer if they knew a printer wasn\u2019t working.\nIn any case, administrative logins are available with Linux; however, logging in directly as \nthose users is disabled by default. The accounts are maintained primarily to provide owner -\nship for files and processes associated with particular services. When daemon processes are \nrun under separate administrative logins, having one of those processes cracked does not \ngive the cracker root permission and the ability to access other processes and files. Con -\nsider the following examples:\nlp: User owns such things as the /var/log/cups  printing log file and various \nprinting cache and spool files. The home directory for lp  is /var/spool/lpd .\napache : User can set up content files and directories on an Apache web server. \nIt is primarily used to run the web server processes ( httpd ) in RHEL and \nFedora systems, while the www-data user runs the Apache service (apache2) on \nUbuntu systems.\navahi : User runs the avahi  daemon process to provide zeroconf  services on \nyour network.\nchrony : User runs the chronyd  daemon, which is used to maintain accurate com-\nputer clocks.\npostfix : User owns various mail server spool directories and files. The user runs the \ndaemon processes used to provide the postfix service ( master ).\nbin: User owns many commands in /bin  in traditional UNIX systems. This is not the \ncase in some Linux systems (such as Ubuntu, Fedora, and Gentoo) because root owns \nmost executable files. The home directory of bin  is /bin .", "doc_id": "324695a1-07b2-4d4f-9581-cfcf72d1b4fb", "embedding": null, "doc_hash": "f114371d820eca48bc1898324741196272a3e91436f741c025f71b66367ff433", "extra_info": {"page_label": "214"}, "node_info": {"start": 0, "end": 2466}, "relationships": {"1": "6b024799-514a-4e3a-bb28-acf1778fde6a"}}, "__type__": "1"}, "a4c1db42-664b-46cb-908f-c69ad36b525e": {"__data__": {"text": "Part III: Becoming a Linux System Administrator186news :  User could do administration of Internet news services, depending on how you \nset permission for /var/spool/news  and other news-related resources. The home \ndirectory for news is /etc/news .\nrpc: User runs the remote procedure calls daemon ( rpcbind ), which is used to receive \ncalls for services on the host system. The NFS service uses the RPC service.\nBy default, the administrative logins in the preceding list are disabled. You would need to \nchange the default shell from its current setting (usually /sbin/nologin  or /bin/false ) \nto a real shell (typically /bin/bash ) to be able to log in as these users. As mentioned ear -\nlier, however, they are really not intended for interactive logins.\nChecking and Configuring Hardware\nIn a perfect world, after installing and booting Linux, all of your hardware is detected and \navailable for access. Although Linux systems have become quite good at detecting hard -\nware, sometimes you must take special steps to get your computer hardware working. Also, \nthe growing use of removable USB devices (CDs, DVDs, flash drives, digital cameras, and \nremovable hard drives) has made it important for Linux to do the following:\n\u25a0\u25a0Efficiently manage hardware that comes and goes\n\u25a0\u25a0Look at the same piece of hardware in different ways. (For example, it should \nbe able to see a printer as a fax machine, scanner, and storage device as well as \na printer.)\nLinux kernel features added in the past few years have made it possible to change dras -\ntically the way that hardware devices are detected and managed. The Udev subsystem \ndynamically names and creates devices as hardware comes and goes.\nIf this sounds confusing, don\u2019t worry. It\u2019s designed to make your life as a Linux user much \neasier. The result of features built on the kernel is that device handling in Linux has \nbecome more automatic and more flexible:\nMore automatic For most common hardware, when a hardware device is connected or \ndisconnected, it is automatically detected and identified. Interfaces to access the \nhardware are added so it is accessible to Linux. Then the fact that the hardware is \npresent (or removed) is passed to the user level, where applications listening for \nhardware changes are ready to mount the hardware and/or launch an application \n(such as an image viewer or music player).\nMore flexible If you don\u2019t like what happens automatically when a hardware item \nis connected or disconnected, you can change it. For example, features built into \nGNOME and KDE desktops let you choose what happens when a music CD or data DVD \nis inserted, or when a digital camera is connected. If you prefer that a different pro -\ngram be launched to handle it, you can easily make that change.", "doc_id": "a4c1db42-664b-46cb-908f-c69ad36b525e", "embedding": null, "doc_hash": "400e1fc67bb5eda1c1438a621fce11694203704f7d306d621bc9afbf968dd5c6", "extra_info": {"page_label": "215"}, "node_info": {"start": 0, "end": 2774}, "relationships": {"1": "3e193d12-fe7d-41ad-ad82-7fb0dd3fc54b"}}, "__type__": "1"}, "a3dd14a6-f8c2-492d-8e2d-5f15e71095f1": {"__data__": {"text": "Chapter 8: Learning System Administration\n187\n8The following sections cover several issues related to getting your hardware working prop -\nerly in Linux. First, it describes how to check information about the hardware compo -\nnents of your system. It then covers how to configure Linux to deal with removable media. \nFinally, it describes how to use tools for manually loading and working with drivers for \nhardware that is not detected and loaded properly.\nChecking your hardware\nWhen your system boots, the kernel detects your hardware and loads drivers that allow \nLinux to work with that hardware. Because messages about hardware detection scroll \nquickly off the screen when you boot, to view potential problem messages you have to \nredisplay those messages after the system comes up.\nThere are a few ways to view kernel boot messages after Linux comes up. Any user can run \nthe dmesg  command to see what hardware was detected and which drivers were loaded by \nthe kernel at boot time. As new messages are generated by the kernel, those messages are \nalso made available to the dmesg  command.\nA second way to see boot messages is the journalctl  command to show the messages \nassociated with a particular boot instance (as shown earlier in this chapter).\nNote\nAfter your system is running, many kernel messages are sent to the /var/log/messages  file. So, for example, if \nyou want to see what happens when you plug in a USB drive, you can type tail -f /var/log/messages  and \nwatch as devices and mount points are created. Likewise, you could use the journalctl -f  command to follow \nmessages as they come into the systemd  journal.\nThe following is an example of some output from the dmesg  command that was trimmed \ndown to show some interesting information:\n$ dmesg | less\n[    0.000000] Linux version 5.0.9-301.fc30.x86_64\n   (mockbuild@bkernel04.phx2.fedoraproject.org) (gcc version 9.0.1 \n20190312\n   (Red Hat 9.0.1-0.10) (GCC)) #1 SMP Tue Apr 23 23:57:35 UTC 2019\n[    0.000000] Command line:\n   BOOT_IMAGE=(hd0,msdos1)/vmlinuz-5.0.9-301.fc30.x86_64\n   root=/dev/mapper/fedora_localhost--live-root ro\n   resume=/dev/mapper/fedora_localhost--live-swap\n   rd.lvm.lv=fedora_localhost-live/root\n   rd.lvm.lv=fedora_localhost-live/swap rhgb quiet\n...\n             S31B1102 USB DISK         1100 PQ: 0 ANSI: 0 CCS\n[79.177466] sd 9:0:0:0: Attached scsi generic sg2 type 0", "doc_id": "a3dd14a6-f8c2-492d-8e2d-5f15e71095f1", "embedding": null, "doc_hash": "cf56d9bed9d1ced784a4e83bfc9309eeb316e87b61f1036a7c5a662e958d9a9c", "extra_info": {"page_label": "216"}, "node_info": {"start": 0, "end": 2380}, "relationships": {"1": "2f138a9c-3bbd-4417-8da9-e08eb1b37be8"}}, "__type__": "1"}, "aeabc1a8-cbfd-4060-8276-f5ac6a65bdb2": {"__data__": {"text": "Part III: Becoming a Linux System Administrator188[79.177854] sd 9:0:0:0: [sdb]\n             8343552 512-byte logical blocks: (4.27 GB/3.97 GiB)\n[79.178593] sd 9:0:0:0: [sdb] Write Protect is off\nFrom this output, you first see the Linux kernel version, followed by kernel command-line \noptions. The last few lines reflect a 4GB USB drive being plugged into the computer.\nIf something goes wrong detecting your hardware or loading drivers, you can refer to this \ninformation to see the name and model number of hardware that\u2019s not working. Then you \ncan search Linux forums or documentation to try to solve the problem. After your system \nis up and running, some other commands let you look at detailed information about your \ncomputer\u2019s hardware. The lspci  command lists PCI buses on your computer and devices \nconnected to them. Here\u2019s a snippet of output:\n$ lspci\n00:00.0 Host bridge: Intel Corporation\n     5000X Chipset Memory ControllerHub\n00:02.0 PCI bridge: Intel Corporation 5000 Series Chipset\n     PCI Express x4 Port 2\n00:1b.0 Audio device: Intel Corporation 631xESB/632xESB\n     High Definition Audio Controller (rev 09)\n00:1d.0 USB controller: Intel Corporation 631xESB/632xESB/3100\n     Chipset UHCI USBController#1 (rev 09)\n07:00.0 VGA compatible controller: nVidia Corporation NV44\n0c:02.0 Ethernet controller: Intel Corporation 82541PI\n     Gigabit Ethernet Controller (rev 05)\nThe host bridge connects the local bus to the other components on the PCI bridge. I cut \ndown the output to show information about the different devices on the system that \nhandle various features: sound (Audio device), flash drives and other USB devices (USB \ncontroller), the video display (VGA compatible controller), and wired network cards (Ether -\nnet controller). If you are having trouble getting any of these devices to work, noting the \nmodel names and numbers gives you something to Google.\nTo get more verbose output from lspci , add one or more -v  options. For example, using \nlspci -vvv , I received information about my Ethernet controller, including latency, capa -\nbilities of the controller, and the Linux driver (e1000) being used for the device.\nIf you are specifically interested in USB devices, try the lsusb  command. By default, \nlsusb  lists information about the computer\u2019s USB hubs along with any USB devices con -\nnected to the computer\u2019s USB ports:\n$ lsusb\nBus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\nBus 002 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub\nBus 003 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub\nBus 004 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub\nBus 005 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub\nBus 002 Device 002: ID 413c:2105 Dell Computer Corp.\n    Model L100 Keyboard", "doc_id": "aeabc1a8-cbfd-4060-8276-f5ac6a65bdb2", "embedding": null, "doc_hash": "e6c6199f4d56defa583f849d60540d33c85a36e14ea761c2fcc6d79117ee520e", "extra_info": {"page_label": "217"}, "node_info": {"start": 0, "end": 2775}, "relationships": {"1": "f493832e-5806-47f2-9f52-8d17afd636f4"}}, "__type__": "1"}, "fce5b89a-7f81-4f6f-bb87-21fcde963285": {"__data__": {"text": "Chapter 8: Learning System Administration\n189\n8Bus 002 Device 004: ID 413c:3012 Dell Computer Corp.\n    Optical Wheel Mouse\nBus 001 Device 005: ID 090c:1000 Silicon Motion, Inc. -\n    Taiwan 64MB QDI U2 DISK\nFrom the preceding output, you can see the model of a keyboard, mouse, and USB flash \ndrive connected to the computer. As with lspci , you can add one or more -v  options to \nsee more details.\nTo see details about your processor, run the lscpu  command. That command gives basic \ninformation about your computer\u2019s processors.\n$ lscpu\nArchitecture:          x86_64\nCPU op-mode(s):        32-bit, 64-bit\nCPU(s):                4\nOn-line CPU(s) list:   0-3\nThread(s) per core:    1\nCore(s) per socket:    4\n...\nFrom the sampling of output of lscpu , you can see that this is a 64-bit system (x86-64), it \ncan operate in 32-bit or 64-bit modes, and there are four CPUs.\nManaging removable hardware\nLinux systems such as Red Hat Enterprise Linux, Fedora, and others, which support full \nGNOME desktop environments, include simple graphical tools for configuring what happens \nwhen you attach popular removable devices to the computer. So, with a GNOME desktop \nrunning, you simply plug in a USB device or insert a CD or DVD, and a window may pop up \nto deal with that device.\nAlthough different desktop environments share many of the same underlying mechanisms \n(in particular, Udev) to detect and name removable hardware, they offer different tools for \nconfiguring how they are mounted or used. Udev (using the udevd  daemon) creates and \nremoves devices ( /dev  directory) as hardware is added and removed from the computer. \nSettings that are of interest to someone using a desktop Linux system, however, can be \nconfigured with easy-to-use desktop tools.\nThe Nautilus file manager used with the GNOME desktop lets you define what happens when \nyou attach removable devices or insert removable media into the computer from the File \nManagement Preferences window. The descriptions in this section are based on GNOME 3.32 \nin Fedora 30.\nFrom the GNOME 3.32 desktop, select Activities and type Removable Media . Then select the \nRemovable Media Setting entry.\nThe following settings are available from the Removable Media window. These settings \nrelate to how removable media are handled when they are inserted or plugged in. In most \ncases, you are prompted about how to handle a medium that is inserted or connected.", "doc_id": "fce5b89a-7f81-4f6f-bb87-21fcde963285", "embedding": null, "doc_hash": "ce18ae67d35986daa8426e49c1e740526473c56a6d4e22d957172d340016d98c", "extra_info": {"page_label": "218"}, "node_info": {"start": 0, "end": 2423}, "relationships": {"1": "d7cc455f-76a9-4086-a39c-b5db2f54de2f"}}, "__type__": "1"}, "fe533649-7236-4575-b4eb-37d837a45005": {"__data__": {"text": "Part III: Becoming a Linux System Administrator190CD audio : When an audio CD is inserted, you can choose to be prompted for what to do \n(default), do nothing, open the contents in a folder window, or select from various \naudio CD players to be launched to play the content. Rhythmbox (music player), \nAudio CD Extractor (CD burner), and Brasero (CD burner) are among the choices that \nyou have for handling an inserted audio CD.\nDVD video : When a commercial video DVD is inserted, you are prompted for what to do \nwith that DVD. You can change that default to launch Totem (videos), Brasero (DVD \nburner), or another media player you have installed (such as MPlayer).\nMusic player : When inserted media contains audio files, you are asked what to do. You \ncan select to have Rhythmbox or some other music player begin playing the files by \nselecting that player from this box.\nPhotos : When inserted media (such as a memory card from a digital camera) contains \ndigital images, you are asked what to do with those images. You can select to do \nnothing, or you can select to have the images opened in the Shotwell image viewer \n(the default application for viewing images on the GNOME desktop) or another \ninstalled photo manager.\nSoftware : When inserted media contains installable software, the Software window \nopens by default. To change that behavior (to ask what to do, do nothing, or open \nthe media contents in a folder), you can select the box for those choices.\nOther Media : Select the Type box under the Other Media heading to select how less \ncommonly used media are handled. For example, you can select what actions are \ntaken to handle audio DVDs or blank Blu-ray discs, CDs, or DVDs. You can select what \napplications to launch for Blu-ray video disc, ebook readers, and Picture CDs.\nNote that the settings described here are in effect only for the user who is currently logged \nin. If multiple users have login accounts, each can have their own way of handling remov -\nable media.\nNote\nThe Totem movie player does not play movie DVDs unless you add extra software to decrypt the DVD. You should look \ninto legal issues and other movie player options if you want to play commercial DVD movies from Linux.\nThe options to connect regular USB flash drives or hard drives are not listed on this \nwindow. If you connect one of those drives to your computer, however, devices are auto -\nmatically created when you plug them in (named / dev/sda , /dev/sdb , and so on). Any \nfilesystems found on those devices are automatically mounted on /run/media/ username , \nand you are prompted if you want to open a Nautilus window to view files on those devices. \nThis is done automatically, so you don\u2019t have to do any special configuration to make \nthis happen.\nWhen you are finished with a USB drive, right-click the device\u2019s name in the Nautilus file \nmanager window and select Safely Remove Drive. This action unmounts the drive and ", "doc_id": "fe533649-7236-4575-b4eb-37d837a45005", "embedding": null, "doc_hash": "4e9c73e195f6b0e1334786b85355ae039f2c6b7de493132a7ca71b1d934f9dff", "extra_info": {"page_label": "219"}, "node_info": {"start": 0, "end": 2939}, "relationships": {"1": "7f61124b-95d4-4f99-b2af-a4a49aaedfae"}}, "__type__": "1"}, "40c48541-8379-4d7c-96db-254470a923bb": {"__data__": {"text": "Chapter 8: Learning System Administration\n191\n8removes the mount point in the /run/media/ username  directory. After that, you can \nsafely unplug the USB drive from your computer.\nWorking with loadable modules\nIf you have added hardware to your computer that isn\u2019t properly detected, you might need \nto load a module manually for that hardware. Linux comes with a set of commands for load -\ning, unloading, and getting information about hardware modules.\nKernel modules are installed in /lib/modules/  subdirectories. The name of each sub -\ndirectory is based on the release number of the kernel. For example, if the kernel were \n5.3.8-200.fc30.x86 _ 64 , the /lib/modules/5.3.8-200.fc30.x86 _ 64  directory \nwould contain drivers for that kernel. Modules in those directories can then be loaded and \nunloaded as they are needed.\nCommands for listing, loading, unloading, and getting information about modules are avail -\nable with Linux. The following sections describe how to use those commands.\nListing loaded modules\nTo see which modules are currently loaded into the running kernel on your computer, use \nthe lsmod  command. Consider the following example:\n# lsmod\nModule                  Size  Used by\nvfat                   17411  1\nfat                    65059  1 vfat\nuas                    23208  0\nusb_storage            65065  2 uas\nfuse                   91446  3\nipt_MASQUERADE         12880  3\nxt_CHECKSUM            12549  1\nnfsv3                  39043  1\nrpcsec_gss_krb5        31477  0\nnfsv4                 466956  0\ndns_resolver           13096  1 nfsv4\nnfs                   233966  3 nfsv3,nfsv4\n.\n.\n.\ni2c_algo_bit           13257  1 nouveau\ndrm_kms_helper         58041  1 nouveau\nttm                    80772  1 nouveau\ndrm                   291361  7 ttm,drm_kms_helper,nouveau\nata_generic            12923  0\npata_acpi              13053  0\ne1000                 137260  0\ni2c_core               55486  5 drm,i2c_i801,drm_kms_helper", "doc_id": "40c48541-8379-4d7c-96db-254470a923bb", "embedding": null, "doc_hash": "a8ece123bdcefdd694e5e77000a869a3993045f7b0ad837175f96cfd756e8495", "extra_info": {"page_label": "220"}, "node_info": {"start": 0, "end": 1959}, "relationships": {"1": "e3b6e21f-e9fa-4fc5-92cd-63c32c90ec09"}}, "__type__": "1"}, "07cc4278-ad98-45cb-880f-969e75a9ccfa": {"__data__": {"text": "Part III: Becoming a Linux System Administrator192This output shows a variety of modules that have been loaded on a Linux system, including \none for a network interface card ( e1000 ).\nTo find information about any of the loaded modules, use the modinfo  command. For \nexample, you can enter the following:\n# /sbin/modinfo -d e1000\nIntel(R) PRO/1000 Network Driver\nNot all modules have descriptions available and, if nothing is available, no data are \nreturned. In this case, however, the e1000  module is described as an Intel(R) PRO/1000 \nNetwork Driver module. You can also use the -a  option to see the author of the module or \n-n to see the object file representing the module. The author information often has the \nemail address of the driver\u2019s creator, so you can contact the author if you have problems or \nquestions about it.\nLoading modules\nYou can load any module (as root user) that has been compiled and installed (to a /\nlib/modules  subdirectory) into your running kernel using the modprobe  command. \nA common reason for loading a module is to use a feature temporarily (such as loading \na module to support a special filesystem on some removable media you want to access). \nAnother reason to load a module is to identify that module as one that will be used by a \nparticular piece of hardware that could not be autodetected.\nHere is an example of the modprobe  command being used to load the parport  module, \nwhich provides the core functions to share parallel ports with multiple devices:\n# modprobe parport\nAfter parport  is loaded, you can load the parport_pc  module to define the PC-style \nports available through the interface. The parport_pc  module lets you optionally define \nthe addresses and IRQ numbers associated with each device sharing the parallel port, as in \nthe following example:\n# modprobe parport_pc io=0x3bc irq=auto\nIn this example, a device is identified as having an address of 0x3bc , and the IRQ for the \ndevice is autodetected.\nThe modprobe  command loads modules temporarily\u2014they disappear at the next reboot. \nTo add the module to your system permanently, add the modprobe  command line to one of \nthe startup scripts run at boot time.\nRemoving modules\nUse the rmmod  command to remove a module from a running kernel. For example, to \nremove the module parport _ pc  from the current kernel, type the following:\n# rmmod parport_pc", "doc_id": "07cc4278-ad98-45cb-880f-969e75a9ccfa", "embedding": null, "doc_hash": "474d19dc2e338f56ff326b0504b2ec9e18e8e7c60759304143cb2e43883f2bc4", "extra_info": {"page_label": "221"}, "node_info": {"start": 0, "end": 2379}, "relationships": {"1": "d7397418-8516-491a-ad0d-76777f097631"}}, "__type__": "1"}, "6ab38410-4630-4994-8c0d-ed56a8813a60": {"__data__": {"text": "Chapter 8: Learning System Administration\n193\n8If it is not currently busy, the parport_pc  module is removed from the running kernel. \nIf it is busy, try killing any process that might be using the device. Then run rmmod \nagain. Sometimes, the module you are trying to remove depends on other modules that \nmay be loaded. For instance, the usbcore  module cannot be unloaded because it is a \nbuilt-in module:\n# rmmod usbcore\nrmmod: ERROR: Module usbcore is builtin.\nInstead of using rmmod  to remove modules, you could use the modprobe -r  command. \nWith modprobe -r , instead of just removing the module you request, you can also remove \ndependent modules that are not being used by other modules.\nSummary\nMany features of Linux, especially those that can potentially damage the system or impact \nother users, require that you gain root privilege. This chapter describes different ways of \nobtaining root privilege: direct login, su  command, or sudo  command. It also covers some \nof the key responsibilities of a system administrator and components (configuration files, \nbrowser-based tools, and so on) that are critical to a system administrator\u2019s work.\nThe next chapter describes how to install a Linux system. Approaches to installing Linux \nthat are covered in that chapter include how to install from live media and from installa -\ntion media.\nExercises\nUse these exercises to test your knowledge of system administration and to explore infor -\nmation about your system hardware. These tasks assume that you are running a Fedora \nor Red Hat Enterprise Linux system (although some tasks work on other Linux systems as \nwell). If you are stuck, solutions to the tasks are shown in Appendix B (although in Linux, \nthere are often multiple ways to complete a task).\n1. From a shell as root user (or using sudo ), enable Cockpit ( cockpit.socket ) using \nthe systemctl  command.\n2. Open your web browser to the Cockpit interface (9090) on your system.\n3. Find all files under the /var/spool  directory that are owned by users other than \nroot and display a long listing of them.\n4. Become the root user using the su -  command. To prove that you have root privi-\nlege, create an empty or plain-text file named /mnt/test.txt . Exit the shell when \nyou are finished. If you are using Ubuntu, you must set your root password first \n(sudo passwd root ).", "doc_id": "6ab38410-4630-4994-8c0d-ed56a8813a60", "embedding": null, "doc_hash": "908ba170ab9d57fa91e5cda000a34e5172d25a79551303d11d399dcb96ac86c7", "extra_info": {"page_label": "222"}, "node_info": {"start": 0, "end": 2354}, "relationships": {"1": "047995ca-9cde-42b7-804d-aa826b1efefd"}}, "__type__": "1"}, "47824ebc-41f3-4338-893c-9039cec34da3": {"__data__": {"text": "Part III: Becoming a Linux System Administrator1945. Log in as a regular user and become root using su - . Edit the /etc/sudo -\ners file to allow your regular user account to have full root privilege via the \nsudo  command.\n6. As the user to whom you just gave sudoers  privilege, use the sudo  command to \ncreate a file called /mnt/test2.txt . Verify that the file is there and owned by the \nroot user.\n7. Run the journalctl -f  command and plug a USB drive into a USB port on your \ncomputer. If it doesn\u2019t mount automatically, mount it on /mnt/test . In a second \nterminal, unmount the device and remove it, continuing to watch the output from \njournalctl -f .\n8. Run a command to see what USB devices are connected to your computer.\n9. Pretend that you added a TV card to your computer, but the module needed to use it \n(bttv ) was not properly detected and loaded. Load the bttv  module yourself, and \nthen look to see that it was loaded. Were other modules loaded with it?\n10. Remove the bttv  module along with any other modules that were loaded with it. \nList your modules to make sure that this was done.", "doc_id": "47824ebc-41f3-4338-893c-9039cec34da3", "embedding": null, "doc_hash": "4d0011387ab2ceb0df5354afb2f0211364afc5b7e1ac7d2a365c8bcbb02443d4", "extra_info": {"page_label": "223"}, "node_info": {"start": 0, "end": 1112}, "relationships": {"1": "22f5f460-7420-4451-9653-ea64cb0d5d19"}}, "__type__": "1"}, "cf13279b-6823-45e5-be38-0e84a5a242cc": {"__data__": {"text": "195\nIN THIS CHAPTER\nChoosing an installation method\nInstalling a single- or multi-boot system\nPerforming a Live media installation of Fedora\nInstalling Red Hat Enterprise Linux\nUnderstanding cloud-based installations\nPartitioning the disk for installation\nUnderstanding the GRUB boot loader\nInstalling Linux has become a fairly easy thing to do\u2014if you are starting with a computer that is \nup to spec (hard disk, RAM, CPU, and so on) and you don\u2019t mind totally erasing your hard drive. \nWith cloud computing and virtualization, installation can be even simpler. It allows you to \nbypass traditional installation and spin a Linux system up or down within a few minutes by adding \nmetadata to prebuilt images.\nThis chapter starts off with a simple installation on a physical computer from Live media and prog -\nresses to more complex installation topics.\nTo ease you into the subject of installing Linux, I cover three different ways of installing Linux and \nstep you through each process:\nInstalling from Live media A Linux Live media ISO is a single, read-only image that contains \neverything you need to start a Linux operating system. That image can be burned to a DVD \nor USB drive and booted from that medium. With the Live media, you can totally ignore your \ncomputer\u2019s hard disk; in fact, you can run Live media on a system with no hard disk. After \nyou are running the Live Linux system, some Live media ISOs allow you to launch an appli-\ncation that permanently installs the contents of the Live medium to your hard disk. The \nfirst installation procedure in this chapter shows you how to install Linux permanently from \na Fedora Live media ISO.Installing LinuxCHAPTER9\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "cf13279b-6823-45e5-be38-0e84a5a242cc", "embedding": null, "doc_hash": "f5e9df4a39ad76667be6706f95d9536a843915aff01822d7777a22b98a6b79cc", "extra_info": {"page_label": "224"}, "node_info": {"start": 0, "end": 1800}, "relationships": {"1": "99d98673-e535-4466-a7f8-37cda0d1a0fe"}}, "__type__": "1"}, "dae5d9a2-ff2b-4095-9b9d-74611c78fd48": {"__data__": {"text": "Part III: Becoming a Linux System Administrator196Installing from an installation DVD An installation DVD, available with Fedora, \nRHEL, Ubuntu, and other Linux distributions, offers more flexible ways of \ninstalling Linux. In particular, instead of just copying the whole Live media con -\ntents to your computer, with an installation DVD you can choose exactly which \nsoftware package you want. The second installation procedure I show in this chap -\nter steps you through an installation process from a Red Hat Enterprise Linux 8 \ninstallation DVD.\nInstalling in the enterprise Sitting in front of a computer and clicking through \ninstallation questions isn\u2019t inconvenient if you are installing a single system. \nBut what if you need to install dozens or hundreds of Linux systems? What if \nyou want to install those systems in particular ways that need to be repeated \nover multiple installations? Later in this chapter, I describe efficient ways of \ninstalling multiple Linux systems using network installation features and kick -\nstart files.\nA fourth method of installation not covered in this chapter is to install Linux to a cloud \nenvironment (such as Amazon Web Services) or virtual machine on a virtualization host, such \nas Virtual Box or a VMware system. Chapter\u00a027 and Chapter\u00a028 describe ways of installing or \ndeploying a virtual machine on a Linux KVM host or in a cloud environment.\nTo try the procedures in this chapter along with me, you should have a computer in front \nof you that you don\u2019t mind totally erasing. As an alternative, you can use a computer that \nhas another operating system installed (such as Windows), as long as there is enough \nunused disk space available outside of that operating system. I describe the procedure, \nand risk of data loss, if you decide to set up one of these \u201cdual boot\u201d (Linux and Windows) \narrangements.\nChoosing a Computer\nYou can get a Linux distribution that runs on handheld devices or an old PC in your closet \nwith as little as 24MB of RAM and a 486 processor. To have a good desktop PC experience \nwith Linux, however, you should consider what you want to be able to do with Linux when \nyou are choosing your computer.\nBe sure to consider the basic specifications that you need for a PC-type computer to run the \nFedora and Red Hat Enterprise Linux distributions. Because Fedora is used as the basis for \nRed Hat Enterprise Linux releases, hardware requirements are similar for basic desktop and \nserver hardware for those two distributions.\nProcessor  A 1GHz Pentium processor is the minimum for a GUI installation. For most \napplications, a 32-bit processor is fine (x86). However, if you want to set up the \nsystem to do virtualization, you need a 64-bit processor (x86_64).", "doc_id": "dae5d9a2-ff2b-4095-9b9d-74611c78fd48", "embedding": null, "doc_hash": "15dcd23c24fe12cad7e86efd15681515161cc2675cc5109540d463367b198c72", "extra_info": {"page_label": "225"}, "node_info": {"start": 0, "end": 2745}, "relationships": {"1": "246abca3-db8f-4208-9502-f0ceb2f56a12"}}, "__type__": "1"}, "97d09484-4b26-4261-96a2-82e5320385c2": {"__data__": {"text": "Chapter 9: Installing Linux\n197\n9RAM Fedora recommends at least 1GB of RAM, but at least 2GB or 3GB would be much \nbetter. On my RHEL desktop, I\u2019m running a web browser, word processor, and mail \nreader, and I\u2019m consuming over 2GB of RAM.\nDVD or USB drive You need to be able to boot up the installation process from a DVD \nor USB drive. In recent releases, the Fedora live media ISO has become too big to fit \non a CD, so you need to burn it to a DVD or USB drive. If you can\u2019t boot from a DVD \nor USB drive, there are ways to start the installation from a hard disk or by using a \nPXE install. After the installation process is started, more software can sometimes be \nretrieved from different locations (over the network or from hard disk, for example).\nNetwork card  You need wired or wireless networking hardware to be able to add more \nsoftware or get software updates. Fedora offers free software repositories if you can con -\nnect to the Internet. For RHEL, updates are available as part of the subscription price.\nDisk space  Fedora recommends at least 20GB of disk space for an average desktop \ninstallation, although installations can range (depending on which packages you \nchoose to install) from 600MB (for a minimal server with no GUI install) to 7GB (to \ninstall all packages from the installation DVD). Consider the amount of data that \nyou need to store. Although documents can consume very little space, videos can \nconsume massive amounts of space. (By comparison, you can install Tiny Core Linux \nto disk with only about 16MB of disk space, which includes a GUI.)\nSpecial hardware features Some Linux features require special hardware features. For \nexample, to use Fedora or RHEL as a virtualization host using KVM, the computer must \nhave a processor that supports virtualization. These include AMD-V or Intel-VT chips.\nIf you\u2019re not sure about your computer hardware, there are a few ways to check what you \nhave. If you are running Windows, the System Properties window can show you the pro -\ncessor you have as well as the amount of RAM that\u2019s installed. As an alternative, with the \nFedora Live CD booted, open a shell and type dmesg | less  to see a listing of hardware \nas it is detected on your system.Note\nIf you have a less powerful computer than the minimum described here, consider using a lightweight Linux  \ndistribution. Lightweight Ubuntu distributions include Peppermint OS ( https://peppermintos.com/ ) and \nLubuntu (https://lubuntu.net/ ). For a lightweight Fedora-based distribution, try the LXDE desktop  \n(https://spins.fedoraproject.org/lxde/ ). For a Linux distribution requiring the least resources, you  \ncould try Tiny Core Linux ( http://tinycorelinux.net/ ).\nNote\nPXE (pronounced pixie) stands for Preboot  eXecution Environment (PXE) . You can boot a client computer from a \nNetwork Interface Card (NIC) that is PXE-enabled. If a PXE boot server is available on the network, it can provide \neverything a client computer needs to boot. What it boots can be an installer. So, with a PXE boot, it is possible to do \na complete Linux installation without a CD, DVD, or any other physical medium.", "doc_id": "97d09484-4b26-4261-96a2-82e5320385c2", "embedding": null, "doc_hash": "dcaafae234fe5cc4292397a887f0c14447cd2226820ca6c67cf670f83ddf018b", "extra_info": {"page_label": "226"}, "node_info": {"start": 0, "end": 3143}, "relationships": {"1": "cd5a2c88-7179-417f-b5e5-1b6e9dee96d9"}}, "__type__": "1"}, "4c8ac1bc-2d1f-47cb-868e-c1f49156a661": {"__data__": {"text": "Part III: Becoming a Linux System Administrator198With your hardware in place, you can choose to install Linux from a Live CD or from instal -\nlation media, as described in the following sections.\nInstalling Fedora from Live Media\nIn Chapter\u00a02, you learned how to get and boot up Linux Live media. This chapter steps you \nthrough an installation process of a Fedora Live DVD so that it is permanently installed on \nyour hard disk.\nSimplicity is the main advantage of installing from Live media. Essentially, you are just \ncopying the kernel, applications, and settings from the ISO image to the hard disk. There \nare fewer decisions that you have to make to do this kind of installation, but you also don\u2019t \nget to choose exactly which software packages to install. After the installation, you can \nadd and remove packages as you please.\nThe first decisions that you must make about your Live media installation include where \nyou want to install the system and whether you want to keep existing operating systems \naround when your installation is done:\nSingle-boot computer The easiest way to install Linux is to not have to worry about \nother operating systems or data on the computer and have Linux replace every -\nthing. When you are done, the computer boots up directly to Fedora.\nMulti-boot computer If you already have Windows installed on a computer and you \ndon\u2019t want to erase it, you can install Fedora along with Windows on that system. \nThen, at boot time, you can choose which operating system to start up. To be able \nto install Fedora on a system with another operating system installed, you must \nhave either extra disk space available (outside the Windows partition) or be able \nto shrink the Windows system to gain enough free space to install Fedora. Because \nmulti-boot computers are tedious to set up and risk damaging your installed system, \nI recommend installing Linux on a separate computer, even an old used one, or on a \nvirtual machine, as opposed to multi-booting.\nBare metal or virtual system The resulting Fedora installation can be installed to \nboot up directly from the computer hardware or from within an existing operating \nsystem on the computer. If you have a computer that is running as a virtual host, \nyou can install Fedora on that system as a virtual guest. Virtualization host software \nincludes KVM, Xen, and VirtualBox (for Linux and UNIX systems as well as Windows \nand the Mac OS), Hyper-V (for Microsoft systems), and VMware (for Linux, Windows, \nand Mac OS). You can use the Fedora Live ISO image from disk or burned to a DVD to \nstart an installation from your chosen hypervisor host. (Chapter\u00a027, \u201cUsing Linux for \nCloud Computing,\u201d describes how to set up a KVM virtualization host.)\nThe following procedure steps you through the process of installing the Fedora Live ISO \ndescribed in Chapter\u00a02 to your local computer. Because the Fedora 30 installation is very \nsimilar to the Red Hat Enterprise Linux 8 installation described later in this chapter, you \ncan refer to that procedure if you want to go beyond the simple selections shown here (par -\nticularly in the area of storage configuration).", "doc_id": "4c8ac1bc-2d1f-47cb-868e-c1f49156a661", "embedding": null, "doc_hash": "36b4c60cb1069f99669555cf8277ae36dd877a5e8c14ab7555b28cd00efca906", "extra_info": {"page_label": "227"}, "node_info": {"start": 0, "end": 3152}, "relationships": {"1": "18c96326-0f03-4419-912c-87f624d99fde"}}, "__type__": "1"}, "53d87b73-c72b-4b9c-a714-531b0b338c1e": {"__data__": {"text": "Chapter 9: Installing Linux\n199\n91. Get Fedora. Choose the Fedora Live media image that you want to use, download \nit to your local system, and burn it to an appropriate medium. See Appendix A for \ninformation on how to get the Fedora Live media and burn it to a DVD or USB drive.\n2. Boot the Live image. Insert the DVD or USB drive. When the BIOS screen appears, \nlook for a message that tells you to press a particular function key (such as F12) \nto interrupt the boot process and select the boot medium. Select the DVD or USB \ndrive, depending on which you have, and Fedora should come up and display the \nboot screen. When you see the boot screen, select Start Fedora-Workstation-Live.\n3. Start the installation. When the Welcome to Fedora screen appears, position your \nmouse over the Install to Hard Drive area and select it. Figure\u00a09.1 shows an example \nof the Install to Hard Drive selection on the Fedora Live media.Cautio N\nBefore beginning the procedure, be sure to make backup copies of any data on the computer that you still want to \nkeep. Although, you can choose not to erase selected disk partitions (as long as there is enough space available on \nother partitions), there is always a risk that data can be lost when you are manipulating disk partitions. Also, unplug \nany USB drives that you have plugged into your computer because they could be overwritten.\nFIGURE 9.1\nStart the installation process from Live media.", "doc_id": "53d87b73-c72b-4b9c-a714-531b0b338c1e", "embedding": null, "doc_hash": "4f17b908c0f83e18183034388992db46fcbe3fe49cac77cbe44e13038455a673", "extra_info": {"page_label": "228"}, "node_info": {"start": 0, "end": 1435}, "relationships": {"1": "73454c8b-1b43-41af-b161-2d7e7d8beed6"}}, "__type__": "1"}, "751b6f78-ddd6-4bd2-ae75-ac7f0e7f8ecc": {"__data__": {"text": "Part III: Becoming a Linux System Administrator2004. Select the language. When prompted, choose the language type that best suits you \n(such as U.S. English) and select Next. You should see the Installation summary \nscreen, as shown in Figure\u00a09.2.\n5. Select Time & Date. From the Time & Date screen, you can select your time zone \neither by clicking the map or choosing the region and city from drop-down boxes. \nTo set the date and time, if you have an Internet connection, you can select the \nNetwork Time button to turn it on, or you can select OFF and set the date and time \nmanually from boxes on the bottom of the screen. Select Done in the upper-right \ncorner when you are finished.\n6. Select the installation destination. Available storage devices (such as your hard \ndrive) are displayed, with your hard drive selected as the installation destination. \nIf you want the installer to install Fedora automatically, reclaiming existing disk \nspace, make sure that your disk is selected (not a USB drive or other device con -\nnected to your computer), then make the following selections:\na. Automatic .\u00a0.\u00a0. If there is enough available disk space on the selected disk drive, \nyou can continue with the installation by selecting Continue. Otherwise, you \nneed to reclaim disk space as follows:\nI would like to make additional space available.\u00a0.\u00a0. If you want to erase the \nhard drive completely, select this check box and click Continue. You can erase \nsome or all of the partitions that currently contain data.\nb. Reclaim Disk Space. From this screen, you can select Delete All. Then select \nReclaim Space. Partitioning is set up automatically and you are returned to the \nInstallation Summary screen.\nFIGURE 9.2\nSelect configuration options from the Installation Summary screen.", "doc_id": "751b6f78-ddd6-4bd2-ae75-ac7f0e7f8ecc", "embedding": null, "doc_hash": "76f6a4e366f654edc47005941e5e4e4c77e47f7ece141216d7a3c1adf732ad3d", "extra_info": {"page_label": "229"}, "node_info": {"start": 0, "end": 1783}, "relationships": {"1": "6e71e1d7-d81b-4835-ad94-b0240c5f9fe9"}}, "__type__": "1"}, "d40a95d7-7a4d-4cd8-84ad-15292b2a6bce": {"__data__": {"text": "Chapter 9: Installing Linux\n201\n97. Select the keyboard. You can just use the default English (U.S.) keyboard or select \nKeyboard to choose a different keyboard layout.\n8. Begin installation. Select Begin Installation to begin installing to hard disk.\n9. Finish the configuration. When the first part of the installation is complete, click Quit.\n10. Reboot. Select the little on/off button from the menu on the top-right corner of the \nscreen. When prompted, click the Restart button. Eject or remove the Live media \nwhen the system boot screen appears. The computer should boot to your newly \ninstalled Fedora system. (You may actually need to power off the computer for it to \nboot back up.)\n11. Begin using Fedora. A first boot screen appears at this point, allowing you to create \na user account and password, among other things. You are automatically logged in \nas that user account when configuration is done. That account has sudo  privileges, \nso you can immediately begin doing administrative tasks as needed.\n12. Get software updates. To keep your system secure and up to date, one of the first \ntasks that you should do after installing Fedora is to get the latest versions of the \nsoftware you just installed. If your computer has an Internet connection (plugging \ninto a wired Ethernet network or selecting an accessible wireless network from the \ndesktop takes care of that), you can simply open a Terminal as your new user and \ntype sudo dnf update to download and update all of your packages from the \nInternet. If a new kernel is installed, you can reboot your computer to have that \nnew kernel take effect.\nAt this point, you can begin using the desktop, as described in Chapter\u00a02. You can also use \nthe system to perform exercises from any of the chapters in this book.\nInstalling Red Hat Enterprise Linux from \nInstallation Media\nIn addition to offering a live DVD, most Linux distributions offer a single image or set of \nimages that can be used to install the distribution. For this type of installation media, \ninstead of copying the entire contents of the medium to disk, software is split up into \npackages that you can select to meet your exact needs. A full installation DVD, for example, \ncan allow you to install anything from a minimal system to a fully featured desktop to a \nfull-blown server that offers multiple services.\nIn this chapter, I use a Red Hat Enterprise Linux 8 installation DVD as the installation \nmedium. Review the hardware information and descriptions of dual booting in the previous \nsection before beginning your RHEL installation.\nFollow this procedure to install Red Hat Enterprise Linux from an installation DVD.\n1. Get the installation media. The process of downloading RHEL install ISO images is \ndescribed on the Red Hat Enterprise Linux product page. If you are not yet a Red ", "doc_id": "d40a95d7-7a4d-4cd8-84ad-15292b2a6bce", "embedding": null, "doc_hash": "608e3c64031726ce97199ddd1965c92b15cd28133b69be7afc62828b89493796", "extra_info": {"page_label": "230"}, "node_info": {"start": 0, "end": 2836}, "relationships": {"1": "febf3f02-8893-4448-90f3-7a68f7999775"}}, "__type__": "1"}, "fbdce1af-d079-47bf-8f69-e7bd81f0ec80": {"__data__": {"text": "Part III: Becoming a Linux System Administrator202Hat customer, you can apply for an evaluation copy here: https://www.redhat.com/\nen/technologies/linux-platforms/enterprise-linux .\nThis requires that you create a Red Hat account. If that is not possible, you can \ndownload an installation DVD from a mirror site of the CentOS project to get a sim-\nilar experience: https://wiki.centos.org/Download .\nFor this example, I used the 6.7G RHEL 8 DVD ISO rhel-8.0-x86_64-dvd.iso . \nAfter you have the DVD ISO, you can burn it to a physical USB drive or dual-layer \nDVD, as described in Appendix A.\n2. Boot the installation media. Insert the USB drive or DVD into your computer \nand reboot. (If you need to, interrupt the boot prompt to select to boot from the \nselected USB or DVD.) The Welcome screen appears.\n3. Select Install or Test Media. Select the Install or the \u201cTest this media & install\u201d \nentry to do a new installation of RHEL. The media test verifies that the DVD has \nnot been corrupted during the copy or burning process. If you need to modify the \ninstallation process, you can add boot options by pressing the Tab key with a boot \nentry highlighted and typing in the options you want. See the section \u201cUsing \ninstallation boot options\u201d later in this chapter.\n4. Select a language. Select your language and choose Continue. The Installation Sum-\nmary screen appears. From that screen, you can select to change any of the avail -\nable Localization, Software, and System features, as shown in Figure\u00a09.3.\nFIGURE 9.3\nChoose from Localization, Software, and System topics on the Installation Summary screen.", "doc_id": "fbdce1af-d079-47bf-8f69-e7bd81f0ec80", "embedding": null, "doc_hash": "5c77a4dc3fd735b1bce4eab789d5f7b6e0a93745522007f0be85b2bb090f308b", "extra_info": {"page_label": "231"}, "node_info": {"start": 0, "end": 1613}, "relationships": {"1": "e1f49267-adbf-4ede-ba27-0a74e4b9c210"}}, "__type__": "1"}, "2760f4fc-33e0-4a06-863b-068adce24da4": {"__data__": {"text": "Chapter 9: Installing Linux\n203\n95. Keyboard. Choose from different types of keyboards available with the languages \nyou selected earlier. Type some text to see how the keys are laid out.\n6. Language Support. You have a chance to add support for additional languages \n(beyond what you set by default earlier). Select Done when you are finished.\n7. Time & Date. Choose a time zone for your machine from either the map or the list \nshown (as described in the section \u201cInstalling Fedora from Live Media\u201d). Either \nset the time manually with up/down arrows or select Network Time to have your \nsystem try to connect to networked time servers automatically to sync system \ntime. Select Done when you are finished.\n8. Installation Source. The installation DVD is used, by default, to provide the RPM \npackages that are used during installation. You have the option of selecting \u201cOn \nthe network\u201d and choosing a Web URL ( http , https , or ftp ) identifying where \nthe Red Hat Enterprise Linux software repository is located. After choosing the DVD \nor a network location, you can add additional yum  repositories to have those repos -\nitories used during installation as well. Select Done when you are finished.\n9. Software Selection. The default \u201cServer with GUI\u201d selection provides a GNOME 3 \ndesktop system on top of a basic server install. Other choices include \"Server\" \n(which has no GUI), \"Minimal Install\" (which starts with a basic package set), and \n\"Workstation\" (geared for end users). You can select to add other services or other \nbase environments to include. Select Done when you are ready to continue.\n10. Installation Destination. The new RHEL system is installed, by default, on the local \nhard drive using automatic partitioning. You also have the option of attaching net -\nwork storage or special storage, such as Firmware RAID. (See the section \u201cPartition -\ning hard drives\u201d later in this chapter for details on configuring storage.) Click Done \nwhen you are finished. You may be asked to verify that it\u2019s okay to delete exist -\ning storage.\n11. Kdump. Enabling kdump  sets aside RAM to be used to capture the resulting kernel \ndump in the event that your kernel crashes. Without kdump , there would be no \nway to diagnose a crashed kernel. By default, enabling kdump sets aside 160MB \nplus 2 bits for every 4KB of RAM for saving kernel crashes.\n12. Network & Host Name. Any network interface cards that are discovered can be con -\nfigured at this point. If a DHCP service is available on the network, network address \ninformation is assigned to the interface after you select ON. Select Configure if you \nprefer to configure the network interface manually. Fill in the Hostname box if you \nwant to set the system\u2019s hostname. Setting up your network and hostname during \ninstallation can make it easier to begin using your system after installation. Click \nDone to continue.\n13. Security Policy. By choosing a security policy (none is chosen by default), you can \nensure that your system complies with a selected security standard. All fields are \noptional and can be changed later.\n14. System Purpose. This optional selection lets you choose the system\u2019s role, service-\nlevel agreement, and usage.", "doc_id": "2760f4fc-33e0-4a06-863b-068adce24da4", "embedding": null, "doc_hash": "8ac4ba3152dc9ec8d747346afa2cd9e60c86ad8a0f7df9d67c65f585a22cad36", "extra_info": {"page_label": "232"}, "node_info": {"start": 0, "end": 3214}, "relationships": {"1": "453a427e-72ff-432b-b4f5-68093881c092"}}, "__type__": "1"}, "54be066c-a795-4ae0-a82a-89d3a528c4e8": {"__data__": {"text": "Part III: Becoming a Linux System Administrator20415. Begin the installation. Click the Begin Installation button to start the install \nprocess. A progress bar marks the progress of the installation. As the system is \ninstalling, you can set the root password and create a new user account for your \nnew system.\n16. Root Password. Set the password for the root user and verify it (type it again). \nClick Done to accept it. If the password is too short or too weak, you stay on the \npage (where you can set a new password). If you decide to keep the weak password \ninstead, click Done again to accept the weak password.\n17. User Creation. It is good practice to log into a Linux system with a non-root user \naccount and request root privilege as needed. You can set up a user account, includ -\ning a username, full name, and password. You can select \u201cMake this user adminis -\ntrator\u201d to give that user sudo  privileges (allowing the account to act as the root \nuser as needed). Select Done when you are finished. If the password you enter is \ntoo short or otherwise weak, you must change it or click Done again if you still \nwant to use the weak password.\n18. Complete the installation. When installation is finished, click Reboot. Pop out the \nDVD when the system restarts and Red Hat Enterprise Linux starts up from the \nhard disk.\n19. Run firstboot. If you installed a desktop interface, the firstboot screen appears the \nfirst time you boot the system. Here\u2019s what you do:\na. License Information. Read and click the check box to accept the license infor -\nmation, then click Done.\nb. Subscription Manager. When prompted, you can leave the default subscrip -\ntion management system in place ( subscription.rhn.redhat.com ) or enter the \nlocation of a Red Hat Satellite server to register your system. Click Next. Enter \nyour Red Hat account and password, then click Register to register and entitle \nyour system to updates. If the subscription found is acceptable, click Attach to \nenable the subscription.\n20. Select Finish Configuration when you are done.\nYou should now be able to log in to your Red Hat Enterprise Linux system. One of the first \nthings that you should do is to get software updates for the new system. Do this by logging \ninto the system and running sudo dnf upgrade  from a Terminal window.\nUnderstanding Cloud-Based Installations\nWhen you install a Linux system on a physical computer, the installer can see the com-\nputer\u2019s hard drive, network interfaces, CPUs, and other hardware components. When you \ninstall Linux in a cloud environment, those physical components are abstracted into a pool \nof resources. So, to install a Linux distribution in an Amazon EC2, Google Compute Engine, \nor OpenStack cloud platform, you need to go about things differently.", "doc_id": "54be066c-a795-4ae0-a82a-89d3a528c4e8", "embedding": null, "doc_hash": "3c04db5e86385354adebbf4fb0863b38bcb6bbdc0b49433b34531f9a27a92bc2", "extra_info": {"page_label": "233"}, "node_info": {"start": 0, "end": 2782}, "relationships": {"1": "d2cc8df2-3670-4696-8d86-d69f3293281d"}}, "__type__": "1"}, "d6f5b857-d818-40ee-9dd2-3140f27f005e": {"__data__": {"text": "Chapter 9: Installing Linux\n205\n9The common way of installing Linux in a cloud is to start with a file that is an image of \nan installed Linux system. Typically, that image includes all of the files needed by a basic, \nrunning Linux system. Metadata is added to that image from a configuration file or by \nfilling out a form from a cloud controller that creates and launches the operating system as \na virtual machine.\nThe kind of information added to the image might include a particular hostname, root \npassword, and new user account. You might also want to choose to have a specific amount \nof disk space, a particular network configuration, and a certain number of CPU proces -\nsors and RAM.\nMethods for installing Linux in a local cloud-like KVM environment are discussed in Chap -\nter\u00a028, \u201cDeploying Linux to the Cloud.\u201d That chapter covers how to run a Linux system \nas a virtual machine image on a KVM environment, Amazon EC2 cloud, or OpenStack \nenvironment.\nInstalling Linux in the Enterprise\nIf you were managing dozens, hundreds, even thousands of Linux systems in a large enter -\nprise, it would be terribly inefficient to have to go to each computer to type and click through \neach installation. Fortunately, with Red Hat Enterprise Linux and other distributions, you \ncan automate installation in such a way that all you need to do is to turn on a computer and \nboot from the computer\u2019s network interface card to get your desired Linux installation.\nAlthough we have focused on installing Linux from a DVD or USB media, there are many \nother ways to launch a Linux installation and many ways to complete an installation. The \nfollowing descriptions step through the installation process and describe ways of changing \nthat process along the way:\nLaunch the installation medium. You can launch an installation from any medium \nthat you can boot from a computer: CD, DVD, USB drive, hard disk, or network inter -\nface card with PXE support. The computer goes through its boot order and looks at the \nmaster boot record on the physical medium or looks for a PXE server on the network.\nStart the anaconda kernel. The job of the boot loader is to point to the special \nkernel (and possibly an initial RAM disk) that starts the Linux installer (called \nanaconda). So, any of the media types just described simply needs to point to the \nlocation of the kernel and initial RAM disk to start the installation. If the software \npackages are not on the same medium, the installation process prompts you for \nwhere to get those packages.\nAdd kickstart or other boot options. Boot options (described later in this chapter) \ncan be passed to the anaconda kernel to configure how it starts up. One option \nsupported by Fedora and RHEL allows you to pass the location of a kickstart file to \nthe installer. That kickstart can contain all of the information needed to complete \nthe installation: root password, partitioning, time zone, and so on to configure the \ninstalled system further. After the installer starts, it either prompts for needed \ninformation or uses the answers provided in the kickstart file.", "doc_id": "d6f5b857-d818-40ee-9dd2-3140f27f005e", "embedding": null, "doc_hash": "6713d692580fee1e627aa1a32913cdbb3e65ccb76ffc7da2fe07ec91cd6b9dc9", "extra_info": {"page_label": "234"}, "node_info": {"start": 0, "end": 3109}, "relationships": {"1": "35a1b625-9734-406a-ae4a-951a6de87ab2"}}, "__type__": "1"}, "18a3a66b-e8b3-4518-ad72-9ead47fd4ddc": {"__data__": {"text": "Part III: Becoming a Linux System Administrator206Find software packages. Software packages don\u2019t have to be on the installation \nmedium. This allows you to launch an installation from a boot medium that con -\ntains only a kernel and initial RAM disk. From the kickstart file or from an option \nyou enter manually to the installer, you can identify the location of the repository \nholding the RPM software packages. That location can be a local CD ( cdrom ), web -\nsite (http ), FTP site ( ftp), NFS share ( nfs), NFS ISO ( nfsiso ), or local disk ( hd).\nModify installation with kickstart scripts. Scripts included in a kickstart can \nrun commands you choose before or after the installation to further configure the \nLinux system. Those commands can add users, change permissions, create files and \ndirectories, grab files over the network, or otherwise configure the installed system \nexactly as you specify.\nAlthough installing Linux in enterprise environments is beyond the scope of this book, I \nwant you to understand the technologies that are available when you want to automate the \nLinux installation process. Here are some of those technologies available to use with Red \nHat Enterprise Linux, along with links to where you can find more information about them:\nInstall server  If you set up an installation server, you don\u2019t have to carry the soft -\nware packages around to each machine where you install RHEL. Essentially, you \ncopy all of the software packages from the RHEL installation medium to a web \nserver (http ), FTP server ( ftp), or NFS server ( nfs) and then point to the location \nof that server when you boot the installer. The RHEL 8 Installation Guide describes \nhow to set up a local or network installation source:\nhttps://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/\nhtml-single/performing_a_standard_rhel_installation/index#prepare-\ninstallation-source_preparing-for-your-installation\nPXE server  If you have a computer with a network interface card that supports PXE \nbooting (as most do), you can set your computer\u2019s BIOS to boot from that NIC. If you \nhave set up a PXE server on that network, that server can present a menu to the \ncomputer containing entries to launch an installation process. The RHEL Installa -\ntion Guide provides information on how to set up PXE servers for installation:\nhttps://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/\nhtml-single/performing_a_standard_rhel_installation/index#booting-the-\ninstallation-using-pxe_booting-the-installer\nKickstart files  To automate an installation completely, you create what is called a \nkickstart file. By passing a kickstart file as a boot option to a Linux installer, you \ncan provide answers to all of the installation questions that you would normally \nhave to click through.\nWhen you install RHEL, a kickstart file containing answers to all installation ques -\ntions for the installation you just did is contained in the /root/anaconda-ks.cfg  \nfile. You can present that file to your next installation to repeat the installation con -\nfiguration or use that file as a model for different installations.", "doc_id": "18a3a66b-e8b3-4518-ad72-9ead47fd4ddc", "embedding": null, "doc_hash": "c40d76a91450406659915b3fcfbfc3709d5ccceb52b6644fc1f7fca0d97444fb", "extra_info": {"page_label": "235"}, "node_info": {"start": 0, "end": 3149}, "relationships": {"1": "9dab0728-a412-4241-beca-a82ebb3cc446"}}, "__type__": "1"}, "bb7812db-1568-4fe8-9a2f-c215eb666b53": {"__data__": {"text": "Chapter 9: Installing Linux\n207\n9See the Advanced RHEL Installation Guide for information on performing a kickstart \ninstallation: https://access.redhat.com/documentation/en-us/red_hat_enter-\nprise_linux/8/html-single/performing_an_advanced_rhel_installation/\nindex/#performing_an_automated_installation_using_kickstart\n.\u00a0.\u00a0. and creating your own kickstart files https://access.redhat.com/  \ndocumentation/en-us/red_hat_enterprise_linux/8/html-single/\nperforming_an_advanced_rhel_installation/index/#creating-kickstart-files_\ninstalling-rhel-as-an-experienced-user\nExploring Common Installation Topics\nSome of the installation topics touched upon earlier in this chapter require further expla -\nnation for you to be able to implement them fully. Read through the following sections to \nget a greater understanding of specific installation topics.\nUpgrading or installing from scratch\nIf you have an earlier version of Linux already installed on your computer, Fedora, Ubuntu, \nand other Linux distributions offer an upgrade option. Red Hat Enterprise Linux offers a \nlimited upgrade path from RHEL 7 to RHEL 8.\nUpgrading lets you move a Linux system from one major release to the next. Between minor \nreleases, you can simply update packages as needed (for example, by typing yum update ). \nHere are a few general rules before performing an upgrade:\nRemove extra packages. If you have software packages that you don\u2019t need, remove \nthem before you do an upgrade. Upgrade processes typically upgrade only those \npackages that are on your system. Upgrades generally do more checking and com-\nparing than clean installs do, so any package that you can remove saves time during \nthe upgrade process.\nCheck configuration files. A Linux upgrade procedure often leaves copies of \nold configuration files. You should check that the new configuration files still \nwork for you.\nSome Linux distributions, most notably Gentoo, have taken the approach of providing \nongoing updates. Instead of taking a new release every few months, you simply continu -\nously grab updated packages as they become available and install them on your system.tip\nInstalling Linux from scratch goes faster than an upgrade. It also results in a cleaner Linux system. So, if you don\u2019t \nneed the data on your system (or if you have a backup of your data), I recommend that you do a fresh installation. \nThen you can restore your data to a freshly installed system.", "doc_id": "bb7812db-1568-4fe8-9a2f-c215eb666b53", "embedding": null, "doc_hash": "23046fcc8571a08d6897549a9180523ac413c992111535f9a466739c64a70a61", "extra_info": {"page_label": "236"}, "node_info": {"start": 0, "end": 2429}, "relationships": {"1": "d8921085-6b8d-4b67-a87e-37fc52b10989"}}, "__type__": "1"}, "bb49b041-d3ec-4e2b-804d-ba5e639b9e02": {"__data__": {"text": "Part III: Becoming a Linux System Administrator208Dual booting\nIt is possible to have multiple operating systems installed on the same computer. One way \nto do this is by having multiple partitions on a hard disk and/or multiple hard disks and \nthen installing different operating systems on different partitions. As long as the boot \nloader contains boot information for each of the installed operating systems, you can \nchoose which one to run at boot time.\nIf the computer you are using already has a Windows system on it, quite possibly the entire \nhard disk is devoted to Windows. Although you can run a bootable Linux, such as KNOPPIX \nor Tiny Core Linux, without touching the hard disk, to do a more permanent installation, \nyou\u2019ll want to find disk space outside of the Windows installation. There are a few ways \nto do this:\nAdd a hard disk. Instead of messing with your Windows partition, you can simply \nadd a hard disk and devote it to Linux.\nResize your Windows partition. If you have available space on a Windows partition, \nyou can shrink that partition so that free space is available on the disk to devote \nto Linux. Commercial tools such as Acronis Disk Director ( https://www.acronis.com/\nen-us/personal/disk-manager ) are available to resize your disk partitions and set \nup a workable boot manager. Some Linux distributions (particularly bootable Linux \ndistributions used as rescue media) include a tool called GParted (which includes \nsoftware from the Linux-NTFS project for resizing Windows NTFS partitions).\nBefore you try to resize your Windows partition, you might need to defragment it. To \ndefragment your disk on some Windows systems so that all your used space is put in order \non the disk, open My Computer, right-click your hard disk icon (typically C:), select Prop -\nerties, click Tools, and select Defragment Now.Cautio N\nAlthough tools for resizing Windows partitions and setting up multi-boot systems have improved in recent years, there \nis still some risk of losing data on Windows/Linux dual-boot systems. Different operating systems often have differ -\nent views of partition tables and master boot records that can cause your machine to become unbootable (at least \ntemporarily) or lose data permanently. Always back up your data before you try to resize a Windows filesystem to \nmake space for Linux.\nNote\nType dnf install gparted (in Fedora) or apt-get install gparted (in Ubuntu) to install GParted. \nRun gparted  as root to start it.", "doc_id": "bb49b041-d3ec-4e2b-804d-ba5e639b9e02", "embedding": null, "doc_hash": "2ddf18c3f4a664ab0204a52edb8f265a009084a66029183aa520e7a1b570c8d8", "extra_info": {"page_label": "237"}, "node_info": {"start": 0, "end": 2481}, "relationships": {"1": "fa796ad6-7726-4a90-b5d0-60b224a2838e"}}, "__type__": "1"}, "e7e4d2d5-be2c-4c58-9aee-3bbc9e602d70": {"__data__": {"text": "Chapter 9: Installing Linux\n209\n9Defragmenting your disk can be a fairly long process. The result of defragmentation is that \nall of the data on your disk are contiguous, creating lots of contiguous free space at the \nend of the partition. Sometimes, you have to complete the following special tasks to make \nthis true:\n\u25a0\u25a0If the Windows swap file is not moved during defragmentation, you must remove it. \nThen, after you defragment your disk again and resize it, you need to restore the \nswap file. To remove the swap file, open the Control Panel, open the System icon, \nclick the Performance tab, and select Virtual Memory. To disable the swap file, click \nDisable Virtual Memory.\n\u25a0\u25a0If your DOS partition has hidden files that are on the space you are trying to free \nup, you need to find them. In some cases, you can\u2019t delete them. In other cases, \nsuch as swap files created by a program, you can safely delete those files. This is \na bit tricky because some files should not be deleted, such as DOS system files. \nYou can use the attrib -s -h command from the root directory to deal with \nhidden files.\nAfter your disk is defragmented, you can use commercial tools described earlier (Acronis \nDisk Director) to repartition your hard disk to make space for Linux. Or, you can use the \nopen-source alternative GParted.\nAfter you have cleared enough disk space to install Linux (see the disk space requirements \ndescribed earlier in this chapter), you can install Ubuntu, Fedora, RHEL, or another Linux \ndistribution. As you set up your boot loader during installation, you can identify Windows, \nLinux, and any other bootable partitions so that you can select which one to boot when \nyou start your computer.\nInstalling Linux to run virtually\nUsing virtualization technology, such as KVM, VMware, VirtualBox, or Xen, you can con -\nfigure your computer to run multiple operating systems simultaneously. Typically, you have \na host operating system running (such as your Linux or Windows desktop), and then you \nconfigure guest operating systems to run within that environment.\nIf you have a Windows system, you can use commercial VMware products to run Linux on \nyour Windows desktop. Get a trial of VMware Workstation ( https://www.vmware.com/try-\nvmware ) to see if you like it. Then run your installed virtual guests with the free VMware \nPlayer. With a full-blown version of VMware Workstation, you can run multiple distributions \nat the same time.\nOpen-source virtualization products that are available with Linux systems include Virtu -\nalBox (https://www.virtualbox.org ), Xen (https://xenproject.org ), and KVM ( https://\nwww.linux-kvm.org ). Some Linux distributions still use Xen. However, all Red Hat systems \ncurrently use KVM as the basis for Red Hat\u2019s hypervisor features in RHEL, Red Hat Virtual -\nization, and other cloud projects. See Chapter\u00a028 for information on installing Linux as a \nvirtual machine on a Linux KVM host.", "doc_id": "e7e4d2d5-be2c-4c58-9aee-3bbc9e602d70", "embedding": null, "doc_hash": "4541070f003410491bc2a5cfcd39b7b057c848ba0b5fdbe4f227310ee2c4fc03", "extra_info": {"page_label": "238"}, "node_info": {"start": 0, "end": 2942}, "relationships": {"1": "b884dda9-bf09-4013-960b-7862b8ae5c74"}}, "__type__": "1"}, "3c16b5bd-3435-419b-8905-fda941c1e035": {"__data__": {"text": "Part III: Becoming a Linux System Administrator210Using installation boot options\nWhen the anaconda kernel launches at boot time for RHEL or Fedora, boot options provided \non the kernel command line modify the behavior of the installation process. By interrupt -\ning the boot loader before the installation kernel boots, you can add your own boot options \nto direct how the installation behaves.\nWhen you see the installation boot screen, depending on the boot loader, press Tab or some \nother key to be able to edit the anaconda kernel command line. The line identifying the \nkernel might look something like the following:\nvmlinuz initrd=initrd.img ...\nThe vmlinuz  is the compressed kernel and initrd.img  is the initial RAM disk (contain -\ning modules and other tools needed to start the installer). To add more options, just type \nthem at the end of that line and press Enter.\nSo, for example, if you have a kickstart file available from /root/ks.cfg  on a CD, your \nanaconda boot prompt to start the installation using the kickstart file could look like the \nfollowing:\nvmlinuz initrd=initrd.img ks=cdrom:/root/ks.cfg\n \nFor Red Hat Enterprise Linux 8 and the latest Fedora releases, kernel boot options used dur -\ning installation are transitioning to a new naming method. With this new naming, a prefix \nof inst.  can be placed in front of any of the boot options shown in this section that are \nspecific to the installation process (for example, inst.xdriver  or inst.repo=dvd ). For \nthe time being, however, you can still use the options shown in the next few sections with \nthe inst.  prefix.\nBoot options for disabling features\nSometimes, a Linux installation fails because the computer has some non-functioning or \nnon-supported hardware. Often, you can get around those issues by passing options to the \ninstaller that do such things as disable selected hardware when you need to select your \nown driver. Table\u00a09.1 provides some examples.\nBoot options for video problems\nIf you are having trouble with your video display, you can specify video settings as noted \nin Table\u00a09.2.\nBoot options for special installation types\nBy default, installation runs in graphical mode when you're sitting at the console \nanswering questions. If you have a text-only console, or if the GUI isn't working properly, \nyou can run an installation in plain-text mode: by typing text , you cause the installation \nto run in text mode.", "doc_id": "3c16b5bd-3435-419b-8905-fda941c1e035", "embedding": null, "doc_hash": "6cd9a9fd166a8d50b89415e30e1c9e021ebc4ddbabf7f2fd80a1a5bef8e5fc31", "extra_info": {"page_label": "239"}, "node_info": {"start": 0, "end": 2425}, "relationships": {"1": "e268c130-e65e-4609-b916-9f56798a1e83"}}, "__type__": "1"}, "60b0dddc-6e5e-41de-ae6e-395aa8624452": {"__data__": {"text": "Chapter 9: Installing Linux\n211\n9If you want to start installation on one computer, but you want to answer the installa -\ntion questions from another computer, you can enable a VNC  (virtual network computing) \ninstallation. After you start this type of installation, you can go to another system and \nopen a vnc viewer , giving the viewer the address of the installation machine (such as \n192.168.0.99:1). Table\u00a09.3 provides the necessary commands, along with what to tell the \nsystem to do.\nBoot options for kickstarts and remote repositories\nYou can boot the installation process from an installation medium that contains little more \nthan the kernel and initial RAM disk. If that is the case, you need to identify the reposi-\ntory where the software packages exist. You can do that by providing a kickstart file or by \nidentifying the location of the repositories in some way. To force the installer to prompt for \nthe repository location (CD/DVD, hard drive, NFS, or URL), add askmethod  to the installa -\ntion boot options.TABLE 9.1  Boot Options for Disabling Features\nInstaller Option Tells System\nnofirewire Not to load support for firewire devices\nnodma Not to load DMA support for hard disks\nnoide Not to load support for IDE devices\nnompath Not to enable support for multipath devices\nnoparport Not to load support for parallel ports\nnopcmcia Not to load support for PCMCIA controllers\nnoprobe Not to probe hardware; instead prompt user for drivers\nnoscsi Not to load support for SCSI devices\nnousb Not to load support for USB devices\nnoipv6 Not to enable IPV6 networking\nnonet Not to probe for network devices\nnuma-off To disable the Non-Uniform Memory Access (NUMA) for AMD64 architecture\nacpi=off To disable the Advanced Configuration and Power Interface (ACPI)\nTABLE 9.2  Boot Options for Video Problems\nBoot Option Tells System\nxdriver=vesa Use standard vesa video driver\nresolution=1024x768 Choose exact resolution to use\nnofb Don't use the VGA 16 framebuffer driver\nskipddc Don't probe DDC of the monitor (the probe can hang the installer)\ngraphical Force a graphical installation", "doc_id": "60b0dddc-6e5e-41de-ae6e-395aa8624452", "embedding": null, "doc_hash": "e95380bba5a12dbf2e57d5b0d8aef6ea75c1cb89ebe60a1e596e247bc111d702", "extra_info": {"page_label": "240"}, "node_info": {"start": 0, "end": 2099}, "relationships": {"1": "4b9a6bc8-e3bd-4095-84e1-3ab38514a46b"}}, "__type__": "1"}, "c7239741-f23f-44d4-b398-563137108b93": {"__data__": {"text": "Part III: Becoming a Linux System Administrator212Using repo=  options, you can identify software repository locations. The following exam-\nples show the syntax to use for creating repo=  entries:\nrepo=hd:/dev/sda1:/myrepo\nRepository in /myrepo on disk 1 first partition\nrepo=http://abc.example.com/myrepo\nRepository available from /myrepo on web server\nrepo=ftp://ftp.example.com/myrepo\nRepository available from /myrepo on FTP server\nrepo=cdrom\nRepository available from local CD or DVD\nrepo=nfs::mynfs.example.com:/myrepo/\nRepository available from /myrepo on NFS share\nrepo=nfsiso::nfs.example.com:/mydir/rhel7.iso\nInstallation ISO image available from NFS server\nInstead of identifying the repository directly, you can specify it within a kickstart file. The \nfollowing are examples of some ways to identify the location of a kickstart file.\nks=cdrom:/stuff/ks.cfg\nGet kickstart from CD/DVD.\nks=hd:sda2:/test/ks.cfg\nGet kickstart from test directory on hard disk(sda2).\nks=http://www.example.com/ksfiles/ks.cfg\nGet kickstart from a web server.\nks=ftp://ftp.example.com/allks/ks.cfg\nGet kickstart from a FTP server.\nks=nfs:mynfs.example.com:/someks/ks.cfg\nGet kickstart from an NFS server.\nMiscellaneous boot options\nHere are a few other options that you can pass to the installer that don\u2019t fit in a category.\nrescue\nInstead of installing, run the kernel to open Linux rescue mode.\n \nmediacheck\nCheck the installation CD/DVD for checksum errors.TABLE 9.3  Boot Options for VNC Installations\nBoot Option Tells System\nvnc Run installation as a VNC server\nvncconnect= hostname[:port] Connect to VNC client hostname and optional port\nvncpassword= password Client uses password (at least 8 characters) to connect \nto installer", "doc_id": "c7239741-f23f-44d4-b398-563137108b93", "embedding": null, "doc_hash": "a5fc24a5017cdb645287c5570b4d50fff31ce14380c415e14d45f37acaf22cb3", "extra_info": {"page_label": "241"}, "node_info": {"start": 0, "end": 1726}, "relationships": {"1": "357b62b9-58aa-44ce-a8a1-ae8180769fa1"}}, "__type__": "1"}, "7caa0d96-ed0e-4ad6-b8dd-9cb816d96d8e": {"__data__": {"text": "Chapter 9: Installing Linux\n213\n9For further information on using the anaconda installer in rescue mode (to rescue a broken \nLinux system), see Chapter\u00a021, \u201cTroubleshooting Linux.\u201d For information on the latest boot \noptions use in RHEL 8, refer to the RHEL 8 Installation Guide:\nhttps://access.redhat.com/documentation/en-us/red _hat_enterprise _linux/8/\nhtml-single/performing _a_standard _rhel_installation/index#custom-boot-\noptions_booting-the-installer\nUsing specialized storage\nIn large enterprise computing environments, it is common to store the operating system \nand data outside of the local computer. Instead, some special storage device beyond the \nlocal hard disk is identified to the installer, and that storage device (or devices) can be \nused during installation.\nOnce identified, the storage devices that you indicate during installation can be used the \nsame way that local disks are used. You can partition them and assign a structure (filesys -\ntem, swap space, and so on) or leave them alone and simply mount them where you want \nthe data to be available.\nThe following types of specialized storage devices can be selected from the Specialized \nStorage Devices screen when you install Red Hat Enterprise Linux, Fedora, or other Linux \ndistributions:\nFirmware RAID A firmware RAID device is a type of device that has hooks in the \nBIOS, allowing it to be used to boot the operating system, if you choose.\nMultipath devices  As the name implies, multipath devices provide multiple paths \nbetween the computer and its storage devices. These paths are aggregated, so these \ndevices look like a single device to the system using them, while the underlying \ntechnology provides improved performance, redundancy, or both. Connections can \nbe provided by iSCSI or Fibre Channel over Ethernet (FCoE) devices.\nOther SAN devices Any device representing a Storage Area Network (SAN).\nWhile configuring these specialized storage devices is beyond the scope of this book, know \nthat if you are working in an enterprise where iSCSI and FCoE devices are available, you can \nconfigure your Linux system to use them at installation time. You need the following types \nof information to do this:\niSCSI devices  Have your storage administrator provide you with the target IP address \nof the iSCSI device and the type of discovery authentication needed to use the \ndevice. The iSCSI device may require credentials.\nFibre Channel over Ethernet Devices (FCoE) For FCoE, you need to know the net -\nwork interface that is connected to your FCoE switch. You can search that interface \nfor available FCoE devices.", "doc_id": "7caa0d96-ed0e-4ad6-b8dd-9cb816d96d8e", "embedding": null, "doc_hash": "41ca1206e090adde28d150c611f024d53f2bc94180aef6ea9dca52bddaeda473", "extra_info": {"page_label": "242"}, "node_info": {"start": 0, "end": 2608}, "relationships": {"1": "b7914716-de6f-457f-91da-b922a2272305"}}, "__type__": "1"}, "db81b2d5-1eb0-4608-b907-2ec4ca837353": {"__data__": {"text": "Part III: Becoming a Linux System Administrator214Partitioning hard drives\nThe hard disk (or disks) on your computer provide the permanent storage area for your data \nfiles, applications programs, and the operating system itself. Partitioning  is the act of divid -\ning a disk into logical areas that can be worked with separately. In Windows, you typically \nhave one partition that consumes the whole hard disk. However, with Linux there are sev -\neral reasons you may want to have multiple partitions:\nMultiple operating systems  If you install Linux on a PC that already has a Windows \noperating system, you may want to keep both operating systems on the computer. \nFor all practical purposes, each operating system must exist on a completely sepa -\nrate partition. When your computer boots, you can choose which system to run.\nMultiple partitions within an operating system To protect their entire operating system \nfrom running out of disk space, people often assign separate partitions to different areas \nof the Linux filesystem. For example, if /home  and /var  were assigned to separate par -\ntitions, then a gluttonous user who fills up the /home  partition wouldn\u2019t prevent logging \ndaemons from continuing to write to log files in the /var/log  directory.\nMultiple partitions also make doing certain kinds of backups (such as an image \nbackup) easier. For example, an image backup of /home  would be much faster (and \nprobably more useful) than an image backup of the root filesystem ( /).\nDifferent filesystem types  Different kinds of filesystems have different structures. \nFilesystems of different types must be on their own partitions. Also, you might \nneed different filesystems to have different mount options for special features (such \nas read-only or user quotas). In most Linux systems, you need at least one filesys -\ntem type for the root of the filesystem ( /) and one for your swap area. Filesystems \non CD-ROM use the iso9660 filesystem type.\nDuring installation, systems such as Fedora and RHEL let you partition your hard disk \nusing graphical partitioning tools. The following sections describe how to partition your \ndisk during a Fedora installation. See the section \u201cTips for creating partitions\u201d for some \nideas for creating disk partitions.tip\nWhen you create partitions for Linux, you usually assign the filesystem type as Linux native (using the ext2, ext3, \next4, or xfs type on most Linux systems). If the applications that you are running require particularly long filenames, \nlarge file sizes, or many inodes (each file consumes an inode), you may want to choose a different filesystem type.\nComing from Windows\nIf you have only used Windows operating systems before, you probably had your whole hard disk \nassigned to C: and never thought about partitions. With many Linux systems, you have the opportunity \nto view and change the default partitioning based on how you want to use the system.", "doc_id": "db81b2d5-1eb0-4608-b907-2ec4ca837353", "embedding": null, "doc_hash": "aaa5bb795010a2f2ba3b379a1c4aa014e253aeaecb6c77b54f10967d23dd87a7", "extra_info": {"page_label": "243"}, "node_info": {"start": 0, "end": 2935}, "relationships": {"1": "67a5322c-4a2d-48e6-94d8-f2c688624584"}}, "__type__": "1"}, "77c38ce9-cd84-4f0b-ad4c-0d81c62224e8": {"__data__": {"text": "Chapter 9: Installing Linux\n215\n9Understanding different partition types\nMany Linux distributions give you the option of selecting different partition types when \nyou partition your hard disk during installation. Partition types include the following:\nLinux partitions Use this option to create a partition for an ext2, ext3, or ext4 file -\nsystem type that is added directly to a partition on your hard disk (or other storage \nmedium). The xfs filesystem type can also be used on a Linux partition. (In fact, xfs \nis now the default filesystem type for RHEL 8 systems.)\nLVM partitions Create an LVM partition if you plan to create or add to an LVM volume \ngroup. LVMs give you more flexibility in growing, shrinking, and moving partitions \nlater than regular partitions do.\nRAID partitions Create two or more RAID partitions to create a RAID array. These \npartitions should be on separate disks to create an effective RAID array. RAID \narrays can help improve performance, reliability, or both as those features relate to \nreading, writing, and storing your data.\nSwap partitions Create a swap partition to extend the amount of virtual memory \navailable on your system.\nThe following sections describe how to add regular Linux partitions and LVM, RAID, and \nswap partitions using the Fedora graphical installer. If you are still not sure when you \nshould use these different partition types, refer to Chapter\u00a012, \u201cManaging Disks and File -\nsystems,\u201d for further information on configuring disk partitions.\nTips for creating partitions\nChanging your disk partitions to handle multiple operating systems can be very tricky, in \npart because each operating system has its own ideas about how partitioning information \nshould be handled as well as different tools for doing it. Here are some tips to help you \nget it right:\n\u25a0\u25a0If you are creating a dual-boot system, particularly for a Windows system, try to \ninstall the Windows operating system first after partitioning your disk. Otherwise, \nthe Windows installation may make the Linux partitions inaccessible.\n\u25a0\u25a0The fdisk  man page recommends that you use partitioning tools that come with \nan operating system to create partitions for that operating system. For example, \nthe Windows fdisk  knows how to create partitions that Windows will like, and the \nLinux fdisk  will happily make your Linux partitions. After your hard disk is set \nup for dual boot, however, you should probably not go back to Windows-only parti-\ntioning tools. Use Linux fdisk  or a product made for multi-boot systems (such as \nAcronis Disk Director).\n\u25a0\u25a0A master boot record (MBR) partition table can contain four primary partitions, one \nof which can be marked to contain 184 logical drives. On a GPT partition table, you \ncan have a maximum of 128 primary partitions on most operating systems, includ -\ning Linux. You typically won\u2019t need nearly that many partitions. If you need more \npartitions, use LVM and create as many logical volumes as you like.", "doc_id": "77c38ce9-cd84-4f0b-ad4c-0d81c62224e8", "embedding": null, "doc_hash": "8a211bdc95aa27acf22645376097f0284246ed226f2335b7169c36b0bc5b8a75", "extra_info": {"page_label": "244"}, "node_info": {"start": 0, "end": 2981}, "relationships": {"1": "6847ac55-369e-418c-ae7d-dcf75d78c2f7"}}, "__type__": "1"}, "4fb8d204-4613-4669-847b-d907cbc0d958": {"__data__": {"text": "Part III: Becoming a Linux System Administrator216If you are using Linux as a desktop system, you probably don\u2019t need lots of different par -\ntitions. However, some very good reasons exist for having multiple partitions for Linux \nsystems that are shared by lots of users or are public web servers or file servers. Having \nmultiple partitions within Fedora or RHEL, for example, offers the following advantages:\nProtection from attacks Denial-of-service attacks sometimes take actions that try \nto fill up your hard disk. If public areas, such as /var , are on separate partitions, a \nsuccessful attack can fill up a partition without shutting down the whole computer. \nBecause /var  is the default location for web and FTP servers, and is expected to \nhold lots of data, entire hard disks often are assigned to the /var  filesystem alone.\nProtection from corrupted filesystems If you have only one filesystem ( /), its \ncorruption can cause the whole Linux system to be damaged. Corruption of a smaller \npartition can be easier to fix and often allows the computer to stay in service while \nthe correction is made.\nTable\u00a09.4 lists some directories that you may want to consider making into separate filesys -\ntem partitions.\nTABLE 9.4  Assigning Partitions to Particular Directories\nDirectory Explanation\n/boot Sometimes, the BIOS in older PCs can access only the first 1024 cylinders of your \nhard disk. To make sure that the information in your /boot  directory is accessible to \nthe BIOS, create a separate disk partition (by default, RHEL 8 sets this partition to \n1024 MiB) for /boot . Even with several kernels installed, there is rarely a reason for /\nboot  to be larger than 1024 MiB.\n/usr This directory structure contains most of the applications and utilities available \nto Linux users. The original theory was that if /usr  were on a separate partition, \nyou could mount that filesystem as read-only after the operating system had been \ninstalled. This would prevent attackers from replacing or removing important \nsystem applications with their own versions that may cause security problems. A \nseparate /usr  partition is also useful if you have diskless workstations on your local \nnetwork. Using NFS, you can share /usr  over the network with those workstations.\n/var Your FTP ( /var/ftp ) and web server ( /var/www ) directories are, by default in many \nLinux systems, stored under /var . Having a separate /var  partition can prevent an \nattack on those facilities from corrupting or filling up your entire hard disk.\n/home Because your user account directories are located in this directory, having a sepa -\nrate /home  account can prevent a reckless user from filling up the entire hard disk. It \nalso conveniently separates user data from your operating system (for easy backups \nor new installs). Often, /home  is created as an LVM logical volume, so it can grow in \nsize as user demands increase. It may also be assigned user quotas to limit disk use.\n/tmp Protecting /tmp  from the rest of the hard disk by placing it on a separate partition \ncan ensure that applications that need to write to temporary files in /tmp  can com -\nplete their processing, even if the rest of the disk fills up.", "doc_id": "4fb8d204-4613-4669-847b-d907cbc0d958", "embedding": null, "doc_hash": "4df047b60f4a4474af08e6b4e72f79f3d5982d22f8b7d4ce618b598094c58c8e", "extra_info": {"page_label": "245"}, "node_info": {"start": 0, "end": 3216}, "relationships": {"1": "99d9e258-987a-47df-8879-bc4b72625ddf"}}, "__type__": "1"}, "8e005cb3-2ab1-4f10-b2d4-c2832730fb91": {"__data__": {"text": "Chapter 9: Installing Linux\n217\n9Although people who use Linux systems rarely see a need for lots of partitions, those who \nmaintain and occasionally have to recover large systems are thankful when the system \nthey need to fix has several partitions. Multiple partitions can limit the effects of deliber -\nate damage (such as denial-of-service attacks), problems from errant users, and accidental \nfilesystem corruption.\nUsing the GRUB boot loader\nA boot loader lets you choose when and how to boot the operating systems installed \non your computer\u2019s hard disks. The GRand Unified Bootloader (GRUB) is the most popular \nboot loader used for installed Linux systems. There are two major versions of GRUB avail -\nable today:\nGRUB Legacy (version 1). This version of GRUB was used with earlier versions of RHEL, \nFedora, and Ubuntu.\nGRUB 2. The current versions of Red Hat Enterprise Linux, Ubuntu, and Fedora use \nGRUB 2 as the default boot loader.\nIf you want to boot to a particular run level, you can add the run level you want to the \nend of the kernel line. For example, to have RHEL boot to run level 3 (multiuser plus net -\nworking mode), add 3 to the end of the kernel line. You can also boot to single-user mode \n(1), multiuser mode ( 2), or X GUI mode ( 5). Level 3 is a good choice if your GUI is tempo -\nrarily broken. Level 1 is good if you have forgotten your root password.\nBy default, you will see a splash screen as Linux boots. If you want to see messages show -\ning activities happening as the system boots up, you can remove the option rhgb quiet \nfrom the kernel line. This lets you see messages as they scroll by. Pressing Esc during boot-\nup gets the same result.\nGRUB 2 represents a major rewrite of the GRUB Legacy project. It was adopted as the default \nboot loader for the latest Red Hat Enterprise Linux, Fedora, and Ubuntu releases. The major \nfunction of the GRUB 2 boot loader is still to find and start the operating system you want, \nbut now much more power and flexibility is built into the tools and configuration files that \nget you there.\nIn GRUB 2, the configuration file is now named /boot/grub2/grub.cfg  or /etc/grub2-\nefi.cfg  (for systems booted with EFI). Everything from the contents of grub.cfg  to the \nway grub.cfg  is created is different from the GRUB Legacy grub.conf  file.Note\nSYSLINUX is another boot loader that you will encounter with Linux systems. The SYSLINUX boot loaders are not typ -\nically used for installed Linux systems. However, SYSLINUX is commonly used as the boot loader for bootable Linux \nCDs and DVDs. SYSLINUX is particularly good for booting ISO9660 CD images (isolinux) and USB sticks (syslinux) \nand for working on older hardware or for PXE booting (pxelinux) a system over the network.", "doc_id": "8e005cb3-2ab1-4f10-b2d4-c2832730fb91", "embedding": null, "doc_hash": "c2de633713cc1f265870cee82a945cb74cb28cf6e6902dd6bedfc417cab410a2", "extra_info": {"page_label": "246"}, "node_info": {"start": 0, "end": 2761}, "relationships": {"1": "df9a3a12-947a-49e5-913d-7e2d9ea6e28e"}}, "__type__": "1"}, "40b31ffa-a2db-495a-810e-6de7a42d74f4": {"__data__": {"text": "Part III: Becoming a Linux System Administrator218Here are some things you should know about the grub.cfg  file:\n\u25a0\u25a0Instead of editing grub.cfg  by hand or having kernel RPM packages add to it, \ngrub.cfg  is generated automatically from the contents of the /etc/default/\ngrub  file and the /etc/grub.d/  directory. You should modify or add to those \nfiles to configure GRUB 2 yourself.\n\u25a0\u25a0The grub.cfg  file can contain scripting syntax, including such things as \nfunctions, loops, and variables.\n\u25a0\u25a0Device names needed to identify the location of kernels and initial RAM disks can \nbe more reliably identified using labels or universally unique identifiers (UUIDs). \nThis prevents the possibility of a disk device such as /dev/sda  being changed \nto /dev/sdb  when you add a new disk (which would result in the kernel not \nbeing found).\n\u25a0\u25a0For Fedora and RHEL systems, *conf  files in the /boot/loader/entries  direc -\ntory are used to create entries that appear on the GRUB menu that appears at \nboot time.\nYou could create your own entry for the GRUB boot menu by following the format of an \nexisting entry. The following file in the /boot/loader/entries  directory creates a \nmenu entry for booting a RHEL 8 kernel and initrd :\ntitle Red Hat Enterprise Linux (4.18.0-80.el8.x86_64) 8.0 (Ootpa)\nversion 4.18.0-80.el8.x86_64\nlinux /vmlinuz-4.18.0-80.el8.x86_64\ninitrd /initramfs-4.18.0-80.el8.x86_64.img $tuned_initrd\noptions $kernelopts $tuned_params\nid rhel-20190313123447-4.18.0-80.el8.x86_64\ngrub_users $grub_users\ngrub_arg --unrestricted\ngrub_class kernel\nThe menu entry for this selection appears as Red Hat Enterprise Linux (4.18. \n0-80.el8.x86 _64) 8.0 (Ootpa) on the GRUB 2 boot menu.\nThe linux  line identifies the location of the kernel ( /vmlinuz-4.18.0-80.el8.x86 _64), \nfollowed by the location of the initrd  (/initramfs-4.18.0-80.el8.x86 _64.img ).\nThere are many, many more features of GRUB 2 that you can learn about if you want to \ndig deeper into your system\u2019s boot loader. The best documentation for GRUB 2 is available \nby typing info grub2  at the shell. The info  entry for GRUB 2 provides lots of informa -\ntion for booting different operating systems, writing your own configuration files, working \nwith GRUB image files, setting GRUB environment variables, and working with other \nGRUB features.", "doc_id": "40b31ffa-a2db-495a-810e-6de7a42d74f4", "embedding": null, "doc_hash": "126bb845c93d6b82b6d3adfac8f4983e443385afeac97e12e0295e79276e8f72", "extra_info": {"page_label": "247"}, "node_info": {"start": 0, "end": 2320}, "relationships": {"1": "f9a54c65-7296-4e40-9553-8ee8ccf38b49"}}, "__type__": "1"}, "5040c277-1bc3-491b-9439-34de1c277722": {"__data__": {"text": "Chapter 9: Installing Linux\n219\n9Summary\nAlthough every Linux distribution includes a different installation method, you need to \ndo many common activities, regardless of which Linux system you install. For every Linux \nsystem, you need to deal with issues of disk partitioning, boot options, and configuring \nboot loaders.\nIn this chapter, you stepped through installation procedures for a Fedora Workstation \n(using a live media installation) and Red Hat Enterprise Linux (from installation media). \nYou learned how deploying Linux in cloud environments can differ from traditional instal -\nlation methods by combining metadata with prebuilt base operating system image files to \nrun on large pools of compute resources.\nThe chapter also covered special installation topics, including using boot options and disk \npartitioning. With your Linux system now installed, Chapter\u00a010, \u201cGetting and Managing \nSoftware,\u201d describes how to begin managing the software on your Linux system.\nExercises\nUse these exercises to test your knowledge of installing Linux. I recommend that you do \nthese exercises on a computer that has no operating system or data on it that you would \nfear losing (in other words, one you don\u2019t mind erasing). If you have a computer that allows \nyou to install virtual systems, that is a safe way to do these exercises as well. These exer -\ncises were tested using Fedora 30 Workstation Live media and a RHEL 8 Installation DVD.\n1. Start installing from Fedora Live media, using as many of the default options \nas possible.\n2. After you have completely installed Fedora, update all of the packages on \nthe system.\n3. Start installing from an RHEL installation DVD but make it so that the installation \nruns in text mode. Complete the installation in any way you choose.\n4. Start installing from an RHEL installation DVD and set the disk partitioning as \nfollows: a 1024MB /boot , / (6G), /var  (2G), and /home  (2G). Leave the rest as \nunused space.\nCautio N\nCompleting Exercise 4 ultimately deletes all content on your hard disk. If you just want to use this exercise to prac -\ntice partitioning, you can reboot your computer before clicking Accept Changes at the very end of this procedure \nwithout harming your hard disk. If you go forward and partition your disk, assume that all data that you have not \nexplicitly changed has been deleted.", "doc_id": "5040c277-1bc3-491b-9439-34de1c277722", "embedding": null, "doc_hash": "384f8f332ad81d344af3c28b257dbdbbea4cfa84c466e530b9f962b1ba315165", "extra_info": {"page_label": "248"}, "node_info": {"start": 0, "end": 2361}, "relationships": {"1": "9694409e-6b4e-40bc-a611-3599ede690f8"}}, "__type__": "1"}, "44173407-ed7a-4c00-b19d-435a1da17ce6": {"__data__": {"text": "221\nCHAPTER10\nGetting and Managing Software\nIN THIS CHAPTER\nInstalling software from the desktop\nWorking with RPM packaging\nUsing YUM to manage packages\nUsing rpm to work with packages\nInstalling software in the enterprise\nIn Linux distributions such as Fedora and Ubuntu, you don\u2019t need to know much about how soft -\nware is packaged and managed to get the software you want. Those distributions have excellent \nsoftware installation tools that automatically point to huge software repositories. Just a few \nclicks and you\u2019re using the software in little more time than it takes to download it.\nThe fact that Linux software management is so easy these days is a credit to the Linux community, \nwhich has worked diligently to create packaging formats, complex installation tools, and high-quality \nsoftware packages. Not only is it easy to get the software, but after it\u2019s installed, it\u2019s easy to manage, \nquery, update, and remove it.\nThis chapter begins by describing how to install software in Fedora using the new Software graphical \ninstallation tool. If you are just installing a few desktop applications on your own desktop system, \nyou may not need much more than that and occasional security updates.\nTo dig deeper into managing Linux software, next I describe what makes up Linux software pack -\nages (comparing deb  and rpm  formatted packaging), underlying software management components, \nand commands ( dnf, yum , and rpm ) for managing software in Fedora and Red Hat Enterprise Linux. \nThat\u2019s followed by a description of how to manage software packages in enterprise computing.\nManaging Software on the Desktop\nThe Fedora Software window offers an intuitive way of choosing and installing desktop applica -\ntions that does not align with typical Linux installation practices. The Ubuntu Software window \noffers the same interface for Ubuntu users. In either case, with the Software window, the smallest \nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "44173407-ed7a-4c00-b19d-435a1da17ce6", "embedding": null, "doc_hash": "af22c98f944675e32b3eb61d652264ddf3a8a8360684508150f4b0c91156e498", "extra_info": {"page_label": "249"}, "node_info": {"start": 0, "end": 2042}, "relationships": {"1": "18ed28b5-ce82-42ac-bce2-dc65a344e4f8"}}, "__type__": "1"}, "4872ce10-7924-4819-b8a4-51d0f4d227ef": {"__data__": {"text": "Part III: Becoming a Linux System Administrator222software component you install is an application. With Linux, you install packages (such as \nrpms and deb s).\nFigure\u00a010.1 shows an example of the Software window.\nTo get to the Software window in either Fedora or Ubuntu, select Activities, then type \nSoftware , and press Enter. The first time you open this window, you can select Enable \nto allow third-party software repositories that are not part of the official redistribut -\nable Fedora repositories. Using the Software window is the best way to install desktop-\noriented applications, such as word processors, games, graphics editors, and educational \napplications.\nFrom the Software window, you can select the applications that you want to install from \nthe Editor\u2019s Picks group (a handful of popular applications), choose from categories of appli-\ncations (Audio & Video, Games, Graphics & Photography, and so on), or search by application \nFIGURE 10.1\nInstall and manage software packages from the Software window.", "doc_id": "4872ce10-7924-4819-b8a4-51d0f4d227ef", "embedding": null, "doc_hash": "dbd74971bff7f946ddaecb81131a0f37de0cfd37fc90c2d1d5fcf9521514a242", "extra_info": {"page_label": "250"}, "node_info": {"start": 0, "end": 1023}, "relationships": {"1": "4b12f117-fa81-49ef-b348-e1da3aeb315b"}}, "__type__": "1"}, "cb44dd25-dbf3-4e59-aff1-e99f493df7d8": {"__data__": {"text": "Chapter 10: Getting and Managing Software\n223\n10name or description. Select the Install button to have the Software window download and \ninstall all of the software packages needed to make the application work.\nOther features of this window let you see all installed applications (Installed tab) or view \na list of applications that have updated packages available for you to install (Updates tab). \nIf you want to remove an installed application, simply click the Remove button next to the \npackage name.\nIf you are using Linux purely as a desktop system, where you want to write documents, \nplay music, and do other common desktop tasks, the Software window might be all you \nneed to get the basic software you want. By default, your system connects to the main \nFedora software repository and gives you access to hundreds of software applications. As \nnoted earlier, you also have the option of accessing third-party applications that are still \nfree for you to use but not redistribute.\nAlthough the Software window lets you download and install hundreds of applications from \nthe Fedora software repository, that repository actually contains tens of thousands of soft -\nware packages. What packages can you not see from that repository, when might you want \nthose other packages, and how can you gain access to those packages (as well as packages \nfrom other software repositories)?\nGoing Beyond the Software Window\nIf you are managing a single desktop system, you might be quite satisfied with the hun -\ndreds of packages that you can find through the Software window. Open-source versions \nof most common types of desktop applications are available to you through the Software \nwindow after you have a connection from Fedora to the Internet.\nHowever, the following are some examples of why you might want to go beyond what you \ncan do with the Software window:\nMore repositories Fedora and Red Hat Enterprise Linux distribute only open-source, \nfreely distributable software. You may want to install some commercial software \n(such as Adobe Flash Player) or non-free software (available from repositories such \nas rpmfusion.org ).\nBeyond desktop applications Tens of thousands of software packages in the Fedora \nrepository are not available through the Software window. Most of these packages \nare not associated with graphical applications at all. For example, some packages \ncontain pure command-line tools, system services, programming tools, or documen -\ntation that doesn\u2019t show up in the Software window.\nFlexibility  Although you may not know it, when you install an application through \nthe Software window, you may actually be installing multiple RPM packages. This \nset of packages may just be a default package set that includes documentation, \nextra fonts, additional software plug-ins, or multiple language packs that you ", "doc_id": "cb44dd25-dbf3-4e59-aff1-e99f493df7d8", "embedding": null, "doc_hash": "4aa5250c0b8cd1e4398f1c3c8fdba3562a9aa71989fc2a6bf47f029987c7223d", "extra_info": {"page_label": "251"}, "node_info": {"start": 0, "end": 2843}, "relationships": {"1": "35e574da-f24f-478b-8567-ad8e4baa085c"}}, "__type__": "1"}, "9b8f31ab-4d81-4c9a-8390-3470ad7c35bc": {"__data__": {"text": "Part III: Becoming a Linux System Administrator224may or may not want. With yum  and rpm  commands, you have more flexibility \non exactly which packages related to an application or other software feature is \ninstalled on your system.\nMore complex queries Using commands such as yum  and rpm , you can get detailed \ninformation about packages, package groups, and repositories.\nSoftware validation Using rpm and other tools, you can check whether a signed \npackage has been modified before you installed it or whether any of the components \nof a package have been tampered with since the package was installed.\nManaging software installation Although the Software window works well if you are \ninstalling desktop software on a single system, it doesn\u2019t scale well for managing \nsoftware on multiple systems. Other tools are built on top of the rpm  facility for \ndoing that.\nBefore I launch into some of the command-line tools for installing and managing software \nin Linux, the next section describes how the underlying packaging and package man -\nagement systems in Linux work. In particular, I focus on RPM packaging as it is used in \nFedora, Red Hat Enterprise Linux, and related distributions as well as Deb packages, which \nare associated with Debian, Ubuntu, Linux Mint, and related distributions.\nUnderstanding Linux RPM and DEB \nSoftware Packaging\nOn the first Linux systems, if you wanted to add software, you would grab the source code \nfrom a project that produced it, compile it into runnable binaries, and drop it onto your \ncomputer. If you were lucky, someone would have already compiled it in a form that would \nrun on your computer.\nThe form of the package could be a tarball containing executable files (commands), doc -\numentation, configuration files, and libraries. (A tarball  is a single file in which multiple \nfiles are gathered together for convenient storage or distribution.) When you install soft -\nware from a tarball, the files from that tarball might be spread across your Linux system \nin appropriate directories ( /usr/share/man , /etc , /bin , and /lib , to name just a few). \nAlthough it is easy to create a tarball and just drop a set of software onto your Linux \nsystem, this method of installing software makes it difficult to do these things:\nGet dependent software  You would need to know if the software you were installing \ndepended on other software being installed for your software to work. Then you \nwould have to track down that software and install that too (which might itself \nhave some dependencies).\nList the software Even if you knew the name of the command, you might not know \nwhere its documentation or configuration files were located when you looked \nfor it later.", "doc_id": "9b8f31ab-4d81-4c9a-8390-3470ad7c35bc", "embedding": null, "doc_hash": "c4bda79ce9cea7e2051074a7c2d53d81285a062ecf8a92cca59f62d9f7619ec0", "extra_info": {"page_label": "252"}, "node_info": {"start": 0, "end": 2724}, "relationships": {"1": "3c81cc73-5a50-4e95-80ba-dccd463f7aeb"}}, "__type__": "1"}, "6e82a88b-42da-4ac7-ac69-3b88b9b03639": {"__data__": {"text": "Chapter 10: Getting and Managing Software\n225\n10Remove the software Unless you kept the original tarball, or a list of files, you \nwouldn\u2019t know where all of the files were when it came time to remove them. Even if \nyou knew, you would have to remove each one individually.\nUpdate the software Tarballs are not designed to hold metadata about the contents \nthat they contain. After the contents of a tarball are installed, you may not have a \nway to tell what version of the software you are using, making it difficult to track \ndown bugs and get new versions of your software.\nTo deal with these problems, packages progressed from simple tarballs to more complex \npackaging. With only a few notable exceptions (such as Gentoo, Slackware, and a few \nothers), the majority of Linux distributions went to one of two packaging formats\u2014\nDEB and RPM:\nDEB (.deb) packaging The Debian GNU/Linux project created .deb  packaging, \nwhich is used by Debian and other distributions based on Debian (Ubuntu, Linux \nMint, KNOPPIX, and so on). Using tools such as apt-get , apt , and dpkg , Linux \ndistributions could install, manage, upgrade, and remove software.\nRPM (.rpm) packaging Originally named Red Hat Package Manager, but later recur -\nsively renamed RPM Package Manager, RPM is the preferred package format for SUSE, \nRed Hat distributions (RHEL and Fedora), and those based on Red Hat distributions \n(CentOS, Oracle Linux, and so on). The rpm  command was the first tool to manage \nRPMs. Later, yum  was added to enhance the RPM facility, and now dnf  is poised to \neventually replace yum .\nFor managing software on individual systems, there are proponents on both sides of the \nRPM vs. DEB debate with valid points. Although RPM is the preferred format for managing \nenterprise-quality software installation, updates, and maintenance, DEB is very popular \namong many Linux enthusiasts. This chapter covers both RPM (Fedora and Red Hat Enter -\nprise Linux) and (to some extent) DEB packaging and software management.\nUnderstanding DEB packaging\nDebian software packages hold multiple files and metadata related to some set of software \nin the format of an ar  archive file. The files can be executables (commands), configura -\ntion files, documentation, and other software items. The metadata includes such things as \ndependencies, licensing, package sizes, descriptions, and other information. Multiple com-\nmand-line and graphical tools are available for working with DEB files in Ubuntu, Debian, \nand other Linux distributions. Some of these include the following:\nUbuntu Software Center  Select the Ubuntu Software application from the GNOME \nActivities menu. The window that appears lets you search for applications and pack -\nages that you want by searching for keywords or navigating categories.", "doc_id": "6e82a88b-42da-4ac7-ac69-3b88b9b03639", "embedding": null, "doc_hash": "ea10a8420ccaa7109adcd2c37962df10e87b44f5261cae098f3a5219d9e989c0", "extra_info": {"page_label": "253"}, "node_info": {"start": 0, "end": 2799}, "relationships": {"1": "a0bef339-e289-46cd-8f4e-ca96e1de02f7"}}, "__type__": "1"}, "ce91d630-2192-47ea-93bc-ef8762671e24": {"__data__": {"text": "Part III: Becoming a Linux System Administrator226aptitude  The aptitude  command is a package installation tool that provides a \nscreen-oriented menu that runs in the shell. After you run the command, use arrow \nkeys to highlight the selection you want, and press Enter to select it. You can \nupgrade packages, get new packages, or view installed packages.\napt* There is a set of apt*  commands ( apt-get , apt , apt-config , apt-cache , \nand so on) that can be used to manage package installation.\nThe Ubuntu Software Center is fairly intuitive for finding and installing packages. How -\never, here are a few examples of commands that can help you install and manage packages \nwith apt * commands. In this case, I\u2019m looking for and installing the vsftpd  package:\nNote\nNotice that the apt * commands are preceded by the sudo  command in these examples. That\u2019s because it is \ncommon practice for an Ubuntu administrator to run administrative commands as a regular user with sudo  privilege.\n    $ sudo apt-get update           Get the latest package versions\n    $ sudo apt-cache search vsftpd  Find package by key word (such as vsftpd)\n    $ sudo apt-cache show vsftpd    Display information about a package\n    $ sudo apt-get install vsftpd   Install the vsftpd package\n    $ sudo apt-get upgrade          Update installed packages if upgrade ready\n    $ sudo apt-cache pkgnames       List all packages that are installed\nThere are many other uses of apt * commands that you can try out. If you have an Ubuntu \nsystem installed, I recommend that you run man apt  to get an understanding of what the \napt and related commands can do.\nUnderstanding RPM packaging\nAn RPM package is a consolidation of files needed to provide a feature, such as a word pro -\ncessor, a photo viewer, or a file server. The commands, configuration files, and documen -\ntation that make up the software feature can be inside an RPM. However, an RPM file also \ncontains metadata that stores information about the contents of that package, where the \npackage came from, what it needs to run, and other information.\nWhat is in an RPM?\nBefore you even look inside an RPM, you can tell much about it by the name of the RPM \npackage itself. To find out the name of an RPM package currently installed on your system \n(in this example the Firefox web browser), you could type the following from the shell in \nFedora or Red Hat Enterprise Linux:\n# rpm -q firefox\nfirefox-67.0-4.fc30.x86_64\nFrom this, you can tell that the base name of the package is firefox . The version number \nis 67.0 (assigned by the upstream producer of Firefox, the Mozilla Project). The release ", "doc_id": "ce91d630-2192-47ea-93bc-ef8762671e24", "embedding": null, "doc_hash": "9c245316ad4fa197569263b0a5a43eaa39f490725e00d2d4ad08d8a61dd5f34d", "extra_info": {"page_label": "254"}, "node_info": {"start": 0, "end": 2639}, "relationships": {"1": "bbaa441a-698b-4ac8-890d-e0466e60a464"}}, "__type__": "1"}, "24b67a22-fa47-467b-968f-eff0e9326b69": {"__data__": {"text": "Chapter 10: Getting and Managing Software\n227\n10(assigned by the packager, Fedora, each time the package is rebuilt at the same release \nnumber) is 4. The firefox  package was built for Fedora 30 (fc30) and is compiled for the \nx86 64-bit architecture (x86_64).\nWhen the firefox  package was installed, it was probably copied from the installation \nmedium (such as a CD or DVD) or downloaded from a YUM repository (more on that later). \nIf you had been given the RPM file and it was sitting in a local directory, the name would \nappear as firefox-67.0-4.fc30.x86_64.rpm  and you could install it from there. Regard -\nless of where it came from, once the package is installed, the name and other information \nabout it are stored in an RPM database on the local machine.\nTo find out more about what is inside an RPM package, you can use options other than the \nrpm command to query that local RPM database, as in this example:\n# rpm -qi firefox\nName        : firefox\nVersion     : 67.0\nRelease     : 4.fc30\nArchitecture: x86_64\nInstall Date: Sun 02 Jun 2019 09:37:25 PM EDT\nGroup       : Unspecified\nSize        : 266449296\nLicense     : MPLv1.1 or GPLv2+ or LGPLv2+\nSignature   : RSA/SHA256, Fri 24 May 2019 12:09:57 PM EDT, Key ID \nef3c111fcfc659b9\nSource RPM  : firefox-67.0-4.fc30.src.rpm\nBuild Date  : Thu 23 May 2019 10:03:55 AM EDT\nBuild Host  : buildhw-08.phx2.fedoraproject.org\nRelocations : (not relocatable)\nPackager    : Fedora Project\nVendor      : Fedora Project\nURL         : https://www.mozilla.org/firefox/\nBug URL     : https://bugz.fedoraproject.org/firefox\nSummary     : Mozilla Firefox Web browser\nDescription :\nMozilla Firefox is an open-source web browser, designed for standards\ncompliance, performance and portability.\nBesides the information you got from the package name itself, the -qi  (query informa -\ntion) option lets you see who built the package (Fedora Project), when it was built, and \nwhen it was installed. The group the package is in (Unspecified), its size, and the licensing \nare listed. To enable you to find out more about the package, the URL points to the project \npage on the Internet and the Summary and Description lines tell you what the package \nis used for.\nWhere do RPMs come from?\nThe software included with Linux distributions, or built to work with those distributions, \ncomes from thousands of open-source projects all over the world. These projects, referred to ", "doc_id": "24b67a22-fa47-467b-968f-eff0e9326b69", "embedding": null, "doc_hash": "6f5bcb23e19d4c892762d37012751b0155e96fd2bfa9d4de5b71c0ba85fb738c", "extra_info": {"page_label": "255"}, "node_info": {"start": 0, "end": 2417}, "relationships": {"1": "cd4a6ca4-1709-4825-a6fa-c758c556d77b"}}, "__type__": "1"}, "e74a262e-b527-475a-b425-7f2bf053045a": {"__data__": {"text": "Part III: Becoming a Linux System Administrator228as upstream software providers , usually make the software available to anyone who wants it, \nunder certain licensing conditions.\nA Linux distribution takes the source code and builds it into binaries. Then it gathers those \nbinaries together with documentation, configuration files, scripts, and other components \navailable from the upstream provider.\nAfter all of those components are gathered into the RPM, the RPM package is signed (so \nthat users can test the package for validity) and placed in a repository of RPMs for the \nspecific distribution and architecture (32-bit x86, 64-bit x86, and so on). The repository is \nplaced on an installation CD or DVD or in a directory that is made available as an FTP, web, \nor NFS server.\nInstalling RPMs\nWhen you initially install a Fedora or Red Hat Enterprise Linux system, many individual \nRPM packages make up that installation. After Linux is installed, you can add more pack -\nages using the Software window (as described earlier). Refer to Chapter\u00a09, \u201cInstalling \nLinux,\u201d for information on installing Linux.\nThe first tool to be developed for installing RPM packages, however, was the rpm  command. \nUsing rpm , you can install, update, query, validate, and remove RPM packages. The \ncommand, however, has some major drawbacks:\nDependencies  For most RPM packages to work, some other software (library, execut -\nables, and so on) must be installed on the system. When you try to install a package \nwith rpm , if a dependent package is not installed, the package installation fails, \ntelling you which components were needed. At that point, you have to dig around to \nfind what package contained that component. When you go to install it, that depen -\ndent package might itself have dependencies that you need to install to get it to \nwork. This situation is lovingly referred to as \u201cdependency hell\u201d and is often used as \nan example of why DEB packages were better than RPMs. DEB packaging tools were \nmade to resolve package dependencies automatically, well before RPM-related pack -\naging tools could do that.\nLocation of RPMs The rpm command expects you to provide the exact location of \nthe RPM file when you try to install it. In other words, you would have to give \nfirefox-67.0-4.fc30.x86_64.rpm  as an option if the RPM were in the current \ndirectory or http://example.com/firefox-67.0-4.fc30.x86_64.rpm  if it were \non a server.\nAs Red Hat Linux and other RPM-based applications grew in popularity, it became apparent \nthat something had to be done to make package installation more convenient. The answer \nwas the YUM facility.", "doc_id": "e74a262e-b527-475a-b425-7f2bf053045a", "embedding": null, "doc_hash": "b4a79ec28ee08fdad7c40d8fb6b2c67fe65892703eb91e517ce289b567d25087", "extra_info": {"page_label": "256"}, "node_info": {"start": 0, "end": 2642}, "relationships": {"1": "54b1bafa-53b1-426f-b6b1-78a162e7d845"}}, "__type__": "1"}, "6bfedf5e-d97b-4485-9997-9003f9fd3fc9": {"__data__": {"text": "Chapter 10: Getting and Managing Software\n229\n10Managing RPM Packages with YUM\nThe YellowDog Updater Modified (YUM) project set out to solve the headache of managing \ndependencies with RPM packages. Its major contribution was to stop thinking about \nRPM packages as individual components and think of them as parts of larger software \nrepositories.\nWith repositories, the problem of dealing with dependencies fell not to the person who \ninstalled the software but to the Linux distribution or third-party software distributor that \nmakes the software available. So, for example, it would be up to the Fedora Project to make \nsure that every component needed by every package in its Linux distribution could be \nresolved by some other package in the repository.\nRepositories could also build on each other. So, for example, the rpmfusion.org  reposi -\ntory could assume that a user already had access to the main Fedora repository. If a \npackage being installed from rpmfusion.org  needed a library or command from the main \nFedora repository, the Fedora package could be downloaded and installed at the same time \nthat you install the rpmfusion.org  package.\nThe yum repositories could be put in a directory on a web server ( http:// ), on an FTP \nserver (ftp:// ), on local media such as a CD or DVD, or in a local directory ( file:// ). The \nlocations of these repositories would then be stored on the user\u2019s system in the /etc/yum.\nconf  file or, more typically, in separate configuration files in the /etc/yum.repos.d  \ndirectory.\nTransitioning from yum to dnf\nThe dnf command-line interface represents the next generation of YUM. DNF, which refers \nto itself as Dandified YUM , (https://github.com/rpm-software-management/dnf/ ) \nhas been part of Fedora since version 18 and has just been added as the default RPM package \nmanager for RHEL 8. Like yum, dnf  is a tool for finding, installing, querying, and generally \nmanaging RPM packages from remote software repositories to your local Linux system.\nWhile dnf  maintains a basic command-line compatibility with yum , one of its main differ -\nences is that it adheres to a strict API. That API encourages the development of extensions \nand plug-ins to dnf .\nFor our purposes, almost all of the yum  commands described in this chapter can be replaced \nby dnf  or used as they are. The yum  command is a symbolic link to dnf  in Fedora and \nRHEL, so typing either command has the same result. For more information on DNF, refer to \nthe DNF page at https://dnf.readthedocs.io/ .\nUnderstanding how yum works\nThis is the basic syntax of the yum  command:\n# yum [options] command", "doc_id": "6bfedf5e-d97b-4485-9997-9003f9fd3fc9", "embedding": null, "doc_hash": "cd9d6a7f45cdc7de1a9bf037ace85eaed023b7679fbe75655d5059ef5c53f890", "extra_info": {"page_label": "257"}, "node_info": {"start": 0, "end": 2629}, "relationships": {"1": "b6fb25da-bf2d-4351-adcd-caff0a90155d"}}, "__type__": "1"}, "b542b99b-cbad-4c8e-8dd2-bbe6aa250dff": {"__data__": {"text": "Part III: Becoming a Linux System Administrator230Using that syntax, you can find packages, see package information, find out about package \ngroups, update packages, or delete packages, to name a few features. With the YUM reposi-\ntory and configuration in place, a user can install a package by simply typing something \nlike the following:\n# yum install firefox\nThe user only needs to know the package name (which could be queried in different ways, \nas described in the section \u201cSearching for packages\u201d later in this chapter). The YUM facility \nfinds the latest version of that package available from the repository, downloads it to the \nlocal system, and installs it.\nTo gain more experience with the YUM facility, and to see where there are opportunities for \nyou to customize how YUM works on your system, follow the descriptions of each phase of \nthe YUM install process described next.\nNote\nIn the latest Fedora and RHEL systems, the YUM configuration files are now actually links to DNF files in the /etc/\ndnf directory. Besides the main dnf  configuration file ( /etc/dnf/dnf.conf ), that directory primarily contains \nmodules and plug-ins that add to your ability to manage RPM packages.\n1. Checking  /etc/yum.conf :\nWhen any yum  command starts, it checks the file /etc/yum.conf  for default set -\ntings. The /etc/yum.conf  file is the basic YUM configuration file. You can also \nidentify the location of repositories here, although the /etc/yum.repos.d  direc -\ntory is the more typical location for identifying repositories. Here\u2019s an example of  \n/etc/yum.conf  on a RHEL 8 system, with a few others added:\n        [main]\n        gpgcheck=1\n        installonly_limit=3\n        clean_requirements_on_remove=True\n        best=True\n \n        cachedir=/var/cache/yum/$basearch/$releasever\n        keepcache=0\n        debuglevel=2\n        logfile=/var/log/yum.log\n        exactarch=1\n        plugins=1\nThe gpgcheck  is used to validate each package against a key that you receive \nfrom those who built the RPM. It is on by default ( gpgcheck=1 ). For packages \nin Fedora or RHEL, the key comes with the distribution to check all packages. To \ninstall packages that are not from your distribution, you need either to import the \nkey to verify those packages or to turn off that feature ( gpgcheck=0 ).", "doc_id": "b542b99b-cbad-4c8e-8dd2-bbe6aa250dff", "embedding": null, "doc_hash": "4768339c223d02e9fe77fd3f0253749683e1ec10e5190d91eea05e5cd8f4daff", "extra_info": {"page_label": "258"}, "node_info": {"start": 0, "end": 2309}, "relationships": {"1": "d3ca3c46-a434-4cb2-8e68-8cb883e61b84"}}, "__type__": "1"}, "fe891f37-2aa4-447d-bc1e-fa400f57d707": {"__data__": {"text": "Chapter 10: Getting and Managing Software\n231\n10The install_onlylimit=3  setting allows up to three versions of the same \npackage to be kept on the system (don\u2019t set this to less than 2 , to ensure that \nyou always have at least two kernel packages). The clean_requirements_on_\nremove=True  tells yum  to remove dependent packages when removing a package, \nif those packages are not otherwise required. With best=True , when upgrading a \npackage, always try to use the highest version available.\nOther settings that you can add to yum.conf  tell YUM where to keep cache files  \n(/var/cache/yum ) and log entries ( /var/log/yum.log ) and whether to keep \ncache files around after a package is installed ( 0 means no). You can raise the \ndebuglevel  value in the yum.conf  file to above 2  if you want to see more details \nin your log files.\nNext, you can see whether the exact architecture (x86, x86_64, and so on) should \nbe matched when choosing packages to install ( 1 means yes) and whether to \nuse plug-ins ( 1 means yes) to allow for things such as blacklists, white lists, or \nconnecting to Red Hat Network for packages.\nTo find other features that you can set in the yum.conf  file, type \nman yum.conf .\n2. Checking /etc/yum.repos.d/*.repo  files:\nSoftware repositories can be enabled by dropping files ending in .repo  into the  \n/etc/yum.repos.d/  directory that point to the location of one or more reposi-\ntories. In Fedora, even your basic Fedora repositories are enabled from .repo  files \nin this directory. Here\u2019s an example of a simple yum configuration file named  \n/etc/yum.repos.d/myrepo.repo :\n        [myrepo]\n        name=My repository of software packages\n        baseurl=http://myrepo.example.com/pub/myrepo\n        enabled=1\n        gpgcheck=1\n        gpgkey=file:///etc/pki/rpm-gpg/MYOWNKEY\nEach repository entry begins with the name of the repository enclosed in square \nbrackets. The name  line contains a human-readable description of the repository. \nThe baseurl  line identifies the directory containing the RPM files, which can be \nan httpd:// , ftp:// , or file://  entry.\nThe enabled  line indicates whether the entry is active. A 1 is active; 0 is inactive. \nIf there is no enabled  line, the entry is active. The last two lines in the preceding \ncode indicate whether to check the signatures on packages in this repository. The \ngpgkey  line shows the location of the key that is used to check the packages in \nthis repository.\nYou can have as many repositories enabled as you like. However, keep in mind that \nwhen you use yum  commands, every repository is checked and metadata about all \npackages is downloaded to the local system running the yum  command. So, to be \nmore efficient, don\u2019t enable repositories that you don\u2019t need.", "doc_id": "fe891f37-2aa4-447d-bc1e-fa400f57d707", "embedding": null, "doc_hash": "472f90119c40450dcb7d9da5d8f89203410ecd0d4f9989df9f1a39fa50084f04", "extra_info": {"page_label": "259"}, "node_info": {"start": 0, "end": 2769}, "relationships": {"1": "b5895300-5cd5-4c75-bf90-e2eae32f84de"}}, "__type__": "1"}, "9447130e-1fd4-4f47-a259-68c364460863": {"__data__": {"text": "Part III: Becoming a Linux System Administrator2323. Downloading RPM packages and metadata from a YUM repository :\nAfter yum  knows the locations of the repositories, metadata from the repodata  \ndirectory of each repository is downloaded to the local system. In fact, it is the \nexistence of a repodata  directory in a directory of RPMs that indicates that it is a \nYUM repository.\nMetadata information is stored on the local system in the /var/cache/yum  direc -\ntory. Any further queries about packages, package groups, or other information \nfrom the repository are gathered from the cached metadata until a time-out period \nis reached.\nAfter the time-out period is reached, yum  retrieves fresh metadata if the yum \ncommand is run. By default, the time-out is 6 hours for yum  and 48 hours for dnf  \nminutes. You can change that period by setting metadata_expire  in the  \n/etc/yum.conf  file.\nNext, yum  looks at the packages that you requested to install and checks if any \ndependent packages are needed by those packages. With the package list gathered, \nyum asks you if it is okay to download all of those packages. If you choose yes, the \npackages are downloaded to the cache directories and installed.\n4. Installing RPM packages to Linux file system:\nAfter all of the necessary packages are downloaded to the cache directories, yum \nruns rpm  commands to install each package. If a package contains preinstall \nscripts (which might create a special user account or make directories), those \nscripts are run. The contents of the packages (commands, config files, docs, and so \non) are copied to the filesystem at locations specified in the RPM metadata. Then \nany post install scripts are run. (Post install scripts run additional commands \nneeded to configure the system after each package is installed.)\n5. Storing YUM repository metadata to local RPM database .\nThe metadata contained in each RPM package that is installed is ultimately copied \ninto the local RPM database. The RPM database is contained in files that are stored \nin the /var/lib/rpm  directory. After information about installed packages is in \nthe local RPM database, you can do all sorts of queries of that database. You can see \nwhat packages are installed, list components of those packages, and see scripts or \nchange logs associated with each package. You can even validate installed packages \nagainst the RPM database to see if anyone has tampered with installed components.\nThe rpm  command (described in the section \u201cInstalling, Querying, and Verifying \nSoftware with the rpm  Command\u201d later in this chapter) is the best tool for que -\nrying the RPM database. You can run individual queries with rpm  or use it in \nscripts to produce reports or run common queries over and over again.\nNow that you understand the basic functioning of the yum  command, your Fedora system \nshould be automatically configured to connect to the main Fedora repository and the Fedora \nUpdates repository. You can try some yum  command lines to install packages right now. Or, \nyou can enable other third-party YUM repositories to draw software from.", "doc_id": "9447130e-1fd4-4f47-a259-68c364460863", "embedding": null, "doc_hash": "b8bca58aa4d280ac645d1643bb70f808ee4fbdbef9d3140b6bb998ee516739d8", "extra_info": {"page_label": "260"}, "node_info": {"start": 0, "end": 3116}, "relationships": {"1": "11702f2e-5e8b-485b-be42-53db1036b7b1"}}, "__type__": "1"}, "f7f940be-22d9-4af0-bcd7-a39c94009003": {"__data__": {"text": "Chapter 10: Getting and Managing Software\n233\n10Using YUM with third-party software repositories\nThe Fedora and Red Hat Enterprise Linux software repositories have been screened to \ncontain only software that meets criteria that make it open and redistributable. In some \ninstances, however, you may want to go beyond those repositories. Before you do, you \nshould understand that some third-party repositories have these limitations:\n\u25a0\u25a0They may have less stringent requirements for redistribution and freedom from \npatent constraints than the Fedora and RHEL repositories have.\n\u25a0\u25a0They may introduce some software conflicts.\n\u25a0\u25a0They may include software that is not open source and, although it may be free for \npersonal use, may not be redistributable.\n\u25a0\u25a0They may slow down the process of installing all of your packages (because meta -\ndata is downloaded for every repository you have enabled).\nFor those reasons, I recommend that you either (1) don\u2019t enable any extra software repos -\nitories, or (2) enable only the RPM Fusion repository ( http://rpmfusion.org ) at first \nfor Fedora and the EPEL repository ( http://fedoraproject.org/wiki/EPEL ) for Red \nHat Enterprise Linux. RPM Fusion represents a fusion of several popular third-party Fedora \nrepositories (Freshrpms, Livna.org , and Dribble). See the repository\u2019s FAQ for details \n(http://rpmfusion.org/FAQ ). To enable the Free RPM Fusion repository in Fedora, do \nthe following:\n1. Open a Terminal window.\n2. Type su  and enter the root password when prompted.\n3. Type the following command on one line with no space in between the slash and \nrpmfusion  (if that doesn\u2019t work, go to the fedora  directory and choose the RPM \nappropriate for your version of Fedora):\n# rpm -Uvh http://download1.rpmfusion.org/free/fedora/\nrpmfusion-free-release-stable.noarch.rpm\nThe RPM Fusion Nonfree repository contains such things as codecs needed to play many \npopular multimedia formats. To enable the Nonfree repository in Fedora, type the following \n(again, type the following two lines on a single line, with no space between the two):\n# rpm -Uhv http://download1.rpmfusion.org/nonfree/fedora/\nrpmfusion-nonfree-release-stable.noarch.rpm\nMost of the other third-party repositories that might interest you contain software that \nis not open source. For example, if you want to install the Adobe Flash plug-in for Linux, \ndownload the YUM repository package from Adobe, and you can use the yum  command \nto install the Flash plug-in and get updates later by running the yum update  command \nwhen updates are available.\nManaging software with the yum command\nThe yum  command has dozens of subcommands that you can use to work with RPM pack -\nages on your system. The following sections provide some examples of useful yum  command ", "doc_id": "f7f940be-22d9-4af0-bcd7-a39c94009003", "embedding": null, "doc_hash": "899ac96db472700130bd27d07ab66c12ac7f178d3c00acfaca9750808db836ce", "extra_info": {"page_label": "261"}, "node_info": {"start": 0, "end": 2781}, "relationships": {"1": "499aba90-d4b4-47f0-897c-aa1f71a9978f"}}, "__type__": "1"}, "3805fbaf-9e0a-44c6-b113-84690771616c": {"__data__": {"text": "Part III: Becoming a Linux System Administrator234lines to search for, install, query, and update packages associated with your YUM reposi-\ntories. The section \u201cInstalling and removing packages\u201d describes how to install and remove \ninstalled packages with the yum  command.\nNote\nMetadata, describing the contents of YUM repositories, is downloaded from each of your enabled YUM repositories \nthe first time you run a yum  command. Metadata is downloaded again after the metadata_expire  time is \nreached. The more YUM repositories that you enable and the larger they are, the longer this download can take. You \ncan reduce this download time by increasing the expire time (in the /etc/yum.conf  file) or by not enabling repos -\nitories you don\u2019t need.\nSearching for packages\nUsing different searching subcommands, you can find packages based on key words, \npackage contents, or other attributes.\nLet\u2019s say that you want to try out a different text editor but you can\u2019t remember the name \nof the one you wanted. You could start by using the search  subcommand to look for the \nterm editor  in the name or description:\n# yum search editor\n...\neclipse-veditor.noarch : Eclipse-based Verilog/VHDL plugin\ned.x86_64 : The GNU line editor\nemacs.x86_64 : GNU Emacs text editor\nThe search uncovered a long list of packages containing editor  in the name or description. \nThe one I was looking for is named emacs . To get information about that package, I can \nuse the info  subcommand:\n# yum info emacs\nName        : emacs\nEpoch        : 1\nVersion      : 26.2\nRelease      : 1.fc30\nArchitecture : x86_64\nSize         : 3.2 M\nSource       : emacs-26.2-1.fc30.src.rpm\nRepository   : updates\nSummary      : GNU Emacs text editor\nURL          : http://www.gnu.org/software/emacs/\nLicense      : GPLv3+ and CC0-1.0\nDescription  : Emacs is a powerful, customizable, self-documenting, \nmodeless text\n             : editor. Emacs contains special code editing features, \na scripting", "doc_id": "3805fbaf-9e0a-44c6-b113-84690771616c", "embedding": null, "doc_hash": "6447d826bb8c5d366d28b78c5738e23c9d6c889473124d80157ebea6c3fc9f8c", "extra_info": {"page_label": "262"}, "node_info": {"start": 0, "end": 1965}, "relationships": {"1": "c28b6add-4e73-403a-b634-b9da565c3eab"}}, "__type__": "1"}, "ff389065-88f5-4f16-ae68-a97c20e9ddf3": {"__data__": {"text": "Chapter 10: Getting and Managing Software\n235\n10             : language (elisp), and the capability to read mail, \nnews, and more\n             : without leaving the editor.\nIf you know the command, configuration file, or library name you want but don\u2019t know \nwhat package it is in, use the provides  subcommand to search for the package. Here you \ncan see that the dvdrecord  command is part of the wodim  package:\n# yum provides dvdrecord\nwodim-1.1.11-41.fc30.x86_64 : A command line CD/DVD recording program\nRepo        : fedora\nMatched from:\nFilename    : /usr/bin/dvdrecord\nThe list  subcommand can be used to list package names in different ways. Use it with a \npackage base name to find the version and repository for a package. You can list just pack -\nages that are available  or installed , or you can list all  packages.\n# yum list emacs\nemacs.i686     1:26.2-1.fc30     updates\n# yum list available\nCUnit.i686     2.1.3-17.el8   rhel-8-for-x86_64-appstream-rpms\nCUnit.x86_64     2.1.3-17.el8   rhel-8-for-x86_64-appstream-rpms\nGConf2.i686      3.2.6-22.el8   rhel-8-for-x86_64-appstream-rpms\nLibRaw.i686      0.19.1-1.el8   rhel-8-for-x86_64-appstream-rpm\n...\n# yum list installed\nInstalled Packages\nGConf2.x86_64       3.2.6-22.el8      @AppStream\nModemManager.x86_64 1.8.0-1.el8       @anaconda\n...\n# yum list all\n...\nIf you find a package but you want to see what components that package is dependent \non, you can use the deplist  subcommand. With deplist , you can see the components \n(dependency) but also the package that component comes in (provider). Using deplist  \ncan help if no package is available to provide a dependency, but you want to know what \nthe component is so that you can search other repositories for it. Consider the follow -\ning example:\n# yum deplist emacs | less\npackage: emacs-1:26.1-8.fc30.x86_64\n  dependency: /bin/sh\n   provider: bash-5.0.7-1.fc30.i686\n   provider: bash-5.0.7-1.fc30.x86_64\n  dependency: /usr/sbin/alternatives\n   provider: alternatives-1.11-4.fc30.x86_64", "doc_id": "ff389065-88f5-4f16-ae68-a97c20e9ddf3", "embedding": null, "doc_hash": "967cf76ffbded36b42db78b48d741fcb8d98f2f759d73e3adab6f798490b58ba", "extra_info": {"page_label": "263"}, "node_info": {"start": 0, "end": 2016}, "relationships": {"1": "aebbb05d-18b5-46da-87f0-c1c876204941"}}, "__type__": "1"}, "50fd5f36-b74f-45a0-a322-ce8c6d924094": {"__data__": {"text": "Part III: Becoming a Linux System Administrator236Installing and removing packages\nThe install  subcommand lets you install one or more packages, along with any depen -\ndent packages needed. With yum install , multiple repositories can be searched to fulfill \nneeded dependencies. Consider the following example of yum install :\n# yum install emacs\n...\nPackage                 Architecture Version            Repository  Size\n=====================================================================\nInstalling:\n emacs                   x86_64       1:26.2-1.fc30      updates     3.2 M\nInstalling dependencies:\n emacs-common            x86_64       1:26.2-1.fc30      updates      38 M\n ImageMagick-libs        x86_64       1:6.9.10.28-1.fc30 fedora     2.2 M\n fftw-libs-double        x86_64       3.3.8-4.fc30            fedora     984 k\n ...\n \nTransaction Summary\n=====================================================================\nInstall  7 Packages\n \nTotal download size: 45 M\nInstalled size: 142 M\nIs this ok [y/N]: y\nYou can see here that emacs  requires that emacs-common  and several other packages be \ninstalled so all are queued up for installation. The six packages together are 45MB to down -\nload, but they consume 142MB after installation. Pressing y installs them. You can put a \n-y on the command line (just after the yum  command) to avoid having to press y to install \nthe packages. Personally, however, I usually want to see all of the packages about to be \ninstalled before I agree to the installation.\nYou can reinstall a package if you mistakenly delete components of an installed package. If \nyou attempt a regular install, the system responds with \u201cnothing to do.\u201d You must instead \nuse the reinstall  subcommand. For example, suppose that you installed the zsh  package \nand then deleted /bin/zsh  by mistake. You could restore the missing components by typ -\ning the following:\n# yum reinstall zsh\nYou can remove a single package, along with its dependencies that aren\u2019t required by other \npackages, with the remove  subcommand. For example, to remove the emacs  package and \ndependencies, you could type the following:\n# yum remove emacs\nRemoving:\n emacs                   x86_64       1:26.2-1.fc30      updates     38 M", "doc_id": "50fd5f36-b74f-45a0-a322-ce8c6d924094", "embedding": null, "doc_hash": "dff9cae3d731af6020546f40f369066447c02a959ca2bbe7ce453af0aa54d517", "extra_info": {"page_label": "264"}, "node_info": {"start": 0, "end": 2248}, "relationships": {"1": "84490578-42f7-4872-b8cc-531c8a05b3cd"}}, "__type__": "1"}, "d254ab76-27dc-4207-ad29-4d1191e92e77": {"__data__": {"text": "Chapter 10: Getting and Managing Software\n237\n10Removing unused dependencies:\n ImageMagick-libs        x86_64       1:6.9.10.28-1.fc30 fedora     8.9 M\n emacs-common            x86_64       1:26.2-1.fc30      updates     89 M\n fftw-libs-double        x86_64       3.3.8-4.fc30       fedora     4.2 M\n ...\n \nTransaction Summary\n=====================================================================\nRemove  7 Packages\n \nFreed space: 142 M\nIs this ok [y/N]: y\nNotice that the space shown for each package is the actual space consumed by the package \nin the file system and not the download size (which is considerably smaller).\nAn alternative method to remove a set of packages that you have installed is to use \nthe history  subcommand. Using history , you can see your yum  activities and undo \nan entire transaction. In other words, all of the packages that you installed can be \nuninstalled using the undo  option of the history  subcommand, as in the follow -\ning example:\n# yum history\nID     | Command line   | Date and time    | Action(s)      | Altered\n---------------------------------------------------------------------\n    12 | install emacs  | 2019-06-22 11:14 | Install        |    7\n...\n# yum history info 12\nTransaction ID : 12\n...\nCommand Line    : install emacs\n...\n# yum history undo 12\nUndoing transaction 12, from Sat 22 Jun 2019 11:14:42 AM EDT\n \nInstall emacs-1:26.2-1.fc30.x86_64                 @updates\n    Install emacs-common-1:26.2-1.fc30.x86_64          @updates\n ...\nBefore you undo the transaction, you can view the transaction to see exactly which packages \nwere involved. Viewing the transaction can save you from mistakenly deleting packages that \nyou want to keep. By undoing transaction 12, you can remove all packages that were installed \nduring that transaction. If you are trying to undo an install that included dozens or even hun-\ndreds of packages, undo can be a very useful option.", "doc_id": "d254ab76-27dc-4207-ad29-4d1191e92e77", "embedding": null, "doc_hash": "dd2634bbe812132905940e994fe73b017f6324431094e55c6a4315fbf608c4a0", "extra_info": {"page_label": "265"}, "node_info": {"start": 0, "end": 1923}, "relationships": {"1": "9135660c-33fc-4c41-89d6-c0770e926a8d"}}, "__type__": "1"}, "5ccac207-cbe8-44e9-91bc-d43eaf85aefc": {"__data__": {"text": "Part III: Becoming a Linux System Administrator238Updating packages\nAs new releases of a package become available, they are sometimes put into separate update \nrepositories or simply added to the original repository. If multiple versions of a package are \navailable (whether in the same repository or in another enabled repository), yum  provides \nthe latest version when you install a package. For some packages, such as the Linux kernel \npackage, you can keep multiple versions of the same package.\nIf a new version of a package shows up later, you can download and install the new version \nof the package by using the update  subcommand.\nThe check-update  subcommand can check for updates. The update  subcommand can \nbe used to update a single package or to get updates to all packages that are currently \ninstalled and have an update available. Or, you can simply update a single package (such as \nthe cups  package), as in this example:\n# yum check-update\n...\nfile.x86_64       5.36-3.fc30     updates\nfile-libs.x86_64  5.36-3.fc30     updates\nfirefox.x86_64    67.0.4-1.fc30   updates\nfirewalld.noarch  0.6.4-1.fc30    updates\n...\n# yum update\nDependencies resolved.\n==============================================================\n Package             Arch   Version         Repository    Size\n==============================================================\nUpgrading:\n NetworkManager      x86_64 1:1.16.2-1.fc30 updates      1.7 M\n NetworkManager-adsl x86_64 1:1.16.2-1.fc30 updates       25 k\n...\nTransaction Summary\n==============================================================\nInstall     7 Packages\nUpgrade   172 Package(s)\nTotal download size: 50 M\nIs this ok [y/N]: y\n# yum update cups\nThe preceding command requested to update the cups  package. If other dependent \npackages need to be updated to update cups , those packages would be downloaded and \ninstalled as well.", "doc_id": "5ccac207-cbe8-44e9-91bc-d43eaf85aefc", "embedding": null, "doc_hash": "4b92adfd24d94f09040464623d8e0019ca1b1d737d6e631d3666a321af720fbd", "extra_info": {"page_label": "266"}, "node_info": {"start": 0, "end": 1883}, "relationships": {"1": "13917d88-9746-464b-83cf-ef2d8a6d7329"}}, "__type__": "1"}, "6c7463d2-3f10-4b15-8fa5-be58bc68f73c": {"__data__": {"text": "Chapter 10: Getting and Managing Software\n239\n10Updating groups of packages\nTo make it easier to manage a whole set of packages at once, YUM supports package groups. \nFor example, you could install GNOME Desktop Environment (to get a whole desktop) or Vir -\ntualization (to get packages needed to set up the computer as a virtualization host). You \ncan start by running the grouplist  subcommand to see a list of group names:\n# yum grouplist | less\nAvailable Environment Groups:\n   Fedora Custom Operating System\n   Minimal Install\n   Fedora Server Edition\n...\nInstalled Groups:\n   LibreOffice\n   GNOME Desktop Environment\n   Fonts\n...\nAvailable Groups:\n   Authoring and Publishing\n   Books and Guides\n   C Development Tools and Libraries\n...\nLet\u2019s say that you wanted to try out a different desktop environment. You see LXDE, and \nyou want to know what is in that group. To find out, use the groupinfo  subcommand:\n# yum groupinfo LXDE\nGroup: LXDE\n Description: LXDE is a lightweight X11 desktop environment...\n Mandatory Packages:\n...\n   lxde-common\n   lxdm\n   lxinput\n   lxlauncher\n   lxmenu-data\n...\nIn addition to showing a description of the group, groupinfo  shows Mandatory Packages \n(those that are always installed with the group), Default Packages (those that are installed \nby default but can be excluded), and Optional Packages (which are part of the group but not \ninstalled by default). When you use some graphical tools to install package groups, you can \nuncheck default packages or check optional packages to change whether they are installed \nwith the group.\nIf you decide that you want to install a package group, use the groupinstall  \nsubcommand:\n# yum groupinstall LXDE", "doc_id": "6c7463d2-3f10-4b15-8fa5-be58bc68f73c", "embedding": null, "doc_hash": "18e3c47813bd94a1953c9ad13d6b083e4b2b64cb551c7883e884a2ce51e29661", "extra_info": {"page_label": "267"}, "node_info": {"start": 0, "end": 1692}, "relationships": {"1": "5d35c0d6-749b-4884-b72e-d4491361bdee"}}, "__type__": "1"}, "73ddd92d-c486-4cb5-bcb1-1aa09fe4c348": {"__data__": {"text": "Part III: Becoming a Linux System Administrator240This groupinstall  resulted in 101 packages from the group being installed and 5 exist -\ning packages being updated. If you decide that you don\u2019t like the group of packages, you \ncan remove the entire group at once using the groupremove  subcommand:\n# yum groupremove LXDE\nMaintaining your RPM package database and cache\nSeveral subcommands to yum  can help you do maintenance tasks, such as checking for \nproblems with your RPM database or clearing out the cache. The YUM facility has tools for \nmaintaining your RPM packages and keeping your system\u2019s software efficient and secure.\nClearing out the cache is something that you want to do from time to time. If you decide \nto keep downloaded packages after they are installed (they are removed by default, based \non the keepcache=0  setting in the /etc/yum.conf  file), your cache directories (under /\nvar/cache/yum ) can fill up. Metadata stored in cache directories can be cleared, causing \nfresh metadata to be downloaded from all enabled YUM repositories the next time yum  is \nrun. Here are ways to clear that information:\n# yum clean packages\n14 files removed\n# yum clean metadata\nCache was expired\n16 files removed\n# yum clean all\n68 files removed\nAlthough unlikely, it\u2019s possible that the RPM database can become corrupted. This can hap -\npen if something unexpected occurs, such as pulling out the power cord when a package is \npartially installed. You can check the RPM database to look for errors ( yum check ) or just \nrebuild the RPM database files. Here\u2019s an example of a corrupt RPM database and the rpm  \ncommand that you can use to fix it:\n# yum check\nerror: db5 error(11) from dbenv->open: Resource temporarily \nunavailable\nerror: cannot open Packages index using db5-Resource temporarily \nunavailable(11)\nerror: cannot open Packages database in /var/lib/rpm\nError: Error: rpmdb open failed\n# rpm --rebuilddb\n# yum check\nThe yum clean  examples in the preceding command lines remove cached data from the /\nvar/cache/yum  subdirectories. The rpm --rebuilddb  example rebuilds the database. \nThe yum check  example can check for problems with the local RPM cache and database \nbut notice that we used the rpm  command to fix the problem.\nIn general, the command best suited for working with the local RPM database is the \nrpm command.", "doc_id": "73ddd92d-c486-4cb5-bcb1-1aa09fe4c348", "embedding": null, "doc_hash": "5c87b6f5d8da6cf8a80c0d2f0b3e0b3df57b0e1fb9520c3d71ccd808d4ed408d", "extra_info": {"page_label": "268"}, "node_info": {"start": 0, "end": 2351}, "relationships": {"1": "8caf5b8e-4104-47e7-b7c6-f5440d0754c7"}}, "__type__": "1"}, "bef9d1a0-9e79-4fb8-afa5-56ea8786e0a6": {"__data__": {"text": "Chapter 10: Getting and Managing Software\n241\n10Downloading RPMs from a YUM repository\nIf you just want to examine a package without actually installing it, you can download that \npackage with the dnf  command or, in earlier releases, use the yumdownloader  command. \nEither case causes the package that you name to be downloaded from the YUM repository \nand copied to your current directory.\nFor example, to download the latest version of the Firefox web browser package with yum -\ndownloader  from the YUM repository to your current directory, type the following:\n# yumdownloader firefox\nfirefox-67.0.4-1.fc30.x86_64.rpm    6.1 MB/s |  92 MB     00:14\nTo use the dnf  command, type this:\n# dnf download firefox\nfirefox-60.7.0-1.el8_0.x86_64.rpm   6.1 MB/s |  93 MB     00:15\nWith any downloaded RPM package now sitting in your current directory, you can use a \nvariety of rpm  commands to query or use that package in different ways (as described in \nthe next section).\nInstalling, Querying, and Verifying Software with the \nrpm Command\nThere is a wealth of information about installed packages in the local RPM database. The \nrpm command contains dozens of options to enable you to find information about each \npackage, such as the files it contains, who created it, when it was installed, how large it is, \nand many other attributes. Because the database contains fingerprints (md5sums) of every \nfile in every package, it can be queried with RPM to find out if files from any package have \nbeen tampered with.\nThe rpm  command can still do basic install and upgrade activities, although most people \nonly use rpm  in that way when there is a package sitting in the local directory, ready to be \ninstalled. So, let\u2019s get one in our local directory to work with. Type the following to down -\nload the latest version of the zsh  package:\n# dnf download zsh\nzsh-5.5.1-6.el8.x86_64.rpm     3.0 MB/s | 2.9 MB   00:00\nWith the zsh  package downloaded to your current directory, try some rpm  com-\nmands on it.\nInstalling and removing packages with rpm\nTo install a package with the rpm  command, type the following:\n# rpm -i zsh-5.5.1-6.el8.x86_64.rpm", "doc_id": "bef9d1a0-9e79-4fb8-afa5-56ea8786e0a6", "embedding": null, "doc_hash": "54faa4541e1ab7260161796bb03e9e199b55306abdbe6f831617e41a5f0529b8", "extra_info": {"page_label": "269"}, "node_info": {"start": 0, "end": 2149}, "relationships": {"1": "2af97b67-8943-4176-aa52-2e3df6a2c556"}}, "__type__": "1"}, "29f3208b-60e1-43e3-8854-91a225ef8e83": {"__data__": {"text": "Part III: Becoming a Linux System Administrator242Notice that the entire package name is given to install with rpm , not just the package base \nname. If an earlier version of zsh  were installed, you could upgrade the package using -U . \nOften, people use -h  and -v  options to get hash signs printed and more verbose output \nduring the upgrade:\n# rpm -Uhv zsh-5.5.1-6.el8.x86_64.rpm\nVerifying...          ######################### [100%]\nPreparing...          ######################### [100%]\n   1:zsh-5.5.1-6.el8  ######################### [100%]\nAlthough an install ( -i) only installs a package if the package is not already installed, an \nupgrade (-U) installs the package even if it is already installed. A third type of install, \ncalled freshen ( -F), installs a package only if an existing, earlier version of a package is \ninstalled on the computer, as in this example:\n# rpm -Fhv *.rpm\nYou could use the previous freshen command if you were in a directory containing thou -\nsands of RPMs but only wanted to update those that were already installed (in an earlier \nversion) on your system and skip those that were not yet installed.\nYou can add a few interesting options to any of your install options. The --replacepkgs  \noption enables you to reinstall an existing version of a package (if, for example, you had \nmistakenly deleted some components), and the --oldpackage  enables you to replace a \nnewer package with an earlier version.\n# rpm -Uhv --replacepkgs emacs-26.1-5.el8.x86_64.rpm\n# rpm -Uhv --oldpackage zsh-5.0.2-25.el7_3.1.x86_64.rpm\nYou can remove a package with the -e  option. You only need the base name of a package to \nremove it. Here\u2019s an example:\n# rpm -e emacs\nThe rpm -e emacs command would be successful because no other packages are depen -\ndent on emacs . However, it would leave behind emacs-common , which was installed as \na dependency to emacs . If you had tried to remove emacs-common  first, that command \nwould fail with a \u201cFailed dependencies\u201d message.\nQuerying rpm information\nAfter the package is installed, you can query for information about it. Using the -q  option, \nyou can see information about the package including a description (-qi) , list of files \n(-ql) , documentation (-qd) , and configuration files (-qc) .\n# rpm -qi zsh\nName        : zsh\nVersion     : 5.5.1\nRelease     : 6.el8\n...", "doc_id": "29f3208b-60e1-43e3-8854-91a225ef8e83", "embedding": null, "doc_hash": "aaf97f0b3c81eca3d1225c75baa754a4b5ec7b6d78b3c1cc65199d9cd8e9da3f", "extra_info": {"page_label": "270"}, "node_info": {"start": 0, "end": 2344}, "relationships": {"1": "a0f7891e-9ea4-404b-bc07-5d8c866c8873"}}, "__type__": "1"}, "57ceb1cf-a5ca-4610-9d08-734e828a2f79": {"__data__": {"text": "Chapter 10: Getting and Managing Software\n243\n10# rpm -ql zsh\n/etc/skel/.zshrc\n/etc/zlogin\n/etc/zlogout\n...\n# rpm -qd zsh\n/usr/share/doc/zsh/BUGS\n/usr/share/doc/zsh/CONTRIBUTORS\n/usr/share/doc/zsh/FAQ\n...\n# rpm -qc zsh\n/etc/skel/.zshrc\n/etc/zlogin\n/etc/zlogout\n...\nYou can use options to query any piece of information contained in an RPM. You can find \nwhat an RPM needs for it to be installed ( --requires ), what version of software a package \nprovides (--provides ), what scripts are run before and after an RPM is installed or \nremoved (--scripts ), and what changes have been made to an RPM ( --changelog ).\n# rpm -q --requires emacs-common\n/bin/sh\n/usr/bin/pkg-config\n/usr/sbin/alternatives\n...\n# rpm -q --provides emacs-common\nconfig(emacs-common) = 1:26.2-1.fc30\nemacs-common = 1:26.2-1.fc30\nemacs-common(x86-64) = 1:26.2-1.fc30\nemacs-el = 1:26.2-1.fc30\npkgconfig(emacs) = 1:26.2\n# rpm -q --scripts httpd\npostinstall scriptlet (using /bin/sh):\nif [ $1 -eq 1 ] ; then\n        # Initial installation\n        systemctl --no-reload preset httpd.service...\n...\n# rpm -q --changelog httpd | less\n* Thu May 02 2019 Lubos Uhliarik <luhliari@redhat.com> - 2.4.39-4\n- httpd dependency on initscripts is unspecified (#1705188)\n* Tue Apr 09 2019 Joe Orton <jorton@redhat.com> - 2.4.39-3\n...\nIn the previous two examples, you can see that scripts inside the httpd  package uses \nsystemctl  command to set up the httpd  service. The --changelog  option enables you \nto see why changes have been made to each version of the package.", "doc_id": "57ceb1cf-a5ca-4610-9d08-734e828a2f79", "embedding": null, "doc_hash": "8a6706b449610d5c01922706018005de07352efe18d02e02c30e50c214b5447e", "extra_info": {"page_label": "271"}, "node_info": {"start": 0, "end": 1526}, "relationships": {"1": "6402bfef-3355-4af7-a591-982d2bd0007d"}}, "__type__": "1"}, "17a96da8-542b-4714-bd4b-960bacb895d3": {"__data__": {"text": "Part III: Becoming a Linux System Administrator244Using a feature called --queryformat , you can query different tags of information and \noutput them in any form you like. Run the --querytags  option to be able to see all of the \ntags that are available:\n# rpm --querytags | less\nARCH\nARCHIVESIZE\nBASENAMES\nBUGURL\n...\n# rpm -q binutils --queryformat \"The package is %{NAME} \\\n     and the release is %{RELEASE}\\n\"\nThe package is binutils and the release is 29.fc30\nAll of the queries that you have done so far have been to the local RPM database. By add -\ning a -p  to those query options, you can query an RPM file sitting in your local directory \ninstead. The -p  option is a great way to look inside a package that someone gives you to \ninvestigate what it is before you install it on your system.\nIf you haven\u2019t already, get the zsh  package and put it in your local directory ( dnf  \ndownload zsh ). Then run some query commands on the RPM file.\n# rpm -qip zsh-5.7.1-1.fc30.x86_64.rpm View info about the RPM file\n# rpm -qlp zsh-5.7.1-1.fc30.x86_64.rpm List all files in the RPM file\n# rpm -qdp zsh-5.7.1-1.fc30.x86_64.rpm Show docs in the RPM file\n # rpm -qcp zsh-5.7.1-1.fc30.x86_64.rpm List config files in the RPM file\nVerifying RPM packages\nUsing the -V  option, you can check the packages installed on your system to see if the \ncomponents have been changed since the packages were first installed. Although it is nor -\nmal for configuration files to change over time, it is not normal for binaries (the commands \nin /bin , /sbin , and so on) to change after installation. Binaries that are changed are \nprobably an indication that your system has been cracked.\nIn this example, I\u2019m going to install the zsh  package and mess it up. If you want to try \nalong with the examples, be sure to remove or reinstall the package when you are finished.\n# rpm -i zsh-5.7.1-1.fc30.x86_64.rpm\n# echo hello > /bin/zsh\n# rm /etc/zshrc\n# rpm -V zsh\nmissing   c  /etc/zshrc\nS.5....T.    /bin/zsh\nIn this output, you can see that the /bin/zsh  file has been tampered with and /etc/\nzshrc  has been removed. Each time that you see a letter or a number instead of a dot from ", "doc_id": "17a96da8-542b-4714-bd4b-960bacb895d3", "embedding": null, "doc_hash": "750736f0e8f039c3154e529c8d0727c37f2ca33d2b5556619088893a74f5a0f1", "extra_info": {"page_label": "272"}, "node_info": {"start": 0, "end": 2167}, "relationships": {"1": "931a68da-aa5c-4b0d-b533-5149d64834f8"}}, "__type__": "1"}, "34351da4-2377-43b9-aa9e-3e9291e9d836": {"__data__": {"text": "Chapter 10: Getting and Managing Software\n245\n10the rpm -V  output, it is an indication of what has changed. Letters that can replace the \ndots (in order) include the following:\nS    file Size differs\nM    Mode differs (includes permissions and file type)\n5    MD5 sum differs\nD    Device major/minor number mismatch\nL    readLink(2) path mismatch\nU    User ownership differs\nG    Group ownership differs\nT    mTime differs\nP    caPabilities differ\nThose indicators are from the Verify section of the rpm  man page. In my example, you can \nsee the file size has changed ( S), the md5sum checked against the file\u2019s fingerprint has \nchanged (5), and the modification time ( T) on the file differs.\nTo restore the package to its original state, use rpm  with the --replacepkgs  option, as \nshown next. (The yum reinstall zsh command would work as well.) Then check it with \n-V again. No output from -V  means that every file is back to its original state.\n# rpm -i --replacepkgs zsh-5.7.1-1.fc30.x86_64.rpm\n# rpm -V zsh\nIt is good practice to back up your RPM database (from /var/lib/rpm ) and copy it to \nsome read-only medium (such as a CD). Then, when you go to verify packages that you sus -\npect were cracked, you know that you aren\u2019t checking it against a database that has also \nbeen cracked.\nManaging Software in the Enterprise\nAt this point, you should have a good working knowledge of how to install, query, remove, \nand otherwise manipulate packages with graphical tools, the yum  command, and the rpm  \ncommand. When you start working with RPM files in a large enterprise, you need to extend \nthat knowledge.\nFeatures used to manage RPM packages in the enterprise with Red Hat Enterprise Linux \noffer a bit more complexity and much more power. Instead of having one big software \nrepository, as Fedora does, RHEL provides software using Red Hat Subscription Manage -\nment, requiring paid subscriptions/entitlements that allow access to a variety of soft -\nware channels and products (RHEL, Red Hat Virtualization, Red Hat Software Collections, \nand so on).\nIn terms of enterprise computing, one of the great benefits of the design of RPM packages is \nthat their management can be automated. Other Linux packaging schemes allow packages \nto stop and prompt you for information when they are being installed (such as asking for a ", "doc_id": "34351da4-2377-43b9-aa9e-3e9291e9d836", "embedding": null, "doc_hash": "e1904fece7d236c590872d5f4caf6f73f747fadcf1c6f015bb388819810234d6", "extra_info": {"page_label": "273"}, "node_info": {"start": 0, "end": 2337}, "relationships": {"1": "1cd95225-d3b7-4c59-832b-64eca57ee952"}}, "__type__": "1"}, "6dcfbce0-7ff5-4fa8-baba-bb44d28f5de5": {"__data__": {"text": "Part III: Becoming a Linux System Administrator246directory location or a username). RPM packages install without interruption, offering some \nof the following advantages:\nKickstart files  All of the questions that you answer during a manual install, and all \nof the packages that you select, can be added into a file called a kickstart file. When \nyou start a Fedora or Red Hat Enterprise Linux installer, you can provide a kickstart \nfile at the boot prompt. From that point on, the entire installation process com-\npletes on its own. Any modifications to the default package installs can be made by \nrunning pre and post scripts from the kickstart file to do such things as add user \naccounts or modify configuration files.\nPXE boot You can configure a PXE server to allow client computers to boot an ana -\nconda (installer) kernel and a select kickstart file. A completely blank computer \nwith a network interface card (NIC) that supports PXE booting can simply boot from \nits NIC to launch a fresh installation. In other words, turn on the computer, and if \nit hits the NIC in its boot order, a few minutes later you can have a freshly installed \nsystem, configured to your exact specifications without intervention.\nSatellite server (Spacewalk)  Red Hat Enterprise Linux systems can be deployed \nusing what is referred to as Satellite Server . Built into Satellite Server are the same \nfeatures that you have from Red Hat CDN to manage and deploy new systems and \nupdates. RHEL systems can be configured to get automatic software updates at times \nset from the satellite server. Sets of packages called Errata that fix specific problems \ncan be quickly and automatically deployed to the systems that need them.\nContainer Images Instead of installing individual RPMs on a system, you can \npackage up a few or a few hundred RPMs into a container image. The container \nimage is like an RPM in that it holds a set of software, but unlike an RPM in that \nit is more easily added to a system, run directly, and deleted from a system than \nan RPM is.\nDescriptions of how to use kickstart files, Satellite Servers, containers and other enter -\nprise-ready installation features are beyond the scope of this book. But the understanding \nyou have gained from learning about YUM and RPM remain critical components of all of the \nfeatures just mentioned.\nSummary\nSoftware packaging in Fedora, Red Hat Enterprise Linux, and related systems is provided \nusing software packages based on the RPM Package Manager (RPM) tools. Debian, Ubuntu, \nand related systems package software into DEB files. You can try easy-to-use graphical tools \nsuch as the Software window for finding and installing packages. The primary command-\nline tools include the yum , dnf , and rpm  commands for Red Hat\u2013related systems and \naptitude , apt*  and dpkg  for Debian-related systems.\nUsing these software management tools, you can install, query, verify, update, and remove \npackages. You can also do maintenance tasks, such as clean out cache files and rebuild the ", "doc_id": "6dcfbce0-7ff5-4fa8-baba-bb44d28f5de5", "embedding": null, "doc_hash": "af9043012b6dad5cf18c99aa042b02e0789e1627ac96c179d20b39f0b97aaad5", "extra_info": {"page_label": "274"}, "node_info": {"start": 0, "end": 3036}, "relationships": {"1": "1eb2e04f-deea-4446-9334-586563527696"}}, "__type__": "1"}, "045547f4-52d3-4b41-aaaa-18bde8aa8871": {"__data__": {"text": "Chapter 10: Getting and Managing Software\n247\n10RPM database. This chapter describes many of the features of the Software window, as well \nas yum , dnf , and rpm  commands.\nWith your system installed and the software packages that you need added, it\u2019s time to \nconfigure your Fedora, RHEL, Debian, or Ubuntu system further. If you expect to have mul -\ntiple people using your system, your next task could be to add and otherwise manage user \naccounts on your system. Chapter\u00a011, \u201cManaging User Accounts,\u201d describes user manage -\nment in Fedora, RHEL, and other Linux systems.\nExercises\nThese exercises test your knowledge of working with RPM software packages in Fedora or \nRed Hat Enterprise Linux. To do the exercises, I recommend that you have a Fedora system \nin front of you that has an Internet connection. (Most of the procedures work equally well \non a registered RHEL system.)\nYou need to be able to reach the Fedora repositories (which should be set up automatically). \nIf you are stuck, solutions to the tasks are shown in Appendix B (although in Linux, there \nare often multiple ways to complete a task).\n1. Search the YUM repository for the package that provides the mogrify  command.\n2. Display information about the package that provides the mogrify  command, and \ndetermine what is that package\u2019s home page (URL).\n3. Install the package containing the mogrify  command.\n4. List all of the documentation files contained in the package that provides the mog -\nrify  command.\n5. Look through the changelog  of the package that provides the mogrify   \ncommand.\n6. Delete the mogrify  command from your system and verify its package against the \nRPM database to see that the command is indeed missing.\n7. Reinstall the package that provides the mogrify  command, and make sure that \nthe entire package is intact again.\n8. Download the package that provides the mogrify  command to your current \ndirectory.\n9. Display general information about the package you just downloaded by querying \nthe package\u2019s RPM file in the current directory.\n10. Remove the package containing the mogrify  command from your system.", "doc_id": "045547f4-52d3-4b41-aaaa-18bde8aa8871", "embedding": null, "doc_hash": "a0e7fdcd558a6919234bd2ac9ba466d6c6b3dce011df030857e77301faaab973", "extra_info": {"page_label": "275"}, "node_info": {"start": 0, "end": 2120}, "relationships": {"1": "d94e67d0-f728-415b-aaa8-e57619a5082f"}}, "__type__": "1"}, "1e0608d2-0744-496f-8b9a-472890556b52": {"__data__": {"text": "249\nCHAPTER11\nManaging User Accounts\nIN THIS CHAPTER\nWorking with user accounts\nWorking with group accounts\nConfiguring centralized user accounts\nAdding and managing users are common tasks for Linux system administrators. User accounts \nkeep boundaries between the people who use your systems and between the processes that \nrun on your systems. Groups  are a way of assigning rights to your system that can be assigned \nto multiple users at once.\nThis chapter describes not only how to create a new user, but also how to create predefined settings \nand files to configure the user\u2019s environment. Using tools such as the useradd  and usermod  com-\nmands, you can assign settings such as the location of a home directory, a default shell, a default \ngroup, and specific user ID and group ID values. With Cockpit, you can add and manage user accounts \nthrough a web UI.\nCreating User Accounts\nEvery person who uses your Linux system should have a separate user account. Having a user \naccount provides you with an area in which to store files securely as well as a means of tailoring \nyour user interface (GUI, path, environment variables, and so on) to suit the way that you use \nthe computer.\nYou can add user accounts to most Linux systems in several ways. Fedora and Red Hat Enterprise \nLinux systems offer Cockpit , which includes an Account selection for creating and managing user \naccounts. If Cockpit is not yet installed and enabled, do that as follows:\n# yum install cockpit -y\n# systemctl enable --now cockpit.socket\n \n \n \n \nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "1e0608d2-0744-496f-8b9a-472890556b52", "embedding": null, "doc_hash": "53e2d0a5ad5f08db88d0509e7d3958893175802b3a3d70fb5f71b2030c9f4275", "extra_info": {"page_label": "276"}, "node_info": {"start": 0, "end": 1657}, "relationships": {"1": "d1cf3a3d-913c-46b6-848d-e7155b45274f"}}, "__type__": "1"}, "aec881a5-658e-4fbf-b3a8-bae19f1a1b4a": {"__data__": {"text": "Part III: Becoming a Linux System Administrator250To create a user account through Cockpit, do the following:\n1. Open the Cockpit interface from your web browser ( hostname:9090 ).\n2. Log in as root (or as a user with root privilege), select the \u201cReuse my password for \nprivileged tasks\u201d check box, and select Accounts.\n3. Select Create New Account.\nFigure\u00a011.1 shows an example of the Create New Account pop-up window:\n4. Begin adding a new user account to your Linux system. Here are the fields you need \nto fill in:\nFull Name  Use the user's real name, typically used with uppercase and lowercase \nletters, as the user would write it in real life. Technically, this information is \nstored in the comment field of the passwd  file, but by convention, most Linux \nand UNIX systems expect this field to hold each user's full name.\nUser Name  This is the name used to log in as this user. When you choose a user -\nname, don't begin with a number (for example, 26jsmith). Also, it's best to use \nall lowercase letters, no control characters or spaces, and a maximum of eight \ncharacters, by convention. The useradd  command allows up to 32 characters, \nFIGURE 11.1\nAdd and modify user accounts from Cockpit.", "doc_id": "aec881a5-658e-4fbf-b3a8-bae19f1a1b4a", "embedding": null, "doc_hash": "9c089d9ae8d6593381bacad5b000618cac5b42a0afe398772a618c7f40e0c68c", "extra_info": {"page_label": "277"}, "node_info": {"start": 0, "end": 1205}, "relationships": {"1": "432209b0-15f4-491e-8de3-92e3d817a4b4"}}, "__type__": "1"}, "bb7ff2b2-0e88-494e-84bf-8382886ba499": {"__data__": {"text": "Chapter 11: Managing User Accounts\n251\n11but some applications can't deal with usernames that long. Tools such as ps  dis-\nplay user IDs (UIDs) instead of names if names are too long. Having users named \nJsmith and jsmith can cause confusion with programs (such as sendmail) that \ndon't distinguish case.\nPassword, Confirm Enter the password you want the user to have in the Password \nand Confirm fields. The password should be at least eight characters long and \ncontain a mixture of uppercase and lowercase letters, numbers, and punctua -\ntion. It should not contain real words, repeated letters, or letters in a row on \nthe keyboard. Through this interface, you must set a password that meets the \nabove criteria. (If you want to add a password that doesn't meet this criteria, \nyou can use the useradd  command, described later in this chapter. )Bars under -\nneath the password fields turn from red to green as you improve the strength of \nyour password.\nAccess  To create an account that you are not quite ready to use, select the Lock \nAccount check box. That prevents anyone from logging into the account until \nyou uncheck that box or change that information in the passwd  file.\n5. Select Create to add the user to the system. An entry for the new user account is \nadded to the /etc/passwd  file and the new group account to the /etc/group  file. \n(I will describe those later in this chapter.)\nThe Cockpit Accounts screen lets you modify a small set of information about a regular user \nafter it has been created. To modify user information later, do the following:\n1. Select the user account that you want to change. A screen appears with available \nselections for that user account.\n2. You can delete but not modify the username, but you can change the following: \ninformation:\nFull Name  Because the user's full name is just a comment, you can change that as \nyou please.\nRoles By default, you have the opportunity to select check boxes that allow the \nuser to be added to the role of Server Administrator (giving the user root priv -\nilege by being added to the wheel group) or Image Builder (allowing the user to \nbuild containers and other image types through the weldr group). Other roles \nmight be added to this list by other Cockpit components. If the user is logged in, \nthat user must log out to obtain those privileges.\nAccess  You can choose Lock Account to lock the account, select to lock the \naccount on a particular date, or never lock the account (setting no account expi-\nration date).\nPassword  You can choose Set Password to set a new password for that user or \nForce Change to force the user to change their password the next time they log \nin. By default, passwords never expire. You can change that to have the pass -\nword expire every set number of days.", "doc_id": "bb7ff2b2-0e88-494e-84bf-8382886ba499", "embedding": null, "doc_hash": "037060e794338b9936c3272705969163c92c804155b5285c6b29c6e06d07f94f", "extra_info": {"page_label": "278"}, "node_info": {"start": 0, "end": 2789}, "relationships": {"1": "cc7d7d5c-5413-4794-b9ed-dda78ef1bdc3"}}, "__type__": "1"}, "e29ccfda-4f98-46ae-a990-6842e70fcbeb": {"__data__": {"text": "Part III: Becoming a Linux System Administrator252Authorized Public SSH Keys If you have a public SSH key for the user, you \ncan select the plus sign ( +) for this field, paste that key into the text box, and \nselect Add key. With that key in place, the user with the associated private \nkey is allowed to log into that user account via SSH without needing to enter \na password.\n3. Changes take effect immediately, so you can simply leave the window when you are \ndone modifying the user account.\nThe Accounts area of the Cockpit web UI was designed to simplify the process of creating \nand modifying user accounts. More features associated with user accounts can be  \nadded or modified from the command line. The next part of this chapter describes how  \nto add user accounts from the command line with useradd  and change them with the \nusermod  command.\nAdding users with useradd\nSometimes, a Linux system doesn't have a desktop tool or web UI available for adding \nusers. Other times, you might find it more convenient to add lots of users at once with a \nshell script or change user account features that are not available from Cockpit. For those \ncases, commands are available to enable you to add and modify user accounts from the \ncommand line.\nThe most straightforward method for creating a new user from the shell is the useradd  \ncommand. After opening a Terminal window with root permission, you simply invoke  \nuseradd  at the command prompt, with details of the new account as parameters.\nThe only required parameter is the login name of the user, but you probably want to include \nsome additional information ahead of it. Each item of account information is preceded by \na single-letter option code with a dash in front of it. The following options are available \nwith useradd :\n-c \"comment\": Provide a description of the new user account. Typically, this is the \nperson's full name. Replace comment  with the name of the user account ( -c Jake ). \nUse quotes to enter multiple words (for example, -c \u2033Jake Jackson \u2033).\n-d home_dir : Set the home directory to use for the account. The default is to name it \nthe same as the login name and to place it in /home . Replace home_dir with the \ndirectory name to use (for example, -d /mnt/homes/jake ).\n-D: Rather than create a new account, save the supplied information as the new \ndefault settings for any new accounts that are created.\n-e expire_date : Assign the expiration date for the account in YYYY-MM-DD  format. \nReplace expire_date with a date that you want to use. (For example, to expire an \naccount on May 5, 2022, use -e 2022-05-05 .)\n-f -1 : Set the number of days after a password expires until the account is perma -\nnently disabled. The default, -1 , disables the option. Setting this to 0  disables the ", "doc_id": "e29ccfda-4f98-46ae-a990-6842e70fcbeb", "embedding": null, "doc_hash": "ac4d48713db74a54dbb1e68b935b52a9780ce88bf731e58b3e2904f7a335d3e6", "extra_info": {"page_label": "279"}, "node_info": {"start": 0, "end": 2781}, "relationships": {"1": "c868d01f-3e31-4e4f-bfa7-216b0def0ae4"}}, "__type__": "1"}, "8645c399-f4ff-4ab5-b61b-2d2c312b517d": {"__data__": {"text": "Chapter 11: Managing User Accounts\n253\n11account immediately after the password has expired. Replace -1  (that's minus one) \nwith the number to use.\n-g group: Set the primary group (it must already exist in the /etc/group  file) the \nnew user will be in. Replace group  with the group name (for example, -g wheel ). \nWithout this option, a new group is created that is the same as the username and is \nused as that user's primary group.\n-G grouplist : Add the new user to the supplied comma-separated list of supplemen -\ntary groups (for example, -G wheel,sales,tech,lunch ). (If you use -G  later \nwith usermod , be sure to use -aG  and not just -G . If you don't, existing supple -\nmentary groups are removed and the groups you provide here are the only ones \nassigned.)\n-k skel_dir : Set the skeleton directory containing initial configuration files and \nlogin scripts that should be copied to a new user's home directory. This parameter \ncan be used only in conjunction with the -m  option. Replace skel_dir  with the \ndirectory name to use. (Without this option, the /etc/skel  directory is used.)\n-m: Automatically create the user's home directory and copy the files in the skeleton \ndirectory ( /etc/skel ) to it. (This is the default action for Fedora and RHEL, so it's \nnot required. It is not the default for Ubuntu.)\n-M: Do not create the new user's home directory, even if the default behavior is set to \ncreate it.\n-n: Turn off the default behavior of creating a new group that matches the name and \nuser ID of the new user. This option is available with Fedora and RHEL systems. \nOther Linux systems often assign a new user to the group named users  instead.\n-o: Use with -u uid  to create a user account that has the same UID as another user -\nname. (This effectively lets you have two different usernames with authority over \nthe same set of files and directories.)\n-p passwd : Enter a password for the account you are adding. This must be an \nencrypted password. Instead of adding an encrypted password here, you can simply \nuse the passwd  user  command later to add a password for user . (To generate an \nencrypted MD5 password, type openssl passwd .)\n-s shell : Specify the command shell to use for this account. Replace shell  with the \ncommand shell (for example, -s /bin/csh ).\n-u user_id : Specify the user ID number for the account (for example, -u 1793 ). \nWithout the -u  option, the default behavior is to assign the next available number \nautomatically. Replace user_id  with the ID number. User IDs that are automat -\nically assigned to regular users begin at 1000, so you should use IDs for regular \nusers that are above that number in a way that doesn't collide with the automatic \nassignments.", "doc_id": "8645c399-f4ff-4ab5-b61b-2d2c312b517d", "embedding": null, "doc_hash": "900cf9c1444aac5f75769c86b38b92426cc788444ea7715ab17161de2c01d750", "extra_info": {"page_label": "280"}, "node_info": {"start": 0, "end": 2726}, "relationships": {"1": "db7e7d16-dad4-48c3-af18-acceb0e970dc"}}, "__type__": "1"}, "d841d29b-5244-4809-9a9a-c2defff22dfc": {"__data__": {"text": "Part III: Becoming a Linux System Administrator254Let's create an account for a new user. The user's full name is Sara Green, with a login name \nof sara . To begin, become root user and type the following command:\n# useradd -c \"Sara Green\" sara\nNext, set the initial password for sara  using the passwd  command. You\u2019re prompted to \ntype the password twice:\n# passwd sara\nChanging password for user sara.\nNew password: **********\nRetype new password: **********\n \nNote\nAsterisks in this example represent the password you type. Nothing is actually displayed when you type the pass -\nword. Also, keep in mind that running passwd  as root user lets you add short or blank passwords that regular users \ncannot add themselves.\nIn creating the account for sara , the useradd  command performs several actions:\n\u25a0\u25a0Reads the /etc/login.defs  and /etc/default/useradd  files to get default \nvalues to use when creating accounts.\n\u25a0\u25a0Checks command-line parameters to find out which default values to override.\n\u25a0\u25a0Creates a new user entry in the /etc/passwd  and /etc/shadow  files based on the \ndefault values and command-line parameters.\n\u25a0\u25a0Creates any new group entries in the /etc/group  file. (Fedora creates a group \nusing the new user's name.)\n\u25a0\u25a0Creates a home directory based on the user's name in the /home  directory.\n\u25a0\u25a0Copies any files located within the /etc/skel  directory to the new home directory. \nThis usually includes login and application startup scripts.\nThe preceding example uses only a few of the available useradd  options. Most account set -\ntings are assigned using default values. You can set more values explicitly if you want to. \nHere's an example that uses a few more options to do so:\n# useradd -g users -G wheel,apache -s /bin/tcsh -c \"Sara Green\" sara\nIn this case, useradd  is told to make users  the primary group sara  belongs to ( -g),  \nadd her to the wheel and apache groups, and assign tcsh  as her primary command shell \n(-s). A home directory in /home  under the user\u2019s name ( /home/sara ) is created by \ndefault. This command line results in a line similar to the following being added to the  \n/etc/passwd  file:\nsara:x:1002:1007:Sara Green:/home/sara:/bin/tcsh", "doc_id": "d841d29b-5244-4809-9a9a-c2defff22dfc", "embedding": null, "doc_hash": "cb6533a88a97637b47a900798946e4659866f3e77350dbb1e32ca25ba7a31f4f", "extra_info": {"page_label": "281"}, "node_info": {"start": 0, "end": 2193}, "relationships": {"1": "e0911cfb-c968-490c-adca-5902a1fc77d8"}}, "__type__": "1"}, "01dc2481-3feb-4e7f-84fa-1e46688fc63a": {"__data__": {"text": "Chapter 11: Managing User Accounts\n255\n11Each line in the /etc/passwd  file represents a single user account record. Each field is \nseparated from the next by a colon ( :) character. The field\u2019s position in the sequence deter -\nmines what it is. As you can see, the login name is first. The password field contains an x \nbecause, in this example, the shadow  password file is used to store encrypted password \ndata (in /etc/shadow ).\nThe user ID selected by useradd  is 1002. The primary group ID is 1007, which  \ncorresponds to a private sara  group in the /etc/group  file. The comment field was  \ncorrectly set to Sara Green , the home directory was automatically assigned as /home  \n/sara , and the command shell was assigned as /bin/tcsh , exactly as specified with the  \nuseradd  options.\nBy leaving out many of the options (as I did in the first useradd  example), defaults are \nassigned in most cases. For example, by not using -g sales  or -G wheel,apache , the \ngroup name sara  was assigned to the new user. Some Linux systems (other than Fedora \nand RHEL) assign users  as the group name by default. Likewise, excluding -s /bin/tcsh  \ncauses /bin/bash  to be assigned as the default shell.\nThe /etc/group  file holds information about the different groups on your Linux system \nand the users who belong to them. Groups are useful for enabling multiple users to share \naccess to the same files while denying access to others. Here is the /etc/group  entry cre -\nated for sara :\nsara:x:1007:\nEach line in the group file contains the name of a group, a group password (usually filled \nwith an x ), the group ID number associated with it, and a list of users in that group. By \ndefault, each user is added to their own group, beginning with the next available GID, \nstarting with 1000.\nSetting user defaults\nThe useradd  command determines the default values for new accounts by reading the  \n/etc/login.defs  and /etc/default/useradd  files. You can modify those defaults by \nediting the files manually with a standard text editor. Although login.defs  is different \non different Linux systems, the following is an example containing many of the settings \nthat you might find in a login.defs  file:\nPASS_MAX_DAYS     99999\nPASS_MIN_DAYS     0\nPASS_MIN_LEN      5\nPASS_WARN_AGE     7\nUID_MIN                  1000\nUID_MAX                 60000\nSYS_UID_MIN               200\nSYS_UID_MAX               999\nGID_MIN                  1000", "doc_id": "01dc2481-3feb-4e7f-84fa-1e46688fc63a", "embedding": null, "doc_hash": "840ee51a0d1f726145dcdff90e81868475941fdda5e3380bdd61030d8f5b5c8e", "extra_info": {"page_label": "282"}, "node_info": {"start": 0, "end": 2441}, "relationships": {"1": "da98e5d9-4456-4aea-b743-90177405d840"}}, "__type__": "1"}, "d4884c0c-ee04-4dc6-9d01-57f901518ac2": {"__data__": {"text": "Part III: Becoming a Linux System Administrator256GID_MAX                 60000\nSYS_GID_MIN               201\nSYS_GID_MAX               999\nCREATE_HOME yes\nAll uncommented lines contain keyword/value pairs. For example, the keyword  \nPASS_MIN_LEN is followed by some white space and the value 5 . This tells useradd  that \nthe user password must be at least five characters. Other lines enable you to customize the \nvalid range of automatically assigned user ID numbers or group ID numbers. (Fedora starts \nat UID 1000; earlier systems started with UID 100.) Permanent administrative user and \ngroup account numbers are reserved for up to 199 and 200, respectively. So, you can assign \nyour own administrative user and group accounts starting at 200 and 201, respectively, up \nto ID number 999.\nA comment section that explains the keyword\u2019s purpose precedes each keyword (which I \nedited out here to save space). Altering a default value is as simple as editing the value \nassociated with a keyword and saving the file before running the useradd  command.\nIf you want to view other default settings, find them in the /etc/default/useradd  file. \nYou can also see default settings by typing the useradd  command with the -D  option, \nas follows:\n# useradd -D\nGROUP=100\nHOME=/home\nINACTIVE=-1\nEXPIRE=\nSHELL=/bin/bash\nSKEL=/etc/skel\nCREATE_MAIL_SPOOL=yes\nYou can also use the -D  option to change defaults. When run with this flag, useradd  \nrefrains from actually creating a new user account; instead, it saves any additionally sup -\nplied options as the new default values in /etc/default/useradd . Not all useradd  \noptions can be used in conjunction with the -D  option. You can use only the five options \nlisted here.\n-b default_home : Set the default directory in which user home directories are cre -\nated. Replace default_home  with the directory name to use (for example, -b /\ngarage ). Usually, this is /home .\n-e default_expire_date : Set the default expiration date on which the user \naccount is disabled. The default_expire_date  value should be replaced with a \ndate in the form YYYY-MM-DD (for example, -e 2011-10-17 ).\n-f default_inactive : Set the number of days after a password has expired before \nthe account is disabled. Replace default_inactive  with a number representing \nthe number of days (for example, -f 7 ).", "doc_id": "d4884c0c-ee04-4dc6-9d01-57f901518ac2", "embedding": null, "doc_hash": "4fd162d2a5a3f5c65f63cfc45619a9847d701f5a611d9d376bda3135c511aef7", "extra_info": {"page_label": "283"}, "node_info": {"start": 0, "end": 2333}, "relationships": {"1": "e6b22b50-9ee2-414a-b904-ba6d8e203ec2"}}, "__type__": "1"}, "ff5b03d4-c1ec-463f-a7af-04f0514c102a": {"__data__": {"text": "Chapter 11: Managing User Accounts\n257\n11-g default_group : Set the default group in which new users will be placed. Nor -\nmally, useradd  creates a new group with the same name and ID number as the user. \nReplace default_group  with the group name to use (for example, -g bears ).\n-s default_shell : Set the default shell for new users. This is /bin/bash ,  \ntypically. Replace default_shell  with the full path to the shell that you want as \nthe default for new users (for example, -s /bin/ash ).\nTo set any of the defaults, give the -D  option first and add the defaults that you want to \nset. For example, to set the default home directory location to /home/everyone  and the \ndefault shell to /bin/tcsh , enter the following:\n# useradd -D -b /home/everyone -s /bin/tcsh\nIn addition to setting up user defaults, an administrator can create default files that are \ncopied to each user\u2019s home directory for use. These files can include login scripts and shell \nconfiguration files (such as .bashrc ). Keep in mind that setting up these kinds of files is \nthe purpose of the default /etc/skel  directory.\nOther commands that are useful for working with user accounts include usermod  (to mod -\nify settings for an existing account) and userdel  (to delete an existing user account).\nModifying users with usermod\nThe usermod  command provides a simple and straightforward method for changing \naccount parameters. Many of the options available with it mirror those found in useradd . \nThe options that can be used with this command include the following:\n-c username : Change the description associated with the user account. Replace \nusername  with the name of the user account ( -c jake ). Use quotes to enter mul -\ntiple words (for example, -c \u2033Jake Jackson \u2033).\n-d home_dir : Change the home directory to use for the account. The default is to \nname it the same as the login name and to place it in /home . Replace home_dir  \nwith the directory name to use (for example, -d /mnt/homes/jake ).\n-e expire_date : Assign a new expiration date for the account in YYYY-MM-DD  \nformat. Replace expire_date  with a date you want to use. (For October 15, 2022, \nuse -e 2022-10-15 .)\n-f -1: Change the number of days after a password expires until the account is per -\nmanently disabled. The default, -1 , disables the option. Setting this to 0  disables \nthe account immediately after the password has expired. Replace -1  with the \nnumber to use.\n-g group: Change the primary group (as listed in the /etc/group  file) the user will \nbe in. Replace group  with the group name (for example, -g wheel ).", "doc_id": "ff5b03d4-c1ec-463f-a7af-04f0514c102a", "embedding": null, "doc_hash": "3af6c925fde5cb4641c6eb23aede2f3807bca06bd9de968dd0cece42c8839b0b", "extra_info": {"page_label": "284"}, "node_info": {"start": 0, "end": 2594}, "relationships": {"1": "01e52505-2dea-4319-a519-2f5ef4de6ecd"}}, "__type__": "1"}, "ef69dd37-6b04-4878-828d-757f6a7ce9c5": {"__data__": {"text": "Part III: Becoming a Linux System Administrator258-G grouplist : Set the user\u2019s secondary groups to the supplied comma-separated \nlist of groups. If the user is already in at least one group besides the user\u2019s private \ngroup, you must add the -a  option as well ( -Ga). If not, the user belongs to only the \nnew set of groups and loses membership to any previous groups.\n-l login_name : Change the login name of the account.\n-L: Lock the account by putting an exclamation point at the beginning of the \nencrypted password in /etc/shadow . This locks the account while still allowing \nyou to leave the password intact (the -U  option unlocks it).\n-m: Available only when \u2013d  is used. This causes the contents of the user\u2019s home direc -\ntory to be copied to the new directory.\n-o: Use only with -u uid  to remove the restriction that UIDs must be unique.\n-s shell : Specify a different command shell to use for this account. Replace shell  \nwith the command shell (for example, -s bash ).\n-u user_id : Change the user ID number for the account. Replace user_id  with the \nID number (for example, -u 1474 ).\n-U: Unlocks the user account (by removing the exclamation mark at the beginning of \nthe encrypted password).\nThe following are examples of the usermod  command:\n# usermod -s /bin/csh chris\n# usermod -Ga sales,marketing, chris\nThe first example changes the shell to the csh  shell for the user named chris . In the \nsecond example, supplementary groups are added for the user chris . The -a  option (-Ga) \nmakes sure that the supplementary groups are added to any existing groups for the user \nchris . If the -a  is not used, existing supplementary groups for chris  are erased and the \nnew list of groups includes the only supplementary groups assigned to that user.\nDeleting users with userdel\nJust as usermod  is used to modify user settings and useradd  is used to create users, \nuserdel  is used to remove users. The following command removes the user chris :\n# userdel -r chris\nHere, the user chris  is removed from the /etc/password  file. The \u2013r  option removes the \nuser\u2019s home directory as well. If you choose not to use \u2013r , as follows, the home directory \nfor chris  is not removed:\n# userdel chris\nKeep in mind that simply removing the user account does not change anything about the \nfiles that user leaves around the system (except those that are deleted when you use -r ). \nHowever, ownership of files left behind appear as belonging to the previous owner\u2019s user ID \nnumber when you run ls -l  on the files.", "doc_id": "ef69dd37-6b04-4878-828d-757f6a7ce9c5", "embedding": null, "doc_hash": "60281c91cb99f3c7f197194592a623d6d23de5d7a70bcd8db7511e22fe510418", "extra_info": {"page_label": "285"}, "node_info": {"start": 0, "end": 2527}, "relationships": {"1": "73adf633-431a-4834-838e-b0b831b93040"}}, "__type__": "1"}, "c3d06f35-73bf-46fb-9f60-3d9cfe0f150b": {"__data__": {"text": "Chapter 11: Managing User Accounts\n259\n11Before you delete the user, you may want to run a find  command to find all files that \nwould be left behind by the user. After you delete the user, you could search on user ID to \nfind files left behind. Here are two find  commands to do those things:\n# find / -user chris -ls\n# find / -uid 504 -ls\nBecause files that are not assigned to any username are considered to be a security risk, it \nis a good idea to find those files and assign them to a real user account. Here\u2019s an example \nof a find  command that finds all files in the filesystem that are not associated with any \nuser (the files are listed by UID):\n# find / -nouser -ls\nUnderstanding Group Accounts\nGroup accounts are useful if you want to share a set of files with multiple users. You can \ncreate a group and change the set of files to be associated with that group. The root user \ncan assign users to that group so they can have access to files based on that group\u2019s permis -\nsion. Consider the following file and directory:\n$ ls -ld /var/salesdocs /var/salesdocs/file.txt\ndrwxrwxr-x. 2 root sales 4096 Jan 14 09:32 /var/salesstuff/\n-rw-rw-r--. 1 root sales    0 Jan 14 09:32 /var/salesstuff/file.txt\nLooking at permissions on the directory /var/salesdocs  (rwxrwxr-x ), you see the sec -\nond set of rwx  shows that any member of the group ( sales ) has permission to read files \nin that directory ( r is read), create and delete files from that directory ( w is write), and \nchange to that directory ( x is execute). The file named file.txt  can be read and changed \nby members of the sales group (based on the second rw- ).\nUsing group accounts\nEvery user is assigned to a primary group. In Fedora and RHEL, by default, that group is \na new group with the same name as the user. So, if the user were named sara , the group \nassigned to her would also be sara . The primary group is indicated by the number in the \nthird field of each entry in the /etc/passwd  file; for example, the group ID 1007 here:\nsara:x:1002:1007:Sara Green:/home/sara:/bin/tcsh\nThat entry points to an entry in the /etc/group  file:\nsara:x:1007:\nLet\u2019s turn to the sara  user and group accounts for examples. Here are a few facts about \nusing groups:\n\u25a0\u25a0When sara  creates a file or directory, by default, that file or directory is assigned \nto sara \u2019s primary group (also called sara ).", "doc_id": "c3d06f35-73bf-46fb-9f60-3d9cfe0f150b", "embedding": null, "doc_hash": "73cc11b93aa232451e23f8bf4c4670efadb18004fa62c9f0b0eb327ad0e236ea", "extra_info": {"page_label": "286"}, "node_info": {"start": 0, "end": 2371}, "relationships": {"1": "dbb0b18a-d246-49f8-ae4a-ccf215e97be5"}}, "__type__": "1"}, "4a0f0463-3e8d-4415-a718-abdc15b46812": {"__data__": {"text": "Part III: Becoming a Linux System Administrator260\u25a0\u25a0The user sara  can belong to zero or more supplementary groups. If sara  were a \nmember of groups named sales  and marketing , those entries could look like the \nfollowing in the /etc/group  file:\nsales:x:1302:joe,bill,sally,sara\nmarketing:x:1303:mike,terry,sara\n\u25a0\u25a0The user sara  can\u2019t add herself to a supplementary group. She can\u2019t even add \nanother user to her sara  group. Only someone with root privilege can assign users \nto groups.\n\u25a0\u25a0Any file assigned to the sales  or marketing  group is accessible to sara  with \ngroup and other permissions (whichever provides the most access). If sara  wants \nto create a file with the sales  or marketing  groups assigned to it, she could use \nthe newgrp  command. In this example, sara  uses the newgrp  command to have \nsales  become her primary group temporarily and creates a file:\n[sara]$ touch file1\n[sara]$ newgrp sales\n[sara]$ touch file2\n[sara]$ ls -l file*\n-rw-rw-r--. 1 sara sara  0 Jan 18 22:22 file1\n-rw-rw-r--. 1 sara sales 0 Jan 18 22:23 file2\n[sara]$ exit\nIt is also possible to allow users to become a member of a group temporarily with the new -\ngrp command without actually being a member of that group. To do that, someone with \nroot permission can use gpasswd  to set a group password (such as gpasswd sales ). \nAfter that, any user can type newgrp sales  into a shell and temporarily use sales  as \ntheir primary group by simply entering the group password when prompted.\nCreating group accounts\nAs the root user, you can create new groups from the command line with the groupadd  \ncommand. Also, as noted earlier, groups are created automatically when a user account \nis created.\nGroup ID numbers from 0 through 999 are assigned to special administrative groups. For \nexample, the root group is associated with GID 0. Regular groups begin at 1000 for Red \nHat Enterprise Linux and Fedora. On the first UNIX systems, GIDs went from 0 to 99. Other \nLinux systems reserve GIDs between 0 to 500 for administrative groups. A relatively new \nfeature, described earlier, reserves administrative user and group accounts up to 199 and \n200, respectively, and lets you create your own administrative accounts between those \nnumbers and 999.", "doc_id": "4a0f0463-3e8d-4415-a718-abdc15b46812", "embedding": null, "doc_hash": "68bc7de6fadf7a67f29d54fbfbad91b256dced662f5ef33d8502fd43d03282b1", "extra_info": {"page_label": "287"}, "node_info": {"start": 0, "end": 2250}, "relationships": {"1": "15cb4107-2b9a-48c4-a94d-c6142df8c9c7"}}, "__type__": "1"}, "dd61db79-5663-42a1-bbfe-d5937c5ba494": {"__data__": {"text": "Chapter 11: Managing User Accounts\n261\n11Here are some examples of creating a group account with the groupadd  command:\n# groupadd kings\n# groupadd -g 1325 jokers\nIn the examples just shown, the group named kings  is created with the next available \ngroup ID. After that, the group jokers  is created using the 1325  group ID. Some adminis -\ntrators like using an undefined group number above 200 and under 1000 so that the group \nthey create doesn\u2019t intrude on the group designations above 1000 (so UID and GID numbers \ncan go along in parallel).\nTo change a group later, use the groupmod  command, as in the following example:\n# groupmod -g 330 jokers\n# groupmod -n jacks jokers\nIn the first example, the group ID for jokers  is changed to 330. In the second, the name \njokers  is changed to jacks . If you then wanted to assign any of the groups as supple -\nmentary groups to a user, you can use the usermod  command (as described earlier in \nthis chapter).\nManaging Users in the Enterprise\nThe basic Linux method of handling user and group accounts has not changed since the \nfirst UNIX systems were developed decades ago. However, as Linux systems have become \nused in more complex ways, features for managing users, groups, and the permissions asso -\nciated with them have been added on to the basic user/group model so that it could be \nmore flexible and more centralized:\nMore flexible In the basic model, only one user and one group can be assigned to \neach file. Also, regular users have no ability to assign specific permissions to dif -\nferent users or groups and very little flexibility setting up collaborative files/\ndirectories. Enhancements to this model allow regular users to set up special col -\nlaborative directories (using features such as sticky bit and set GID bit directories). \nUsing Access Control Lists (ACLs), any user can also assign specific permissions to \nfiles and directories to any users and groups they like.\nMore centralized When you have only one computer, storing user information for all \nusers in the /etc/passwd  file is probably not a hardship. However, if you need to \nauthenticate the same set of users across thousands of Linux systems, centralizing \nthat information can save lots of time and heartache. Red Hat Enterprise Linux \nincludes features that enable you to authenticate users from LDAP servers or Micro -\nsoft Active Directories servers.\nThe following sections describe how to use features such as Access Control Lists (ACLs) and \nshared directories (sticky bit and set GID bit directories) to provide powerful ways to share \nfiles and directories selectively.", "doc_id": "dd61db79-5663-42a1-bbfe-d5937c5ba494", "embedding": null, "doc_hash": "c9ced6f9b299bb94db663ab25ee8f6a5ba9628a2aaf8f3a5bb548438de687551", "extra_info": {"page_label": "288"}, "node_info": {"start": 0, "end": 2619}, "relationships": {"1": "3d04c603-0322-45ca-851d-6668e6f5e76a"}}, "__type__": "1"}, "c5390049-ec4d-4af0-8a2f-70823e25974a": {"__data__": {"text": "Part III: Becoming a Linux System Administrator262Setting permissions with Access Control Lists\nThe Access Control List (ACL) feature was created so that regular users could share their files \nand directories selectively with other users and groups. With ACLs, a user can allow others \nto read, write, and execute files and directories without leaving those filesystem elements \nwide open or requiring the root user to change the user or group assigned to them.\nHere are a few things to know about ACLs:\n\u25a0\u25a0For ACLs to be used, they must be enabled on a filesystem when that filesystem \nis mounted.\n\u25a0\u25a0In Fedora and Red Hat Enterprise Linux, ACLs are automatically enabled on any file -\nsystem created when the system is installed.\n\u25a0\u25a0If you create a filesystem after installation (such as when you add a hard disk), \nyou need to make sure that the acl  mount option is used when the filesystem is \nmounted (more on that later).\n\u25a0\u25a0To add ACLs to a file, you use the setfacl  command; to view ACLs set on a file, \nyou use the getfacl  command.\n\u25a0\u25a0To set ACLs on any file or directory, you must be the actual owner (user) assigned \nto it. In other words, being assigned user or group permissions with setfacl  does \nnot give you permission to change ACLs on those files yourself.\n\u25a0\u25a0Because multiple users and groups can be assigned to a file/directory, the actual \npermission a user has is based on a union of all user/group designations to which \nthey belong. For example, if a file had read-only permission ( r--) for the sales \ngroup and read/write/execute ( rwx) for the market group, and mary belonged to \nboth, mary would have rwx  permission.\nNote\nIf ACLs are not enabled on the filesystem you are trying to use with setfacl , see the section \u201cEnabling ACLs\u201d later \nin this chapter for information on how to mount a filesystem with ACLs enabled.\nSetting ACLs with setfacl\nUsing the setfacl  command, you can modify permissions ( -m) or remove ACL permissions \n(-x). The following is an example of the syntax of the setfacl  command:\nsetfacl -m u:username:rwx filename\nIn the example just shown, the modify option ( -m) is followed by the letter u , indicating \nthat you are setting ACL permissions for a user. After a colon ( :), you indicate the user -\nname, followed by another colon and the permissions that you want to assign. As with the \nchmod  command, you can assign read ( r), write (w), and/or execute ( x) permissions to the \nuser or group (in the example, full rwx  permission is given). The last argument is replaced \nby the actual filename you are modifying.", "doc_id": "c5390049-ec4d-4af0-8a2f-70823e25974a", "embedding": null, "doc_hash": "53e2d266690355c5adc084298a663b45368dee39c4c29bac0921312a098b33ec", "extra_info": {"page_label": "289"}, "node_info": {"start": 0, "end": 2573}, "relationships": {"1": "77412024-e9f2-495d-b308-2a259872b3c8"}}, "__type__": "1"}, "f787c4c4-ded4-4cf2-b8a1-25ac1be41c50": {"__data__": {"text": "Chapter 11: Managing User Accounts\n263\n11The following are some examples of the user mary  using the setfacl  command to add \npermission for other users and groups on a file:\n[mary]$ touch /tmp/memo.txt\n[mary]$ ls -l /tmp/memo.txt\n-rw-rw-r--. 1 mary mary 0 Jan 21 09:27 /tmp/memo.txt\n[mary]$ setfacl -m u:bill:rw /tmp/memo.txt\n[mary]$ setfacl -m g:sales:rw /tmp/memo.txt\nIn the preceding example, mary  created a file named /tmp/memo.txt . Using the setfacl  \ncommand, she modified ( -m) permissions for the user named bill  so that he now has read/\nwrite (rw) permissions to that file. Then she modified permissions for the group sales  so \nthat anyone belonging to that group would also have read/write permissions. Look at ls \n-l and getfacl  output on that file now:\n[mary]$ ls -l /tmp/memo.txt\n-rw-rw-r--+ 1 mary mary 0 Jan 21 09:27 /tmp/memo.txt\n[mary]$ getfacl /tmp/memo.txt\n# file: tmp/memo.txt\n# owner: mary\n# group: mary\nuser::rw-\nuser:bill:rw-\ngroup::rw-\ngroup:sales:rw-\nmask::rw-\nother::r--\nFrom the ls -l  output, notice the plus sign ( +) in the rw-rw-r--+  output. The plus sign \nindicates that ACLs are set on the file, so you know to run the getfacl  command to see \nhow ACLs are set. The output shows mary  as owner and group (same as what you see with \nls -l ), the regular user permissions ( rw-), and permissions for ACL user bill  (rw-). The \nsame is true for group permissions and permissions for the group sales . Other permis -\nsions are r-- .\nThe mask line (near the end of the previous getfacl  example) requires some special dis -\ncussion. As soon as you set ACLs on a file, the regular group permission on the file sets a \nmask of the maximum permission an ACL user or group can have on a file. So, even if you \nprovide an individual with more ACL permissions than the group permissions allow, the \nindividual\u2019s effective permissions do not exceed the group permissions as in the follow -\ning example:\n[mary]$ chmod 644 /tmp/memo.txt\n[mary]$ getfacl /tmp/memo.txt\n# file: tmp/memo.txt\n# owner: mary\n# group: mary\nuser::rw-\nuser:bill:rw-   #effective:r--", "doc_id": "f787c4c4-ded4-4cf2-b8a1-25ac1be41c50", "embedding": null, "doc_hash": "be9a966fb548fae043f03f012222d5c82b1e657abe6b1b7f711fe48d67d749fc", "extra_info": {"page_label": "290"}, "node_info": {"start": 0, "end": 2082}, "relationships": {"1": "1dbbbfda-1860-434a-8da1-0055df485e7b"}}, "__type__": "1"}, "b828da60-ac94-43cb-99f8-226e1d029b9c": {"__data__": {"text": "Part III: Becoming a Linux System Administrator264group::rw-      #effective:r--\ngroup:sales:rw- #effective:r--\nmask::r--\nother::r--\nNotice in the preceding example that even though the user bill  and group sales  have \nrw- permissions, their effective permissions are r-- . So, bill  or anyone in sales  would \nnot be able to change the file unless mary  were to open permissions again (for example, by \ntyping chmod 664 /tmp/memo.txt ).\nSetting default ACLs\nSetting default ACLs on a directory enables your ACLs to be inherited. This means that \nwhen new files and directories are created in that directory, they are assigned the same \nACLs. To set a user or group ACL permission as the default, you add a d:  to the user or \ngroup designation. Consider the following example:\n[mary]$ mkdir /tmp/mary\n[mary]$ setfacl -m d:g:market:rwx /tmp/mary/\n[mary]$ getfacl /tmp/mary/\n# file: tmp/mary/\n# owner: mary\n# group: mary\nuser::rwx\ngroup::rwx\nother::r-x\ndefault:user::rwx\ndefault:group::rwx\ndefault:group:sales:rwx\ndefault:group:market:rwx\ndefault:mask::rwx\ndefault:other::r-x\n \nTo make sure that the default ACL worked, create a subdirectory. Then run getfacl again. \nYou will see that default lines are added for user, group, mask, and other, which are inher -\nited from the directory's ACLs:\n[mary]$ mkdir /tmp/mary/test\n[mary]$ getfacl /tmp/mary/test\n# file: tmp/mary/test\n# owner: mary\n# group: mary\nuser::rwx\ngroup::rwx\ngroup:sales:rwx\ngroup:market:rwx\nmask::rwx\nother::r-x", "doc_id": "b828da60-ac94-43cb-99f8-226e1d029b9c", "embedding": null, "doc_hash": "ca8238c9a19f5e80f7f4107c11fb4e531e0eb668e5c5ae2f2febb54c86d45cdf", "extra_info": {"page_label": "291"}, "node_info": {"start": 0, "end": 1478}, "relationships": {"1": "b78dc95d-08de-4c07-abd8-d2c7dede22c0"}}, "__type__": "1"}, "de216f62-6959-4f50-bd36-09d359106cfd": {"__data__": {"text": "Chapter 11: Managing User Accounts\n265\n11default:user::rwx\ndefault:group::rwx\ndefault:group:sales:rwx\ndefault:group:market:rwx\ndefault:mask::rwx\ndefault:other::r-x\nNotice that when you create a file in that directory, the inherited permissions are different. \nBecause a regular file is created without execute permission, the effective permission is \nreduced to rw- :\n[mary@cnegus ~]$ touch /tmp/mary/file.txt\n[mary@cnegus ~]$ getfacl /tmp/mary/file.txt\n# file: tmp/mary/file.txt\n# owner: mary\n# group: mary\nuser::rw-\ngroup::rwx         #effective:rw-\ngroup:sales:rwx    #effective:rw-\ngroup:market:rwx   #effective:rw-\nmask::rw-\nother::r--\nEnabling ACLs\nIn recent Fedora and RHEL systems, xfs and ext filesystem types (ext2, ext3, and ext4) are \nautomatically created with ACL support. On other Linux systems, or on filesystems created \non other Linux systems, you can add the acl  mount option in several ways:\n\u25a0\u25a0Add the acl  option to the fifth field in the line in the /etc/fstab  file that auto -\nmatically mounts the filesystem when the system boots up.\n\u25a0\u25a0Implant the acl  line in the Default mount options  field in the filesystem\u2019s \nsuper block, so that the acl  option is used whether the filesystem is mounted \nautomatically or manually.\n\u25a0\u25a0Add the acl  option to the mount  command line when you mount the filesystem \nmanually with the mount  command.\nKeep in mind that in Fedora and Red Hat Enterprise Linux systems, you only have to add \nthe acl  mount option to those filesystems that were created elsewhere. The anaconda \ninstaller automatically adds ACL support to every filesystem it creates during install time \nand mkfs  adds acl  to every filesystem you create with that tool. To check that the acl  \noption has been added to an ext filesystem, determine the device name associated with the \nfilesystem, and run the tune2fs -l  command to view the implanted mount options, as in \nthis example:\n# mount | grep home\n/dev/mapper/mybox-home on /home type ext4 (rw)\n# tune2fs -l /dev/mapper/mybox-home | grep \"mount options\"\nDefault mount options:    user_xattr acl", "doc_id": "de216f62-6959-4f50-bd36-09d359106cfd", "embedding": null, "doc_hash": "9d344eb806fc4de41af814e98525e3371be56f937cbb2453650646ae0ea21af9", "extra_info": {"page_label": "292"}, "node_info": {"start": 0, "end": 2079}, "relationships": {"1": "b22b1749-1cb4-42ee-bf35-7352660aee81"}}, "__type__": "1"}, "2777637a-840a-47da-ad94-b6e4bf219e4d": {"__data__": {"text": "Part III: Becoming a Linux System Administrator266First, I typed the mount  command to see a list of all filesystems that are currently \nmounted, limiting the output by grepping for the word home  (because I was looking for \nthe filesystem mounted on /home ). After I saw the filesystem\u2019s device name, I used it as \nan option to tune2fs -l  to find the default mount options line. There, I could see that \nmount options user _ xattr  (for extended attributes such as SELinux) and acl  were both \nimplanted in the filesystem super block so that they would be used when the filesystem \nwas mounted.\nIf the Default mount options  field is blank (such as when you have just created a \nnew filesystem), you can add the acl  mount option using the tune2fs -o  command. For \nexample, on a different Linux system, I created a filesystem on a removable USB drive that \nwas assigned as the /dev/sdc1  device. To implant the acl  mount option and check that it \nis there, I ran the following commands:\n# tune2fs -o acl /dev/sdc1\n# tune2fs -l /dev/sdc1 | grep \"mount options\"\nDefault mount options:    acl\nYou can test that this worked by remounting the filesystem and trying to use the setfacl  \ncommand on a file in that filesystem.\nA second way to add acl  support to a filesystem is to add the acl  option to the line in the \n/etc/fstab  file that automatically mounts the filesystem at boot time. The following is \nan example of what a line would look like that mounts the ext4 filesystem located on the /\ndev/sdc1  device to the /var/stuff  directory:\n/dev/sdc1     /var/stuff      ext4    acl        1 2\nInstead of the defaults  entry in the fourth field, I added acl . If there were already \noptions set in that field, add a comma after the last option and add acl . The next time the \nfilesystem is mounted, ACLs are enabled. If the filesystem were already mounted, I could \ntype the following mount  command as root to remount the filesystem using acl  or any \nother values added to the /etc/fstab  file:\n# mount -o remount /dev/sdc1\nA third way that you can add ACL support to a filesystem is to mount the filesystem by \nhand and specifically request the acl  mount option. So, if there were no entry for the \nfilesystem in the /etc/fstab  file, after creating the mount point ( /var/stuff ), type the \nfollowing command to mount the filesystem and include ACL support:\n# mount -o acl /dev/sdc1 /var/stuff\nKeep in mind that the mount  command only mounts the filesystem temporarily. When  \nthe system reboots, the filesystem is not mounted again, unless you add an entry to the  \n/etc/fstab  file.", "doc_id": "2777637a-840a-47da-ad94-b6e4bf219e4d", "embedding": null, "doc_hash": "06652f43c8ac068d79a5cbeaffae4b6fd7901cb0c50ccf581b549b14a7d9189c", "extra_info": {"page_label": "293"}, "node_info": {"start": 0, "end": 2596}, "relationships": {"1": "31566a4e-4573-4055-824b-ba70dc65ef5e"}}, "__type__": "1"}, "1c9934a7-c713-4e3b-9214-a9247c72fff1": {"__data__": {"text": "Chapter 11: Managing User Accounts\n267\n11Adding directories for users to collaborate\nA special set of three permission bits are typically ignored when you use the chmod  \ncommand to change permissions on the filesystem. These bits can set special permissions \non commands and directories. The focus of this section is setting the bits that help you \ncreate directories to use for collaboration.\nAs with read, write, and execute bits for user , group , and other , these special file per -\nmission bits can be set with the chmod  command. If, for example, you run chmod 775 /\nmnt/xyz , the implied permission is actually 0775 . To change permissions, you can replace \nthe number 0 with any combination of those three bits (4, 2, and 1), or you can use letter \nvalues instead. (Refer to Chapter\u00a04, \u201cMoving Around the Filesystem,\u201d if you need to be \nreminded about how permissions work.) The letters and numbers are shown in Table\u00a011.1.\nThe bits in which you are interested for creating collaborative directories are the set group \nID bit (2) and sticky bit (1). If you are interested in other uses of the set user ID and set \ngroup ID bits, refer to the sidebar \u201cUsing Set UID and Set GID Bit Commands.\u201d\nCreating group collaboration directories (set GID bit)\nWhen you create a set GID directory, any files created in that directory are assigned to the \ngroup assigned to the directory itself. The idea is to have a directory where all members of \na group can share files but still protect them from other users. Here\u2019s a set of steps for cre -\nating a collaborative directory for all users in the group I created called sales :\n1. Create a group to use for collaboration:\n# groupadd -g 301 sales\n2. Add to the group some users with which you want to be able to share files (I \nused mary ):\n# usermod -aG sales mary\n3. Create the collaborative directory:\n# mkdir /mnt/salestoolsTABLE 11.1  Commands to Create and Use Files\nName Numeric value Letter value\nSet user ID bit 4 u+s\nSet group ID bit 2 g+s\nSticky bit 1 o+t", "doc_id": "1c9934a7-c713-4e3b-9214-a9247c72fff1", "embedding": null, "doc_hash": "81f4d94b6899d759e1eaae941d71cd81d33171ef4fa83c073cc321f021a67d83", "extra_info": {"page_label": "294"}, "node_info": {"start": 0, "end": 2013}, "relationships": {"1": "4cd39dfd-644b-420e-9fa0-0116e032ee3f"}}, "__type__": "1"}, "ab3b88ef-de2e-47c6-9d87-c479121dfb76": {"__data__": {"text": "Part III: Becoming a Linux System Administrator2684. Assign the group sales  to the directory:\n        # chgrp sales /mnt/salestools\n5. Change the directory permission to 2775. This turns on the set group ID bit (2), full \nrwx for the user  (7), rwx  for group  (7), and r-x  (5) for other :\n        # chmod 2775 /mnt/salestools\n6. Become mary  (run su - mary ). As mary , create a file in the shared directory and \nlook at the permissions. When you list permissions, you can see that the directory \nis a set GID directory because a lowercase s  appears where the group execute per -\nmission should be ( rwxrwsr-x):\n        # su - mary\n        [mary]$ touch /mnt/salestools/test.txt\n        [mary]$ ls -ld /mnt/salestools/ /mnt/salestools/test.txt\n        drwxrwsr-x. 2 root sales 4096 Jan 22 14:32 /mnt/salestools/\n        -rw-rw-r--. 1 mary sales    0 Jan 22 14:32 /mnt/salestools/test.txt\nTypically, a file created by mary  would have the group mary  assigned to it. But because \ntest.txt  was created in a set group ID bit directory, the file is assigned to the sales  \ngroup. Now, anyone who belongs to the sales  group can read from or write to that file, \nbased on group permissions.\nCreating restricted deletion directories (sticky bit)\nA restricted deletion directory  is created by turning on a directory\u2019s sticky bit. What makes a \nrestricted deletion directory different than other directories? Normally, if write permission Using Set UID and Set GID Bit Commands\nThe set UID and set GID bits are used on special executable files that allow commands set to be run \ndifferently than most. Normally, when a user runs a command, that command runs with that user\u2019s per -\nmissions. In other words, if I run the vi  command as chris , that instance of the vi  command would \nhave the permissions to read and write files that the user chris  could read and write.\nCommands with the set UID or set GID bits set are different. It is the owner and group assigned to \nthe command, respectively, that determines the permissions the command has to access resources \non the computer. So, a set UID command owned by root would run with root permissions; a set GID \ncommand owned by apache would have apache group permissions.\nExamples of applications that have set UID bits turned on are the su  and newgrp  commands. In both \nof those cases, the commands must be able to act as the root user to do their jobs. However, to actu -\nally get root permissions, a user must provide a password. You can tell su  is a set UID bit command \nbecause of the s  where the first execute bit ( x) usually goes:\n    $ ls /bin/su\n    -rwsr-xr-x. 1 root root  30092 Jan 30 07:11 su", "doc_id": "ab3b88ef-de2e-47c6-9d87-c479121dfb76", "embedding": null, "doc_hash": "0f49ee5c8d54bdf3d4e7994c941b48a589038189a482db607074719f756ad252", "extra_info": {"page_label": "295"}, "node_info": {"start": 0, "end": 2661}, "relationships": {"1": "a788d5fc-39b3-4bd1-a1f2-514e2a2a46e4"}}, "__type__": "1"}, "c9a04133-9102-4c7e-bed8-0ddbbcdd2f5e": {"__data__": {"text": "Chapter 11: Managing User Accounts\n269\n11is open to a user on a file or directory, that user can delete that file or directory. However, \nin a restricted deletion directory, unless you are the root user or the owner of the direc -\ntory, you can never delete another user\u2019s files.\nTypically, a restricted deletion directory is used as a place where lots of different users can \ncreate files. For example, the /tmp  directory is a restricted deletion directory:\n$ ls -ld /tmp\ndrwxrwxrwt. 116 root root 36864 Jan 22 14:18 /tmp\nYou can see that the permissions are wide open, but instead of an x  for the execute bit for \nother , the t  indicates that the sticky bit is set. The following is an example of creating a \nrestricted deletion directory with a file that is wide open for writing by anyone:\n[mary]$ mkdir /tmp/mystuff\n[mary]$ chmod 1777 /tmp/mystuff\n[mary]$ cp /etc/services /tmp/mystuff/\n[mary]$ chmod 666 /tmp/mystuff/services\n[mary]$ ls -ld /tmp/mystuff /tmp/mystuff/services\ndrwxrwxrwt. 2 mary mary   4096 Jan 22 15:28 /tmp/mystuff/\n-rw-rw-rw-. 1 mary mary 640999 Jan 22 15:28 /tmp/mystuff/services\nWith permissions set to 1777  on the /tmp/mystuff  directory, you can see that all per -\nmissions are wide open, but a t  appears instead of the last execute bit. With the /tmp/\nmystuff/services  file open for writing, any user could open it and change its con -\ntents. However, because the file is in a sticky bit directory, only root and mary  can delete \nthat file.\nCentralizing User Accounts\nAlthough the default way of authenticating users in Linux is to check user information \nagainst the /etc/passwd  file and passwords from the /etc/shadow  file, you can authen -\nticate in other ways as well. In most large enterprises, user account information is stored in \na centralized authentication server, so each time you install a new Linux system, instead of \nadding user accounts to that system, you have the Linux system query the authentication \nserver when someone tries to log in.\nAs with local passwd /shadow  authentication, configuring centralized authentication \nrequires that you provide two types of information: account information (username, user/\ngroup IDs, home directory, default shell, and so on) and authentication method (different \ntypes of encrypted passwords, smart cards, retinal scans, and so on). Linux provides ways \nof configuring those types of information.\nAuthentication domains that are supported via the authconfig  command include LDAP, \nNIS, and Windows Active Directory.", "doc_id": "c9a04133-9102-4c7e-bed8-0ddbbcdd2f5e", "embedding": null, "doc_hash": "b47c1d6c747afa253083eee89159e984451a5b505a394bcca111bd620d95e1d7", "extra_info": {"page_label": "296"}, "node_info": {"start": 0, "end": 2517}, "relationships": {"1": "0a10260f-78be-4219-9687-9290ca269631"}}, "__type__": "1"}, "35a487e0-6605-436e-b0d7-3fc5852d2c46": {"__data__": {"text": "Part III: Becoming a Linux System Administrator270Supported centralized database types include the following:\nLDAP  The Lightweight Directory Access Protocol (LDAP) is a popular protocol for provid -\ning directory services (such as phone books, addresses, and user accounts). It is an \nopen standard that is configured in many types of computing environments.\nNIS The Network Information Service (NIS)  was originally created by Sun Microsystems \nto propagate information such as user accounts, host configuration, and other types \nof system information across many UNIX systems. Because NIS passes information \nin clear text, most enterprises now use the more secure LDAP or Winbind protocols \nfor centralized authentication.\nWinbind  Selecting Winbind  from the Authentication Configuration window enables \nyou to authenticate your users against a Microsoft Active Directory (AD) server. \nMany large companies extend their desktop authentication setup to do server con -\nfiguration as well as using an AD server.\nIf you are looking into setting up your own centralized authentication services and you \nwant to use an open-source project, I recommend looking into the 389 Directory Server \n(https://directory.fedoraproject.org/ ). Fedora and other Linux systems offer this \nenterprise-quality LDAP server.\nSummary\nHaving separate user accounts is the primary method of setting secure boundaries between \nthe people who use your Linux system. Regular users typically can control the  \nfiles and directories within their own home directories but very little outside of those \ndirectories.\nIn this chapter, you learned how to add user and group accounts, how to modify them,  \nand even how to extend user and group accounts beyond the boundaries of the local  \n/etc/passwd  file. You also learned that authentication can be done by accessing  \ncentralized LDAP servers.\nThe next chapter introduces another basic topic needed by Linux system administrators: \nhow to manage disks. In that chapter, you learn how to partition disks, add filesystems, \nand mount them so the contents of the disk partitions are accessible to those using your \nsystem.\nExercises\nUse these exercises to test your knowledge of adding and managing user and group \naccounts in Linux. These tasks assume that you are running a Fedora or Red Hat Enterprise \nLinux system (although some tasks work on other Linux systems as well). If you are stuck, \nsolutions to the tasks are shown in Appendix B (although in Linux, you often have multiple \nways to complete a task).", "doc_id": "35a487e0-6605-436e-b0d7-3fc5852d2c46", "embedding": null, "doc_hash": "ba6f6b2a89c1b189584097d08ebccde442168f28603ae2b18da667ef8c43ff7a", "extra_info": {"page_label": "297"}, "node_info": {"start": 0, "end": 2535}, "relationships": {"1": "1b731b72-f980-4709-88e6-e6f12b0ebeec"}}, "__type__": "1"}, "74820e9c-3430-41bf-8f2f-e4208cb51c7b": {"__data__": {"text": "Chapter 11: Managing User Accounts\n271\n111. Add a local user account to your Linux system that has a username of jbaxter  \nand a full name of John Baxter and that uses /bin/sh  as its default shell. Let the \nUID be assigned by default. Set the password for jbaxter  to: My1N1te0ut!\n2. Create a group account named testing  that uses group ID 315.\n3. Add jbaxter  to the testing  group and the bin group.\n4. Open a shell as jbaxter  (either a new login session or using a current shell) and \ntemporarily have the testing  group be your default group so that when you \ntype touch /home/jbaxter/file.txt , the testing  group is assigned as the \nfile\u2019s group.\n5. Note what user ID has been assigned to jbaxter , and delete the user account \nwithout deleting the home directory assigned to jbaxter .\n6. Find any files in the /home  directory (and any subdirectories) that are assigned to \nthe user ID that recently belonged to the user named jbaxter .\n7. Copy the /etc/services  file to the default skeleton directory so that it  \nshows up in the home directory of any new user. Then add a new user to the  \nsystem named mjones , with a full name of Mary Jones and a home directory of  \n/home/maryjones .\n8. Find all files under the /home  directory that belong to mjones . Are there any files \nowned by mjones  that you didn\u2019t expect to see?\n9. Log in as mjones , and create a file called /tmp/maryfile.txt . Using ACLs, assign \nthe bin  user read/write permission to that file. Then assign the lp  group read/\nwrite permission to that file.\n10. Still as mjones , create a directory named /tmp/mydir . Using ACLs, assign  \ndefault permissions to that directory so that the adm  user has read/write/execute \npermission to that directory and any files or directories created in it. Create the  \n/tmp/mydir/testing/  directory and /tmp/mydir/newfile.txt  file, and make \nsure that the adm  user was also assigned full read/write/execute permissions. \n(Note that despite rwx  permission being assigned to the adm  user, the effective \npermission on newfile.txt  is only rw . What could you do to make sure that adm  \ngets execute permission as well?)", "doc_id": "74820e9c-3430-41bf-8f2f-e4208cb51c7b", "embedding": null, "doc_hash": "1f3e3d38ea07f69b0178c87e6c1638657ec2b097634831a1c795da32fc8569d5", "extra_info": {"page_label": "298"}, "node_info": {"start": 0, "end": 2142}, "relationships": {"1": "59e5af05-c95d-4f34-b605-14a9870a7512"}}, "__type__": "1"}, "05a9f93f-8788-43e2-aebf-ee032e90f9bc": {"__data__": {"text": "273\nCHAPTER12\nManaging Disks and Filesystems\nIN THIS CHAPTER\nWorking with shell scripts\nCreating logical volumes with LVM\nAdding filesystems\nMounting filesystems\nUnmounting filesystems\nYour operating system, applications, and data all need to be kept on some kind of permanent \nstorage so that when you turn your computer off and then on again, it is all still there. Tra -\nditionally, that storage has been provided by a hard disk in your computer. To organize the \ninformation on that disk, the disk is usually divided into partitions, with most partitions given a \nstructure referred to as a filesystem.\nThis chapter describes how to work with hard drives. Hard drive tasks include partitioning, adding \nfilesystems, and managing those filesystems in various ways. Storage devices that are attached to the \nsystems such as removable devices, including hard disk drives (HDDs) and solid-state drives (SSDs), \nand network devices can be partitioned and managed in the same ways.\nAfter covering basic partitions, I describe how Logical Volume Manager (LVM) can be used to make it \neasier to grow, shrink, and otherwise manage filesystems more efficiently.\nUnderstanding Disk Storage\nThe basics of how data storage works are the same in most modern operating systems. When you \ninstall the operating system, the disk is divided into one or more partitions. Each partition is for -\nmatted with a filesystem. In the case of Linux, some of the partitions may be specially formatted \nfor elements such as swap area or LVM physical volumes. Disks are used for permanent storage; \nrandom access memory (RAM) and swap are used for temporary storage. For example, when you run \na command, that command is copied from the hard disk into RAM so that your computer processor \n(CPU) can access it more quickly.\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "05a9f93f-8788-43e2-aebf-ee032e90f9bc", "embedding": null, "doc_hash": "ec7a649b4f5e93f76fe4d0094b38c616386439cf1661d91ac85415a00601ca7b", "extra_info": {"page_label": "299"}, "node_info": {"start": 0, "end": 1920}, "relationships": {"1": "b6ffd4cf-0db4-4dc8-87e5-da0c6e17eb4e"}}, "__type__": "1"}, "c93f14c6-6d02-4c1f-8ca7-ff19d0a1f56b": {"__data__": {"text": "Part III: Becoming a Linux System Administrator274Your CPU can access data much faster from RAM than it can from a hard disk, although \nSSDs are more like RAM than HDDs. However, a disk is usually much larger than RAM, RAM \nis much more expensive, and RAM is erased when the computer reboots. Think of your \noffice as a metaphor for RAM and disk. A disk is like a file cabinet where you store folders \nof information you need. RAM is like the top of your desk, where you put the folder of \npapers while you are using it but put it back in the file cabinet when you are not.\nIf RAM fills up by running too many processes or a process with a memory leak, new processes \nfail if your system doesn\u2019t have a way to extend system memory. That\u2019s where a swap area \ncomes in. A swap space is a hard disk swap partition or a swap file where your computer can \n\u201cswap out\u201d data from RAM that isn\u2019t being used at the moment and then \u201cswap in\u201d the data \nback to RAM when it is again needed. Although it is better never to exceed your RAM (perfor -\nmance takes a hit when you swap), swapping out is better than having processes just fail.\nAnother special partition is a Logical Volume Manager (LVM) physical volume. LVM physi-\ncal volumes enable you to create pools of storage space called volume groups . From those \nvolume groups, you have much more flexibility for growing and shrinking logical volumes \nthan you have resizing disk partitions directly.\nFor Linux, at least one disk partition is required, assigned to the root (/)  of the entire \nLinux filesystem. However, it is more common to have separate partitions that are assigned \nto particular directories, such as /home , /var , and/or /tmp . Each of the partitions is con -\nnected to the larger Linux filesystem by mounting it to a point in the filesystem where you \nwant that partition to be used. Any file added to the mount point directory of a partition, \nor a subdirectory, is stored on that partition.\nThe business of connecting disk partitions to the Linux filesystem is done automatically \nand invisibly to the end user. How does this happen? Each regular disk partition created \nwhen you install Linux is associated with a device name. An entry in the /etc/fstab  \nfile tells Linux each partition\u2019s device name and where to mount it (as well as other bits of \ninformation). The mounting is done when the system boots.\nMost of this chapter focuses on understanding how your computer\u2019s disk is partitioned and \nconnected to form your Linux filesystem as well as how to partition disks, format filesys -\ntems and swap space, and have those items used when the system boots. The chapter then \ncovers how to do partitioning and filesystem creation manually.Note\nThe word mount  refers to the action of connecting a filesystem from a hard disk, USB drive, or network storage \ndevice to a particular point in the filesystem. This action is done using the mount  command, along with options to \ntell the command where the storage device is located and to which directory in the filesystem to connect it.", "doc_id": "c93f14c6-6d02-4c1f-8ca7-ff19d0a1f56b", "embedding": null, "doc_hash": "c858a31df1a93b5fb0e24a815396db26329d0cab0931ed461df108e1fa4cd72f", "extra_info": {"page_label": "300"}, "node_info": {"start": 0, "end": 3053}, "relationships": {"1": "c55b5193-70ae-4700-8a97-9b507c524504"}}, "__type__": "1"}, "62a8324f-549e-45bb-acf2-fc2ec2ef0e54": {"__data__": {"text": "Chapter 12: Managing Disks and Filesystems\n275\n12Partitioning Hard Disks\nLinux provides several tools for managing your hard disk partitions. You need to know how \nto partition your disk if you want to add a disk to your system or change your existing disk \nconfiguration.\nThe following sections demonstrate disk partitioning using a removable USB flash drive and \na fixed hard disk. To be safe, I use a USB flash drive that doesn\u2019t contain any data that I \nwant to keep in order to practice partitioning.\nUnderstanding partition tables\nPC architecture computers have traditionally used Master Boot Record (MBR) partition  tables \nto store information about the sizes and layouts of the hard disk partitions. There are Coming from Windows\nFilesystems are organized differently in Linux than they are in Microsoft Windows operating systems. \nInstead of drive letters (for example, A:, B:, C:) for each local disk, network filesystem, CD-ROM, or \nother type of storage medium, everything fits neatly into the Linux directory structure.\nSome drives are connected (mounted) automatically into the filesystem when you insert removable \nmedia. For example, a CD might be mounted on /media/cdrom . If the drive isn\u2019t mounted automat -\nically, it is up to an administrator to create a mount point in the filesystem and then connect the disk \nto that point.\nLinux can understand VFAT filesystems, which are often the default format when you buy a USB \nflash drive. A VFAT and exFAT USB flash drive provides a good way to share data between Linux and \nWindows systems. Linux kernel support is available for NTFS filesystems, which are usually used with \nWindows these days. However, NTFS, and sometimes exFAT, often require that you install additional \nkernel drivers in Linux.\nVFAT file systems are often used when files need to be exchanged between different types of operating \nsystems. Because VFAT was used in MS-DOS and early Windows operating systems, it offers a good \nlowest common denominator for sharing files with many types of systems (including Linux). NTFS is \nthe file system type most commonly used with modern Microsoft Windows systems.\nChanging partitioning can make a system \nunbootable!\nI don\u2019t recommend using your system\u2019s primary hard disk to practice changing partitioning because \na mistake can make your system unbootable. Even if you use a separate USB flash drive to practice, \na bad entry in /etc/fstab  can hang your system on reboot. If after changing partitions your system \nfails to boot, refer to Chapter\u00a021, \u201cTroubleshooting Linux,\u201d for information on how to fix the problem.", "doc_id": "62a8324f-549e-45bb-acf2-fc2ec2ef0e54", "embedding": null, "doc_hash": "a97b396b9b400b607d933fb7a462374ef3d26d5c52b4cb6d1f18372766dbdb88", "extra_info": {"page_label": "301"}, "node_info": {"start": 0, "end": 2601}, "relationships": {"1": "e7b8e214-0f3f-4003-b606-1204c9918a19"}}, "__type__": "1"}, "ec16935f-b39a-419e-b676-af793741891a": {"__data__": {"text": "Part III: Becoming a Linux System Administrator276many tools for managing MBR partitions that are quite stable and well known. A few years \nago, however, a new standard called Globally Unique Identifier (GUID) partition tables began \nbeing used on systems as part of the UEFI computer architecture to replace the older BIOS \nmethod of booting the system.\nMany Linux partitioning tools have been updated to handle GUID partition tables (gpt). \nOther tools for handling GUID partition tables have been added. Because the popular \nfdisk  command does not support gpt partitions, the parted  command is used to illus -\ntrate partitioning in this chapter.\nLimitations imposed by the MBR specification brought about the need for GUID partitions. \nIn particular, MBR partitions are limited to 2TB in size. GUID partitions can create parti-\ntions up to 9.4ZB (zettabytes).\nViewing disk partitions\nTo view disk partitions, use the parted  command with the -l  option. The following is an \nexample of partitioning on a 160GB fixed hard drive on a Red Hat Enterprise Linux 8 system:\n# parted -l /dev/sda\nDisk /dev/sda: 160.0 GB, 160000000000 bytes, 312500000 sectors\nUnits = sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisk label type: dos\nDisk identifier: 0x0008870c\n   Device Boot      Start         End      Blocks   Id  System\n/dev/sda1   *        2048     1026047      512000   83  Linux\n/dev/sda2         1026048   304281599   151627776   8e  Linux LVM\nWhen a USB flash drive is inserted, it is assigned to the next available sd  device. The fol -\nlowing example shows the partitioning on the hard drive ( /dev/sda ) and a USB drive from \na Fedora 30 system, where /dev/sdb  is assigned as the USB device name (the second disk \non the system). This USB drive is a new 128GB USB flash drive:\n# fdisk -l /dev/sdb\nAlthough this drive was assigned to /dev/sdb , your drive might be assigned to a different \ndevice name. Here are some things to look for:\n\u25a0\u25a0A SCSI or USB storage device, represented by an sd?  device (such as sda , sdb , \nsdc, and so on) can have up to 16 minor devices (for example, the main /dev/sdc  \ndevice and /dev/sdc1  through /dev/sdc15 ). So, there can be 15 partitions total. \nA NVMe SSD storage device, represented by a nvme  device (such as nvme0 , nvme1 , \nnvme2 , and so on) can be divided into one or more namespaces (most devices just \nuse the first namespace) and partitions. For example, /dev/nvme0n1p1  represents \nthe first partition in the first namespace on the first NVMe SSD.\n\u25a0\u25a0For x86 computers, disks can have up to four primary partitions. So, to have more \nthan four total partitions, one must be an extended partition. Any partitions ", "doc_id": "ec16935f-b39a-419e-b676-af793741891a", "embedding": null, "doc_hash": "679cf3775c8ea0cc0014a07ea00356331e6c80b4f4da1c5f3c9116b9c9800e1f", "extra_info": {"page_label": "302"}, "node_info": {"start": 0, "end": 2761}, "relationships": {"1": "49efdd10-018e-4fac-b840-63e5b5a4d329"}}, "__type__": "1"}, "9e15c98e-1e73-4f96-a994-ef55e37faa7e": {"__data__": {"text": "Chapter 12: Managing Disks and Filesystems\n277\n12beyond the four primary partitions are logical partitions that use space from the \nextended partition.\n\u25a0\u25a0The id  field indicates the type of partition. Notice that there is a Linux LVM parti-\ntion in the first example.\nYour first primary hard disk usually appears as /dev/sda . With RHEL and Fedora installa -\ntions, there is usually at least one LVM partition created by the installer, out of which other \npartitions can be assigned. So, the output of fdisk  might be as simple as the following:\n# parted -l\nDisk /dev/sda: 500.1 GB, 500107862016 bytes\nThe first partition is roughly 210MB and is mounted on the /boot/efi  directory. The sec -\nond partition (1074MB) is mounted on the /boot  partition. For older MBR partition tables, \nthere is only a /boot  partition. The boot  under the Flags column indicates that the parti-\ntion is bootable. The rest of the disk is consumed by the LVM partition, which is ultimately \nused to create logical volumes.\nFor the moment, I recommend that you leave the hard disk alone and find a USB flash drive \nthat you do not mind erasing. You can try the commands I demonstrate on that drive.\nCreating a single-partition disk\nTo add a new storage medium (hard disk, USB flash drive, or similar device) to your com-\nputer so that it can be used by Linux, you first need to connect the disk device to your \ncomputer and then partition the disk. Here\u2019s the general procedure:\n1. Install the new hard drive or insert the new USB flash drive.\n2. Partition the new disk.\n3. Create the filesystems on the new disk.\n4. Mount the filesystems.\nThe easiest way to add a disk or flash drive to Linux is to have the entire disk devoted to a \nsingle Linux partition. You can have multiple partitions, however, and assign them each to \ndifferent types of filesystems and different mount points if you like.\nThe following process takes you through partitioning a USB flash drive to be used for \nLinux that has only one partition. If you have a USB flash drive (any size) that you don\u2019t \nmind erasing, you can work through this procedure as you read. The section following this \ndescribes how to partition a disk with multiple partitions.\nWarNiNg\nIf you make a mistake partitioning your disk with parted , make sure that you correct that change. Unlike fdisk , \nwhere you could just type q to exit without saving your changes, parted  makes your changes immediately, so you \nare not able just to quit to abandon changes.", "doc_id": "9e15c98e-1e73-4f96-a994-ef55e37faa7e", "embedding": null, "doc_hash": "2ea9e987f0df51030bb014b5cf6d5629216234dfa7782030be7b09dbc549cb08", "extra_info": {"page_label": "303"}, "node_info": {"start": 0, "end": 2489}, "relationships": {"1": "b81240ec-12d8-4103-8614-6cb6cea0a065"}}, "__type__": "1"}, "a1c73952-c972-46e5-b5e2-dea429571bcb": {"__data__": {"text": "Part III: Becoming a Linux System Administrator2781. For a USB flash drive, just plug it into an available USB port. Going forward, I use a \n128GB USB flash drive, but you can get a USB flash drive of any size.\n2. Determine the device name for the USB drive. As root user from a shell, type the \nfollowing journalctl  command, and then insert the USB flash drive. Messages \nappear, indicating the device name of the drive you just plugged in (press Ctrl+C to \nexit the tail  command when you are finished):\n# journalctl -f\nkernel: usb 4-1: new SuperSpeed Gen 1 USB device number 3 using\nxhci_hcd\nkernel: usb 4-1: New USB device found, idVendor=0781, \nidProduct=5581, bcdDevice= 1.00\nkernel: usb 4-1: New USB device strings: Mfr=1, Product=2,\nSerialNumber=3\nkernel: usb 4-1: Product: Ultra\nkernel: usb 4-1: Manufacturer: SanDisk\n...\nkernel: sd 6:0:0:0: Attached scsi generic sg2 type 0\nkernel:  sdb: sdb1\nkernel: sd 6:0:0:0: [sdb] Attached SCSI removable disk\nudisksd[809]: Mounted /dev/sdb1 at /run/media/chris/7DEB-B010\non behalf of uid 1000\n3. From the output, you can see that the USB flash drive was found and assigned to /\ndev/sdb . (Your device name may be different.) It also contains a single formatted \npartition: sdb1 . Be sure you identify the correct disk or you could lose all data \nfrom disks you may want to keep!\n4. If the USB flash drive mounts automatically, unmount it. Here is how to find the \nUSB partitions in this example and unmount them:\n# mount | grep sdb\n/dev/sdb1 on /run/media...\n# umount /dev/sdb1\n5. Use the parted  command to create partitions on the USB drive. For example, if \nyou are formatting the second USB, SATA, or SCSI disk ( sdb), you can type the \nfollowing:\n# parted /dev/sdb\nGNU Parted 3.2\nUsing /dev/sdb\nWelcome to GNU Parted! Type 'help' to view a list of commands.\n(parted) \nNow you are in parted  command mode, where you can use the parted  single-\nletter command set to work with your partitions.", "doc_id": "a1c73952-c972-46e5-b5e2-dea429571bcb", "embedding": null, "doc_hash": "ac0b1d07f7e9db9fbc3b5a1a22ba20e13aee9fd5748c39291cc7adab0f96f673", "extra_info": {"page_label": "304"}, "node_info": {"start": 0, "end": 1946}, "relationships": {"1": "0f431ba6-5ec3-4617-9866-00ac10b68bdd"}}, "__type__": "1"}, "49ae2e3d-9f83-4c27-912c-38732e78bec7": {"__data__": {"text": "Chapter 12: Managing Disks and Filesystems\n279\n126. If you start with a new USB flash drive, it may have one partition that is entirely \ndevoted to a Windows-compatible filesystem (such as VFAT or fat32). Use p to \nview all partitions and rm  to delete the partition. Here\u2019s what it looked like when \nI did that:\n         (parted) p\n        Model: SanDisk Ultra (scsi)\n        Disk /dev/sdb: 123GB\n        Sector size (logical/physical): 512B/512B\n        Partition Table: msdos\n        Disk Flags: \n \n        Number  Start   End    Size   Type     File system  Flags\n        1      16.4kB  123GB  123GB  primary   fat32        lba\n         (parted) rm\n        Partition number? 1\n7. Relabel the disk as having a gpt partition table.\n          (parted) mklabel gpt\n           Warning: The existing disk label on /dev/sdb will be destroyed and all data\n        on this disk will be lost. Do you want to continue?\n        Yes/No? Yes\n          (parted) \n8. To create a new partition, type mkpart . You are prompted for the file system \ntype, then the start and end of the partition. This example names the parti-\ntion alldisk , uses xfs  as the file system type, starts the partition at 1M and \nends at 123GB:\n          (parted) mkpart\n        Partition name?  []? alldisk                                              \n        File system type?  [ext2]? xfs                                            \n        Start? 1                                                                  \n        End? 123GB \n9. Double-check that the drive is partitioned the way you want by pressing p . (Your \noutput will differ, depending on the size of your drive.)\n         (parted) p                                                                \n        Model: SanDisk Ultra (scsi)\n        Disk /dev/sdb: 123GB\n        Sector size (logical/physical): 512B/512B\n        Partition Table: gpt\n        Disk Flags: \n \n        Number  Start   End    Size   File system  Name     Flags\n         1      1049kB  123GB  123GB  xfs          alldisk \n ", "doc_id": "49ae2e3d-9f83-4c27-912c-38732e78bec7", "embedding": null, "doc_hash": "8f26ef978beca7f59ac39c48d245d38b3276b4a1459d6ebcde76eda5ae08ef14", "extra_info": {"page_label": "305"}, "node_info": {"start": 0, "end": 2025}, "relationships": {"1": "38cff964-089f-4afb-badb-822137d647ff"}}, "__type__": "1"}, "3aab36d4-bc51-4ac7-b76f-2ff9edd6fdc2": {"__data__": {"text": "Part III: Becoming a Linux System Administrator28010. Although the partitioning is done, the new partition is not yet ready to use. For \nthat, you have to create a filesystem on the new partition. To create a filesystem on \nthe new disk partition, use the mkfs  command. By default, this command creates \nan ext2  filesystem, which is usable by Linux. However, in most cases you want to \nuse a journaling filesystem (such as ext3, ext4, or xfs). To create an xfs filesystem \non the first partition of the second hard disk, type the following:\n        # mkfs -t xfs /dev/sdb1\n11. To be able to use the new filesystem, you need to create a mount point and mount \nit to the partition. Here is an example of how to do that. You then check to make \nsure that the mount succeeded.\n        # mkdir /mnt/test\n        # mount /dev/sdb1 /mnt/test\n        # df -h /mnt/sdb1\n        Filesystem         Size  Used Avail Use% Mounted on\n        /dev/sdb1          115G   13M  115G   1% /mnt/test\nThe df  command shows that /dev/sdb1  is mounted on /mnt/test  and that it \noffers about 115GB of disk space. The mount  command shows all mounted filesys -\ntems, but here I just list sdb1  to show that it is mounted.\nAny files or directories that you create later in the /mnt/test  directory, and any \nof its subdirectories, are stored on the /dev/sdb1  device.\n12. When you are finished using the drive, you can unmount it with the umount  \ncommand, after which you can safely remove the drive (see the description of the \numount  command later if this command fails):\n        # umount /dev/sdb1\n13. You don\u2019t usually set up a USB flash drive to mount automatically every time the \nsystem boots because it mounts automatically when you plug it in. But if you \ndecide that you want to do that, edit /etc/fstab  and add a line describing what \nand where to mount. Here is an example of a line you might add:\n        /dev/sdb1    /mnt/test      xfs    defaults    0 1\nIn this example, the partition ( /dev/sdb1 ) is mounted on the /mnt/test  direc -\ntory as an xfs  filesystem. The defaults  keyword causes the partition to be tip\nYou can use different commands, or options to this command, to create other filesystem types. For example, use \nmkfs.exfat  to create a VFAT filesystem, mkfs.msdos  for DOS, or mkfs.ext4  for the ext4 filesystem type. \nYou may want a VFAT or exFAT (available with Ubuntu) filesystem if you want to share files among Linux, Windows, and \nMac systems.", "doc_id": "3aab36d4-bc51-4ac7-b76f-2ff9edd6fdc2", "embedding": null, "doc_hash": "66c51a17cecc3554c6b1260b853e7969c5c5fd43833cc9fabf85811823205a20", "extra_info": {"page_label": "306"}, "node_info": {"start": 0, "end": 2461}, "relationships": {"1": "b1bdf9f0-8ac4-4210-bd21-64d4f3da3da9"}}, "__type__": "1"}, "b6b374c3-17ef-4cef-9cb9-4c6e01ce34d3": {"__data__": {"text": "Chapter 12: Managing Disks and Filesystems\n281\n12mounted at boot time. The number 0 tells the system not to back up files automat -\nically from this filesystem with the dump  command ( dump  is rarely used anymore, \nbut the field is here). The 1 in the last column tells the system to check the parti-\ntion for errors after a certain number of mounts.\nAt this point, you have a working, permanently mounted disk partition. The next section \ndescribes how to partition a disk that has multiple partitions.\nCreating a multiple-partition disk\nNow that you understand the basic process of partitioning a disk, adding a filesystem, and \nmaking that filesystem available (temporarily and permanently), it is time to try a more \ncomplex example. Taking that same 128GB USB flash drive, I ran the procedure described \nlater in this section to create multiple partitions on one disk.\nIn this procedure, I configure a Master Boot Record (MBR) partition to illustrate how extended \npartitions work and to use the older fdisk  command. I create two partitions of 5GB ( sdb1  \nand sdb2 ), two 3GB ( sdb3  and sdb5 ), and 4GB ( sdb6 ). The sdb4  device is an extended par -\ntition, which consumes all remaining disk space. Space from the sdb5  and sdb6  partitions is \ntaken from the extended partition. This leaves plenty of space to create new partitions.\nAs before, insert the USB flash drive and determine the device name (in my case, /dev/\nsdb). Also, be sure to unmount any partitions that mount automatically when you insert \nthe USB flash drive.\n1. I started this procedure by overwriting the USB drive with the dd  command ( dd \nif=/dev/zero of=/dev/sd <number> bs=1M count=100 ). This allowed me \nto start with a fresh master boot record. Please be careful to use the right drive \nnumber, or you could erase your operating system!\n2. Create six new partitions as follows.\n        # fdisk /dev/sdb\n        Welcome to fdisk (util-linux 2.33.2).\n         Changes will remain in memory only, until you decide to write them.\n        Be careful before using the write command.\n        Device does not contain a recognized partition table.\n        Created a new DOS disklabel with disk identifier 0x8933f665.tip\nWhen you indicate the size of each partition, type the plus sign and the number of megabytes or gigabytes you want \nto assign to the partition. For example, +1024M  to create a 1024-megabyte partition or +10G  for a 10-gigabyte \npartition. Be sure to remember the plus sign ( +) and the M or G ! If you forget the M or G , fdisk  thinks you mean \nsectors and you get unexpected results.", "doc_id": "b6b374c3-17ef-4cef-9cb9-4c6e01ce34d3", "embedding": null, "doc_hash": "be4d460bde7f3b7e06757f627e9923f271fc463d5efab8b789d1cb540bc6d78c", "extra_info": {"page_label": "307"}, "node_info": {"start": 0, "end": 2587}, "relationships": {"1": "1e678764-6328-4e6f-9960-fc433b8b2095"}}, "__type__": "1"}, "fa0e15f6-28a9-4342-81a8-65544201741d": {"__data__": {"text": "Part III: Becoming a Linux System Administrator282        Command (m for help): n\n        Partition type\n           p   primary (0 primary, 0 extended, 4 free)\n           e   extended (container for logical partitions)\n        Select (default p): p\n        Partition number (1-4, default 1): 1\n        First sector (2048-240254975, default 2048): \n        Last sector, +/-sectors or +/-size{K,M,G,T,P} (2048-\n240254975, default 240254975): +5G\n        Created a new partition 1 of type 'Linux' and of size 5 GiB.\n        Command (m for help): n\n        Partition type\n           p   primary (1 primary, 0 extended, 3 free)\n           e   extended (container for logical partitions)\n        Select (default p): p\n        Partition number (2-4, default 2): 2\n        First sector (10487808-240254975, default 10487808): \n        Last sector, +/-sectors or +/-size{K,M,G,T,P} (10487808-\n240254975, default 240254975): +5G\n        Created a new partition 2 of type 'Linux' and of size 5 GiB.\n        Command (m for help): n\n        Partition type\n           p   primary (2 primary, 0 extended, 2 free)\n           e   extended (container for logical partitions)\n        Select (default p): p\n        Partition number (3,4, default 3): 3\n        First sector (20973568-240254975, default 20973568): \n        Last sector, +/-sectors or +/-size{K,M,G,T,P} (20973568-\n240254975, default 240254975): +3G\n        Created a new partition 3 of type 'Linux' and of size 3 GiB.\n        Command (m for help): n\n        Partition type\n           p   primary (3 primary, 0 extended, 1 free)\n           e   extended (container for logical partitions)\n        Select (default e): e\n        Selected partition 4", "doc_id": "fa0e15f6-28a9-4342-81a8-65544201741d", "embedding": null, "doc_hash": "eccab61653bd117fd8572cd6eb78b28fd9dc55dd8323da18867b4b3d0abb75f2", "extra_info": {"page_label": "308"}, "node_info": {"start": 0, "end": 1690}, "relationships": {"1": "ea0ddb09-5e45-4fa8-8380-6fc3f57f855c"}}, "__type__": "1"}, "bd454f9b-bfac-4218-bd8e-898e03fad768": {"__data__": {"text": "Chapter 12: Managing Disks and Filesystems\n283\n12        First sector (27265024-240254975, default 27265024): \n        Last sector, +/-sectors or +/-size{K,M,G,T,P} (27265024-\n240254975, default 240254975): <ENTER>\n         Created a new partition 4 of type 'Extended' and of size 101.6 GiB.\n        Command (m for help): n\n        All primary partitions are in use.\n        Adding logical partition 5\n        First sector (27267072-240254975, default 27267072): \n        Last sector, +/-sectors or +/-size{K,M,G,T,P} (27267072-\n240254975, default 240254975): +3G\n        Created a new partition 5 of type 'Linux' and of size 3 GiB.\n        Command (m for help): n\n        All primary partitions are in use.\n        Adding logical partition 6\n        First sector (33560576-240254975, default 33560576): \n        Last sector, +/-sectors or +/-size{K,M,G,T,P} (33560576-\n240254975, default 240254975): +4G\n        Created a new partition 6 of type 'Linux' and of size 4 GiB.\n3. Check the partitioning before saving by typing p . Notice that there are five usable \npartitions ( sdc1 , sdc2 , sdc3 , sdc5 , and sdc6 ) and that the sectors between the \nStart and End for sdc4  are being consumed by sdc5  and sdc6 .\n        Command (m for help): p\n        ...\n        Device     Boot    Start       End   Sectors   Size Id Type\n        /dev/sdb1           2048  10487807  10485760     5G 83 Linux\n        /dev/sdb2       10487808  20973567  10485760     5G 82 Linux\n        /dev/sdb3       20973568  27265023   6291456     3G 83 Linux\n        /dev/sdb4       27265024 240254975 212989952 101.6G  5 Extended\n        /dev/sdb5       27267072  33558527   6291456     3G 83 Linux\n        /dev/sdb6       33560576  41949183   8388608     4G 83 Linux\n4. The default partition type is Linux. I decided that I wanted to use some of the par -\ntitions for swap space ( type 82 ), FAT32 (type x ), and Linux LVM ( type 8e ). To \ndo that, I type t and indicate which partition type to use. Type L to see a list of \npartition types.\n        Command (m for help): t\n        Partition number (1-6): 2\n        Hex code (type L to list codes): 82", "doc_id": "bd454f9b-bfac-4218-bd8e-898e03fad768", "embedding": null, "doc_hash": "5f29d8a903b15c34c4a48d144cb473774d144ff28c89c4f310d646ad737fd120", "extra_info": {"page_label": "309"}, "node_info": {"start": 0, "end": 2125}, "relationships": {"1": "6f44f3b0-f413-4de6-b972-702b426c0b1e"}}, "__type__": "1"}, "b91ec09b-d992-4aab-8104-8f5065a933ea": {"__data__": {"text": "Part III: Becoming a Linux System Administrator284        Changed type of partition 'Linux' to 'Linux swap / Solaris'.\n        Command (m for help): t\n        Partition number (1-6): 5\n        Hex code (type L to list codes): c\n        Changed type of partition 'Linux' to 'W95 FAT32 (LBA)'.\n        Command (m for help): t\n        Partition number (1-6): 6\n        Hex code (type L to list codes): 8e\n        Changed type of partition 'Linux' to 'Linux LVM'.\n5. I check that the partition table is the way I want it and then write the changes:\n        Comm and (m for help): p\n        ...\n        Device     Boot    Start       End   Sectors   Size Id Type\n        /dev/sdb1           2048  10487807  10485760     5G 83 Linux\n        /dev/sdb2        10487808   20973567   10485760      5G  82 Linux swap / Solaris\n        /dev/sdb3       20973568  27265023   6291456     3G 83 Linux\n        /dev/sdb4      27265024  240254975 212989952 101.6G  5 Extended\n        /dev/sdb5      27267072  33558527    6291456     3G  c W95 FAT32 (LBA)\n        /dev/sdb6    33560576  41949183 8388608    4G 8e Linux LVM\n        Command (m for help): w\n        The partition table has been altered!\n        The kernel still uses the old partitions. The new table \nwill be used at the next reboot. \n        Syncing disks\n6. After the write is completed, check that the kernel knows about the changes to the \npartition table. To do that, search the /proc/partitions  for sdb. If the new \ndevices are not there, run the partprobe /dev/sdb  command on the drive or \nreboot your computer.\n        # grep sdb /proc/partitions\n           8       16  120127488 sdb\n           8       17  120125440 sdb1\n        # partprobe /dev/sdb\n        # grep sdb /proc/partitions\n           8       16  120127488 sdb\n           8       17    5242880 sdb1\n           8       18    5242880 sdb2\n           8       19    3145728 sdb3\n           8       20          1 sdb4\n           8       21    3145728 sdb5\n           8       22    4194304 sdb6", "doc_id": "b91ec09b-d992-4aab-8104-8f5065a933ea", "embedding": null, "doc_hash": "252bd0b2280dfe8a57ef22c32370acd03b087f50711da18fb0e6ddfb82a55664", "extra_info": {"page_label": "310"}, "node_info": {"start": 0, "end": 2006}, "relationships": {"1": "e470c461-f826-4ca4-8e2b-91f197579c06"}}, "__type__": "1"}, "f886f97d-f083-4e84-bde9-64477065ae5b": {"__data__": {"text": "Chapter 12: Managing Disks and Filesystems\n285\n127. While the partitions are now set for different types of content, other commands are \nneeded to structure the partitions into filesystems or swap areas. Here\u2019s how to do \nthat for the partitions just created:\nsdb1 : To make this into a regular Linux ext4  filesystem, type the following:\n        # mkfs -t ext4 /dev/sdb1\nsdb2 : To format this as a swap area, type the following:\n        # mkswap /dev/sdb2\nsdb3 : To make this into an ext2  filesystem (the default), type the following:\n        # mkfs /dev/sdb3\nsdb5 : To make this into a VFAT filesystem (the default), type the following:\n        # mkfs -t vfat /dev/sdb5\nsdb6 : To make this into a LVM physical volume, type the following:\n        # pvcreate /dev/sdb6\nThese partitions are now ready to be mounted, used as swap areas, or added to an LVM \nvolume group. See the next section, \u201cUsing Logical Volume Manager Partitions,\u201d to see \nhow LVM physical volumes are used to ultimately create LVM logical volumes from volume \ngroups. See the section \u201cMounting Filesystems\u201d for descriptions of how to mount filesys -\ntems and enable swap areas.\nUsing Logical Volume Manager Partitions\nBasic disk partitioning in Linux has its shortcomings. What happens if you run out of disk \nspace? In the old days, a common solution was to copy data to a bigger disk, restart the \nsystem with the new disk, and hope that you didn\u2019t run out of space again anytime soon. \nThis process meant downtime and inefficiency.\nLogical Volume Manager (LVM) offers lots of flexibility and efficiency in dealing with con -\nstantly changing storage needs. With LVM, physical disk partitions are added to pools of \nspace called volume groups. Logical volumes are assigned space from volume groups as \nneeded. This gives you these abilities:\n\u25a0\u25a0Add more space to a logical volume from the volume group while the volume is \nstill in use.\n\u25a0\u25a0Add more physical volumes to a volume group if the volume group begins to run out \nof space. The physical volumes can be from disks.\n\u25a0\u25a0Move data from one physical volume to another so you can remove smaller disks \nand replace them with larger ones while the filesystems are still in use\u2014again, \nwithout downtime.", "doc_id": "f886f97d-f083-4e84-bde9-64477065ae5b", "embedding": null, "doc_hash": "44289f9567c7e4e59e4307d33c69cd08b01897eacb8c142c4a36e2974e137368", "extra_info": {"page_label": "311"}, "node_info": {"start": 0, "end": 2223}, "relationships": {"1": "5309e019-436f-4e76-9efe-a5c5a25cbd0e"}}, "__type__": "1"}, "304f26b9-576e-4b14-8d4e-8bcc76ee5ca3": {"__data__": {"text": "Part III: Becoming a Linux System Administrator286With LVM, it is also easier to shrink filesystems to reclaim disk space, although shrinking \ndoes require that you unmount the logical volume (but no reboot is needed). LVM also sup -\nports advanced features, such as mirroring and working in clusters.\nChecking an existing LVM\nLet\u2019s start by looking at an existing LVM example on a Red Hat Enterprise Linux system. \nThe following command displays the partitions on my first hard disk:\n# fdisk -l /dev/sda | grep /dev/sda\nDisk /dev/sda: 160.0 GB, 160000000000 bytes\n/dev/sda1   *        2048     1026047      512000    83   Linux\n/dev/sda2   *     1026048   312498175   155736064    8e   Linux LVM\nOn this RHEL system, the 160GB hard drive is divided into one 500MB Linux partition \n(sda1 ) and a second (Linux LVM) partition that consumes the rest of the disk ( sda2 ). Next, \nI use the pvdisplay  command to see if that partition is being used in an LVM group:\n# pvdisplay /dev/sda2\n  --- Physical volume ---\n  PV Name               /dev/sda2\n  VG Name               vg_abc\n  PV Size               148.52 GiB / not usable 2.00 MiB\n  Allocatable           yes (but full)\n  PE Size               4.00 MiB\n  Total PE              38021\n  Free PE               0\n  Allocated PE          38021\n  PV UUID               wlvuIv-UiI2-pNND-f39j-oH0X-9too-AOII7R\nYou can see that the LVM physical volume represented by /dev/sda2  has 148.52GiB of \nspace, all of which has been totally allocated to a volume group named vg_abc . The small -\nest unit of storage that can be used from this physical volume is 4.0MiB, which is referred \nto as a Physical Extent (PE) .\nNext, you want to see information about the volume group:\n# vgdisplay vg_abc\n  --- Volume group ---\n  VG Name               vg_abcNote\nNotice that LVM tools show disk space in MiB and GiB. One MB is 1,000,000 bytes (10 \u22276), while a MiB is 1,048,576 \nbytes (2 \u222720). A MiB is a more accurate way to reflect how data are stored on a computer. But marketing people tend \nto use MB because it makes the hard disks, CDs, and DVDs they sell look like they have more capacity than they do. \nKeep in mind that most tools in Linux display storage data in MiB and GiB, although some can display MB and GB as \nwell.", "doc_id": "304f26b9-576e-4b14-8d4e-8bcc76ee5ca3", "embedding": null, "doc_hash": "e0e6edda5e0b0b681808198cbcc7f61091b84054d97780ac0087eb6b40a3128f", "extra_info": {"page_label": "312"}, "node_info": {"start": 0, "end": 2257}, "relationships": {"1": "6cc6387c-cd19-42c1-9e1f-e99a19e0bee9"}}, "__type__": "1"}, "1f1a3deb-710b-4115-bf92-402d61a8b003": {"__data__": {"text": "Chapter 12: Managing Disks and Filesystems\n287\n12  System ID\n  Format                lvm2\n  Metadata Areas        1\n  Metadata Sequence No  4\n  VG Access             read/write\n  VG Status             resizable\n  MAX LV                0\n  Cur LV                3\n  Open LV               3\n  Max PV                0\n  Cur PV                1\n  Act PV                1\n  VG Size               148.52 GiB\n  PE Size               4.00 MiB\n  Total PE              38021\n  Alloc PE / Size       38021 / 148.52 GiB\n  Free  PE / Size       0 / 0\n  VG UUID               c2SGHM-KU9H-wbXM-sgca-EtBr-UXAq-UnnSTh\nYou can see that all of the 38,021 PEs have been allocated. Using lvdisplay  as follows, \nyou can see where they have been allocated (I have snipped some of the output):\n# lvdisplay vg_abc\n  --- Logical volume ---\n  LV Name                /dev/vg_abc/lv_root\n  VG Name                vg_abc\n  LV UUID                33VeDc-jd0l-hlCc-RMuB-tkcw-QvFi-cKCZqa\n  LV Write Access        read/write\n  LV Status              available\n  # open                 1\n  LV Size                50.00 GiB\n  Current LE             12800\n  Segments               1\n  Allocation             inherit\n  Read ahead sectors     auto\n  - currently set to     256\n  Block device           253:0\n  --- Logical volume ---\n  LV Name                /dev/vg_abc/lv_home\n  VG Name                vg_abc\n  ...\n  LV Size                92.64 GiB\n  --- Logical volume ---\n  LV Name                /dev/vg_abc/lv_swap\n  VG Name                vg_abc\n  ...\n  LV Size                5.88 GiB\nThere are three logical volumes drawing space from vg_abc . Each logical volume is asso -\nciated with a device name that includes the volume group name and the logical volume ", "doc_id": "1f1a3deb-710b-4115-bf92-402d61a8b003", "embedding": null, "doc_hash": "f63613fdf31dbc8373daf1a0318c5a111ccf358f097b63d7ea2c2a22810b98ff", "extra_info": {"page_label": "313"}, "node_info": {"start": 0, "end": 1730}, "relationships": {"1": "d63890c7-87a6-4190-b2be-adfd38fffd52"}}, "__type__": "1"}, "728147cb-e064-4bc2-bbf8-f2cba6bf9754": {"__data__": {"text": "Part III: Becoming a Linux System Administrator288name: /dev/vg_abc/lv_root  (50GB), /dev/vg_abc/lv_home  (92.64GB), and  \n/dev/vg_abc/lv_swap  (5.88GB). Other devices linked to these names are located in the \n/dev/mapper  directory: vg_abc-lv_home , vg_abc-lv_root , and vg_abc-lv_swap . \nEither set of names can be used to refer to these logical volumes.\nThe root and home logical volumes are formatted as ext4  filesystems, whereas the swap \nlogical volume is formatted as swap space. Let\u2019s look in the /etc/fstab  file to see how \nthese logical volumes are used:\n# grep vg_ /etc/fstab\n/dev/mapper/vg_abc-lv_root /      ext4  defaults    1 1\n/dev/mapper/vg_abc-lv_home /home  ext4  defaults    1 2\n/dev/mapper/vg_abc-lv_swap swap   swap  defaults    0 0\nFigure\u00a012.1 illustrates how the different partitions, volume groups, and logical volumes \nrelate to the complete Linux filesystem. The sda1  device is formatted as a filesystem and \nmounted on the /boot  directory. The sda2  device provides space for the vg_abc  volume \ngroup. Then logical volumes lv_home  and lv_root  are mounted on the /home  and / \ndirectories, respectively.\nIf you run out of space on any of the logical volumes, you can assign more space from the \nvolume group. If the volume group is out of space, you can add another hard drive or net -\nwork storage drive and add space from that drive to the volume group so more is available.\nNow that you know how LVM works, the next section shows you how to create LVM logical \nvolumes from scratch./bin /boot /etc /home ...\nLogical\nvolumes\n(Iv)/\nVolume group\n(vg)\nPhysical\nvolume\n(pv)/dev/sda1/dev/sda2vg_abc/dev/mapper/vg_abc-lv_root\n/dev/mapper/vg_abc-lv_home\n/dev/mapper/vg_abc-lv_swapFIGURE 12.1\nLVM logical volumes can be mounted like regular partitions on a Linux filesystem.", "doc_id": "728147cb-e064-4bc2-bbf8-f2cba6bf9754", "embedding": null, "doc_hash": "3c49ec3494a0dcdd3d52160b448addc8406f0d534f9f0ebc5c2aff2b3a1e8558", "extra_info": {"page_label": "314"}, "node_info": {"start": 0, "end": 1802}, "relationships": {"1": "8c5bfb2c-17bd-482f-a0db-c0c6c5e59c22"}}, "__type__": "1"}, "ca648513-08e8-47bc-aa8e-cf6dc33d6dec": {"__data__": {"text": "Chapter 12: Managing Disks and Filesystems\n289\n12Creating LVM logical volumes\nLVM logical volumes are used from the top down, but they are created from the bottom up. \nAs illustrated in Figure\u00a012.1, first you create one or more physical volumes (pv), use the \nphysical volumes to create volume groups (vg), and then create logical volumes from the \nvolume groups (lv).\nCommands for working with each LVM component begin with the letters pv , vg, and lv . \nFor example, pvdisplay  shows physical volumes, vgdisplay  shows volume groups, and \nlvdisplay  shows logical volumes.\nThe following procedure takes you through the steps of creating LVM volumes from scratch. \nTo do this procedure, you could use the USB flash drive and partitions that I described ear -\nlier in this chapter.\n1. Obtain a disk with some spare space on it and create a disk partition on it of the \nLVM type ( 8e). Then use the pvcreate  command to identify this partition as an \nLVM physical volume. The process of doing this is described in the section \u201cCreating \na multiple-partition disk\u201d using the /dev/sdb6  device in that example.\n2. To add that physical volume to a new volume group, use the vgcreate  command. \nThe following command shows you how to create a volume group called myvg0  \nusing the /dev/sdb6  device:\n        # vgcreate myvg0 /dev/sdc6\n            Volume group \"myvg0\" successfully created\n3. To see the new volume group, type the following:\n        # vgdisplay myvg0\n          --- Volume group ---\n          VG Name               myvg0\n          ...\n          VG Size               <4.00 GiB\n          PE Size               4.00 MiB\n          Total PE              1023\n          Alloc PE / Size       0 / 0\n          Free  PE / Size       1023 / <4.00 MiB\n4. All of the 1023 physical extents (PEs, 4.00 MiB each) are available. Here\u2019s how to \ncreate a logical volume from some of the space in that volume group and then check \nthat the device for that logical volume exists:\n        # lvcreate -n music -L 1G myvg0\n          Logical volume \"music\" created\n        # ls /dev/mapper/myvg0*\n        /dev/mapper/myvg0-music", "doc_id": "ca648513-08e8-47bc-aa8e-cf6dc33d6dec", "embedding": null, "doc_hash": "2f2f84ef8391bc2105a0b72dd00c87a73a2d03aaca06feb169595be31e75165e", "extra_info": {"page_label": "315"}, "node_info": {"start": 0, "end": 2115}, "relationships": {"1": "ecd73127-6cf6-46f9-97d1-cdfbeccd3fc9"}}, "__type__": "1"}, "19483242-0cf3-4c30-a0d8-80c2e5e8cf1d": {"__data__": {"text": "Part III: Becoming a Linux System Administrator2905. As you can see, the procedure created a device named /dev/mapper/myvg0-\nmusic . That device can now be used to put a filesystem on and mount, just as you \ndid with regular partitions in the first part of this chapter. For example:\n        # mkfs -t ext4 /dev/mapper/myvg0-music\n        # mkdir /mnt/mymusic\n        # mount /dev/mapper/myvg0-music /mnt/mymusic\n        # df -h /mnt/mymusic\n        Filesystem               Size  Used  Avail  Use%  Mounted on\n        /dev/mapper/myvg0-music  976M  2.6M   987M    1%  /mnt/mymusic\n6. As with regular partitions, logical volumes can be mounted permanently by adding \nan entry to the /etc/fstab  file, such as\n        /dev/mapper/myvg0-music /mnt/mymusic  ext4 defaults 1 2\nThe next time you reboot, the logical volume is automatically mounted on /mnt/mymusic . \n(Be sure to unmount the logical volume and remove this line if you want to remove the USB \nflash drive from your computer.)\nGrowing LVM logical volumes\nIf you run out of space on a logical volume, you can add space to it without even unmount -\ning it. To do that, you must have space available in the volume group, grow the logical \nvolume, and grow the filesystem to fill it. Building on the procedure in the previous section,  \nhere\u2019s how to grow a logical volume:\n1. Note how much space is currently on the logical volume, and then check that space \nis available in the logical volume\u2019s volume group:\n        # vgdisplay myvg0\n        ...\n          VG Size               <4.00 MiB\n          PE Size               4.00 MiB\n          Total PE              1023\n          Alloc PE / Size       256 / 1.00 GiB\n          Free  PE / Size       767 / <3.00 GiB\n        # df -h /mnt/mymusic/\n        Filesystem                 Size  Used Avail Use% Mounted on\n        /dev/mapper/myvg0-music    976M  2.6M  987M   1% /mnt/mymusic\n2. Expand the logical volume using the lvextend  command:\n        # lvextend -L +1G /dev/mapper/myvg0-music\n          Size of logical volume myvg0/music changed \n                 from 1.00GiB to 2.00 GiB (512 extents).\n          Logical volume myvg0/music successfully resized\n3. Resize the filesystem to fit the new logical volume size:\n        # resize2fs -p /dev/mapper/myvg0-music", "doc_id": "19483242-0cf3-4c30-a0d8-80c2e5e8cf1d", "embedding": null, "doc_hash": "b45bdb3aa88fb8285c09bd09c1e2849497443740e2df441c45f7d05a5b4f2e5b", "extra_info": {"page_label": "316"}, "node_info": {"start": 0, "end": 2271}, "relationships": {"1": "1374cc7a-e78d-4801-b627-1bdeff052265"}}, "__type__": "1"}, "747f48f9-5159-49df-91b4-246cf1246c21": {"__data__": {"text": "Chapter 12: Managing Disks and Filesystems\n291\n124. Check to see that the filesystem is now resized to include the additional disk space:\n        # df -h /mnt/mymusic/\n        Filesystem               Size  Used Avail Use% Mounted on\n        /dev/mapper/myvg0-music  2.0G  3.0M  1.9G   1% /mnt/mymusic\nYou can see that the filesystem is now about 1G larger.\nMounting Filesystems\nNow that you have had a chance to play with disk partitioning and filesystems, I\u2019m going \nto step back and talk about how filesystems are set up to connect permanently to your \nLinux system.\nMost of the hard disk partitions created when you install Linux are mounted automati-\ncally for you when the system boots. When you install Fedora, Ubuntu, Red Hat Enterprise \nLinux, and other Linux systems, you have the option to let the installer automatically con -\nfigure your hard disk or create partitions yourself and indicate the mount points for those \npartitions.\nWhen you boot Linux, usually all of the Linux partitions on your hard disk are listed in \nyour /etc/fstab  file and are mounted. For that reason, the following sections describe \nwhat you might expect to find in that file. It also describes how you can mount other parti-\ntions so that they become part of your Linux filesystem.\nThe mount  command is used not only to mount local storage devices but also to mount \nother kinds of filesystems on your Linux system. For example, mount  can be used to mount \ndirectories (folders) over the network from NFS or Samba servers. It can be used to mount \nfilesystems from a new hard drive or USB flash drive that is not configured to automount. It \ncan also mount filesystem image files using loop devices.\nSupported filesystems\nTo see filesystem types that are currently loaded in your kernel, type cat /proc/ \nfilesystems . The list that follows shows a sample of filesystem types that are currently \nsupported in Linux, although they may not be in use at the moment or even available on \nthe Linux distribution you are using.\nbefs: Filesystem used by the BeOS operating system.Note\nWith the addition of automatic mounting features and changes in how removable media are identified with the Linux \n2.6 kernel (using features such as Udev and Hardware Abstraction Layer), you no longer need to mount removable \nmedia manually for many Linux desktop systems. Understanding how to mount and unmount filesystems manually on \na Linux server, however, can be a very useful skill if you want to mount remote filesystems or temporarily mount parti -\ntions in particular locations.", "doc_id": "747f48f9-5159-49df-91b4-246cf1246c21", "embedding": null, "doc_hash": "93624efb199f2b3d5089014b7d10187dda675dbd6e665145c43048ebc6630e08", "extra_info": {"page_label": "317"}, "node_info": {"start": 0, "end": 2560}, "relationships": {"1": "d1b5f179-e496-461b-a21d-07bf0e9b291c"}}, "__type__": "1"}, "cff5bf1a-dad0-4fc0-942c-55966011b554": {"__data__": {"text": "Part III: Becoming a Linux System Administrator292btrfs : A copy-on-write filesystem that implements advanced filesystem features. It \noffers fault tolerance and easy administration. The btrfs file system has recently \ngrown in popularity for enterprise applications.\ncifs: Common Internet Filesystem (CIFS), the virtual filesystem used to access servers \nthat comply with the SNIA CIFS specification. CIFS is an attempt to refine and stan -\ndardize the SMB protocol used by Samba and Windows file sharing.\next4: Successor to the popular ext3 filesystem. It includes many improvements over \next3, such as support for volumes up to 1 exbibyte and file sizes up to 16 tebibytes. \n(This replaced ext3 as the default filesystem used in Fedora and RHEL. It has since \nbeen supplanted by xfs as the default for RHEL.)\next3: Ext filesystems are the most common in most Linux systems. Compared ext2, \nthe ext3 filesystem, also called the third extended filesystem, includes journal -\ning features that, compared to ext2, improve a filesystem\u2019s capability to recover \nfrom crashes.\next2: The default filesystem type for earlier Linux systems. Features are the same as \next3, except that ext2 doesn\u2019t include journaling features.\next: This is the first version of ext3. It is not used very often anymore.\niso9660 : Evolved from the High Sierra filesystem (the original standard for CD-ROMs). \nExtensions to the High Sierra standard (called Rock Ridge extensions) allow iso9660 \nfilesystems to support long filenames and UNIX-style information (such as file per -\nmissions, ownership, and links). Data CD-ROMs typically use this filesystem type.\nkafs: AFS client filesystem. Used in distributed computing environments to share files \nwith Linux, Windows, and Macintosh clients.\nminix : Minix filesystem type, used originally with the Minix version of UNIX. It sup -\nports filenames of up to only 30 characters.\nmsdos : An MS-DOS filesystem. You can use this type to mount media that comes from \nold Microsoft operating systems.\nvfat: Microsoft extended FAT (VFAT) filesystem.\nexfat : Extended FAT (exFAT) file system that has been optimized for SD cards, USB \ndrives, and other flash memory.\numsdos : An MS-DOS filesystem with extensions to allow features that are similar to \nUNIX (including long filenames).\nproc: Not a real filesystem, but rather a filesystem interface to the Linux kernel. You \nprobably won\u2019t do anything special to set up a proc filesystem. However, the /proc  \nmount point should be a proc filesystem. Many utilities rely on /proc  to gain access \nto Linux kernel information.", "doc_id": "cff5bf1a-dad0-4fc0-942c-55966011b554", "embedding": null, "doc_hash": "0bb2fa14d59f0dffd7e2bf22f7e476a30a0c3a1f350a5d58e65dd04e7823df2a", "extra_info": {"page_label": "318"}, "node_info": {"start": 0, "end": 2588}, "relationships": {"1": "e54f1bcc-9d27-4c7c-ac9b-de566f69c998"}}, "__type__": "1"}, "6c8070d8-57c5-4224-90e3-b8edcca6bd27": {"__data__": {"text": "Chapter 12: Managing Disks and Filesystems\n293\n12reiserfs : ReiserFS journaled filesystem. ReiserFS was once a common default filesystem \ntype for several Linux distributions. However, ext and xfs filesystems are by far \nmore common filesystem types used with Linux today.\nswap : Used for swap partitions. Swap areas are used to hold data temporarily when \nRAM is used up. Data is swapped to the swap area and then returned to RAM when it \nis needed again.\nsquashfs : Compressed, read-only filesystem type. Squashfs is popular on live CDs, \nwhere there is limited space and a read-only medium (such as a CD or DVD).\nnfs: Network Filesystem (NFS) type of filesystem. NFS is used to mount filesystems on \nother Linux or UNIX computers.\nhpfs: Filesystem is used to do read-only mounts of an OS/2 HPFS filesystem.\nncpfs : A filesystem used with Novell NetWare. NetWare filesystems can be mounted \nover a network.\nntfs: Windows NT filesystem. Depending upon the distribution you have, it may be sup -\nported as a read-only filesystem (so that you can mount and copy files from it).\nufs: Filesystem popular on Sun Microsystems\u2019s operating systems (that is, Solaris \nand SunOS).\njfs: A 64-bit journaling filesystem by IBM that is relatively lightweight for the many \nfeatures it has.\nxfs: A high-performance filesystem originally developed by Silicon Graphics that works \nextremely well with large files. This filesystem is the default type for RHEL 7.\ngfs2: A shared disk filesystem that allows multiple machines to all use the same shared \ndisk without going through a network filesystem layer such as CIFS, NFS, and so on.\nTo see the list of filesystems that come with the kernel you are using, type  \nls /lib/modules/kernelversion/kernel/fs/ . The actual modules are stored in \nsubdirectories of that directory. Mounting a filesystem of a supported type causes the  \nfilesystem module to be loaded, if it is not already loaded.\nType man fs  to see descriptions of Linux filesystems.\nEnabling swap areas\nA swap area  is an area of the disk that is made available to Linux if the system runs out of \nmemory (RAM). If your RAM is full and you try to start another application without a swap \narea, that application will fail.\nWith a swap area, Linux can temporarily swap out data from RAM to the swap area and \nthen get it back when needed. You take a performance hit, but it is better than having \nprocesses fail.", "doc_id": "6c8070d8-57c5-4224-90e3-b8edcca6bd27", "embedding": null, "doc_hash": "84924b1067129469321b2cb3157867fe5ba6c9b25fec9bd75c635947d37baeb4", "extra_info": {"page_label": "319"}, "node_info": {"start": 0, "end": 2408}, "relationships": {"1": "49367836-b72f-498e-a9f4-844def9b6335"}}, "__type__": "1"}, "b5f1b2ec-8f05-4ea3-af4e-1285d267d9a3": {"__data__": {"text": "Part III: Becoming a Linux System Administrator294To create a swap area from a partition or a file, use the mkswap  command. To enable that \nswap area temporarily, you can use the swapon  command. For example, here\u2019s how to check \nyour available swap space, create a swap file, enable the swap file, and then check that the \nspace is available on your system:\n# free -m\n         total    used     free    shared  buffers  cached\nMem:      1955     663     1291         0       42     283\n-/+ buffers/cache:          337      1617\nSwap:      819       0      819\n# dd if=/dev/zero of=/var/tmp/myswap bs=1M count=1024\n# mkswap /var/opt/myswap\n# swapon /var/opt/myswap\n# free -m\n         total    used     free  shared  buffers     cached\nMem:      1955    1720      235       0       42       1310\n-/+ buffers/cache:          367    1588\nSwap:     1843       0     1843\nThe free  command shows the amount of swap before and after creating, making, and \nenabling the swap area with the swapon  command. That amount of swap is available \nimmediately and temporarily to your system. To make that swap area permanent, you need \nto add it to your /etc/fstab  file. Here is an example:\n/var/opt/myswap  swap   swap    defaults   0 0\nThis entry indicates that the swap file named /var/opt/myswap  should be enabled at \nboot time. Because there is no mount point for swap area, the second field is just set to \nswap, as is the partition type. To test that the swap file works before rebooting, you can \nenable it immediately ( swapon -a ) and check that the additional swap area appears:\n# swapon -a\nDisabling swap area\nIf at any point you want to disable a swap area, you can do so using the swapoff  \ncommand. You might do this, in particular, if the swap area is no longer needed and you \nwant to reclaim the space being consumed by a swap file or remove a USB drive that is pro -\nviding a swap partition.\nFirst, make sure that no space is being used on the swap device (using the free  command), \nand then use swapoff  to turn off the swap area so that you can reuse the space. Here is \nan example:\n# free -m\n         total    used     free     shared    buffers     cached\nMem:      1955    1720      235          0         42       1310\n-/+ buffers/cache: 367     1588", "doc_id": "b5f1b2ec-8f05-4ea3-af4e-1285d267d9a3", "embedding": null, "doc_hash": "6b496d94b615d6a367a9d4bc03fc6de6cca13824c67e3016d3d87aab485c3ce7", "extra_info": {"page_label": "320"}, "node_info": {"start": 0, "end": 2264}, "relationships": {"1": "570520c9-950f-4948-b152-c5cb7c03af14"}}, "__type__": "1"}, "0b870b43-3fcc-47c8-9f50-8f4d0cf9b091": {"__data__": {"text": "Chapter 12: Managing Disks and Filesystems\n295\n12Swap:     1843       0     1843\n# swapoff /var/opt/myswap\n# free -m\nMem:      1955    1720      235          0         42       1310\n-/+ buffers/cache: 367     1588\nSwap:      819       0      819\nNotice that the amount of available swap was reduced after running the swapoff   \ncommand.\nUsing the fstab file to define mountable file systems\nThe hard disk partitions on your local computer and the remote filesystems that you use \nevery day are probably set up to mount automatically when you boot Linux. The /etc/\nfstab  file contains definitions for each partition, along with options describing how the \npartition is mounted. Here\u2019s an example of an /etc/fstab  file:\n# /etc/fstab\n/dev/mapper/vg_abc-lv_root     /        ext4   defaults       1 1\nUUID=78bdae46-9389-438d-bfee-06dd934fae28 /boot ext4  defaults  1 2\n/dev/mapper/vg_abc-lv_home     /home    ext4   defaults       1 2\n/dev/mapper/vg_abc-lv_swap     swap     swap   defaults       0 0\n# Mount entries added later\n/dev/sdb1                      /win     vfat   ro             1 2\n192.168.0.27:/nfsstuff         /remote  nfs    users,_netdev  0 0\n//192.168.0.28/myshare         /share   cifs   guest,_netdev  0 0\n# special Linux filesystems\ntmpfs                          /dev/shm tmpfs   defaults      0 0\ndevpts                         /dev/pts devpts gid=5,mode=620 0 0\nsysfs                          /sys     sysfs  defaults       0 0\nproc                           /proc    proc   defaults       0 0\nThe /etc/fstab  file just shown is from a default Red Hat Enterprise Linux 6 server install, \nwith a few lines added.\nFor now, you can ignore the tmpfs , devpts , sysfs , and proc  entries. Those are special \ndevices associated with shared memory, terminal windows, device information, and kernel \nparameters, respectively.\nIn general, the first column of /etc/fstab  shows the device or share (what is mounted), \nwhile the second column shows the mount point (where it is mounted). That is followed by \nthe type of filesystem, any mount options (or defaults), and two numbers (used to tell com-\nmands such as dump  and fsck  what to do with the filesystem).\nThe first three entries represent the disk partitions assigned to the root of the filesystem \n(/), the /boot  directory, and the /home  directory. All three are ext4  filesystems. The \nfourth line is a swap device (used to store data when RAM overflows). Notice that the \ndevice names for / , /home , and swap  all start with /dev/mapper . That\u2019s because they \nare LVM", "doc_id": "0b870b43-3fcc-47c8-9f50-8f4d0cf9b091", "embedding": null, "doc_hash": "6bd3bc774db283f24c97359a8f70dbb0bf2c23c8ca3d6997bdf017ae27980942", "extra_info": {"page_label": "321"}, "node_info": {"start": 0, "end": 2544}, "relationships": {"1": "ff2b767f-71d8-4b42-931f-b6bf3cabfdca", "3": "3e8791f6-8b8b-441f-a335-323452ea6e8b"}}, "__type__": "1"}, "3e8791f6-8b8b-441f-a335-323452ea6e8b": {"__data__": {"text": "information, and kernel \nparameters, respectively.\nIn general, the first column of /etc/fstab  shows the device or share (what is mounted), \nwhile the second column shows the mount point (where it is mounted). That is followed by \nthe type of filesystem, any mount options (or defaults), and two numbers (used to tell com-\nmands such as dump  and fsck  what to do with the filesystem).\nThe first three entries represent the disk partitions assigned to the root of the filesystem \n(/), the /boot  directory, and the /home  directory. All three are ext4  filesystems. The \nfourth line is a swap device (used to store data when RAM overflows). Notice that the \ndevice names for / , /home , and swap  all start with /dev/mapper . That\u2019s because they \nare LVM logical volumes that are assigned space from a pool of space called an LVM volume \ngroup (more on LVM in the section \u201cUsing Logical Volume Manager Partitions\u201d earlier in \nthis chapter).", "doc_id": "3e8791f6-8b8b-441f-a335-323452ea6e8b", "embedding": null, "doc_hash": "26895df23cae5b0f0f484159b8c95a56955c3b6a1c0dd51cfb6cb94f3c899f69", "extra_info": {"page_label": "321"}, "node_info": {"start": 1790, "end": 2730}, "relationships": {"1": "ff2b767f-71d8-4b42-931f-b6bf3cabfdca", "2": "0b870b43-3fcc-47c8-9f50-8f4d0cf9b091"}}, "__type__": "1"}, "738a9260-71d4-469d-8980-7b588e2b03bf": {"__data__": {"text": "Part III: Becoming a Linux System Administrator296The /boot  partition is on its own physical partition, /dev/sda1 . Instead of using  \n/dev/sda1 , however, a unique identifier (UUID) identifies the device. Why use a UUID \ninstead of /dev/sda1  to identify the device? Suppose you plugged another disk into your \ncomputer and booted up. Depending on how your computer iterates through connected \ndevices on boot, it is possible that the new disk might be identified as /dev/sda , causing \nthe system to look for the contents of /boot  on the first partition of that disk.\nTo see all of the UUIDs assigned to storage devices on your system, type the blkid  \ncommand, as follows:\n# blkid\n/dev/sda1:\n  UUID=\"78bdae46-9389-438d-bfee-06dd934fae28\" TYPE=\"ext4\"\n/dev/sda2:\n  UUID=\"wlvuIv-UiI2-pNND-f39j-oH0X-9too-AOII7R\" TYPE=\"LVM2_member\"\n/dev/mapper/vg_abc-lv_root:\n  UUID=\"3e6f49a6-8fec-45e1-90a9-38431284b689\" TYPE=\"ext4\"\n/dev/mapper/vg_abc-lv_swap:\n  UUID=\"77662950-2cc2-4bd9-a860-34669535619d\" TYPE=\"swap\"\n/dev/mapper/vg_abc-lv_home:\n  UUID=\"7ffbcff3-36b9-4cbb-871d-091efb179790\" TYPE=\"ext4\"\n/dev/sdb1:\n  SEC_TYPE=\"msdos\" UUID=\"75E0-96AA\" TYPE=\"vfat\"\nAny of the device names can be replaced by the UUID designation in the left column of an \n/etc/fstab  entry.\nI added the next three entries in /etc/fstab  to illustrate some different kinds of entries. \nI connected a hard drive from an old Microsoft Windows system and had it mounted on the \n/win  directory. I added the ro  option so it would mount read-only.\nThe next two entries represent remote filesystems. On the /remote  directory, the  \n/nfsstuff  directory is mounted read/write (rw) from the host at address 192.168.0.27 as \nan NFS share. On the /share  directory, the Windows share named myshare  is mounted \nfrom the host at 192.168.0.28. In both cases, I added the _netdev  option, which tells \nLinux to wait for the network to come up before trying to mount the shares. For more \ninformation on mounting CIFS and NFS shares, refer to Chapters\u00a019, \u201cConfiguring a Windows \nFile Sharing (Samba) Server,\u201d and 20, \u201cConfiguring an NFS File Server,\u201d respectively.\nComing from Windows\nThe section \u201cUsing the fstab file to define mountable file systems\u201d shows mounting a hard disk parti -\ntion from an old VFAT filesystem being used in Windows. Most Windows systems today use the NTFS \nfilesystem. Support for this system, however, is not delivered with every Linux system. NTFS is available \nfrom Fedora in the ntfs-3g package.", "doc_id": "738a9260-71d4-469d-8980-7b588e2b03bf", "embedding": null, "doc_hash": "62c7c967ed5cd4c62873f58506dff6698efb9366c2615955ab53fd4f6aa1e5fb", "extra_info": {"page_label": "322"}, "node_info": {"start": 0, "end": 2483}, "relationships": {"1": "9582983a-0b70-46f7-81f7-e80a40144a85"}}, "__type__": "1"}, "1f591369-ea64-457c-bc7b-104ff1e40ccb": {"__data__": {"text": "Chapter 12: Managing Disks and Filesystems\n297\n12To help you understand the contents of the /etc/fstab  file, here is what is in each field \nof that file:\nField 1 : Name of the device representing the filesystem. This field can include the \nLABEL  or UUID  option with which you can indicate a volume label or universally \nunique identifier ( UUID ) instead of a device name. The advantage to this approach \nis that because the partition is identified by volume name, you can move a volume \nto a different device name and not have to change the fstab  file. (See the descrip -\ntion of the mkfs  command in the section \u201cUsing the mkfs  Command to Create a \nFilesystem\u201d later in this chapter for information on creating and using labels.)\nField 2 : Mount point in the filesystem. The filesystem contains all data from the mount \npoint down the directory tree structure unless another filesystem is mounted at \nsome point beneath it.\nField 3 : Filesystem type. Valid filesystem types are described in the section \u201cSupported \nfilesystems\u201d earlier in this chapter (although you can only use filesystem types for \nwhich drivers are included for your kernel).\nField 4 : Use defaults  or a comma-separated list of options (no spaces) that you want \nto use when the entry is mounted. See the mount  command manual page (under  \nthe -o  option) for information on other supported options.\nField 5 : The number in this field indicates whether the filesystem needs to be dumped \n(that is, have its data backed up). A 1 means that the filesystem needs to be \ndumped, and a 0 means that it doesn\u2019t. (This field is no longer particularly useful \nbecause most Linux administrators use more sophisticated backup options than the \ndump  command. Most often, a 0 is used.)\nField 6 : The number in this field indicates whether the indicated filesystem should be \nchecked with fsck  when the time comes for it to be checked: 1 means it needs to \nbe checked first, 2 means to check after all those indicated by 1 have already been \nchecked, and 0 means don\u2019t check it.\nIf you want to find out more about mount options as well as other features of the  \n/etc/fstab  file, there are several man pages to which you can refer, including man  \n5 nfs  and man 8 mount .\nUsing the mount command to mount file systems\nLinux systems automatically run mount -a  (mount all filesystems from the  \n/etc/fstab  file) each time you boot. For that reason, you generally use the mount  tip\nTypically, only the root user is allowed to mount a filesystem using the mount  command. However, to allow any user \nto mount a filesystem (such as a filesystem on a CD), you could add the user  option to Field 4 of /etc/fstab .", "doc_id": "1f591369-ea64-457c-bc7b-104ff1e40ccb", "embedding": null, "doc_hash": "95373db054afc414dc28f52f9dc42c66c3e9b5d356c351d49834f5b2a4bc83ac", "extra_info": {"page_label": "323"}, "node_info": {"start": 0, "end": 2680}, "relationships": {"1": "a36618e2-03dd-41dd-939d-55c55b613729"}}, "__type__": "1"}, "81969284-a34d-443d-ba47-6abbf3e45265": {"__data__": {"text": "Part III: Becoming a Linux System Administrator298command only for special situations. In particular, the average user or administrator uses \nmount  in two ways:\n\u25a0\u25a0To display the disks, partitions, and remote filesystems currently mounted\n\u25a0\u25a0To mount a filesystem temporarily\nAny user can type mount  (with no options) to see what filesystems are currently mounted \non the local Linux system. The following is an example of the mount  command. It shows \na single hard disk partition ( /dev/sda1 ) containing the root ( /) filesystem and proc and \ndevpts filesystem types mounted on /proc  and /dev , respectively.\n$ mount\n/dev/sda3 on / type ext4 (rw)\n/dev/sda2 on /boot type ext4 (rw)\n/dev/sda1 on /mnt/win type vfat (rw)\n/dev/proc on /proc type proc (rw)\n/dev/sys on /sys type sysfs (rw)\n/dev/devpts on /dev/pts type devpts (rw,gid=5,mode=620)\n/dev/shm on /dev/shm type tmpfs (rw)\nnone on /proc/sys/fs/binfmt_misc type binfmt_misc (rw)\n/dev/cdrom on /media/MyOwnDVD type iso9660 (ro,nosuid,nodev)\nTraditionally, the most common devices to mount by hand are removable media, such as \nDVDs or CDs. However, depending on the type of desktop you are using, CDs and DVDs may \nbe mounted for you automatically when you insert them. (In some cases, applications are \nlaunched as well when media is inserted. For example, a music player or photo editor may \nbe launched when your inserted USB medium has music or digital images on it.)\nOccasionally, however, you may find it useful to mount a filesystem manually. For example, \nyou want to look at the contents of an old hard disk, so you install it as a second disk on \nyour computer. If the partitions on the disk did not automount, you could mount partitions \nfrom that disk manually. For example, to mount a read-only disk partition sdb1  that has \nan older ext3  filesystem, you could type this:\n# mkdir /mnt/temp\n# mount -t ext3 -o ro /dev/sdb1 /mnt/tmp\nAnother reason to use the mount  command is to remount a partition to change its mount \noptions. Suppose that you want to remount /dev/sdb1  as read/write, but you do not want \nto unmount it (maybe someone is using it). You could use the remount option as follows:\n# mount -t ext3 -o remount,rw /dev/sdb1\nMounting a disk image in loopback\nAnother valuable way to use the mount  command has to do with disk images. If you down -\nload an SD card or DVD ISO image file from the Internet and you want to see what it contains, \nyou can do so without burning it to DVD or other medium. With the image on your hard disk, \ncreate a mount point and use the -o loop  option to mount it locally. Here\u2019s an example:\n# mkdir /mnt/mydvdimage\n# mount -o loop whatever-i686-disc1.iso /mnt/mydvdimage", "doc_id": "81969284-a34d-443d-ba47-6abbf3e45265", "embedding": null, "doc_hash": "de7e45e00ac681c096b67f670659f62d6e4b6878a3a100e7986b94d297044786", "extra_info": {"page_label": "324"}, "node_info": {"start": 0, "end": 2686}, "relationships": {"1": "327c53d4-15c6-4c30-87fa-d5ea733b93ad"}}, "__type__": "1"}, "02121a17-09a1-4166-aafa-49979286b613": {"__data__": {"text": "Chapter 12: Managing Disks and Filesystems\n299\n12In this example, the /mnt/mydvdimage  directory is created, and then the disk image \nfile (whatever-i686-disc1.iso ) residing in the current directory is mounted on it. \nYou can now cd  to that directory, view the contents of it, and copy or use any of its con -\ntents. This is useful for downloaded DVD images from which you want to install software \nwithout having to burn the image to DVD. You could also share that mount point over \nNFS, so you could install the software from another computer. When you are finished, \nto unmount the image, type umount /mnt/mydvdimage .\nOther options to mount  are available only for specific filesystem types. See the mount  \nmanual page for those and other useful options.\nUsing the umount command\nWhen you are finished using a temporary filesystem, or you want to unmount a permanent \nfilesystem temporarily, use the umount  command. This command detaches the filesystem \nfrom its mount point in your Linux filesystem. To use umount , you can give it either a \ndirectory name or a device name, as shown in this example:\n# umount /mnt/test\nThis unmounts the device from the mount point /mnt/test . You can also unmount using \nthis form:\n# umount /dev/sdb1\nIn general, it\u2019s better to use the directory name ( /mnt/test ) because the umount  \ncommand will fail if the device is mounted in more than one location. (Device names all \nbegin with /dev .)\nIf you get the message device is busy , the umount  request has failed because either \nan application has a file open on the device or you have a shell open with a directory on \nthe device as a current directory. Stop the processes or change to a directory outside the \ndevice you are trying to unmount for the umount  request to succeed.\nAn alternative for unmounting a busy device is the -l  option. With umount -l  (a lazy \nunmount), the unmount happens as soon as the device is no longer busy. To unmount a \nremote NFS filesystem that\u2019s no longer available (for example, the server went down), you \ncan use the umount -f  option to forcibly unmount the NFS filesystem.\ntip\nA really useful tool for discovering what\u2019s holding open a device you want to unmount is the lsof  command. Type \nlsof  with the name of the partition that you want to unmount (such as lsof /mnt/test ). The output shows you \nwhat commands are holding files open on that partition. The fuser-v /mnt/test  command can be used in the \nsame way.", "doc_id": "02121a17-09a1-4166-aafa-49979286b613", "embedding": null, "doc_hash": "c4731c6f2f3af2068156acdd3236843639c67dd62e96397052c215d29333dca8", "extra_info": {"page_label": "325"}, "node_info": {"start": 0, "end": 2456}, "relationships": {"1": "032e4ecc-9e25-43fb-a673-4d944e993375"}}, "__type__": "1"}, "c6789ab8-71c6-4d07-9b01-c1d5c34da506": {"__data__": {"text": "Part III: Becoming a Linux System Administrator300Using the mkfs Command to Create a Filesystem\nYou can create a filesystem for any supported filesystem type on a disk or partition that \nyou choose. You do so with the mkfs  command. Although this is most useful for creating \nfilesystems on hard-disk partitions, you can create filesystems on USB flash drives or \nrewritable DVDs as well.\nBefore you create a new filesystem, make sure of the following:\n\u25a0\u25a0You have partitioned the disk as you want (using the fdisk  command).\n\u25a0\u25a0You get the device name correct, or you may end up overwriting your hard disk by \nmistake. For example, the first partition on the second SCSI or USB flash drive on \nyour system is /dev/sdb1  and the third disk is /dev/sdc1 .\n\u25a0\u25a0To unmount the partition if it\u2019s mounted before creating the filesystem.\nThe following are two examples of using mkfs  to create a filesystem on two partitions on \na USB flash drive located as the first and second partitions on the third SCSI disk ( /dev/\nsdc1  and /dev/sdc2 ). The first creates an xfs partition, while the second creates an ext4 \npartition.\n# mkfs -t xfs /dev/sdc1\nmeta-data=/dev/sda3        isize=256    agcount=4, agsize=256825 blks\n         =                 sectsz=512   attr=2, projid32bit=1\n         =                 crc=0\ndata     =                 bsize=4096   blocks=1027300, imaxpct=25\n         =                 sunit=0      swidth=0 blks\nnaming   =version 2        bsize=4096   ascii-ci=0 ftype=0\nlog      =internal log     bsize=4096   blocks=2560, version=2\n         =                 sectsz=512   sunit=0 blks, lazy-count=1\nrealtime =none             extsz=4096   blocks=0, rtextents=0\n \n# mkfs -t ext4 /dev/sdc2\nmke2fs 1.44.6 (5-Mar-2019)\nCreating filesystem with 524288 4k blocks and 131072 inodes\nFilesystem UUID: 6379d82e-fa25-4160-8ffa-32bc78d410eee\nSuperblock backups stored on blocks:\n        32768, 98304, 163840, 229376, 294912\nAllocating group tables: done\nWriting inode tables: done\nCreating journal (16384 blocks): done\nWriting superblocks and filesystem accounting information: done\nYou can now mount either of these filesystems (for example, mkdir /mnt/myusb ; \nmount /dev/sdc1 /mnt/myusb ), change to /mnt/myusb  as your current directory ( cd \n/mnt/myusb ), and create files on it as you please.", "doc_id": "c6789ab8-71c6-4d07-9b01-c1d5c34da506", "embedding": null, "doc_hash": "2b26d9cc191c4bf50fbaa316830edf9d9a44f5e54f925aeaa330bd04e861b9d0", "extra_info": {"page_label": "326"}, "node_info": {"start": 0, "end": 2301}, "relationships": {"1": "182a1aee-6198-41fa-85e9-f124f8eeb483"}}, "__type__": "1"}, "d10128ae-5640-4ec7-b9e6-06ed18550f05": {"__data__": {"text": "Chapter 12: Managing Disks and Filesystems\n301\n12Managing Storage with Cockpit\nMost of the features described in this chapter for working with disk partitions and filesys -\ntems using command-line tools can be accomplished using the Cockpit web user interface. \nWith Cockpit running on your system, open the web UI ( hostname:9090 ) and select the \nStorage tab. Figure\u00a012.2 shows an example of the Cockpit Storage tab on a Fedora system.\nThe Storage tab provides a solid overview of your system\u2019s storage. It charts read and write \nactivity of your storage devices every minute. It displays the local filesystems and storage \n(including RAID devices and LVM volume groups) as well as remotely mounted NFS shares \nand iSCSI targets. Each hard disk, DVD, and other physical storage device is also displayed \non the Storage tab.\nSelect a mounted filesystem, and you can see and change partitioning for that filesystem. \nFor example, by selecting the entry for a filesystem that was automatically mounted on  \n/run/media , you can see all of the partitions for the device it is on ( /dev/sdb1  and  \n/dev/sdb2 ). Figure\u00a012.3 shows that there is an ISO9660 filesystem (typical for bootable \nmedia) and a smaller VFAT filesystem on the two partitions.\nWith the storage device information displayed, you could reformat the entire storage device \n(Create Partition Table) or, assuming that space is available on the device, add a new parti-\ntion (Create Partition). Figure\u00a012.4 shows an example of the window that appears when you \nselect Create Partition Table.\nFIGURE 12.2\nView storage devices, filesystems, and activities from the Cockpit Storage page.", "doc_id": "d10128ae-5640-4ec7-b9e6-06ed18550f05", "embedding": null, "doc_hash": "14e53849d643db4b2b148165761c749b6a7a5458e179a03fe5bcf7ab30735910", "extra_info": {"page_label": "327"}, "node_info": {"start": 0, "end": 1647}, "relationships": {"1": "3ca4012d-5576-4cf1-94d2-40bbcf7d8a34"}}, "__type__": "1"}, "369ac8bf-355a-4d6d-8a49-3d28bb7c1918": {"__data__": {"text": "Part III: Becoming a Linux System Administrator302\nFIGURE 12.3\nView and change disk partitions for a select storage device.\nFIGURE 12.4\nCreating a new partition table", "doc_id": "369ac8bf-355a-4d6d-8a49-3d28bb7c1918", "embedding": null, "doc_hash": "05518e99ec98cde9225e8aa37a8df0ef1c8e489b0be492c18d3d9e4b1f6c01a6", "extra_info": {"page_label": "328"}, "node_info": {"start": 0, "end": 166}, "relationships": {"1": "8bb4bcab-df22-484a-8714-44d1f2458714"}}, "__type__": "1"}, "a53e1d1c-b021-48e0-9376-400bde1e9d27": {"__data__": {"text": "Chapter 12: Managing Disks and Filesystems\n303\n12If you decide that you want to format the disk or USB drive, change the Erase setting to \nallow all of the data on the drive to be overwritten and then choose the type of partition -\ning. Select Format to unmount any mounted partitions from the drive and create a new \npartition table. After that, you can add partitions to the storage device, choosing the size, \nfilesystem type, and whether or not to encrypt data. You can even choose where in the \noperating system\u2019s filesystem to mount the new partition. With just a few selections, you \ncan quickly create the disk layouts that you want in ways that are more intuitive than \nmethods for doing comparable steps from the command line.\nSummary\nManaging filesystems is a critical part of administering a Linux system. Using com-\nmands such as fdisk , you can view and change disk partitions. Filesystems can be added \nto partitions using the mkfs  command. Once created, filesystems can be mounted and \nunmounted using the mount  and umount  commands, respectively.\nLogical Volume Manager (LVM) offers a more powerful and flexible way of managing disk \npartitions. With LVM, you create pools of storage, called volume groups, which can allow \nyou to grow and shrink logical volumes as well as extend the size of your volume groups by \nadding more physical volumes.\nFor a more intuitive way of working with storage devices, Cockpit offers an intuitive, Web-\nbased interface for viewing and configuring storage on your Linux system. Using the Web \nUI, you can see both local and networked storage as well as reformat disks and modify disk \npartitions.\nWith most of the basics needed to become a system administrator covered at this point \nin the book, Chapter\u00a013, \u201cUnderstanding Server Administration,\u201d introduces concepts for \nextending those skills to manage network servers. Topics in that chapter include informa -\ntion on how to install, manage, and secure servers.\nExercises\nUse these exercises to test your knowledge of creating disk partitions, Logical Volume Man -\nager, and working with filesystems. You need a USB flash drive that is at least 1GB, which \nyou can erase for these exercises.\nThese tasks assume that you are running a Fedora or Red Hat Enterprise Linux system \n(although some tasks work on other Linux systems as well). If you are stuck, solutions to \nthe tasks are shown in Appendix B (although in Linux, there are often multiple ways to \ncomplete a task).\n1. Run a command as root to watch the system journal in a Terminal as fresh data \ncomes in and insert your USB flash drive. Determine the device name of the USB \nflash drive.", "doc_id": "a53e1d1c-b021-48e0-9376-400bde1e9d27", "embedding": null, "doc_hash": "3b67ad5dc14f0f7a818130a41d01b686e8d597a413918b91b71f4708234024f0", "extra_info": {"page_label": "329"}, "node_info": {"start": 0, "end": 2655}, "relationships": {"1": "f74019a3-4aa7-4bad-a044-fc1e1c028224"}}, "__type__": "1"}, "edc46c87-dd07-4fdf-8a93-c3215a39742a": {"__data__": {"text": "Part III: Becoming a Linux System Administrator3042. Run a command to list the partition table for the USB flash drive.\n3. Delete all the partitions on your USB flash drive, save the changes, and make sure \nthe changes were made both on the disk\u2019s partition table and in the Linux kernel.\n4. Add three partitions to the USB flash drive: 100MB Linux partition, 200MB swap \npartition, and 500MB LVM partition. Save the changes.\n5. Put an ext4 filesystem on the Linux partition.\n6. Create a mount point called /mnt/mypart  and mount the Linux partition on it.\n7. Enable the swap partition and turn it on so that additional swap space is immedi-\nately available.\n8. Create a volume group called abc  from the LVM partition, create a 200MB logical \nvolume from that group called data , add a VFAT partition, and then temporarily \nmount the logical volume on a new directory named /mnt/test . Check that it was \nsuccessfully mounted.\n9. Grow the logical volume from 200MB to 300MB.\n10. Do what you need to do to remove the USB flash drive safely from the computer: \nunmount the Linux partition, turn off the swap partition, unmount the logical \nvolume, and delete the volume group from the USB flash drive.", "doc_id": "edc46c87-dd07-4fdf-8a93-c3215a39742a", "embedding": null, "doc_hash": "f43c40a79e8b1075c4062aba5c915670847166ec08ce4a44004793f6671bd1ba", "extra_info": {"page_label": "330"}, "node_info": {"start": 0, "end": 1200}, "relationships": {"1": "58db01db-a401-437a-9989-24d7ec6882c3"}}, "__type__": "1"}, "77610945-a8b7-477d-857a-1bee8e30e18c": {"__data__": {"text": "Part IVChapter\u00a013 \nUnderstanding Server Administration\nChapter\u00a014 \nAdministering Networking\nChapter\u00a015 \nStarting and Stopping Services\nChapter\u00a016 \nConfiguring a Print Server\nChapter\u00a017 \nConfiguring a Web Server\nChapter\u00a018 \nConfiguring an FTP Server\nChapter\u00a019 \nConfiguring a Windows File Sharing (Samba) Server\nChapter\u00a020 \nConfiguring an NFS File Server\nChapter\u00a021 \nTroubleshooting LinuxBecoming a Linux Server \nAdministrator\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "77610945-a8b7-477d-857a-1bee8e30e18c", "embedding": null, "doc_hash": "5ff734c9fa251643775764b3e58321a691fa1f7afbcd2e29d0eb4029f2debc4e", "extra_info": {"page_label": "331"}, "node_info": {"start": 0, "end": 548}, "relationships": {"1": "e561c16d-fc03-4932-a73c-9648d362537b"}}, "__type__": "1"}, "72a10eb7-53c6-491d-b7a0-20ec29a7fede": {"__data__": {"text": "307\nCHAPTER13\nUnderstanding Server \nAdministration\nIN THIS CHAPTER\nAdministering Linux servers\nCommunicating with servers over networksSetting up logging locally and remotelyMonitoring server systemsManaging servers in the enterprise\nAlthough some system administration tasks are needed even on a desktop system (installing \nsoftware, setting up printers, and so on), many new tasks appear when you set up a Linux system to act as a server. That\u2019s especially true if the server that you configure is made public \nto anyone on the Internet, where you can be overloaded with requests from good guys while need-ing to be constantly on guard against attacks from bad guys.\nDozens of different kinds of servers are available for Linux systems. Most servers serve up data to remote clients, but others serve the local system (such as those that gather logging messages or kick off maintenance tasks at set times using the cron  facility). Many servers are represented by \nprocesses that run continuously in the background and respond to requests that come to them. These processes are referred to as daemon  processes.\nAs the name implies, servers exist to serve. The data that they serve can include web pages, files, database information, email, and lots of other types of content. As a server administrator, some of the additional challenges to your system administration skills include the following:\nRemote access  T o use a desktop system, you typically sit at its console. Server systems, by \ncontrast, tend to be housed in racks in climate-controlled environments under lock and key. More often than not, after the physical computers are in place, most administration of those machines is done using remote access tools. Often, no graphical interface is available, so you must rely on command-line tools or browser-based interfaces to do things such as remote login, remote copying, and remote execution. The most common of these tools are built on the Secure Shell (SSH) facility.\nDiligent security\n T\no be useful, a server must be able to accept requests for content from \nremote users and systems. Unlike desktop systems, which can simply close down all network \nLinux\u00ae Bible , Tenth Edition. Christopher Negus.\n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "72a10eb7-53c6-491d-b7a0-20ec29a7fede", "embedding": null, "doc_hash": "78eda9229049024a38f514f089cea3ceb4a41d79fdc481bf575020dfb857c171", "extra_info": {"page_label": "332"}, "node_info": {"start": 0, "end": 2289}, "relationships": {"1": "fd52834e-01e0-4394-821e-828524c37b01"}}, "__type__": "1"}, "2f24674a-9d84-4578-a438-fa11060fc2dd": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator308ports that allow incoming requests for access, a server must make itself vulner -\nable by allowing some access to its ports. That\u2019s why as a server administrator, it is \nimportant to open ports to services that are needed and lock down ports that are \nnot needed. You can secure services using tools such as iptables  and firewalld  \n(firewall tools) and Security Enhanced Linux (to limit the resources a service can \naccess from the local system).\nContinuous monitoring Although you typically turn off your laptop or desktop \nsystem when you are not using it, servers usually stay on 24\u00d77, 365 days a year. \nBecause you don\u2019t want to sit next to each server and continuously monitor it \npersonally, you can configure tools to monitor each server, gather log messages, \nand even forward suspicious messages to an email account of your choice. You can \nenable system activity reporters to gather data around the clock on CPU usage, \nmemory usage, network activity, and disk access.\nIn this chapter, I lay out some of the basic tools and techniques that you need to know to \nadminister remote Linux servers. You learn to use SSH tools to access your server securely, \ntransfer data back and forth, and even launch remote desktops or graphical applications and \nhave them appear on your local system. You learn to use remote logging and system activity \nreports to monitor system activities continuously.\nStarting with Server Administration\nWhether you are installing a file server, web server, or any of the other server facil -\nities available with Linux systems, many of the steps required for getting the server up \nand running are the same. Where server setup diverges is in the areas of configuration \nand tuning.\nIn later chapters, I describe specific servers and how they differ. In each of the server-\nrelated chapters that follow, you\u2019ll go through the same basic steps for getting that server \nstarted and available to be used by your clients.\nStep 1: Install the server\nAlthough most server software is not preinstalled on the typical Linux system, any general-\npurpose Linux system offers the software packages needed to supply every major type of \nserver available.\nSometimes, multiple software packages associated with a particular type of server are gath -\nered together in package groups (sometimes called package collections ). At other times, \nyou just need to install the server packages you want individually. Here are some server \npackage categories in Fedora and some of the packages available in each category:\nSystem logging server The rsyslog  service allows the local system to gather log \nmessages delivered from a variety of components on the system. It can also act as a \nremote logging server, gathering logging messages sent from other logging servers. \n(The rsyslog  service is described later in this chapter.) In recent Ubuntu, Fedora, ", "doc_id": "2f24674a-9d84-4578-a438-fa11060fc2dd", "embedding": null, "doc_hash": "33ebacb58b4e3bf1b513917d4e01a1fa4cc1eaa00a0e0bc4d076c5bb5be701e5", "extra_info": {"page_label": "333"}, "node_info": {"start": 0, "end": 2917}, "relationships": {"1": "aca8caa3-94b5-4081-a010-94c3082db795"}}, "__type__": "1"}, "79039ba9-b3fe-40ad-9cd9-1eca75851992": {"__data__": {"text": "Chapter 13: Understanding Server Administration\n309\n1313and RHEL systems, log messages are gathered in the systemd  journal, which can be \npicked up and redirected by the rsyslog  service or displayed locally by the jour -\nnalctl  command.\nPrint server  The Common UNIX Printing Service ( cups  package) is used most \noften to provide print server features on Linux systems. Packages that provide \ngraphical administration of CUPS ( system-config-printer ) and printer drivers \n(foomatic , hpijs , and others) are also available when you install CUPS. (See  \nChapter\u00a016, \u201cConfiguring a Print Server.\u201d)\nWeb server  The Apache ( httpd  or apache2  package) web server is the software \nused most often to serve web pages (HTTP content). Related packages include mod -\nules to help serve particular types of content (Perl, Python, PHP, and SSL connec -\ntions). Likewise, there are packages of related documentation ( httpd-manual ), \ntools for monitoring web data (webalizer), and tools for providing web proxy  \nservices (squid). (See Chapter\u00a017, \u201cConfiguring a Web Server.\u201d)\nFTP server  The Very Secure FTP daemon ( vsftpd  package) is the default FTP server \nused in Fedora and RHEL. Other FTP server packages include proftpd  and pure-\nftpd . (See Chapter\u00a018, \u201cConfiguring an FTP Server.\u201d)\nWindows file server Samba (samba  package) allows a Linux system to act as a Win -\ndows file and print server. (See Chapter\u00a019, \u201cConfiguring a Windows File Sharing \n[Samba] Server.\u201d)\nNFS file server Network File System (NFS) is the standard Linux and UNIX feature \nfor providing shared directories to other systems over a network. The nfs-utils  \npackage provides NFS services and related commands. (See Chapter\u00a020, \u201cConfiguring \nan NFS File Server.\u201d)\nMail server  These types of packages enable you to configure email servers, some -\ntimes referred to as a Mail Transport Agent (MTA) server. You have several choices \nof email servers, including sendmail , postfix  (default in Fedora and RHEL), and \nexim . Related packages, such as dovecot , allow the mail server to deliver email \nto clients.\nDirectory server Packages in this category provide remote and local authentication \nservices. These include Kerberos ( krb5-server ), LDAP (openldap-servers ), and \nNIS (ypserv ).\nDNS server The Berkeley Internet Name Domain service ( bind ) provides the software \nneeded to configure a server to resolve hostnames into IP addresses.\nNetwork Time Protocol server The ntpd  or chronyd  package provides a service \nthat you can enable to sync up your system clock with clocks from public or private \nNTP servers.\nSQL server  The PostgreSQL ( postgresql  and postgresql-server  packages) \nservice is an object-relational database management system. Related packages pro -\nvide PostgreSQL documentation and related tools. The MySQL ( mysql  and mysql-\nserver  packages) service is another popular open source SQL database server.  ", "doc_id": "79039ba9-b3fe-40ad-9cd9-1eca75851992", "embedding": null, "doc_hash": "cb058c35ee17daaca4b18ad72fd00531c523aa1118eece1d91baa5b1c213a68a", "extra_info": {"page_label": "334"}, "node_info": {"start": 0, "end": 2914}, "relationships": {"1": "28fb81f9-0196-4a98-97e6-f705938dd852"}}, "__type__": "1"}, "90ec7b2d-2dfa-4edb-836a-fc25c9726e7d": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator310A community-developed branch of MySQL called MariaDB has supplanted MySQL on \nmany Linux distributions.\nStep 2: Configure the server\nMost server software packages are installed with a default configuration that leans more \ntoward security than immediate full use. Here are some things to think about when you set \nout to configure a server.\nUsing configuration files\nTraditionally, Linux servers have been configured by editing plain-text files in the /etc  \ndirectory (or subdirectories). Often, there is a primary configuration file; sometimes, there \nis a related configuration directory in which files ending in .conf  can be pulled into the \nmain configuration file.\nThe httpd  package (Apache web server) is an example of a server package that has a pri-\nmary configuration file and a directory where other configuration files can be dropped in \nand be included with the service. The main configuration file in Fedora and RHEL is  \n/etc/httpd/conf/httpd.conf . The configuration directory is /etc/httpd/conf.d/ .\nAfter installing httpd  and related packages, you will see files in the /etc/httpd/conf.d/   \ndirectory that were placed there by different packages: mod_ssl , mod_perl , and so on. \nThis is a way that add-on packages to a service can have their configuration information \nenabled in the httpd  server, without the package trying to run a script to edit the main \nhttpd.conf  file.\nThe one downside to plain-text configuration files is that you don\u2019t get the kind of immedi-\nate error checking you get when you use graphical administration tools. You either have to \nrun a test command (if the service includes one) or actually try to start the service to see if \nthere is any problem with your configuration file.\nChecking the default configuration\nMost server software packages in Fedora and RHEL are installed with minimal configuration \nand lean more toward being secure than totally useful out of the box. While installing a \nsoftware package, some Linux distributions ask you things such as the directory in which \nyou want to install it or the user account with which you want to manage it.Tip\nInstead of using vi  to edit configuration files, use vim . Using the vim  command can help you catch configuration \nfile errors as you are editing.\nThe vim  command knows about the formats of many configuration files ( passwd , httpd.conf , fstab , and \nothers). If you make a mistake and type an invalid term or option in one of those files, or break the format somehow, \nthe color of the text changes. For example, in /etc/fstab , if you change the option defaults  to default , the \nword\u2019s color changes.", "doc_id": "90ec7b2d-2dfa-4edb-836a-fc25c9726e7d", "embedding": null, "doc_hash": "c08b05a3e08a75dcea2605938465a6f18e9d90b4ea8fa6668fe07e14e45ad9e0", "extra_info": {"page_label": "335"}, "node_info": {"start": 0, "end": 2677}, "relationships": {"1": "4a160c16-e8b2-4d6d-917b-032d47c7637f"}}, "__type__": "1"}, "ec8f9ae3-d7a3-4382-a1ae-a339bd5c4c76": {"__data__": {"text": "Chapter 13: Understanding Server Administration\n311\n1313Because RPM packages are designed to be installed unattended, the person installing the \npackage has no choice on how it is installed. The files are installed in set locations, spe -\ncific user accounts are enabled to manage it, and when you start the service, it might well \noffer limited accessibility. You are expected to configure the software after the package is \ninstalled to make the server fully functional.\nTwo examples of servers that are installed with limited functionality are mail servers \n(sendmail  or postfix  packages) and DNS servers ( bind  package). Both of these servers \nare installed with default configurations and start up on reboot. However, both also only \nlisten for requests on your localhost . So, until you configure those servers, people who \nare not logged in to your local server cannot send mail to the mail server or use your com-\nputer as a public DNS server, respectively.\nStep 3: Start the server\nMost services that you install in Linux are configured to start up when the system boots \nand then run continuously, listening for requests, until the system is shut down. There \nare two major facilities for managing services: systemd  (used now by RHEL, Ubuntu, and \nFedora) and SystemVinit scripts (used by Red Hat Enterprise Linux through RHEL 6. x).\nRegardless of which facility is used on your Linux system, it is your job to do things such \nas set whether you want the service to come up when the system boots and to start, stop, \nand reload the service as needed (possibly to load new configuration files or temporarily \nstop access to the service). Commands for doing these tasks are described in Chapter\u00a015, \n\u201cStarting and Stopping Services.\u201d\nMost, but not all, services are implemented as daemon processes. Here are a few things that \nyou should know about those processes:\nUser and group permissions Daemon processes often run as users and groups other \nthan root. For example, httpd  runs as apache and ntpd  runs as the ntp user. The \nreason for this is that if someone cracks these daemons, they would not have per -\nmissions to access files beyond what the services can access.\nDaemon configuration files Often, a service has a configuration file for the daemon \nstored in the /etc/sysconfig  directory. This is different than the service  \nconfiguration file in that its job is often just to pass arguments to the server  \nprocess itself rather than configure the service. For example, options you set in the \n/etc/sysconfig/rsyslogd  file are passed to the rsyslogd  daemon when it \nstarts up. You can tell the daemon, for example, to output additional debugging \ninformation or accept remote logging messages. See the man page for the service \n(for example, man rsyslogd ) to see what options are supported.\nPort numbers  Packets of data go to and from your system over network interfaces \nthrough ports for each supported protocol (usually UDP or TCP). Most standard ser -\nvices have specific port numbers to which daemons listen and to which clients  \nconnect. Unless you are trying to hide the location of a service, you typically \ndon\u2019t change the ports on which a daemon process listens. When you go to secure ", "doc_id": "ec8f9ae3-d7a3-4382-a1ae-a339bd5c4c76", "embedding": null, "doc_hash": "595465c789aff42c9e6c0fa34c804e4d1731b5bdd001d20bdd4d8ecbd3a7920c", "extra_info": {"page_label": "336"}, "node_info": {"start": 0, "end": 3227}, "relationships": {"1": "8ebd34ea-8ea7-4d80-a8ec-df5ef2a9f831"}}, "__type__": "1"}, "836e8d7b-02a3-4cbe-9d13-62848c5d4242": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator312a service, you must make sure that the port to the service is open on the firewall \n(see Chapter\u00a025, \u201cSecuring Linux on a Network,\u201d for information on iptables  and \nfirewalld  firewalls). Also, if you change a port on which the service is listening, \nand SELinux is in enforcing mode, SELinux may prevent the daemon from listening \non that port (see Chapter\u00a024, \u201cEnhancing Linux Security with SELinux,\u201d for more \ninformation on SELinux).\nNot all services run continuously as daemon processes. Some older UNIX services ran on \ndemand using the xinetd  super server. Other services just run once on startup and exit. \nStill others run only a set number of times, being launched when the crond  daemon sees \nthat the service was configured to run at the particular time.\nIn recent years, previous xinetd  services in RHEL and Fedora, such as telnet  and tftp , \nhave been converted to systemd  services. A number of services, including cockpit , use \nsystemd  sockets to achieve the same results.\nStep 4: Secure the server\nOpening your system to allow remote users to access it over the network is not a decision to be \ntaken lightly. Crackers all over the world run programs to scan for vulnerable servers that they \ncan take over for their data or their processing power. Luckily, there are measures that you can \nput in place on Linux systems to protect your servers and services from attacks and abuse.\nSome common security techniques are described in the following sections. These and other \ntopics are covered in more depth in Part V, \u201cLearning Linux Security Techniques.\u201d\nPassword protection\nGood passwords and password policies are the first line of defense in protecting a Linux \nsystem. If someone can log in to your server via ssh as the root user with a password of \nfoobar , expect to be cracked. A good technique is to disallow direct login by root and \nrequire every user to log in as a regular user and then use su  or sudo  to become root.\nYou can also use the Pluggable Authentication Module (PAM) facility to adjust the number \nof times that someone can have failed login attempts before blocking access to that person. \nPAM also includes other features for locking down authentication to your Linux server. For \na description of PAM, see Chapter\u00a023, \u201cUnderstanding Advanced Linux Security.\u201dNoTe\nOne reason for changing port numbers on a service is \u201csecurity by obscurity.\u201d For example, the sshd  service is a \nwell-known target for people trying to break into a system by guessing logins and passwords on TCP port 22.\nI have heard about people changing their Internet-facing sshd  service to listen on some other port number (perhaps \nsome unused, very high port number). Then they tell their friends or colleagues to log in to their machine from SSH by \npointing to this other port. The idea is that port scanners looking to break into a system might be less likely to scan \nthe normally unused port.", "doc_id": "836e8d7b-02a3-4cbe-9d13-62848c5d4242", "embedding": null, "doc_hash": "e2e3e5a3f66f80a6ba0e4e02e23beab6106d6557d44891d839d48dfc0fdc19b0", "extra_info": {"page_label": "337"}, "node_info": {"start": 0, "end": 2968}, "relationships": {"1": "5c8aec44-f558-4e2e-a36a-9bc8c9f66662"}}, "__type__": "1"}, "339cd940-60fe-419e-b2c7-4c62de0a1ce8": {"__data__": {"text": "Chapter 13: Understanding Server Administration\n313\n1313Of course, you can bypass passwords altogether by requiring public key authentication. To \nuse that type of authentication, you must make sure that any user you want to have access \nto your server has their public key copied to the server (such as through ssh-copy-id ). \nThen they can use ssh , scp , or related commands to access that server without typing \ntheir password. See the section \u201cUsing key-based (passwordless) authentication\u201d later in \nthis chapter for further information.\nFirewalls\nThe iptables  firewall service can track and respond to every packet coming from and \ngoing to network interfaces on your computer. Using iptables , you can drop or reject \nevery packet making requests for services on your system except for those few that you \nhave enabled. Further, you can tell iptables  to allow service requests only from certain \nIP addresses (good guys) or not allow requests from other addresses (bad guys).\nIn recent RHEL and Fedora versions, the firewalld  feature adds a layer of functionality \nto Linux firewall rules. With firewalld , you can not only insert firewall rules into the \nkernel, you can also organize firewall rules by dividing them up into zones and changing \nfirewall rules on the fly to react to different events.\nIn each of the server chapters coming up, I describe what ports need to be open to allow \naccess to services. Descriptions of how iptables  and firewalld  work are included in \nChapter\u00a025, \u201cSecuring Linux on a Network.\u201d\nTCP Wrappers\nTCP Wrappers, which uses /etc/hosts.allow and /etc/hosts.deny files to allow  \nand deny access in a variety of ways to selected services, was used primarily to secure older \nUNIX services, and it is no longer considered to be very secure. While the use of the TCP \nWrapper program (/usr/sbin/tcpd) is only common on systems that use xinetd, the  \n/etc/hosts.allow and /etc/hosts.deny files that the TCP Wrapper program checked \nbefore granting access to network services are often checked by daemons that are configured \nto do so. The configuration option within the configuration files for these daemons is often \nlabeled as TCP Wrapper support.\nSELinux\nFedora, Red Hat Enterprise Linux, and other Linux distributions come with the Security \nEnhanced Linux (SELinux) feature included and in Enforcing mode. Although the default \ntargeted mode doesn\u2019t have much impact on most applications that you run in Linux, it has \na major impact on most major services.\nA major function of SELinux is to protect the contents of your Linux system from the processes \nrunning on the system. In other words, SELinux makes sure a web server, FTP server, Samba \nserver, or DNS server can access only a restricted set of files on the system (as defined by \nfile contexts) and allows only a restricted set of features (as defined by Booleans and limited \nport access).\nDetails about how to use SELinux are contained in Chapter\u00a024, \u201cEnhancing Linux Security \nwith SELinux.\u201d", "doc_id": "339cd940-60fe-419e-b2c7-4c62de0a1ce8", "embedding": null, "doc_hash": "612dbfa6a08ec87cef1a113190e321c6ad75472150b84b76f5e2843591282a49", "extra_info": {"page_label": "338"}, "node_info": {"start": 0, "end": 3001}, "relationships": {"1": "74d3fbec-3350-441d-a0ca-21ae0adc6127"}}, "__type__": "1"}, "d85ba796-3d21-42ef-9e90-553ff0bfa055": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator314Security settings in configuration files\nWithin the configuration files of most services are values that you can set to secure the ser -\nvice further. For example, for file servers and web servers, you can restrict access to certain \nfiles or data based on username, hostname, IP address of the client, or other attributes.\nStep 5: Monitor the server\nBecause you can\u2019t be there to monitor every service, every minute, you need to put mon -\nitoring tools in place to watch your servers for you and make it easy for you to find out \nwhen something needs attention. Some of the tools that you can use to monitor your \nservers are described in the sections that follow.\nConfigure logging\nUsing the rsyslog  service (rsyslogd  daemon), you can gather critical information and \nerror conditions into log files about many different services. By default, in RHEL log mes -\nsages from applications are directed into log files in the /var/log  directory. For added \nsecurity and convenience, log messages can also be directed to a centralized server, provid -\ning a single location to view and manage logging for a group of systems.\nSeveral different software packages are available to work with rsyslog  and manage log \nmessages. The logwatch  feature scans your log files each night and sends critical informa -\ntion gathered from those files to an email account of your choice. The logrotate  feature \nbacks up log files into compressed archives when the logs reach a certain size or pass a set \namount of time since the previous backup.\nThe features for configuring and managing system logging are described in the section \n\u201cConfiguring System Logging\u201d later in this chapter.\nRun system activity reports\nThe sar  facility (which is enabled by the sysstat  package) can be configured to watch \nactivities on your system such as memory usage, CPU usage, disk latency, network activ -\nities, and other resource drains. By default, the sar  facility launches the sadc  program \nevery few minutes, day and night, to gather data. Viewing that data later can help you go \nback and figure out where and when demand is spiking on your system. The sar  facility is \ndescribed in the section \u201cChecking System Resources with sar \u201d later in this chapter.\nWatch activity live with Cockpit\nWith Cockpit running on your system, you can watch system activity in real time. Open \nyour web browser to display the Cockpit console ( https://localhost:9090 ). In real time, \nyou can watch percentage of CPU use, memory and swap consumption, how much data is \nwritten to and from disk (disk i/o), and network traffic as it is gathered and displayed \nacross the screen. Figure\u00a013.1 shows an example of the System area of the Cockpit console, \ndisplaying activity data.", "doc_id": "d85ba796-3d21-42ef-9e90-553ff0bfa055", "embedding": null, "doc_hash": "f69f262f3269c152d861a3ad3426715f25f8248964a8efc32e469be3ca4fa084", "extra_info": {"page_label": "339"}, "node_info": {"start": 0, "end": 2787}, "relationships": {"1": "abd6883c-c573-4fc0-a395-4cdf8754b926"}}, "__type__": "1"}, "b3d36e08-c5b2-4e70-b063-79cc3e6fcc96": {"__data__": {"text": "Chapter 13: Understanding Server Administration\n315\n1313Keep system software up to date\nAs security holes are discovered and patched, you must make sure that the updated soft -\nware packages containing those patches are installed on your servers. Again, with mission-\ncritical servers, the safest and most efficient way is to use subscribed Red Hat Enterprise \nLinux systems for your servers and then deploy security-related package updates to your \nsystem as soon as they are released and tested.\nTo keep your personal server and desktop systems up to date, there are various graphical \ntools to add software and to check for updates. You can also use the yum  command to \ncheck for and install all packages that are available for your RHEL or Fedora systems (enter \ndnf update  or yum update ).\nCheck the filesystem for signs of crackers\nTo check your filesystem for possible intrusion, you can run commands such as rpm -V  to \ncheck to see if any commands, document files, or configuration files have been tampered \nwith on your system. For more information on rpm -V , refer to the description of rpm -V  \nin Chapter\u00a010, \u201cGetting and Managing Software.\u201d\nNow that you have an overview of how Linux server configuration is done, the next sections \nof this chapter focus on the tools that you need to access, secure, and maintain your Linux \nserver systems.\nFIGURE 13.1\nLog in to Cockpit", "doc_id": "b3d36e08-c5b2-4e70-b063-79cc3e6fcc96", "embedding": null, "doc_hash": "34942dafb7af3ee1ddd290e168cb1cc0ae7ed80b5656d15d3be291df34f8e985", "extra_info": {"page_label": "340"}, "node_info": {"start": 0, "end": 1388}, "relationships": {"1": "dcb92122-199e-4561-ad5b-eda9717edee6"}}, "__type__": "1"}, "b023170f-8bb9-4433-a9ae-3c33ba2b1d21": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator316Checking and Setting Servers\nIf you are tasked with managing a Linux server, the following sections include a bunch \nof items that you can check. Keep in mind that nowadays many servers in large data cen -\nters are deployed and managed by larger platforms. So, know how the server is managed \nbefore you make any changes to it. Your changes might be overwritten automatically if you \nchanged the defined state of that system.\nManaging Remote Access with the Secure \nShell Service\nThe Secure Shell tools are a set of client and server applications that allow you to do basic \ncommunications between client computers and your Linux server. The tools include ssh , \nscp, sftp , and many others. Because communication is encrypted between the server \nand the clients, these tools are more secure than similar, older tools. For example, instead \nof using older remote login commands such as telnet  or rlogin , you could use ssh . \nThe ssh  command can also replace older remote execution commands, such as rsh . \nRemote copy commands, such as rcp , can be replaced with secure commands such as scp  \nand rsync .\nWith Secure Shell tools, both the authentication process and all communications that \nfollow are encrypted. Communications from telnet  and the older \u201c r\u201d commands expose \npasswords and all data to someone sniffing the network. Today, telnet  and similar com-\nmands should be used only for testing access to remote ports, providing public services \nsuch as PXE booting, or doing other tasks that don\u2019t expose your private data.\nMost Linux systems include secure shell clients, and many include the secure shell server \nas well. If you are using the Fedora or RHEL distribution, for example, the client and server \nsoftware packages that contain the ssh  tools are openssh , openssh-clients , and \nopenssh-server  packages as follows:\n# yum list installed | grep openssh\n...\nopenssh.x86_64           7.9p1-5.fc30    @anaconda       \nopenssh-clients.x86_64   7.9p1-5.fc30    @anaconda       \nopenssh-server.x86_64    7.9p1-5.fc30    @anaconda     \nOn Ubuntu, only the openssh-clients  package is installed. It includes the functional -\nity of the openssh  package. If you need the server installed, use the sudo apt-get \ninstall openssh-server  command.NoTe\nFor a deeper discussion of encryption techniques, refer to Chapter\u00a023, \u201cUnderstanding Advanced Linux Security.\u201d", "doc_id": "b023170f-8bb9-4433-a9ae-3c33ba2b1d21", "embedding": null, "doc_hash": "b875e6fdaf3c90cfcaa217fcef86d86e76cae4084747dc48229a95e951a498b1", "extra_info": {"page_label": "341"}, "node_info": {"start": 0, "end": 2424}, "relationships": {"1": "d2ee98bf-d5b7-4a47-a5d1-aad0a47aaf66"}}, "__type__": "1"}, "4fb366d2-0df5-49c1-b9fb-21f51c040cd7": {"__data__": {"text": "Chapter 13: Understanding Server Administration\n317\n1313$ sudo dpkg --list | grep openssh\nopenssh-client/bionic-updates,bionic-security,now 1:7.6p1-4ubuntu0.3 amd64  \n[installed]\n  secure shell (SSH) client, for secure access to remote machines\nopenssh-client-ssh1/bionic 1:7.5p1-10 amd64\n  secure shell (SSH) client for legacy SSH1 protocol\n \nopenssh-sftp-server/bionic-updates,bionic-security,now 1:7.6p1-4ubuntu0.3 \namd64 [installed]\n  secure shell (SSH) sftp server module, for SFTP access from remote machines\n$ sudo apt-get install openssh-server\nStarting the openssh-server service\nLinux systems that come with the openssh-server  package already installed  \nsometimes are not configured for it to start automatically. Managing Linux services (see  \nChapter\u00a015, \u201cStarting and Stopping Services\u201d) can be very different depending on the  \ndifferent distributions. Table\u00a013.1 shows the commands to use in order to ensure that the \nssh server daemon, sshd , is up and running on a Linux system.\nIf sshd  is not currently running, you can start it by issuing one of the commands listed in \nTable\u00a013.2. These commands need root privileges in order to work.\nThe commands in Table\u00a013.2 only start the ssh  or sshd  service. They do not configure it to \nstart automatically at boot. To make sure the server service is set up to start automatically, \nyou need to use one of the commands in Table\u00a013.3 using root privileges.TABLE 13.1  Commands to Determine sshd  Status\nDistribution Command to Determine sshd  Status\nRHEL 6 chkconfig --list sshd\nFedora and RHEL 7 or later systemctl status sshd.service\nUbuntu systemctl status ssh.service\nTABLE 13.2  Commands to Start sshd\nDistribution Command to Start sshd\nRHEL 6 service sshd start\nFedora and RHEL 7 or later systemctl start sshd.service\nUbuntu systemctl start ssh.service", "doc_id": "4fb366d2-0df5-49c1-b9fb-21f51c040cd7", "embedding": null, "doc_hash": "eb614b92163c68a62da4c599bc764b0f0e4a9f76688a3504b1c3f57350a1f78f", "extra_info": {"page_label": "342"}, "node_info": {"start": 0, "end": 1822}, "relationships": {"1": "565ace53-d45f-453a-980d-7c94b60086ac"}}, "__type__": "1"}, "87b4f30f-387e-4b49-aa9b-4dbdb23906ca": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator318When you install openssh-server  on Ubuntu, the sshd  daemon is configured to start \nautomatically at boot. Therefore, you may not need to run the command in Table\u00a013.3 for \nyour Ubuntu server.\nModify your firewall settings to allow the openssh-client  to access port 22 (firewalls are \ncovered in Chapter\u00a025, \u201cSecuring Linux on a Network\u201d). After the service is up and running \nand the firewall is properly configured, you should be able to use ssh  client commands to \naccess your system via the ssh  server.\nAny further configurations for what the sshd  daemon is allowed to do are handled in the \n/etc/ssh/sshd_config  file. At a minimum, set the PermitRootLogin  setting to no . \nThis stops anyone from remotely logging in as root.\n# grep PermitRootLogin /etc/ssh/sshd_config\nPermitRootLogin no\nAfter you have changed the sshd_config  file, restart the sshd  service. After that point, \nif you use ssh  to log in to that system from a remote client, you must do so as a regular \nuser and then use su  or sudo  to become the root user.\nUsing SSH client tools\nMany tools for accessing remote Linux systems have been created to make use of the SSH \nservice. The most frequently used of those tools is the ssh  command, which can be used \nfor remote login, remote execution, and other tasks. Commands such as scp  and rsync  \ncan copy one or more files at a time between SSH client and server systems. The sftp  \ncommand provides an FTP-like interface for traversing a remote filesystem and getting and \nputting files between the systems interactively.\nBy default, all of the SSH-related tools authenticate using standard Linux usernames and \npasswords, all done over encrypted connections. However, SSH also supports key-based \nauthentication, which can be used to configure key-based and possibly passwordless \nauthentication between clients and SSH servers, as described in the section \u201cUsing key-\nbased (passwordless) authentication\u201d later in this chapter.\nUsing ssh for remote login\nUse the ssh  command from another Linux computer to test that you can log in to the \nLinux system running your sshd  service. The ssh  command is one that you will use often \nto access a shell on the servers you are configuring.TABLE 13.3  Commands to Start sshd  at Boot\nDistribution Command to Start sshd  at Boot\nRHEL 6 chkconfig sshd on\nFedora and RHEL 7 or later systemctl enable sshd.service\nUbuntu systemctl enable ssh.service", "doc_id": "87b4f30f-387e-4b49-aa9b-4dbdb23906ca", "embedding": null, "doc_hash": "514f81825a5a9f04586146b38293d15bad641fbcfa05d85ebd7ec7ee6d4636d0", "extra_info": {"page_label": "343"}, "node_info": {"start": 0, "end": 2471}, "relationships": {"1": "a6eb447b-1b9c-44f0-9504-b2ba82a019c6"}}, "__type__": "1"}, "08d1a41a-9330-49a3-be95-1dc1d02f9a0b": {"__data__": {"text": "Chapter 13: Understanding Server Administration\n319\n1313Try logging in to your Linux server from another Linux system using the ssh  command. (If \nyou don\u2019t have another Linux system, you can simulate this by typing localhost  instead \nof the IP address and logging in as a local user.) The following is an example of remotely \nlogging in to johndoe \u2019s account on 10.140.67.23 :\n$ ssh johndoe@10.140.67.23\nThe authenticity of host '10.140.67.23 (10.140.67.23)' \n     can't be established.\nRSA key fingerprint is \n     a4:28:03:85:89:6d:08:fa:99:15:ed:fb:b0:67:55:89.\nAre you sure you want to continue connecting (yes/no)? yes\nWarning: Permanently added '10.140.67.23' (RSA) to the \n     list of known hosts.\njohndoe@10.140.67.23's password: *********\nIf this is the very first time that you have logged in to that remote system using the ssh  \ncommand, the system asks you to confirm that you want to connect. Type yes , and press \nEnter. When prompted, enter the user\u2019s password.\nWhen you type yes  to continue, you accept the remote host\u2019s public key. At that point, the \nremote host\u2019s public key is downloaded to the client in the client\u2019s ~/.ssh/known_hosts  \nfile. Now data exchanged between these two systems can be encrypted and decrypted using \nRSA asymmetric encryption (see Chapter\u00a023, \u201cUnderstanding Advanced Linux Security\u201d). \nAfter you are logged in to the remote system, you can begin typing shell commands. The \nconnection functions like a normal login. The only difference is that the data is encrypted \nas it travels over the network.\nWhen you are finished, type exit  to end the remote connection. The connection is closed, \nand you are returned to the command prompt on your local system. (If the local shell \ndoesn\u2019t return after you exit the remote shell, typing ~.  usually closes the connection.)\n$ exit\nlogout\nConnection to 10.140.67.23 closed\nAfter you have remotely connected to a system, a file in your local system subdirectory, \n~.ssh/known_hosts , will exist. This file contains the public key of the remote host \nalong with its IP address. Your server\u2019s public and private keys are stored in the /etc/ssh  \ndirectory.\n$ ls .ssh\nknown_hosts\n$ cat .ssh/known_hosts\n10.140.67.23 ssh-rsa\nAAAAB3NzaC1yc2EAAAABIwAAAQEAoyfJK1YwZhNmpHE4yLPZAZ9ZNEdRE7I159f3I\nyGiH21Ijfqs\nNYFR10ZlBLlYyTQi06r/9O19GwCaJ753InQ8FWHW+OOYOG5pQmghhn\n/x0LD2uUb6egOu6zim1NEC\nJwZf5DWkKdy4euCUEMSqADh/WYeuOSoZ0pp2IAVCdh6\nw/PIHMF1HVR069cvdv+OTL4vD0X8llSpw", "doc_id": "08d1a41a-9330-49a3-be95-1dc1d02f9a0b", "embedding": null, "doc_hash": "05309dc93cede4c4b1f3fcb9bf8e27fca41fde1b12173552363972c3f0702275", "extra_info": {"page_label": "344"}, "node_info": {"start": 0, "end": 2448}, "relationships": {"1": "c7be0de5-97af-4039-9546-96d64af43239"}}, "__type__": "1"}, "f3914009-8f15-4d65-a1b9-b49f2e29445c": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator3200ozqRptz2UQgQBBbBjK1RakD7fY1TrWv\nNQhYG/ugt gPaY4JDYeY6OBzcadpxZmf7EYUw0ucXGVQ1a\nNP/erIDOQ9rA0YNzCRv\ny2LYCm2/9adpAxc+UYi5UsxTw4ewSBjmsXYq//Ahaw4mjw==\nUsing ssh for remote execution\nBesides logging into a remote shell, the ssh  command can be used to execute a command \non the remote system and have the output returned to the local system. Here is \nan example:\n$ ssh johndoe@10.140.67.23 hostname\njohndoe@10.140.67.23's password: **********\nhost01.example.com\nIn the example just shown, the hostname  command runs as the user johndoe  on the \nLinux system located at IP address 10.140.67.23 . The output of the command is the \nname of the remote host (in this case, host01.example.com ), which appears on the \nlocal screen.\nIf you run a remote execution command with ssh  that includes options or arguments, be \nsure to surround the whole remote command line in quotes. Keep in mind that if you refer \nto files or directories in your remote commands, relative paths are interpreted in relation to \nthe user\u2019s home directory, as shown here:\n$ ssh johndoe@10.140.67.23 \"cat myfile\"\njohndoe@10.140.67.23's password: **********\nContents of the myfile file located in johndoe's home directory.\nThe ssh  command just shown goes to the remote host located at 10.140.67.23  and runs \nthe cat myfile  command as the user johndoe . This causes the contents of the myfile  \nfile from that system to be displayed on the local screen.\nAnother type of remote execution that you can do with ssh  is X11 forwarding. If X11 \nforwarding is enabled on the server ( X11Forwarding yes is set in the /etc/sshd/\nsshd_config  file), you can run graphical applications from the server securely over the \nSSH connection using ssh  -X. For a new server administrator, this means that if there are \ngraphical administration tools installed on a server, you can run those tools without having  \nto sit at the console, as in this example:\n$ ssh -X johndoe@10.140.67.23 system-config-printer\njohndoe@10.140.67.23's password: **********Tip\nAny later attempts by this user to contact the server at 10.140.67.23 are authenticated using this stored key. If the \nserver should change its key (which happens if the operating system is reinstalled or if keys are rotated), attempts \nto ssh  to that system result in a refused connection and dire warnings that you may be under attack. If the key has \nindeed changed, in order to be able to ssh  to that address again, just remove the host\u2019s key (the whole line) from \nyour known _hosts  file and you can copy over the new key.", "doc_id": "f3914009-8f15-4d65-a1b9-b49f2e29445c", "embedding": null, "doc_hash": "d17228e44a07c2c1208cd73de2d09cb519046ae2f4cb2611aa8a261b3340a04c", "extra_info": {"page_label": "345"}, "node_info": {"start": 0, "end": 2586}, "relationships": {"1": "eb846ad8-65cf-45c2-ad18-411e00398d9e"}}, "__type__": "1"}, "6f02c832-6607-49be-a7c8-2eb3c745eef0": {"__data__": {"text": "Chapter 13: Understanding Server Administration\n321\n1313After running this command, you are prompted for the root password. After that, the \nPrinters window appears, ready for you to configure a printer. Just close the window when \nyou are finished, and the local prompt returns. You can do this for any graphical adminis -\ntration tool or just regular X applications (such as the gedit graphical editor, so that you \ndon\u2019t have to use vi ).\nIf you want to run several X commands and don\u2019t want to have to reconnect each time, you \ncan use X11 forwarding directly from a remote shell as well. Put them in the background \nand you can have several remote X applications running on your local desktop at once. \nHere\u2019s an example:\n$ ssh -X johndoe@10.140.67.23\njohndoe@10.140.67.23's password: **********\n$ system-config-printer &\n$ gedit &\n$ exit\nAfter you have finished using the graphical applications, close them as you would normally. \nThen type exit , as shown in the preceding code, to leave the remote shell and return to \nyour local shell.\nCopying files between systems with scp and rsync\nThe scp  command is similar to the old UNIX rcp  command for copying files to and from \nLinux systems, except that all communications are encrypted. Files can be copied from the \nremote system to the local system or local to remote. You can also copy files recursively \nthrough a whole directory structure if you choose.\nThe following is an example of using the scp  command to copy a file called memo  from \nthe home directory of the user chris  to the /tmp  directory on a remote computer as the \nuser johndoe :\n$ scp /home/chris/memo johndoe@10.140.67.23:/tmp\njohndoe@10.140.67.23's password: ***************\nmemo       100%|****************|  153   0:00\nYou must enter the password for johndoe . After the password is accepted, the file is \ncopied to the remote system successfully.\nYou can do recursive copies with scp  using the -r  option. Instead of a file, pass a directory \nname to the scp  command and all files and directories below that point in the filesystem \nare copied to the other system.\n$ scp johndoe@10.140.67.23:/usr/share/man/man1/ /tmp/\njohndoe@10.140.67.23's password: ***************\nvolname.1.gz                              100%  543   0.5KB/s  00:00\nmtools.1.gz                               100% 6788   6.6KB/s  00:00\nroqet.1.gz                                100% 2496   2.4KB/s  00:00\n...", "doc_id": "6f02c832-6607-49be-a7c8-2eb3c745eef0", "embedding": null, "doc_hash": "4221cceb7baf86aaaeb5e76dbf16c96808d58faea4da1024d3e2e9a6a44e7aad", "extra_info": {"page_label": "346"}, "node_info": {"start": 0, "end": 2414}, "relationships": {"1": "68a34bb1-8dc7-414a-9237-c93435a7a17d"}}, "__type__": "1"}, "f4f7e0f9-19c4-4b98-ab26-5966659d8915": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator322As long as the user johndoe  has access to the files and directories on the remote system \nand the local user can write to the target directory (both are true in this case), the direc -\ntory structure from /usr/share/man/man1  down is copied to the local /tmp  directory.\nThe scp  command can be used to back up files and directories over a network. However, if \nyou compare scp  to the rsync  command, you see that rsync  (which also works over SSH \nconnections) is a better backup tool. Try running the scp  command shown previously to \ncopy the man1  directory (you can simulate the command using localhost  instead of the \nIP address if you only have one accessible Linux system). Now enter the following on the \nsystem to which you copied the files:\n$ ls -l /usr/share/man/man1/batch* /tmp/man1/batch*\n-rw-r--r--.1 johndoe johndoe 2628 Apr 15 15:32 /tmp/man1/batch.1.gz\nlrwxrwxrwx.1 root root 7 Feb 14 17:49 /usr/share/man/man1/batch.1.gz\n      -> at.1.gz\nNext, run the scp  command again and list the files once more:\n$ scp johndoe@10.140.67.23:/usr/share/man/man1/ /tmp/\njohndoe@10.140.67.23's password: ***************\n$ ls -l /usr/share/man/man1/batch* /tmp/man1/batch*\n-rw-r--r--.1 johndoe johndoe 2628 Apr 15 15:40 /tmp/man1/batch.1.gz\nlrwxrwxrwx.1 root root 7 Feb 14 17:49 /usr/share/man/man1/batch.1.gz\n      -> at.1.gz\nThe output of those commands tells you a few things about how scp  works:\nAttributes lost  Permissions or date/time stamp attributes were not retained when \nthe files were copied. If you were using scp  as a backup tool, you would probably \nwant to keep permissions and time stamps on the files if you needed to restore the \nfiles later.\nSymbolic links lost The batch.1.gz  file is actually a symbolic link to the at.1.gz  \nfile. Instead of copying the link, scp  follows the link and actually copies the file. \nAgain, if you were to restore this directory, batch.1.gz  would be replaced by the \nactual at.1.gz  file instead of a link to it.\nCopy repeated unnecessarily If you watched the second scp  output, you would notice \nthat all files were copied again, even though the exact files being copied were already \non the target. The updated modification date confirms this. By contrast, the rsync  \ncommand can determine that a file has already been copied and not copy the file again.\nThe rsync  command is a better network backup tool because it can overcome some of the \nshortcomings of scp  just listed. Try running an rsync  command to do the same action \nthat scp  just did, but with a few added options:\n$ rm -rf /tmp/man1/\n$ rsync -avl johndoe@10.140.67.23:/usr/share/man/man1/ /tmp/\njohndoe@10.140.67.23's password: ***************\nsending incremental file list\nman1/", "doc_id": "f4f7e0f9-19c4-4b98-ab26-5966659d8915", "embedding": null, "doc_hash": "a73ba87c84837487eb67e3f36d9ddf4194702ae7488f2cd33c89b4041244ce89", "extra_info": {"page_label": "347"}, "node_info": {"start": 0, "end": 2760}, "relationships": {"1": "a9e10a71-1581-4121-8e75-e7653839a766"}}, "__type__": "1"}, "798322db-f167-43fe-b474-e5dd9cb15d09": {"__data__": {"text": "Chapter 13: Understanding Server Administration\n323\n1313man1/HEAD.1.gz\nman1/Mail.1.gz -> mailx.1.gz\n...\n$ rsync -avl johndoe@10.140.67.23:/usr/share/man/man1/ /tmp/\njohndoe@10.140.67.23's password: ***************\nsending incremental file list\nsent 42362 bytes  received 13 bytes  9416.67 bytes/sec\ntotal size is 7322223  speedup is 172.80\n$ ls -l /usr/share/man/man1/batch* /tmp/man1/batch*\nlrwxrwxrwx.1 johndoe johndoe 7 Feb 14 17:49 /tmp/man1/batch.1.gz\n       -> at.1.gz\nlrwxrwxrwx.1 root root 7 Feb 14 17:49 /usr/share/man/man1/batch.1.gz\n       -> at.1.gz\nAfter removing the /tmp/man1  directory, you run an rsync  command to copy all of the \nfiles to the /tmp/man1  directory, using -a  (recursive archive), -v  (verbose), and -l  (copy \nsymbolic links). Then run the command immediately again and notice that nothing is \ncopied. The rsync  command knows that all of the files are there already, so it doesn\u2019t copy \nthem again. This can be a tremendous savings of network bandwidth for directories with \ngigabytes of files where only a few megabytes change.\nAlso notice from the output of ls  -l that the symbolic links have been preserved on the \nbatch.1.gz  file and so has the date/time stamp on the file. If you need to restore those \nfiles later, you can put them back exactly as they were.\nThis use of rsync  is good for backups. But what if you wanted to mirror two directories, \nmaking the contents of two directory structures exactly the same on two machines? The \nfollowing commands illustrate how to create an exact mirror of the directory structure on \nboth machines using the directories shown with the previous rsync  commands.\nFirst, on the remote system, copy a new file into the directory being copied:\n# cp /etc/services /usr/share/man/man1\nNext, on the local system, run rsync  to copy across any new files (in this case, just the \ndirectory and the new file, services ):\n$ rsync -avl johndoe@10.140.67.23:/usr/share/man/man1 /tmp\njohndoe@10.140.67.23's password:\n***************\nsending incremental file list\nman1/\nman1/services\nAfter that, go back to the remote system and remove the new file:\n$ sudo rm /usr/share/man/man1/services\nNow, on the local system, run rsync  again and notice that nothing happens. At this point, \nthe remote and local directories are different because the local system has the services file \nand the remote doesn\u2019t. That is correct behavior for a backup directory. (You want to have ", "doc_id": "798322db-f167-43fe-b474-e5dd9cb15d09", "embedding": null, "doc_hash": "79e458dedb35a6e44837be07ed2480204eddd9e66898464203b6e21b6793149e", "extra_info": {"page_label": "348"}, "node_info": {"start": 0, "end": 2439}, "relationships": {"1": "6a67a70f-32ed-4ac4-ac56-ea799b7ea338"}}, "__type__": "1"}, "c81184ad-6949-49ec-adab-006f837a5725": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator324files on the backup in case something was removed by mistake.) However, if you want the \nremote and local directories to be mirrored, you would have to add the --delete  option. \nThe result is that the services file is deleted on the local system, making the remote and \nlocal directory structures in sync.\n$ rsync -avl /usr/share/man/man1 localhost:/tmp\njohndoe@10.140.67.23's password: ***************\nsending incremental file list\nman1/\n$ rsync -avl --delete johndoe@10.140.67.23:/usr/share/man/man1 /tmp\njohndoe@10.140.67.23's password: ***************\nsending incremental file list\ndeleting man1/services\nInteractive copying with sftp\nIf you don\u2019t know exactly what you want to copy to or from a remote system, you can use \nthe sftp  command to create an interactive FTP-style session over the SSH service. Using \nsftp , you can connect to a remote system over SSH, change directories, list directory con -\ntents, and then (given proper permission) get files from and put files on the server. Keep in \nmind that, despite its name, sftp  has nothing to do with the FTP protocol and doesn\u2019t use \nFTP servers. It simply uses an FTP style of interaction between a client and a sshd  server.\nThe following example shows the user johndoe  connecting to jd.example.com :\n$ sftp johndoe@jd.example.com\nConnecting to jd.example.com\njohndoe@jd.example.com's password: ***************\nsftp>\nAt this point, you can begin an interactive FTP session. You can use get  and put  com-\nmands on files as you would with any FTP client, but with the comfort of knowing that you \nare working on an encrypted and secure connection. Because the FTP protocol passes user -\nnames, passwords, and data in clear text, using sftp  over SSH, if possible, is a much better \nalternative for allowing your users to copy files interactively from the system.\nUsing key-based (passwordless) authentication\nIf you are using SSH tools to connect to the same systems throughout the day, you might \nfind it inconvenient to be entering your password over and over again. Instead of using \npassword-based authentication, SSH allows you to set up key-based authentication to use \ninstead. Here\u2019s how it works:\n\u25a0\u25a0You create a public key and a private key.\n\u25a0\u25a0You guard the private key but copy the public key across to the user account on the \nremote host to which you want to do key-based authentication.\n\u25a0\u25a0With your key copied to the proper location, you use any SSH tools to connect to \nthe user account on the remote host, but instead of asking you for a password, the \nremote SSH service compares the public key and the private key and allows you \naccess if the two keys match.", "doc_id": "c81184ad-6949-49ec-adab-006f837a5725", "embedding": null, "doc_hash": "d9e868953b7c580896f2c1c6c2520c5e31fac63a06039077eb8cfeab00a8df37", "extra_info": {"page_label": "349"}, "node_info": {"start": 0, "end": 2692}, "relationships": {"1": "e4323b44-16c2-43de-b8b5-664de2dd767a"}}, "__type__": "1"}, "a36db39b-9dd9-445f-b91c-56794d81ac4d": {"__data__": {"text": "Chapter 13: Understanding Server Administration\n325\n1313When you create the keys, you are given the option to add a passphrase to your private \nkey. If you decide to add a passphrase, even though you don\u2019t need to enter a password to \nauthenticate to the remote system, you still need to enter your passphrase to unlock your \nprivate key. If you don\u2019t add a passphrase, you can communicate using your public/private \nkey pairs in a way that is completely passwordless. However, if someone should get ahold of \nyour private key, they could act as you in any communication that required that key.\nThe following procedure demonstrates how a local user named chris  can set up key-based \nauthentication to a remote user named johndoe  at IP address 10.140.67.23 . If you don\u2019t \nhave two Linux systems, you can simulate this by using two user accounts on your local \nsystem. I start by logging in as the local user named chris  and typing the following to \ngenerate my local public/private key pair:\n$ ssh-keygen\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/home/chris/.ssh/id_rsa): ENTER\nEnter passphrase (empty for no passphrase): ENTER\nEnter same passphrase again: ENTER\nYour identification has been saved in /home/chris/.ssh/id_rsa.\nYour public key has been saved in /home/chris/.ssh/id_rsa.pub.\nThe key fingerprint is:\nbf:06:f8:12:7f:f4:c3:0a:3a:01:7f:df:25:71:ec:1d chris@abc.example.com\nThe key's randomart image is:\n ...\nI accepted the default RSA key (DSA keys are also allowed) and pressed Enter twice to have \na blank passphrase associated with the key. As a result, my private key ( id_rsa ) and \npublic key ( id_rsa.pub ) are copied to the .ssh  directory in my local home directory. The \nnext step is to copy that key over to a remote user so that I can use key-based authentica -\ntion each time I connect to that user account with ssh  tools:\n $ ssh-copy-id -i ~/.ssh/id_rsa.pub johndoe@10.140.67.23\njohndoe@10.140.67.23's password: \n***************\nWhen prompted, I entered johndoe \u2019s password. With that accepted, the public key \nbelonging to chris  is copied to the authorized_keys  file in johndoe \u2019s .ssh  directory \non the remote system. Now, the next time chris  tries to connect to johndoe \u2019s account, \nthe SSH connection is authenticated using those keys. Because no passphrase is put on the \nprivate key, no passphrase is required to unlock that key when it is used.\nLog into the machine with ssh johndoe@10.140.67.23 , and check in the $HOME/.ssh/\nauthorized_keys  to make sure that you haven\u2019t added extra keys that you weren\u2019t \nexpecting.\n[chris]$ ssh johndoe@10.140.67.23\nLast login: Sun Apr 17 10:12:22 2016 from  10.140.67.22\n[johndoe]$", "doc_id": "a36db39b-9dd9-445f-b91c-56794d81ac4d", "embedding": null, "doc_hash": "5ee06411e4434c46ed2e46040da9f748f086d3c00ad06924c3bb4aaafe6d6733", "extra_info": {"page_label": "350"}, "node_info": {"start": 0, "end": 2695}, "relationships": {"1": "7348dee9-51b1-4658-99d9-f3eee1141e83"}}, "__type__": "1"}, "b7a3e8dc-2f15-4f7a-a7f4-b61b5f1c17ed": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator326With the keys in place, chris  could now use ssh , scp , rsync , or any other SSH-enabled \ncommand to do key-based authentication. Using these keys, for example, an rsync  \ncommand could go into a cron  script and automatically back up johndoe \u2019s home directory \nevery night.\nWant to secure your remote system further? After you have the keys in place on your \nremote system for everyone you want to allow to log in to that system, you can set the \nsshd  service on the remote system to not allow password authentication by changing the \nPasswordAuthentication  setting in the /etc/ssh/sshd_config  file to no , so that it \nappears as follows:\nPasswordAuthentication no\nThen restart the sshd  service (systemctl restart sshd ). After that, anyone with \na valid key is still accepted. Anyone who tries to log in without a key gets the following \nfailure message and doesn\u2019t even get a chance to enter a username and password:\nPermission denied (publickey,gssapi-keyex,gssapi-with-mic) .\nConfiguring System Logging\nWith the knowledge of how to access your remote server using SSH tools, you can log in to \nthe server and set up some of the services needed to make sure that it\u2019s running smoothly. \nSystem logging is one of the basic services configured for Linux to keep track of what is \nhappening on the system.\nThe rsyslog  service (rsyslogd  daemon) provides the features to gather log messages \nfrom software running on the Linux system and direct those messages to local log files, \ndevices, or remote logging hosts. Configuration of rsyslog  is similar to the configuration \nof its predecessor, syslog . However, rsyslog  allows you to add modules to manage and \ndirect log messages more specifically.\nIn recent Red Hat Enterprise Linux and Fedora releases, the rsyslog  facility leverages \nmessages that are gathered and stored in the systemd  journal. To display journal log \n messages directly from the systemd  journal, instead of viewing them from files in the  \n/var/log  directory, use the journalctl  command.\nEnabling system logging with rsyslog\nMost of the files in the /var/log  directory are populated with log messages directed to \nthem from the rsyslog  service. The rsyslogd  daemon is the system logging daemon. It \naccepts log messages from a variety of other programs and writes them to the appropriate \nlog files. This is better than having every program write directly to its own log file because \nit enables you to manage centrally how log files are handled.\nConfiguring rsyslogd  to record varying levels of detail in the log files is possible. It can \nbe told to ignore all but the most critical messages, or it can record every detail.", "doc_id": "b7a3e8dc-2f15-4f7a-a7f4-b61b5f1c17ed", "embedding": null, "doc_hash": "c3d1fda5f184330a6217b65ac7959060055837257f0482f360147320fb903dcb", "extra_info": {"page_label": "351"}, "node_info": {"start": 0, "end": 2713}, "relationships": {"1": "a63beb90-a819-49bf-9de1-d855c827a2d6"}}, "__type__": "1"}, "27cf3b8d-f30f-4141-aad0-362eed165343": {"__data__": {"text": "Chapter 13: Understanding Server Administration\n327\n1313The rsyslogd  daemon can even accept messages from other computers on your network. \nThis remote logging feature is particularly handy because it enables you to centralize the \nmanagement and review of the log files from many systems on your network. There is also a \nmajor security benefit to this practice.\nWith remote logging, if a system on your network is broken into, the cracker cannot delete \nor modify the log files because those files are stored on a separate computer. It is impor -\ntant to remember, however, that those log messages are not, by default, encrypted (though \nencryption can be enabled). Anyone tapping into your local network can eavesdrop on \nthose messages as they pass from one machine to another. Also, although crackers may not \nbe able to change old log entries, they can affect the system such that any new log mes -\nsages should not be trusted.\nRunning a dedicated loghost, a computer that serves no purpose other than to record log \nmessages from other computers on the network, is not uncommon. Because this system \nruns no other services, it is unlikely that it will be broken into. This makes it nearly impos -\nsible for crackers to erase their tracks completely.\nUnderstanding the rsyslog.conf file\nThe /etc/rsyslog.conf  file is the primary configuration file for the rsyslog  service. \nIn the /etc/rsyslog.conf  file, a modules section lets you include or not include specific \nfeatures in your rsyslog  service. The following is an example of the modules section of  \n/etc/rsyslog.conf  in RHEL 8:\nmodule(load=\"imuxsock\"\n    # provides support for local system logging (e.g. via logger command)\n     SysSock.Use=\"off\") # Turn off message reception via local log socket;\n                        # local messages are retrieved through imjournal now.\nmodule(load=\"imjournal\"\n    # provides access to the systemd journal\n        StateFile=\"imjournal.state\") # File to store the position in the journal\n#module(load=\"imklog\") \n    # reads kernel messages (the same are read from journald)\n#module(load=\"immark\")\n    # provides --MARK-- message capability\n \n# Provides UDP syslog reception\n# for parameters see http://www.rsyslog.com/doc/imudp.html\n#module(load=\"imudp\") # needs to be done just once\n#input(type=\"imudp\" port=\"514\")\n \n# Provides TCP syslog reception\n# for parameters see http://www.rsyslog.com/doc/imtcp.html\n#module(load=\"imtcp\") # needs to be done just once\n#input(type=\"imtcp\" port=\"514\")\nEntries beginning with module(load=  load the modules that follow. Modules that are cur -\nrently disabled are preceded by a pound sign ( #). The imjournal  module lets rsyslog  ", "doc_id": "27cf3b8d-f30f-4141-aad0-362eed165343", "embedding": null, "doc_hash": "1b2ce561c48b2860a36249f8c172af8cf123d2adf31eb5077155d1846dd02e2a", "extra_info": {"page_label": "352"}, "node_info": {"start": 0, "end": 2677}, "relationships": {"1": "c6260607-7b54-4216-bc53-3f28e15172ee"}}, "__type__": "1"}, "834b91d0-dcc9-4ba5-b5e8-0aa082ba0a9d": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator328access the systemd  journal. The imuxsock  module is needed to accept messages from the \nlocal system. (It should not be commented out\u2014preceded by a pound sign\u2014unless you have \na specific reason to do so.) The imklog  module logs kernel messages.\nModules not enabled by default include the immark  module, which allows --MARK--  mes-\nsages to be logged (used to indicate that a service is alive). The imudp  and imtcp  modules \nand related port number entries are used to allow the rsyslog  service to accept remote \nlogging messages and are discussed in more detail in the section \u201cSetting up and using a \nloghost with rsyslogd \u201d later in this chapter.\nMost of the work done in the /etc/rsyslog.conf  configuration file involves modifying \nthe RULES  section. The following is an example of some of the rules in the RULES  sec-\ntion of the /etc/rsyslog.conf  file (note that in Ubuntu, you need to look in the /etc/\nrsyslog.d  directory for this configuration information):\n#### RULES ####\n# Log all kernel messages to the console.\n \n# Logging much else clutters up the screen.\n \n#kern.*                                        /dev/console\n# Log anything (except mail) of level info or higher.\n# Don't log private authentication messages!\n*.info;mail.none;authpriv.none;cron.none       /var/log/messages\n# The authpriv file has restricted access.\nauthpriv.*                                     /var/log/secure\n# Log all the mail messages in one place.\nmail.*                                         -/var/log/maillog\n# Log cron stuff\ncron.*                                         /var/log/cron\nRules entries come in two columns. In the left column are designations of what messages \nare matched; the right column shows where matched messages go. Messages are matched \nbased on facility ( mail , cron , kern , and so on) and priority (starting at debug , info , \nnotice , and up to crit , alert , and emerg ), separated by a dot ( .). So mail.info  \nmatches all messages from the mail service that are info level and above.\nAs for where the messages go, most messages are directed to files in the /var/log  direc -\ntory. You can, however, direct messages to a device (such as /dev/console ) or a remote \nloghost (such as @loghost.example.com ). The at sign ( @) indicates that the name that \nfollows is the name of the loghost.\nBy default, logging is done only to local files in the /var/log  directory. However, if you \nuncomment the kern.*  entry, you can easily direct kernel messages of all levels to your \ncomputer\u2019s console screen.\nThe first working entry in the preceding example shows that info level messages from \nall services ( *) are matched by that rule, with the exception of messages from mail , ", "doc_id": "834b91d0-dcc9-4ba5-b5e8-0aa082ba0a9d", "embedding": null, "doc_hash": "4877bf1ebdd839f907319da7887aff682f9a04b3952e616e58d757630bf164d4", "extra_info": {"page_label": "353"}, "node_info": {"start": 0, "end": 2761}, "relationships": {"1": "45758165-6462-4f92-afaa-29c2e4f9046b"}}, "__type__": "1"}, "20c243ac-ab44-4fc3-bd52-49acdeb1d9b2": {"__data__": {"text": "Chapter 13: Understanding Server Administration\n329\n1313authpriv , and cron  services (which are excluded with the word none ). All of the \nmatched messages are directed to the /var/log/messages  file.\nThe mail , authpriv  (authentication messages), and cron  (cron  facility messages) ser -\nvices each has its own log files, as listed in the columns to their right. To understand \nthe format of those and other log files, the format of the /var/log/messages  file is \ndescribed next.\nUnderstanding the messages log file\nBecause of the many programs and services that record information to the messages  log \nfile, understanding the format of this file is important. You can get a good early warning \nof problems developing on your system by examining this file. Each line in the file is a \nsingle message recorded by some program or service. Here is a snippet of an actual mes -\nsages  log file:\nFeb 25 11:04:32 toys network: Bringing up loopback:  succeeded\nFeb 25 11:04:35 toys network: Bringing up interface eth0:  succeeded\nFeb 25 13:01:14 toys vsftpd(pam_unix)[10565]: authentication failure;\n      logname= uid=0 euid=0 tty= ruser= rhost=10.0.0.5  user=chris\nFeb 25 14:44:24 toys su(pam_unix)[11439]: session opened for\n      user root by chris(uid=500)\nThe default message format in the /var/log/messages  file is divided into five main \nparts. This format is determined by the following entry in the /etc/rsyslog.conf  file:\nmodule(load=\"builtin:omfile\" Template=\"RSYSLOG_TraditionalFileFormat\")\nWhen you view messages in files from the /var/log  directory, from left to right, message \nparts are as follows:\n\u25a0\u25a0The date and time that the message was logged\n\u25a0\u25a0The name of the computer from which the message came\n\u25a0\u25a0The program or service name to which the message pertains\n\u25a0\u25a0The process number (enclosed in square brackets) of the program sending \nthe message\n\u25a0\u25a0The actual text message\nTake another look at the preceding file snippet. In the first two lines, you can see that the \nnetwork was restarted. The next line shows that the user named chris  tried and failed \nto get to the FTP server on this system from a computer at address 10.0.0.5 . (He typed \nthe wrong password and authentication failed.) The last line shows chris  using the su  \ncommand to become root user.\nBy occasionally reviewing the messages  and secure  files, you could catch a cracking \nattempt before it is successful. If you see an excessive number of connection attempts for a \nparticular service, especially if they are coming from systems on the Internet, you may be \nunder attack.", "doc_id": "20c243ac-ab44-4fc3-bd52-49acdeb1d9b2", "embedding": null, "doc_hash": "cc9fc3f9a0cd6edfe65ab66ffbf1a6e660b753aec99c832f0c1300ba144d24dd", "extra_info": {"page_label": "354"}, "node_info": {"start": 0, "end": 2570}, "relationships": {"1": "2e29fa28-b0e2-47d3-810d-b1d1984988c7"}}, "__type__": "1"}, "804c76bf-9b90-42ed-8e68-191fa43dca8e": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator330Setting up and using a loghost with rsyslogd\nTo redirect your computer\u2019s log files to another computer\u2019s rsyslogd , you must make \nchanges to both the local and remote rsyslog  configuration file, /etc/rsyslog.conf . \nBecome root using the su \u2013  command, and then open the /etc/rsyslog.conf  file in a \ntext editor (such as vi ).\nOn the client side\nTo send the messages to another computer (the loghost) instead of a file, start by replacing \nthe log file name with the @  character followed by the name of the loghost. For example, to \ndirect the output of messages that are being sent to the messages , secure , and maillog   \nlog files to a loghost as well, add the lines in bold to the messages file:\n# Log anything (except mail) of level info or higher.\n# Don't log private authentication messages!\n*.info;mail.none;news.none;authpriv.none;cron.none  /var/log/messages\n*.info;mail.none;news.none;authpriv.none;cron.none  @loghost\n# The authpriv file has restricted access.\nauthpriv.*                                /var/log/secure\nauthpriv.*                                @loghost\n# Log all the mail messages in one place.\nmail.*                                     -/var/log/maillog\nmail.*                                    @loghost\nThe messages are now sent to the rsyslogd  running on the computer named loghost. The \nname loghost  was not an arbitrary choice. Creating such a hostname and making it an \nalias to the actual system acting as the loghost is customary. That way, if you ever need to \nswitch the loghost duties to a different machine, you need to change only the loghost alias; \nyou do not need to re-edit the syslog.conf  file on every computer.\nOn the loghost side\nThe loghost that is set to accept the messages must listen for those messages on standard \nports (514 UDP, although it can be configured to accept messages on 514 TCP as well). Here \nis how you would configure the Linux loghost that is also running the rsyslog  service:\n\u25a0\u25a0Edit the /etc/rsyslog.conf  file on the loghost system and uncomment the lines \nthat enable the rsyslogd  daemon to listen for remote log messages. Uncomment \nthe first two lines to enable incoming UDP log messages on port 514 (default); \nuncomment the two lines after that to allow messages that use TCP protocol (also \nport 514):\n        module(load=\"imudp\") # needs to be done just once\n        input(type=\"imudp\" port=\"514\")\n        module(load=\"imtcp\") # needs to be done just once\n        input(type=\"imtcp\" port=\"514\")", "doc_id": "804c76bf-9b90-42ed-8e68-191fa43dca8e", "embedding": null, "doc_hash": "977b5b6cfe78f56b54dab5be9c07bd4e3465d3f378b4bf2add4d25a4ae8e19e9", "extra_info": {"page_label": "355"}, "node_info": {"start": 0, "end": 2537}, "relationships": {"1": "334afe40-3d75-41ea-807f-6446a30d45d0"}}, "__type__": "1"}, "cfe299c9-5624-4e91-a938-0b2203a548d8": {"__data__": {"text": "Chapter 13: Understanding Server Administration\n331\n1313\u25a0\u25a0Open your firewall to allow new messages to be directed to your loghost. (See Chap -\nter\u00a025, \u201cSecuring Linux on a Network,\u201d for a description of how to open specific \nports to allow access to your system.)\n\u25a0\u25a0Restart the rsyslog  service (service rsyslog restart  or systemctl \nrestart rsyslog.service ).\n\u25a0\u25a0If the service is running, you should be able to see that the service is listening on \nthe ports that you enabled (UDP and/or TCP ports 514). Run the netstat  command \nas follows to see that the rsyslogd  daemon is listening on IPv4 and IPv6 ports \n514 for both UDP and TCP services:\n        # netstat -tupln | grep 514\n        tcp      0    0 0.0.0.0:514   0.0.0.0:*   LISTEN     25341/rsyslogd\n        tcp      0    0 :::514        :::*        LISTEN     25341/rsyslogd\n        udp      0    0 0.0.0.0:514   0.0.0.0:*              25341/rsyslogd\n        udp      0    0 :::514        :::*                   25341/rsyslogd\nWatching logs with logwatch\nThe logwatch  service runs in most Linux systems that do system logging with rsyslog . \nBecause logs on busy systems can become very large over time, it doesn\u2019t take long for \nthere to be too many messages for a system administrator to watch every message in every \nlog. To install the logwatch  facility, enter the following:\n# yum install logwatch\nWhat logwatch  does is gather messages once each night that look like they might repre -\nsent a problem, put them in an email message, and send it to any email address the admin -\nistrator chooses. To enable logwatch , all you have to do is install the logwatch  package.\nThe logwatch  service runs from a cron  job (0logwatch ) placed in /etc/cron.daily . \nThe /etc/logwatch/conf/logwatch.conf  file holds local settings. The default options \nused to gather log messages are set in the /usr/share/logwatch/default.conf/log -\nwatch.conf  file.\nSome of the default settings define the location of log files (/var/log), location of the  \ntemporary directory (/var/cache/logwatch), and the recipient of the daily logwatch \nemail (the local root user). Unless you expect to log in to the server to read logwatch  \nmessages, you probably want to change the MailTo setting in the /etc/logwatch/conf/\nlogwatch.conf file:\nMailTo = chris@example.com\nLook in /usr/share/logwatch/default.conf/logwatch.conf  for other settings to \nchange (such as detail level or the time range for each report). Then make your additions to \n/etc/logwatch/conf/logwatch.conf  as mentioned.", "doc_id": "cfe299c9-5624-4e91-a938-0b2203a548d8", "embedding": null, "doc_hash": "3eb0b208021a22f505457e00e9e35847fbcb0f1b20ece138130421b3d8c3fed9", "extra_info": {"page_label": "356"}, "node_info": {"start": 0, "end": 2527}, "relationships": {"1": "4f2ed9aa-df2b-41eb-93c5-0a509ffb36d9"}}, "__type__": "1"}, "8109a3a5-5a97-465b-84a7-67683d1f7ccb": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator332When the service is enabled (which it is just by installing the logwatch  package), you will \nsee a message each night in the root user\u2019s mailbox. When you are logged in as root, you \ncan use the old mail  command to view the root user\u2019s mailbox:\n        # mail\n        Heirloom Mail version 12.5 7/5/10.  Type ? for help.\n        \"/var/spool/mail/root\": 2 messages 2 new\n         >N  1 logwatch@abc.ex  Sun Feb 15 04:02 45/664   \"Logwatch for abc\"\n             2 logwatch@abc.ex  Mon Feb 16 04:02 45/664   \"Logwatch for abc\"\n        & 1\n        & x\nIn mail, you should see email messages from logwatch  run each day (here at 4:02 a.m.). \nType the number of the message that you want to view and page through it with the space -\nbar or line by line by pressing Enter. Type x to exit when you are finished.\nThe kind of information that you see includes kernel errors, installed packages, authen -\ntication failures, and malfunctioning services. Disk space usage is reported, so you can \nsee if your storage is filling up. Just by glancing through this logwatch  message, you \nshould get an idea whether sustained attacks are under way or if some repeated failures are \ntaking place.\nChecking System Resources with sar\nThe System Activity Reporter ( sar) is one of the oldest system monitoring facilities created \nfor early UNIX systems\u2014predating Linux by a few decades. The sar  command itself can \ndisplay system activity continuously, at set intervals (every second or two), and display it \non the screen. It can also display system activity data that was gathered earlier.\nThe sar  command is part of the sysstat  package. When you install sysstat  and enable \nthe sysstat  service, your system immediately begins gathering system activity data that \ncan be reviewed later using certain options to the sar  command.\n# systemclt enable sysstat\n# systemctl start sysstat\nTo read the data in the /var/log/sa/sa ?? files, you can use some of the following \nsar commands:\n# sar -u | less\nLinux 5.3.8-200.fc30.x86_64 (fedora30host) 11/28/2019   _x86_64_  (1 CPU)\n \n23:27:46     LINUX RESTART (1 CPU)\n \n11:30:05 PM  CPU       %user   %nice %system    %iowait    %steal      %idle\n11:40:06 PM  all      0.90    0.00    1.81      1.44      0.28     95.57\nAverage:     all      0.90    0.00    1.81      1.44      0.28     95.57", "doc_id": "8109a3a5-5a97-465b-84a7-67683d1f7ccb", "embedding": null, "doc_hash": "7b79a40f74034875c9abca22b162b3f65a1b0bfed2e2498fb09faef937a475c5", "extra_info": {"page_label": "357"}, "node_info": {"start": 0, "end": 2369}, "relationships": {"1": "a0abbe8d-8b8e-42d2-9c3d-55fe5fc2661c"}}, "__type__": "1"}, "48aeba71-0f34-4f50-9865-2d7f45a8f181": {"__data__": {"text": "Chapter 13: Understanding Server Administration\n333\n1313The -u  option shows CPU usage. By default, the output starts at midnight on the current \nday and then shows how much processing time is being consumed by different parts of the \nsystem. The output continues to show the activity every 10 minutes until the current time \nis reached.\nTo see disk activity output, run the sar -d  command. Again, output comes in 10-minute \nintervals starting at midnight.\n# sar -d | less\nLinux 5.3.8-200.fc30.x86_64 (fedora30host)  11/28/2019 _x86_64_ (1 CPU)\n \n23:27:46     LINUX RESTART  (1 CPU)\n \n11:30:05 PM        DEV   tps   rkB/s   wkB/s   areq-sz    aqu-sz  await...\n11:40:06 PM     dev8-0 49.31 5663.94   50.38    115.89      0.03   1.00\n11:40:06 PM   dev253-0 48.99 5664.09    7.38    115.78      0.05   0.98\n11:40:06 PM   dev253-1 10.84    0.01   43.34      4.00      0.04   3.29\nAverage:        dev8-0 49.31 5663.94   50.38    115.89      0.03   1.00\nAverage:      dev253-0 48.99 5664.09    7.38    115.78      0.05   0.98  \nAverage:      dev253-1 10.84    0.01   43.34      4.00      0.04   3.29 \nIf you want to run sar  activity reports live, you can do that by adding counts and time \nintervals to the command line, as shown here:\n# sar -n DEV 5 2\nLinux 5.3.8-200.fc30.x86_64 (fedora30host)  11/28/2019  _x86_64_  (1 CPU)\n11:19:36 PM IFACE rxpck/s txpck/s  rxkB/s  txkB/s rxcmp/s txcmp/s...\n11:19:41 PM    lo    5.42    5.42    1.06    1.06    0.00    0.00...\n11:19:41 PM  ens3    0.00    0.00    0.00    0.00    0.00    0.00...\n...\nAverage: IFACE rxpck/s txpck/s rxkB/s txkB/ rxcmp/s txcmp/s rxmcst/s\nAverage:    lo    7.21    7.21   1.42  1.42    0.00    0.00     0.00\nAverage:  ens3    0.00    0.00   0.00  0.00    0.00    0.00     0.00\nAverage: wlan0    4.70    4.00   4.81  0.63    0.00    0.00     0.00\n \nAverage:  pan0    0.00    0.00   0.00  0.00    0.00    0.00     0.00\nAverage:  tun0    3.70    2.90   4.42  0.19    0.00    0.00     0.00\nWith the -n Dev  example just shown, you can see how much activity came across the dif", "doc_id": "48aeba71-0f34-4f50-9865-2d7f45a8f181", "embedding": null, "doc_hash": "3ce2d76593d0c7267c82bdd57f0073adc24e1abc012eb4da69aeb42551e23953", "extra_info": {"page_label": "358"}, "node_info": {"start": 0, "end": 2036}, "relationships": {"1": "ed424271-7919-4890-9d70-177e596695be", "3": "ff303e4d-efff-433d-9ee7-7ccceda8c86d"}}, "__type__": "1"}, "ff303e4d-efff-433d-9ee7-7ccceda8c86d": {"__data__": {"text": "0.00    0.00   0.00  0.00    0.00    0.00     0.00\nAverage: wlan0    4.70    4.00   4.81  0.63    0.00    0.00     0.00\n \nAverage:  pan0    0.00    0.00   0.00  0.00    0.00    0.00     0.00\nAverage:  tun0    3.70    2.90   4.42  0.19    0.00    0.00     0.00\nWith the -n Dev  example just shown, you can see how much activity came across the dif -\nferent network interfaces on your system. You can see how many packets were transmitted \nand received and how many KB of data were transmitted and received. In that example, \nsamplings of data were taken every 5 seconds and repeated twice.\nRefer to the sar , sadc , sa1 , and sa2  man pages for more information on how sar  data \ncan be gathered and displayed.", "doc_id": "ff303e4d-efff-433d-9ee7-7ccceda8c86d", "embedding": null, "doc_hash": "eea842b73e42f6edaedcd62231b5c99b601bd4cd957f93be44be4a4e41257f6f", "extra_info": {"page_label": "358"}, "node_info": {"start": 1690, "end": 2399}, "relationships": {"1": "ed424271-7919-4890-9d70-177e596695be", "2": "48aeba71-0f34-4f50-9865-2d7f45a8f181"}}, "__type__": "1"}, "4029cdd6-c3d7-4eb5-8cec-06b6b0b978c1": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator334Checking System Space\nAlthough logwatch  can give you a daily snapshot of space consumption on your system \ndisks, the df  and du  commands can help you immediately see how much disk space is \navailable. The following sections show examples of those commands.\nDisplaying system space with df\nYou can display the space available in your filesystems using the df  command. To see the \namount of space available on all of the mounted filesystems on your Linux computer, type \ndf with no options:\n$ df\nFilesystem  1k-blocks     Used  Available  Use%   Mounted on\n/dev/sda3    30645460  2958356   26130408   11%   /\n/dev/sda2       46668     8340      35919   19%   /boot\n...\nThis example output shows the space available on the hard disk partition mounted on the \n/ (root) directory ( /dev/sda1 ) and /boot  partition ( /dev/sda2 ). Disk space is shown in \n1KB blocks. To produce output in a more human-readable form, use the -h  option:\n$ df -h\nFilesystem            Size  Used  Avail  Use%   Mounted on\n/dev/sda3              29G  2.9G    24G   11%   /\n/dev/sda2              46M  8.2M    25M   19%   /boot\n...\nWith the df -h  option, output appears in a friendlier megabyte or gigabyte listing. Other \noptions with df  enable you to do the following:\n\u25a0\u25a0Print only filesystems of a particular type ( -t type ).\n\u25a0\u25a0Exclude filesystems of a particular type ( -x type ). For example, type df -x \ntmpfs -x devtmpfs  to exclude temporary filesystem types (limiting output to \nfilesystems that represent real storage areas).\n\u25a0\u25a0Include filesystems that have no space, such as /proc  and /dev/pts  (-a).\n\u25a0\u25a0List only available and used inodes ( -i).\n\u25a0\u25a0Display disk space in certain block sizes ( --block-size=# ).\nChecking disk usage with du\nTo find out how much space is being consumed by a particular directory (and its subdirec -\ntories), use the du  command. With no options, du  lists all directories below the current \ndirectory, along with the space consumed by each directory. At the end, du  produces total \ndisk space used within that directory structure.\nThe du  command is a good way to check how much space is being used by a particular user \n(du /home/jake ) or in a particular filesystem partition ( du /var ). By default, disk space ", "doc_id": "4029cdd6-c3d7-4eb5-8cec-06b6b0b978c1", "embedding": null, "doc_hash": "7783a93d4554fce8aaf671f6b80c939d398ace97183772d26f503e84623d1eda", "extra_info": {"page_label": "359"}, "node_info": {"start": 0, "end": 2286}, "relationships": {"1": "4a37045f-4676-4056-bba8-f38fa91ff266"}}, "__type__": "1"}, "9a95c5e0-6889-434a-ab98-ca4d5cd5ea87": {"__data__": {"text": "Chapter 13: Understanding Server Administration\n335\n1313is displayed in 1KB block sizes. To make the output friendlier (in kilobytes, megabytes, and \ngigabytes), use the -h  option as follows:\n$ du -h /home/jake\n114k    /home/jake/httpd/stuff\n234k    /home/jake/httpd\n137k    /home/jake/uucp/data\n701k    /home/jake/uucp\n1.0M    /home/jake\nThe output shows the disk space used in each directory under the home directory of the \nuser named jake  (/home/jake ). Disk space consumed is shown in kilobytes ( k) and mega -\nbytes (M). The total space consumed by /home/jake  is shown on the last line. Add the \u2013s  \noption to see total disk space used for a directory and its subdirectories.\nFinding disk consumption with find\nThe find  command is a great way to find file consumption of your hard disk using a vari-\nety of criteria. You can get a good idea of where disk space can be recovered by finding files \nthat are over a certain size or were created by a particular person.\nIn the following example, the find  command searches the root filesystem ( /) for any files \nowned by the user named jake  (-user jake ) and prints the filenames. The output of the \nfind  command is organized in a long listing in size order ( ls -ldS ). Finally, that output \nis sent to the file /tmp/jake . When you view the file /tmp/jake  (for example, less  \n/tmp/jake ), you will find all of the files that are owned by the user jake  listed in size \norder. Here is the command line:\n# find / -xdev -user jake -print | xargs ls -ldS > /tmp/jake\nHere\u2019s another example, except that instead of looking for a user\u2019s files, we\u2019re looking for \nfiles larger than 100 kilobytes ( -size +100M ):\n# find / -xdev -size +100M | xargs ls -ldS > /tmp/sizeNoTe\nYou must be the root user to run this command effectively, unless you are just checking your personal files. If you \nare not the root user, there are many places in the filesystem for which you do not have permission to check. Regular \nusers can usually check their own home directories but not those of others.\nTip\nThe -xdev  option prevents filesystems other than the selected filesystem from being searched. This is a good way to \ncut out lots of junk that may be output from the / proc  filesystem. It can also keep large, remotely mounted filesys -\ntems from being searched.", "doc_id": "9a95c5e0-6889-434a-ab98-ca4d5cd5ea87", "embedding": null, "doc_hash": "460f907ca7b37c7e7293a47191dada1a12c44f5643617bcd052af59b6d2fdce6", "extra_info": {"page_label": "360"}, "node_info": {"start": 0, "end": 2306}, "relationships": {"1": "cebd34c7-efd9-46ce-9113-de0aff878b3b"}}, "__type__": "1"}, "c42a2352-8e3c-4ac1-927b-057509bc77da": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator336You can save yourself lots of disk space just by removing some of the largest files that are \nno longer needed. In this example, you can see that large files are sorted by size in the  \n/tmp/size  file.\nManaging Servers in the Enterprise\nMost of the server configuration covered in this book describes how to install systems man -\nually and work directly on host computers. Having to set up each host individually would \nbe far too inefficient for modern data centers consisting of dozens, hundreds, or even thou -\nsands of computers. To make the process of setting up Linux servers in a large data center \nmore efficient, some of the following are employed:\nAutomated deployments  One way to install systems without having to step through \na manual install process is with PXE booting. By setting up a PXE server and boot -\ning a computer on that network from a PXE-enabled network interface card, you can \nstart a full install of that system simply by booting the system. Once the install is \ndone, the system can reboot to run from the installed system.\nGeneric host systems  By making your host systems as generic as possible, individual \ninstallation, configuration, and upgrades can be greatly simplified. This can be \nautomated in layers, where the base system is installed by PXE booting, configuration \nis done through features such as cloud-int, and applications can bring along their own \ndependencies when they run. On the application level, this can be done by running an \napplication from inside a virtual machine or container. When the application is done \nrunning, it can be discarded without leaving its dependent software on the host.\nSeparation of management and worker systems Instead of individually managing \nhost systems, a separate platform can offer a way to manage large sets of systems. \nTo do this, a platform such as OpenStack or OpenShift can have management nodes \n(in some cases called control plane  or master nodes ) manage the machines where \nthe workload actually runs (sometimes called workers , slaves , or just nodes ). This \nseparation of tasks by host type makes it possible to have applications deployed \non any available worker that meets the needs of the application (such as available \nmemory or CPU).\nKeep in mind that understanding how individual applications are configured and services \nare run is still the foundation for these more advanced ways of managing data center \nresources. Although in-depth coverage of enterprise deployment and monitoring tools is \noutside the scope of this book, refer to Part VI, \u201cEngaging with Cloud Computing,\u201d for an \nintroduction to how different Linux-based cloud platforms manage these issues.\nSummary\nAlthough many different types of servers are available with Linux systems, the basic pro -\ncedure for installing and configuring a server is essentially the same. The normal course ", "doc_id": "c42a2352-8e3c-4ac1-927b-057509bc77da", "embedding": null, "doc_hash": "c972d4676d3791aa4432f3b9d19bf622b32ea643ae8be97e21723285fbbc5d89", "extra_info": {"page_label": "361"}, "node_info": {"start": 0, "end": 2918}, "relationships": {"1": "554f1a4e-a39e-480f-8467-974a431fb456"}}, "__type__": "1"}, "9fb91a98-3258-49c5-ae92-4f72b6414193": {"__data__": {"text": "Chapter 13: Understanding Server Administration\n337\n1313of events is to install, configure, start, secure, and monitor your servers. Basic tasks that \napply to all servers include using networking tools (particularly SSH tools) to log in, copy \nfiles, or execute remote commands.\nBecause an administrator can\u2019t be logged in watching servers all the time, tools for gath -\nering data and reviewing the log data later are very important when administering Linux \nservers. The rsyslog  facility can be used for local and remote logging. The sar  facility \ngathers live data or plays back data gathered earlier at 10-minute intervals. Cockpit lets \nyou watch CPU, memory, disk, and networking activity live from a web user interface. To \nwatch disk space, you can run df  and du  commands.\nThe skills described in this chapter are designed to help you build a foundation to do \nenterprise-quality system administration in the future. Although these skills are useful, \nto manage many Linux systems at the same time, you need to extend your skills by using \nautomating deployment and monitoring tools, as described in the cloud computing section \nof this book.\nAlthough it is easy to set up networking to reach your servers in simple, default cases, \nmore complex network configuration requires a knowledge of networking configuration \nfiles and related tools. The next chapter describes how to set up and administer net -\nworking in Linux.\nExercises\nThe exercises in this section cover some of the basic tools for connecting to and watching \nover your Linux servers. As usual, you can accomplish the tasks here in several ways. So, \ndon\u2019t worry if you don\u2019t go about the exercises in the same way as shown in the answers, \nas long as you get the same results. If you are stuck, solutions to the tasks are shown in \nAppendix B.\nSome of the exercises assume that you have a second Linux system available that you can \nlog in to and try different commands. On that second system, you need to make sure that \nthe sshd  service is running, that the firewall is open, and that ssh  is allowed for the user \naccount that you are trying to log in to (root is often blocked by sshd ).\nIf you have only one Linux system, you can create an additional user account and simply \nsimulate communications with another system by connecting to the name localhost  \ninstead, as shown in this example:\n# useradd joe\n# passwd joe\n# ssh joe@localhost\n1. Using the ssh  command, log in to another computer (or the local computer) using \nany account to which you have access. Enter the password when prompted.\n2. Using remote execution with the ssh  command, display the contents of a remote  \n/etc/system-release  file and have its contents displayed on the local system.", "doc_id": "9fb91a98-3258-49c5-ae92-4f72b6414193", "embedding": null, "doc_hash": "318e6dbcdad5e2a5f4c84c13e1bf556bdb1645c25e828187ed24088ef64b64a9", "extra_info": {"page_label": "362"}, "node_info": {"start": 0, "end": 2744}, "relationships": {"1": "4e3ff75c-242a-47cc-b939-c4e5a46d7ae0"}}, "__type__": "1"}, "8c33af57-21fe-4fe8-9814-a45e7fcea357": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator3383. Use the ssh  command to use X11 forwarding to display a gedit window on your \nlocal system; then save a file in the remote user\u2019s home directory.\n4. Recursively copy all of the files from the /usr/share/selinux  directory on a \nremote system to the /tmp  directory on your local system in such a way that all \nof the modification times on the files are updated to the time on the local system \nwhen they are copied.\n5. Recursively copy all of the files from the /usr/share/logwatch  directory on a \nremote system to the /tmp  directory on your local system in such a way that all of \nthe modification times on the files from the remote system are maintained on the \nlocal system.\n6. Create a public/private key pair to use for SSH communications (no passphrase on \nthe key), copy the public key file to a remote user\u2019s account with ssh-copy-id , \nand use key-based authentication to log in to that user account without having to \nenter a password.\n7. Create an entry in /etc/rsyslog.conf  that stores all authentication messages \n(authpriv ) info level and higher into a file named /var/log/myauth . From one \nterminal, watch the file as data comes into it, and in another terminal, try to ssh  \ninto your local machine as any valid user with a bad password.\n8. Use the du  command to determine the largest directory structures under /usr/\nshare , sort them from largest to smallest, and list the top ten of those directories \nin terms of size.\n9. Use the df  command to show the space that is used and available from all of the \nfilesystems currently attached to the local system but exclude any tmpfs  or devt-\nmpfs  filesystems.\n10. Find any files in the /usr  directory that are more that 10MB in size.", "doc_id": "8c33af57-21fe-4fe8-9814-a45e7fcea357", "embedding": null, "doc_hash": "d12bc2ee7979e8afd0875cd502c7fc39b23deb90c652c687fa16bbc281b1f12a", "extra_info": {"page_label": "363"}, "node_info": {"start": 0, "end": 1758}, "relationships": {"1": "3fac4e34-3fde-43c3-b8b1-466245ebb7a9"}}, "__type__": "1"}, "d26dd00f-fd60-4ccb-860a-0607158d041b": {"__data__": {"text": "339\nCHAPTER14\nAdministering Networking\nIN THIS CHAPTER\nAutomatically connecting Linux to a network\nUsing NetworkManager for simple network connectivity\nConfiguring networking from the command line\nWorking with network configuration files\nConfiguring routing, DHCP, DNS, and other networking infrastructure features for the enterprise\nConnecting a single desktop system or laptop to a network, particularly one that connects \nto the Internet, has become so easy that I have put off writing a full chapter on Linux net -\nworking until now. If you are trying to connect your Fedora, RHEL, Ubuntu, or another Linux \ndesktop system to the Internet, here\u2019s what you can try given an available wired or wireless net -\nwork interface:\nWired network If your home or office has a wired Ethernet port that provides a path to the \nInternet and your computer has an Ethernet port, use an Ethernet cable to connect the two \nports. After you turn on your computer, boot up Linux and log in. Clicking the NetworkMan -\nager icon on the desktop should show you that you are connected to the Internet or allow \nyou to connect with a single click.\nWireless network For a wireless computer running Linux, log in and click the NetworkMan -\nager icon on the desktop. From the list of wireless networks that appear, select the one you \nwant and, when prompted, enter the required password. Each time you log in from that com-\nputer from the same location, it automatically connects to that wireless network.\nIf either of those types of network connections works for you, and you are not otherwise curious \nabout how networking works in Linux, that may be all you need to know. However, what if your \nLinux system doesn\u2019t automatically connect to the Internet? What if you want to configure your desk -\ntop to talk to a private network at work (VPN)? What if you want to lock down network settings on \nyour server or configure your Linux system to work as a router?\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "d26dd00f-fd60-4ccb-860a-0607158d041b", "embedding": null, "doc_hash": "509b5bbc82d81b451c082f1fb9c992dfad179b35a58121f5c95e0e7715fac847", "extra_info": {"page_label": "364"}, "node_info": {"start": 0, "end": 2063}, "relationships": {"1": "527ef8fe-4bbb-4854-b8ec-ca36681de503"}}, "__type__": "1"}, "140aa4e0-32b5-4b8c-84d1-4e4bc41d86ad": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator340In this chapter, topics related to networking are divided into networks for desktops, servers, \nand enterprise computing. The general approach to configuring networking in these three \ntypes of Linux systems is as follows:\nDesktop/laptop networking  On desktop or laptop systems, NetworkManager runs by \ndefault in order to manage network interfaces. With NetworkManager, you can auto -\nmatically accept the address and server information that you need to connect to \nthe Internet. However, you can also set address information manually. You can con -\nfigure things such as proxy servers or virtual private network connections to allow \nyour desktop to work from behind an organization\u2019s firewall or to connect through a \nfirewall, respectively.\nServer networking  Although NetworkManager originally worked best on desktop and \nlaptop network configurations, it now works extremely well on servers. Today, fea -\ntures that are useful for configuring servers, such as Ethernet channel bonding and \nconfiguring aliases, can be found in NetworkManager.\nEnterprise networking  Explaining how to configure networking in a large enterprise \ncan fill several volumes itself. However, to give you a head start using Linux in an \nenterprise environment, I discuss basic networking technologies, such as DHCP and \nDNS servers, which make it possible for desktop systems to connect to the Internet \nautomatically and find systems based on names and not just IP addresses.\nConfiguring Networking for Desktops\nWhether you connect to the Internet from Linux, Windows, a smartphone, or any other \nkind of network-enabled device, certain things must be in place for that connection to \nwork. The computer must have a network interface (wired or wireless), an IP address, an \nassigned DNS server, and a route to the Internet (identified by a gateway device).\nBefore I discuss how to change your networking configuration in Linux, let\u2019s look at the \ngeneral activities that occur when Linux is set to connect to the Internet automatically \nwith NetworkManager:\nActivate network interfaces  NetworkManager looks to see what network interfaces \n(wired or wireless) are set to start. By default, external interfaces are usually set to \nstart automatically using DHCP, although static names and addresses can be set at \ninstall time instead.\nRequest DHCP service The Linux system acts as a DHCP client to send out a request \nfor DHCP service on each enabled interface. It uses the MAC address of the network \ninterface to identify itself in the request.\nGet response from DHCP server A DHCP server, possibly running on a wireless \nrouter, cable modem, or other device providing a route to the Internet from your \nlocation, responds to the DHCP request. It can provide lots of different types of \ninformation to the DHCP client. That information probably contains at least the \nfollowing:", "doc_id": "140aa4e0-32b5-4b8c-84d1-4e4bc41d86ad", "embedding": null, "doc_hash": "2a283ff5c14a977e4455c878749f55e30c3b3b64f2797d0f1fc2c9f6553d527b", "extra_info": {"page_label": "365"}, "node_info": {"start": 0, "end": 2914}, "relationships": {"1": "6b29b30d-5620-4500-b9a8-2620489a9cf0"}}, "__type__": "1"}, "9fd90ec3-c241-45aa-b88a-26931e284fc7": {"__data__": {"text": "Chapter 14: Administering Networking\n341\n14IP address The DHCP server typically has a range of Internet Protocol (IP) \naddresses that it can hand out to any system on the network that requests an \naddress. In more secure environments, or one in which you want to be sure that \nspecific machines get specific addresses, the DHCP server provides a specific IP \naddress to requests from specific MAC addresses. (MAC addresses are made to be \nunique among all network interface cards and are assigned by the manufacturer \nof each card.)\nSubnet mask  When the DHCP client is assigned an IP address, the accompanying \nsubnet mask tells that client which part of the IP address identifies the subnet -\nwork and which identifies the host. For example, an IP address of 192.168.0.100 \nand subnet mask of 255.255.255.0 tell the client that the network is 192.168.0 \nand the host part is 100.\nLease time  When an IP address is dynamically allocated to the DHCP client (Linux \nsystem), that client is assigned a lease time. The client doesn\u2019t own that address \nbut must lease it again when the time expires and request it once again when \nthe network interface restarts. Usually, the DHCP server remembers the client \nand assigns the same address when the system starts up again or asks to renew \nthe lease. The default lease time is typically 86,400 seconds (24 hours) for IPV4 \naddresses. The more plentiful IPV6 addresses are assigned for 2,592,000 seconds \n(30 days) by default.\nDomain name server Because computers like to think in numbers (such as IP \naddresses like 192.168.0.100) and people tend to think in names (such as the \nhostname www.example.com ), computers need a way to translate hostnames \ninto IP addresses and sometimes the opposite as well. The domain name system \n(DNS) was designed to handle that problem by providing a hierarchy of servers \nto do name-to-address mapping on the Internet. The location of one or more DNS \nservers (usually two or three) is usually assigned to the DHCP client from the \nDHCP host.\nDefault gateway  Although the Internet has one unique namespace, it is actually  \norganized as a series of interconnected subnetworks. In order for a network \nrequest to leave your local network, it must know what node on your network \nprovides a route to addresses outside of your local network. The DHCP server \nusually provides the \u201cdefault gateway\u201d IP address. By having network inter -\nfaces on both your subnetwork and the next network on the way to the ultimate \ndestination of your communication, a gateway can route your packets to their \ndestination.\nOther information A DHCP server can be configured to provide all kinds of infor -\nmation to help the DHCP client. For example, it can provide the location of an \nNTP server (to sync time between clients), font server (to get fonts for your X \ndisplay), IRC server (for online chats), or print server (to designate available \nprinters).", "doc_id": "9fd90ec3-c241-45aa-b88a-26931e284fc7", "embedding": null, "doc_hash": "f9532c01727e7abeaa70146a09509d3d4b6d5be5105ce61cbf72906d8502cd93", "extra_info": {"page_label": "366"}, "node_info": {"start": 0, "end": 2921}, "relationships": {"1": "9ac36017-4571-4d76-9975-fa99df621ebd"}}, "__type__": "1"}, "8bf698ba-071e-4ad9-aeb3-de011b9d5d13": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator342Update local network settings  After the settings are received from the DHCP server, \nthey are implemented as appropriate on the local Linux system. For example, the IP \naddress is set on the network interface, the DNS server entries are added to the local \n/etc/resolv.conf  file (by NetworkManager), and the lease time is stored by the \nlocal system so it knows when to request that the lease be renewed.\nAll of the steps just described typically happen without your having to do anything but \nturn on your Linux system and log in. Now suppose that you want to be able to verify \nyour network interfaces or change some of those settings. You can do that using the tools \ndescribed in the next sections.\nChecking your network interfaces\nThere are both graphical and command-line tools for viewing information about your net -\nwork interfaces in Linux. From the desktop, NetworkManager tools and the Cockpit web \nuser interface are good places to start.\nChecking your network from NetworkManager\nThe easiest way to check the basic setting for a network interface is to open the pull-down \nmenu at the upper-right corner of your desktop and select your active network interface. \nFigure\u00a014.1 shows the Wi-Fi settings for an active network on a Fedora GNOME 3 desktop.\nFIGURE 14.1\nChecking network interfaces with NetworkManager", "doc_id": "8bf698ba-071e-4ad9-aeb3-de011b9d5d13", "embedding": null, "doc_hash": "a5f9ddcd445874eaa46632aecda6b91c59fa0103fab0563bc4de1d8d97563834", "extra_info": {"page_label": "367"}, "node_info": {"start": 0, "end": 1375}, "relationships": {"1": "a55da908-a8af-46a4-bf19-c08e23e079c0"}}, "__type__": "1"}, "27e724ac-b044-4b8b-a905-ef2937e00550": {"__data__": {"text": "Chapter 14: Administering Networking\n343\n14As you can see in Figure\u00a014.1, both IPv4 and IPv6 addresses are assigned to the interface. \nThe IP address 192.168.1.254 offers both a DNS service and a route to external networks.\nTo see more about how your Linux system is configured, click one of the tabs at the top \nof the window. For example, Figure\u00a014.2 shows the Security tab, where you can select the \ntype of security connection to the network and set the password needed to connect to \nthat network.\nChecking your network from Cockpit\nProvided you have enabled Cockpit, you can see and change information about your net -\nwork interfaces through your web browser. On your local system, you open https://\nlocalhost:9090/network  to go directly to the Cockpit Networking page for your local \nsystem. Figure\u00a014.3 shows an example of this.\nFrom the Cockpit Networking page, you can see information about all of your network inter -\nfaces at once. In this case, there are three network interfaces: wlp2s0  (the active wireless \ninterface), enp4s0  (an inactive wired interface), and virbr0  (an inactive interface into \nthe network connected to any virtual machines running on the local system).\nAt the top of the Cockpit Networking page, you can see data being sent from and received \non the local system. Select a network interface to see a page displaying activities for that \nparticular interface.\nSelect Firewall to see the list of services that are allowed into your system. For example, \nFigure\u00a014.4 shows that UDP ports are open for three services (DHCPv6 client, Multicast \nDNS, and Samba Client). DHCPv6 lets the system acquire an IPv6 address from the network. \nMulticast DNS and Samba Client services can allow the autodetection of printers, share file \nsystems, and a variety of devices and shared resources.\nThe only TCP service shown here as open is ssh. With the ssh service (TCP port 22) open, \nthe sshd service running on your local system is available for remote users to log into your \nlocal system.\nFIGURE 14.2\nViewing network settings with NetworkManager", "doc_id": "27e724ac-b044-4b8b-a905-ef2937e00550", "embedding": null, "doc_hash": "79fc9bf30894b1593f2d813c3941056d31133df4e8981406d928bcccf5e2a8e2", "extra_info": {"page_label": "368"}, "node_info": {"start": 0, "end": 2074}, "relationships": {"1": "769e9a4d-0b20-47b7-bbdb-b5ee36c6e8c1"}}, "__type__": "1"}, "356f2fab-15b9-4d7e-a8c9-153da9d32d87": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator344\nFIGURE 14.3\nViewing and changing network settings from Cockpit\nFIGURE 14.4\nView services that are accessible through the firewall from Cockpit", "doc_id": "356f2fab-15b9-4d7e-a8c9-153da9d32d87", "embedding": null, "doc_hash": "6d3d6c81e2733808c2d33f3779aeef2ea63f5f2ea9a9542bd1351a27f0c825ff", "extra_info": {"page_label": "369"}, "node_info": {"start": 0, "end": 192}, "relationships": {"1": "4748651f-8211-4225-b0a1-48a705d5bf0a"}}, "__type__": "1"}, "a0d51a9e-9114-4db1-9e1f-e742876f1a17": {"__data__": {"text": "Chapter 14: Administering Networking\n345\n14The fact that those ports are open doesn\u2019t necessarily mean that the services are running. \nHowever, if they are running, the computer\u2019s firewall will allow access to them.\nMore advanced features available from the Cockpit Networking page allow you to add bonds, \nteams, bridges, and VLANs to your local network interfaces.\nChecking your network from the command line\nTo get more detailed information about your network interfaces, try running some com-\nmands. There are commands that can show you information about your network interfaces, \nroutes, hosts, and traffic on the network.\nViewing network interfaces\nTo see information about each network interface on your local Linux system, enter the \nfollowing:\n# ip addr show\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue\n        state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host\n       valid_lft forever preferred_lft forever\n2: enp4s0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500\n        qdisc fq_codel state DOWN group default qlen 1000\n    link/ether 30:85:a9:04:9b:f9 brd ff:ff:ff:ff:ff:ff\n3: wlp2s0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500\n        qdisc mq state UP group default qlen 1000\n    link/ether e0:06:e6:83:ac:c7 brd ff:ff:ff:ff:ff:ff\n    inet 192.168.1.83/24 brd 192.168.1.255 scope global\n        dynamic noprefixroute wlp2s0\n       valid_lft 78738sec preferred_lft 78738sec\n    inet6 2600:1700:722:a10::489/128 scope global dynamic \nnoprefixroute\n       valid_lft 5529sec preferred_lft 5229sec\n    inet6 fe80::25ff:8129:751b:23e3/64 scope link noprefixroute\n       valid_lft forever preferred_lft forever\n4: virbr0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500\n       qdisc noqueue state DOWN group default qlen 1000\n    link/ether 52:54:00:0c:69:0a brd ff:ff:ff:ff:ff:ff\n    inet 192.168.122.1/24 brd 192.168.122.255 scope global virbr0\n       valid_lft forever preferred_lft forever\nThe ip addr show output displays information about your network interfaces, in this \ncase from a laptop running Fedora 30. The lo  entry in the first line of the output shows \nthe loopback interface, which is used to allow network commands run on the local system ", "doc_id": "a0d51a9e-9114-4db1-9e1f-e742876f1a17", "embedding": null, "doc_hash": "fb22ae52677b7d2dd48ad9f046fd2e0d44d8067297b0467d6f85cc4d99f60431", "extra_info": {"page_label": "370"}, "node_info": {"start": 0, "end": 2329}, "relationships": {"1": "ff01361e-8959-4346-a013-3929992273ac"}}, "__type__": "1"}, "0e1dfe27-7a14-424a-b01c-1321e655ce6b": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator346to connect to the local system. The IP address for localhost is 127.0.0.1/8 (the /8 is CIDR \nnotation, indicating that 127.0 is the network number and 0.1 is the host number). Add a \n-s option (ip -s addr show ) to see statistics of packet transmissions and errors associ-\nated with each interface.\nIn this case, the wired Ethernet interface ( enp4s0 ) is down (no cable), but the wireless \ninterface is up ( wlp2s0 ). The MAC address on the wireless interface ( wlp2s0 ) is \ne0:06:e6:83:ac:c7 and the Internet (IPv4) address is 192.168.1.83. An IPv6 address is \nalso enabled.\nOlder versions of Linux are used to assign more generic network interface names, such as \neth0  and wlan0 . Now interfaces are named by their locations on the computer\u2019s bus. For \nexample, the first port on the network card seated in the third PCI bus for a Fedora system \nis named p3p1 . The first embedded Ethernet port would be em1 . Wireless interfaces some -\ntimes appear using the name of the wireless network as the device name.\nAnother popular command for seeing network interface information is the ifconfig   \ncommand. By default, ifconfig  shows similar information to that of ip addr , but \nifconfig  also shows the number of packets received (RX) and transmitted (TX) by \ndefault, as well as the amount of data and any errors or dropped packets:\n# ifconfig wlp2s0\nwlp2s0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 192.168.1.83  netmask 255.255.255.0\n             broadcast 192.168.1.255\n        inet6 2600:1700:722:a10:b55a:fca6:790d:6aa6\n             prefixlen 64  scopeid 0x0<global>\n        inet6 fe80::25ff:8129:751b:23e3\n             prefixlen 64  scopeid 0x20<link>\n        inet6 2600:1700:722:a10::489\n             prefixlen 128  scopeid 0x0<global>\n        ether e0:06:e6:83:ac:c7  txqueuelen 1000  (Ethernet)\n        RX packets 208402  bytes 250962570 (239.3 MiB)\n        RX errors 0  dropped 4  overruns 0  frame 0\n        TX packets 113589  bytes 13240384 (12.6 MiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\nChecking connectivity to remote systems\nTo make sure that you can reach systems that are available on the network, you can use \nthe ping  command. As long as the computer responds to ping  requests (not all do), you \ncan use ping  to send packets to that system in a way that asks them to respond. Here is \nan example:\n$ ping host1\nPING host1 (192.168.1.15 ) 56(84) bytes of data.\n64 bytes from host1 (192.168.1.15 ): icmp_seq=1 ttl=64 time=0.062 ms\n64 bytes from host1 (192.168.1.15 ): icmp_seq=2 ttl=64 time=0.044 ms\n^C", "doc_id": "0e1dfe27-7a14-424a-b01c-1321e655ce6b", "embedding": null, "doc_hash": "16eba53329998e89db6507cd12e3d439f14f1e03edf7364b941a7859c99991ae", "extra_info": {"page_label": "371"}, "node_info": {"start": 0, "end": 2629}, "relationships": {"1": "de8ebf51-113e-4c7b-8ee7-3fe89735ae2d"}}, "__type__": "1"}, "6609a223-082c-4970-a208-8a9250179ee0": {"__data__": {"text": "Chapter 14: Administering Networking\n347\n14--- host1 ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 1822ms\nrtt min/avg/max/mdev = 0.044/0.053/0.062/0.009 ms\nThe ping  command shown here continuously pings the host named host1 . After a few \npings, press Ctrl+C to end the pings, and the last few lines show you how many of the ping  \nrequests succeeded.\nYou could have used the IP address (192.168.1.15, in this case) to see that you could reach \nthe system. However, using the hostname gives you the additional advantage of knowing \nthat your name-to-IP-address translation (being done by your DNS server or local hosts file) \nis working properly as well. In this case, however, host1  appeared in the local  \n/etc/hosts  file.\nChecking routing information\nRouting is the next thing that you can check with respect to your network interfaces. The \nfollowing snippets show you how to use the ip  and route  commands to do that:\n# ip route show\ndefault via 192.168.122.1 dev ens3 proto dhcp metric 20100 \n192.168.122.0/24 dev ens3 proto kernel scope link src 192.168.122.194 \nmetric 100 \nThe ip route show command example illustrates that the 192.168.122.1 address provides \nthe route to the host from a RHEL 8 VM over the ens3  network interface. Communications \nto any address in the 192.168.122.0/24 range from the VM (192.168.122.194) goes over that \ninterface. The route  command can provide similar information:\n# route\nKernel IP routing table\nDestination   Gateway    Genmask       Flags Metric Ref Use Iface\ndefault       homeportal 0.0.0.0       UG    600    0     0 wlp2s0\n192.168.1.0   0.0.0.0    255.255.255.0 U     600    0     0 wlp2s0\n192.168.122.0 0.0.0.0    255.255.255.0 U     0      0     0 virbr0\nThe output from the kernel routing table is from a Fedora system with a single active exter -\nnal network interface. The wireless network interface card is on PCI slot 2, port 1 ( wlp2). \nAny packets destined for the 192.168.1 network use the wlp2  NIC. Packets destined for any \nother location are forwarded to the gateway system at 192.168.1.0. That system represents \nmy router to the Internet. Here\u2019s a more complex routing table:\n# route\nKernel IP routing table\nDestination   Gateway      Genmask         Flags Metric Ref Use Iface\ndefault       gateway      0.0.0.0         UG    600    0     0 wlp3s0\n10.0.0.0      vpn.example. 255.0.0.0       U     50     0     0 tun0\n10.10.135.0   0.0.0.0      255.255.217.0   U     50     0     0 tun0\nvpn.example.  gateway      255.255.255.255 UGH   600    0     0 wlp3s0", "doc_id": "6609a223-082c-4970-a208-8a9250179ee0", "embedding": null, "doc_hash": "80d4597542dd11957aac3e8fd3a3c040d5d6b4d25670047c83e94e4153257c5c", "extra_info": {"page_label": "372"}, "node_info": {"start": 0, "end": 2561}, "relationships": {"1": "0d38d107-652f-421b-8c28-a0c67fca7a5a"}}, "__type__": "1"}, "dcea1d42-c3de-4f4f-98b8-2a2f842c9f52": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator348172.17.0.0    0.0.0.0      255.255.0.0     U     0      0     0 docker0\n192.168.1.0   *            255.255.255.0   U     600    0     0 wlp3s0\nIn the route example just shown, there is a wireless interface ( wlp3s0 ) as well as an inter -\nface representing a virtual private network (VPN) tunnel. A VPN provides a way to have \nencrypted, private communications between a client and a remote network over an insecure \nnetwork (such as the Internet). Here the tunnel goes from the local system over the wlan0  \ninterface to a host named vpn.example.com  (some of the name is truncated).\nAll communication to the 192.168.1.0/24 network still goes directly over the wireless \nLAN. However, packets destined for the 10.10.135.0/24 and 10.0.0.0/8 networks are routed \ndirectly to vpn.example.com  for communication with hosts on the other side of the VPN \nconnection over the tunneled interface ( tun0 ).\nA special route is set up for communications to containers ( docker0 ) running on the local \nsystem on network 172.17.0.0. All other packets go to the default route via the address \n192.168.1.0. As for the flags shown in the output, a U says the route is up, a G identifies \nthe interface as a gateway, and an H says the target is a host (as is the case with the VPN \nconnection).\nSo far, I have shown you the routes to leave the local system. If you want to follow the \nentire route to a host from beginning to end, you can use the traceroute  command ( dnf \ninstall traceroute ). For example, to trace the route a packet takes from your local \nsystem to the google.com  site, type the following traceroute  command:\n# traceroute google.com\ntraceroute to google.com (74.125.235.136), 30 hops max, 60 byte pkts\n...\n 7  rrcs-70-62-95-197.midsouth.biz.rr.com (70.62.95.197)  ...\n 8  ge-2-1-0.rlghncpop-rtr1.southeast.rr.com (24.93.73.62)  ...\n 9  ae-3-0.cr0.dca10.tbone.rr.com (66.109.6.80) ...\n10  107.14.19.133 (107.14.19.133)  13.662  ms  ...\n11  74.125.49.181 (74.125.49.181)  13.912  ms ...\n12  209.85.252.80 (209.85.252.80)  61.265  ms ...\n13  66.249.95.149 (66.249.95.149)  18.308  ms ...\n14  66.249.94.22 (66.249.94.22)  18.344  ms ...\n15  72.14.239.83 (72.14.239.83)  85.342  ms ...\n16  64.233.174.177 (64.233.174.177)  167.827  ms ...\n17  209.85.255.35 (209.85.255.35)  169.995  ms  ...\n18  209.85.241.129 (209.85.241.129)  170.322  ms  ...\n19  nrt19s11-in-f8.1e100.net (74.125.235.136)  169.360 ms  ...\nI truncated some of the output to drop off some of the initial routes and the amount  \nof time (in milliseconds) that the packets were taking to traverse each route. Using  \ntraceroute , you can see where the bottlenecks are along the way if your network  \ncommunication is stalling.", "doc_id": "dcea1d42-c3de-4f4f-98b8-2a2f842c9f52", "embedding": null, "doc_hash": "633a2ac4f465b1035676c6311db13445d77b720561a868d1e9cfedbd5a665e01", "extra_info": {"page_label": "373"}, "node_info": {"start": 0, "end": 2743}, "relationships": {"1": "3efe6f9c-d557-441a-92e8-a3a31a5ea434"}}, "__type__": "1"}, "f1b25289-9af7-4af5-b24b-50d5ac05b685": {"__data__": {"text": "Chapter 14: Administering Networking\n349\n14Viewing the host and domain names\nTo see the hostname assigned to the local system, type hostname . To just see the domain \nportion of that name, use the dnsdomainname  command:\n# hostname\nspike.example.com\n# dnsdomainname\nexample.com\nConfiguring network interfaces\nIf you don\u2019t want to have your network interfaces assigned automatically from a DHCP \nserver (or if there is no DHCP server), you can configure network interfaces manually. This \ncan include assigning IP addresses, the locations of DNS servers and gateway machines, and \nroutes. This basic information can be set up using NetworkManager.\nSetting IP addresses manually\nTo change the network configuration for your wired network interface through Network -\nManager, do the following:\n1. Select the Settings icon from the drop-down menu in the upper-right corner of the \ndesktop and select Network.\n2. Assuming that you have a wired NIC that is not yet in use, select the settings \nbutton (small gear icon) next to the interface that you want to change.\n3. Choose IPv4 and change the IPv4 Method setting from Automatic (DHCP) to Manual.\n4. Fill in the following information (only Address and Netmask are required):\na. Address : The IP address that you want to assign to your local network inter -\nface. For example, 192.168.100.100.\nb. Netmask : The subnetwork mask that defines which part of the IP address rep -\nresents the network and which part identifies the host. For example, a netmask \nof 255.255.255.0 would identify the network portion of the previous address as \n192.168.100 and the host portion as 100.\nc. Gateway : The IP address of the computer or device on the network that acts \nas the default route. The default route will route packets from the local net -\nwork to any address that is not available on the local network or via some other \ncustom route.\nd. DNS servers : Fill in the IP addresses for the system providing DNS service \nto your computer. If there is more than one DNS server, add the others in a \ncomma-separated list of servers.\n5. Click the Apply button. The new information is saved, and the network is \nrestarted using the new information. Figure\u00a014.5 shows an example of those net -\nwork settings.", "doc_id": "f1b25289-9af7-4af5-b24b-50d5ac05b685", "embedding": null, "doc_hash": "3351d6d5a5cc672dfc75ff6f73c8e682f75db1a77cf04a925ff37541055407ff", "extra_info": {"page_label": "374"}, "node_info": {"start": 0, "end": 2239}, "relationships": {"1": "5569f031-2c26-46e0-a95b-3e00aaab0a97"}}, "__type__": "1"}, "434e059a-f17e-478b-b560-00694e83463f": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator350Setting IP address aliases\nYou can attach multiple IP addresses to a single network interface. In the same Network -\nManager screen, this is done by simply filling in a subsequent Addresses box and adding \nthe new IP address information. Here are a few things you should know about adding \naddress aliases:\n\u25a0\u25a0A netmask is required for each address, but a gateway is not required.\n\u25a0\u25a0The Apply button stays grayed out until you include valid information in the fields.\n\u25a0\u25a0The new address does not have to be on the same subnetwork as the original \naddress, although it is listening for traffic on the same physical network.\nAfter adding the address 192.168.100.103 to my wired interface, running ip addr show \nenp4s0  displays the following indication of the two IP addresses on the interface:\n2: enp4s0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel \nstate UP group default qlen 1000\n    link/ether 30:85:a9:04:9b:f9 brd ff:ff:ff:ff:ff:ff\n    inet 192.168.100.100/24 brd 192.168.100.255 scope\n          global noprefixroute enp4s0\n       valid_lft forever preferred_lft forever\n    inet 192.168.100.103/24 brd 192.168.100.255 scope\n          global secondary noprefixroute enp4s0\n       valid_lft forever preferred_lft forever\nFIGURE 14.5\nChanging network settings with NetworkManager", "doc_id": "434e059a-f17e-478b-b560-00694e83463f", "embedding": null, "doc_hash": "43b13d2291c9ea9b22b2f2b985a9684e8f03a885c566bc9415b503fac5e8b7c1", "extra_info": {"page_label": "375"}, "node_info": {"start": 0, "end": 1343}, "relationships": {"1": "e02c1741-9c35-4f8d-92ad-13922a1a40e3"}}, "__type__": "1"}, "d0a4dd62-059f-4541-92ce-29ba3e4311ef": {"__data__": {"text": "Chapter 14: Administering Networking\n351\n14For information on setting up aliases directly in configuration files, refer to the section \n\u201cSetting alias network interfaces\u201d later in this chapter.\nSetting routes\nWhen you request a connection to an IP address, your system looks through your routing \ntable to determine the path on which to connect to that address. Information is sent in \nthe form of packets. A packet is routed in the following different ways, depending on its \ndestination:\n\u25a0\u25a0The local system is sent to the lo  interface.\n\u25a0\u25a0A system on your local network is directed through your NIC directly to the \nintended recipient system\u2019s NIC.\n\u25a0\u25a0Any other system is sent to the gateway (router) that directs the packet on to its \nintended address on the Internet.\nOf course, what I have just described here is one of the simplest cases. You may, in fact, \nhave multiple NICs with multiple interfaces to different networks. You may also have mul -\ntiple routers on your local network that provide access to other private networks. For exam-\nple, suppose you have a router (or other system acting as a router) on your local network; \nyou can add a custom route to that router via NetworkManager. Using the NetworkManager \nexample shown previously, scroll down the page to view the Routes section. Then add the \nfollowing information:\nAddress The network address of the subnetwork you route to. For example, if the \nrouter (gateway) will provide you access to all systems on the 192.168.200 network, \nadd the address 192.168.200.0.\nNetmask  Add the netmask needed to identify the subnetwork. For example, if the \nrouter provides access to the Class C address 192.168.200, you could use the netmask \n255.255.255.0.\nGateway  Add the IP address for the router (gateway) that provides access to the new \nroute. For example, if the router has an IP address on your 192.168.1 network of \n192.168.1.199, add that address in this field.\nClick Apply to apply the new routing information. You may have to restart the interface for \nthis to take effect (for example, ifup enp4s0 ). Enter route -n  to make sure the new \nrouting information has been applied.\n# route -n\nKernel IP routing table\nDestination     Gateway         Genmask       Flags Metric Ref Use Iface\n0.0.0.0         192.168.100.1   0.0.0.0       UG    1024   0     0 p4p1\n192.168.100.0   0.0.0.0         255.255.255.0 U     0      0     0 p4p1\n \n192.168.200.0   192.168.1.199   255.255.255.0 UG    1      0     0 p4p1", "doc_id": "d0a4dd62-059f-4541-92ce-29ba3e4311ef", "embedding": null, "doc_hash": "ea2c3b857056f0072f18c4c6c6a0a420ddff867c5ff592f52d641e3231769d89", "extra_info": {"page_label": "376"}, "node_info": {"start": 0, "end": 2476}, "relationships": {"1": "5bc831aa-2322-4e1e-9d00-801c0a6bf809"}}, "__type__": "1"}, "f51de19b-575f-4626-9f66-0e20a638cbfb": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator352In the example just shown, you can see that the default gateway is 192.168.100.1. How -\never, any packets destined for the 192.168.200 network are routed through the gateway \nhost at IP address 192.168.1.199. Presumably that host has a network interface that faces \nthe 192.168.200 network, and it is set up to allow other hosts to route through it to \nthat network.\nSee the section \u201cSetting custom routes\u201d later in this chapter for information on how to set \nroutes directly in configuration files.\nConfiguring a network proxy connection\nIf your desktop system is running behind a corporate firewall, you might not have direct \naccess to the Internet. Instead, you might have to reach the Internet via a proxy server. \nInstead of allowing you full access to the Internet, a proxy server lets you make requests \nonly for certain services outside of the local network. The proxy server then passes those \nrequests on to the Internet or another network.\nProxy servers typically provide access to web servers ( http://  and https:// ) and FTP \nservers (ftp:// ). However, a proxy server that supports SOCKS can provide a proxy service \nfor different protocols outside of the local network. ( SOCKS  is a network protocol made to \nallow client computers to access the Internet through a firewall.) You can identify a proxy \nserver in NetworkManager and have communications for selected protocols go through that \nserver (from the Settings window, select Network and then select Network Proxy).\nInstead of identifying a proxy server to your network interfaces (via NetworkManager), you \ncan configure your browser to use a proxy server directly by changing your Firefox prefer -\nences to use a proxy server. Here\u2019s how to define a proxy server from the Firefox window:\n1. From Firefox, select Preferences. The Firefox Preferences window appears.\n2. From the Firefox Preferences window, scroll down to Network Settings and \nselect Settings.\n3. From the Connection Settings window that appears, you can try to autodetect the \nproxy settings or, if you set the proxy in NetworkManager, you can choose to use \nsystem proxy settings. You can also select Manual Proxy Configuration, fill in the \nfollowing information, and click OK.\na. HTTP Proxy : The IP address of the computer providing the proxy service. This \ncauses all requests for web pages ( http://  protocol) to be forwarded to the \nproxy server.\nb. Port: The port associated with the proxy service. By default, the port number is \n3128, but it can differ.\nc. Use this proxy server for all protocols : Select this box to use the same proxy \nserver and port associated with the HTTP proxy for all other service requests. \nThis causes other proxy settings to be grayed out. (Instead of selecting this \nbox, you can set those proxy services separately.)", "doc_id": "f51de19b-575f-4626-9f66-0e20a638cbfb", "embedding": null, "doc_hash": "a0c5e0fa579c54376494e3fc3fcd72740a3d90c89f11854d35cc1dab8f27e3ad", "extra_info": {"page_label": "377"}, "node_info": {"start": 0, "end": 2849}, "relationships": {"1": "ec0e8fdd-6af3-4094-9534-825e94765638"}}, "__type__": "1"}, "0c1ca8ce-c338-4cce-9e0a-8150ff3a2f01": {"__data__": {"text": "Chapter 14: Administering Networking\n353\n14d. No Proxy for : Add the hostname or IP address for any system that you want to \nbe able to contact with Firefox directly without going through the proxy server. \nYou don\u2019t need to add localhost and the local IP address (127.0.0.1) in this box, \nsince those addresses are already set not to redirect.\nFigure\u00a014.6 shows an example of the Configure Proxy Access to the Internet window filled \nin to configure a connection to a proxy server located at IP address 192.168.1.1 for all pro -\ntocols. After you click OK, all requests from the Firefox browser to locations outside of \nthe local system are directed to the proxy server, which forwards those requests on to the \nappropriate server.\nConfiguring Networking from the Command Line\nWhile NetworkManager does a great job of autodetecting wired networks or presenting you \nwith lists of wireless networks, sometimes you need to abandon the NetworkManager GUI \nand commands or Cockpit to configure the features that you need. These are some of the \nnetworking features in RHEL and Fedora described in the coming sections:\nBasic configuration : See how to use nmtui  to configure basic networking with a \nmenu-based interface from a shell. This tool provides an intuitive interface for con -\nfiguring networking on servers that have no graphical interface for running GUI-\nbased tools.\nFIGURE 14.6\nSetting up Firefox to use a proxy server", "doc_id": "0c1ca8ce-c338-4cce-9e0a-8150ff3a2f01", "embedding": null, "doc_hash": "bdf995d3e4c9375135a3ed7062b45636b74886ab74dad3ee3e9e9b3017f71e1d", "extra_info": {"page_label": "378"}, "node_info": {"start": 0, "end": 1430}, "relationships": {"1": "6cb540ae-9c33-4981-85a3-74bec71b2cf8"}}, "__type__": "1"}, "82f4c9ca-2a59-44c7-9945-df77f8b8336e": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator354Configuration files : Understand configuration files associated with Linux networking \nand how to configure them directly.\nEthernet channel bonding : Set up Ethernet channel bonding (multiple network cards \nlistening on the same IP address).\nConfigure networking with nmtui\nMany servers don\u2019t have graphical interfaces available. So, if you want to configure net -\nworking, you must be able to do so from the shell. One way to do that is to edit networking \nconfiguration files directly. Another method is to use menu-based commands that let \nyou press arrow and Tab keys to navigate and forms you fill in to configure your network \ninterface.\nThe nmtui  command ( yum install NetworkManager-tui ) provides a menu-based \ninterface that runs in the shell. As root, enter nmtui  to see a screen similar to the one \npresented in Figure\u00a014.7.\nUse arrow keys and the Tab key to move around the interface. With the item you want to \nselect highlighted, press Enter to select it. The interface is limited to modifying the follow -\ning kinds of information: Edit or Activate a connection (network interface cards) and Set \nsystem hostname (hostname and DNS configuration).\nEditing a NetworkManager TUI connection\nFrom the NetworkManager TUI screen displayed, here is how to edit an existing connection.\n1. Edit a connection : With \u201cEdit a connection\u201d highlighted, press Enter. A list of net -\nwork devices (usually wired or wireless Ethernet cards) is displayed, along with any \nwireless networks to which you have connected in the past.\n2. Network devices : Highlight one of the network devices (in my case, I chose a wired \nEthernet interface) and press Enter.\nFIGURE 14.7\nConfiguring networking with NetworkManager TUI", "doc_id": "82f4c9ca-2a59-44c7-9945-df77f8b8336e", "embedding": null, "doc_hash": "1f46c82aa1563ff7f398e404c27d49623920ea57a7b613b3c09dcac7c9cf7e8e", "extra_info": {"page_label": "379"}, "node_info": {"start": 0, "end": 1762}, "relationships": {"1": "59dc4057-40b1-43f1-b6f6-2a3312d67d55"}}, "__type__": "1"}, "68138da9-34cf-4657-9686-26bb6f8da903": {"__data__": {"text": "Chapter 14: Administering Networking\n355\n143. IPv4 Configuration : Move to the IPv4 Configuration show button and press Enter. \nThe Edit Connection window that appears lets you change information relating to \nthe selected network device.\n4. Change to Manual : You can leave the Profile Name and Device fields as they are. \nBy default, Automatic is enabled. Automatic is what allows the network interface \nto come up automatically on the network if a DHCP service is available. To enter \naddress and other information yourself, use the Tab key to highlight the Automatic \nfield and press the spacebar; then use the arrow keys to highlight Manual and \npress Enter.\n5. Addresses : Now fill in the address information (IP address and netmask). \nFor example, 192.168.0.150/24 (where 24 is the CIDR equivalent for the \n255.255.255.0 netmask).\n6. Gateway : Type in the IP address for the computer or router that is supplying the \nroute to the Internet.\n7. DNS servers : Type in the IP addresses of either one or two DNS servers to tell the \nsystem where to go to translate hostnames you request into IP addresses.\n8. Search domains : The Search domains entries are used when you request a host \nfrom an application without using a fully qualified domain name. For example, if \nyou type ping host1  with an example.com  search path, the command would \ntry to send ping packets to host1.example.com .\n9. Routing : You can set custom routes by highlighting Edit in the Routing field and \npressing Enter. Fill in the Destination/Prefix and Next Hop fields and select OK to \nsave the new custom route.\n10. Other selections : Of the other selections on the screen, consider setting \u201cNever use \nthis network for default route\u201d if the network doesn\u2019t connect to wider networks \nand \u201cIgnore automatically obtained routes\u201d if you don\u2019t want those features to be \nset automatically from the network. Figure\u00a014.8 shows the screen after Manual has \nbeen selected and the address information has been filled in.\nTab to the OK button and press the spacebar. Then click Quit to exit.\nUnderstanding networking configuration files\nWhether you change your network setup using NetworkManager or nmtui , most of the \nsame configuration files are updated. In Fedora and RHEL, network interfaces and custom \nroutes are set in files in the /etc/sysconfig/network-scripts  directory.\nOpen the /usr/share/doc/initscripts/sysconfig.txt  file for descriptions of net -\nwork-scripts configuration files (available from the initscripts  package).", "doc_id": "68138da9-34cf-4657-9686-26bb6f8da903", "embedding": null, "doc_hash": "b2fa8691ed5c117813394e41ab094807f1a14f92144f29cc25b3926da20d034a", "extra_info": {"page_label": "380"}, "node_info": {"start": 0, "end": 2509}, "relationships": {"1": "bb497585-9b09-40f1-8c5e-d33e7e35936c"}}, "__type__": "1"}, "7b01b1a6-4428-4a29-a978-13f225885eee": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator356One thing to be careful about is that NetworkManager believes that it controls the files \nin the network-scripts directory. So keep in mind that if you set manual addresses on an \ninterface that NetworkManager has configured for DHCP, it could overwrite changes that \nyou made manually to the file.\nNetwork interface files\nConfiguration files for each wired, wireless, ISDN, dialup, or other type of network interface \nare represented by files in the /etc/sysconfig/network-scripts  directory that begin \nwith ifcfg- interface . Note that interface  is replaced by the name of the network \ninterface.\nGiven a network interface for a wired NIC as enp4s0 , here\u2019s an example of an ifcfg-enp4s0   \nfile for that interface, configured to use DHCP:\nDEVICE=enp4s0\nTYPE=Ethernet\nBOOTPROTO=dhcp\nONBOOT=yes\nDEFROUTE=yes\nUUID=f16259c2-f350-4d78-a539-604c3f95998c\nIPV4_FAILURE_FATAL=no\nIPV6INIT=yes\nIPV6_AUTOCONF=yes\nIPV6_DEFROUTE=yes\nIPV6_FAILURE_FATAL=no\nFIGURE 14.8\nSet static IP addresses by selecting Manual from the Edit Connection screen.", "doc_id": "7b01b1a6-4428-4a29-a978-13f225885eee", "embedding": null, "doc_hash": "b79e50c1a21294bc431d5f24bc48ccfb4507b0627a3ba6fa9a058382484929ab", "extra_info": {"page_label": "381"}, "node_info": {"start": 0, "end": 1083}, "relationships": {"1": "80bbcdde-7957-45de-87a2-2a5d3c0a6281"}}, "__type__": "1"}, "29580fa6-f4ab-46a4-a8d9-b12e4efb5b82": {"__data__": {"text": "Chapter 14: Administering Networking\n357\n14NAME=\"System enp4s0\"\nPEERDNS=yes\nPEERROUTES=yes\nIPV6_PEERDNS=yes\nIPV6_PEERROUTES=yes\nIn this ifcfg-enp4s0  example, the first two lines set the device name and the type \nof interface to Ethernet . The BOOTPROTO  variable is set to dhcp , which causes it to \nrequest address information from a DHCP server. With ONBOOT=yes , the interface starts \nautomatically at system boot time. IPV6 settings say to initialize IPV6 and use the IPV6 \nsettings that are presented, but the interface will continue to initialize if there is no IPV6 \nnetwork available. Other settings say to use peer DNS automatically and route values that \nare detected.\nHere\u2019s what a simple ifcfg-enp4s1  file might look like for a wired Ethernet interface that \nuses static IP addresses:\nDEVICE=enp4s1\nHWADDR=00:1B:21:0A:E8:5E\nTYPE=Ethernet\nBOOTPROTO=none\nONBOOT=yes\nUSERCTL=no\nIPADDR=192.168.0.140\nNETMASK=255.255.255.0\nGATEWAY=192.168.0.1\nIn this ifcfg-enp4s1  example, because this is setting the address and other informa -\ntion statically, BOOTPROTO  is set to none . Other differences are needed to set the address \ninformation that is normally gathered from a DHCP server. In this case, the IP address is set \nto 192.168.0.140 with a netmask of 255.255.255.0. The GATEWAY=192.168.0.1  identifies \nthe address of the router to the Internet.\nHere are a couple of other settings that might interest you:\nPEERDNS : Setting PEERDNS=no  prevents DHCP from overwriting the /etc/resolv  \n.conf  file. This allows you to set which DNS servers your system uses without fear \nof that information being erased by data that is provided by the DHCP server.\nDNS?: If an ifcfg  file is being managed by NetworkManager, it sets the address of DNS \nservers using DNS ? entries. For example, DNS1=192.168.0.2  causes that IP address \nto be written to /etc/resolv.conf  as the first DNS server being used on the \nsystem. You can have multiple DNS ? entries ( DNS2= , DNS3= , and so on).\nIn addition to configuring the primary network interfaces, you can also create files in the \n/etc/sysconfig/network-scripts  directory that can be used to set aliases (multiple \nIP addresses for the same interface), bonded interfaces (multiple NICs listening on the same \naddress), and custom routes. Those are described later in this chapter.", "doc_id": "29580fa6-f4ab-46a4-a8d9-b12e4efb5b82", "embedding": null, "doc_hash": "e137ed7aada2c0fafd497d3964ce55a23045221ebb413faf4568e76b9fef5193", "extra_info": {"page_label": "382"}, "node_info": {"start": 0, "end": 2328}, "relationships": {"1": "ac683eb4-0b4c-470e-b7c1-d2fa51e8140b"}}, "__type__": "1"}, "1dbda34e-2b4e-4a99-995d-4386a82ba93d": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator358Other networking files\nIn addition to the network interface files, there are other network configuration files that \nyou can edit directly to configure Linux networking. Here are some of those files.\n/etc/sysconfig/network file\nSystem-wide settings associated with your local networking can be included in your /etc/\nsysconfig/network  file. The system\u2019s hostname was commonly set in this file up to \nRHEL 6, but other settings can be added to this file as well. Here is an example of the con -\ntents of an /etc/sysconfig/network  file:\nGATEWAY=192.168.0.1\nIn the previous example, the default GATEWAY  is set to 192.168.0.1. Different interfaces can \nuse different GATEWAY  addresses. For other settings that can appear in the network  files, \ncheck the sysconfig.txt  file in the /usr/share/doc/initscripts  directory.\n/etc/hostname file\nIn RHEL and Fedora releases, the system\u2019s hostname is stored in the /etc/hostname  file. \nFor example, if the file included the hostname host1.example.com , that hostname would \nbe set each time the system booted up. You can check how the current hostname is set at \nany time by typing the hostname  command.\n/etc/hosts file\nBefore DNS was created, translating hostnames to IP addresses was done by passing around \na single hosts file. While there were only a few dozen and then a few hundred hosts on the \nInternet, this approach worked pretty well. But as the Internet grew, the single hosts file \nbecame unscalable and DNS was invented.\nThe /etc/hosts  file still exists on Linux systems. It can still be used to map IP addresses \nto hostnames. The /etc/hosts  file is a way to set up names and addresses for a small local \nnetwork or just create aliases in order to make it easier to access the systems that you use \nall the time.\nHere\u2019s an example of an /etc/hosts  file:\n127.0.0.1  localhost localhost.localdomain\n::1        localhost localhost.localdomain\n192.168.0.201  node1.example.com node1 joe\n192.168.0.202  node2.example.com node2 sally\nThe first two lines ( 127.0.0.1  and ::1 ) set addresses for the local system. The IPv4 address \nfor the local host is 127.0.0.1 ; the IPv6 address for the local host is ::1 . There are also \nentries for two IP addresses. You could reach the first IP address (192.168.0.201) by the \nnames node1.example.com , node1 , or joe . For example, typing ping joe  results in \npackets being sent to 192.168.0.201.", "doc_id": "1dbda34e-2b4e-4a99-995d-4386a82ba93d", "embedding": null, "doc_hash": "700dc86c4f90a27533dfdea52cc3a9b321b731cfb0a6ba585db84553dab6fbef", "extra_info": {"page_label": "383"}, "node_info": {"start": 0, "end": 2444}, "relationships": {"1": "a2687c95-664d-43ab-9cfe-fc510f339ec6"}}, "__type__": "1"}, "531f9723-7220-47c2-8a02-6797c16d1e16": {"__data__": {"text": "Chapter 14: Administering Networking\n359\n14/etc/resolv.conf file\nDNS servers and search domains are set in the /etc/resolv.conf  file. If NetworkManager \nis enabled and running, you should not edit this file directly. Using DNS ?= entries from \nifcfg-*  files, NetworkManager overwrites the /etc/resolv.conf  file so that you would \nlose any entries you add to that file. Here\u2019s an example of the /etc/resolv.conf  file that \nwas modified by NetworkManager:\n# Generated by NetworkManager\nnameserver 192.168.0.2\nnameserver 192.168.0.3\nEach nameserver entry identifies the IP address of a DNS server. The order defines the order \nin which the DNS servers are checked. It\u2019s normal to have two or three nameserver entries, \nin case the first is not available. More than that, and it can take too long for an unresolv -\nable hostname to get checked for each server.\nAnother type of entry that you can add to this file is a search entry. A search entry  lets you \nindicate domains to be searched when a hostname is requested by its base name instead of \nits entire fully qualified domain name. You can have multiple search entries by identifying \none or more domain names after the search keyword, as in this example:\nsearch example.com example.org example.net\nThe search options are separated by spaces or tabs.\n/etc/nsswitch.conf\nUnlike in earlier releases, the /etc/nsswitch.conf  file is managed by the authselect  \ncommand and should not be modified manually. To make changes, edit the /etc/authse -\nlect/user-nsswitch.conf  file and run authselect apply-changes .\nSettings in the /etc/nsswitch.conf  file determine that hostname resolution is done  \nby first searching the local /etc/hosts  file (files) and then DNS servers listed in the  \n/etc/resolv.conf  file (dns). The myhostname  value is used to ensure that an address \nis always returned for the host. This is how the hosts entry in the /etc/resolv.conf  file \nappears in Red Hat Enterprise Linux:\nhosts:      files dns myhostname\nYou can add other locations, such as Network Information Service ( nis or nisplus ) data -\nbases, for querying hostname-to-IP-address resolution. You can also change the order in \nwhich the different services are queried. You can check that hostname-to-IP-address reso -\nlution is working properly using different commands.\nIf you want to check that your DNS servers are being queried properly, you can use the \nhost  or dig  commands, as in, for example:\n$ host redhat.com\nredhat.com has address 209.132.183.105\nredhat.com mail is handled by 10 us-smtp-inbound-1.mimecast.com.", "doc_id": "531f9723-7220-47c2-8a02-6797c16d1e16", "embedding": null, "doc_hash": "8f140fa470874a993edef1918af41eb50f4a4118f700bdf4b3bd755ea2e116f5", "extra_info": {"page_label": "384"}, "node_info": {"start": 0, "end": 2567}, "relationships": {"1": "1d65f319-62c9-4998-b159-2ef1c2c96e74"}}, "__type__": "1"}, "7f26319e-1d75-4581-9d6c-3eec050cfcb4": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator360redhat.com mail is handled by 10 us-smtp-inbound-2.mimecast.com.\n$ dig redhat.com\n; <<>> DiG 9.11.11-RedHat-9.11.11-1.fc30 <<>> redhat.com\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 9948\n;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;redhat.com.          IN  A\n...\n;; ANSWER SECTION:\nredhat.com.     3600  IN  A  09.132.183.105\n;; Query time: 49 msec\n;; SERVER: 8.8.8.8#53(8.8.8.8)\n;; WHEN: Sat Nov 23 19:16:14 EST 2019\nBy default, the host  command produces simpler output for DNS queries. It shows the  \nIP address for redhat.com  and the names of the mail servers (MX records) that serve \nredhat.com . The dig  command shows information similar to what appears in the files \nthat hold DNS records. The QUESTION SECTION part of the output shows that the address \nsection asked for the address of redhat.com  and the ANSWER SECTION part showed \nthe answer ( 209.132.183.105 ). You can also see the address of the DNS server that \nwas queried.\nThe host  and dig  commands are only used to query DNS servers. They don\u2019t check the \nnsswitch.conf  file to find other places to query, such as the local hosts file. For that, \nyou would have to use the getent  command:\n# getent hosts node1\n192.168.0.201  node1\nThis getent  example finds a host named node1  that was entered into my local  \n/etc/hosts  file. The getent  command can be used to query any information setup in the \nnsswitch.conf  file. For example, typing getent passwd root  shows the entry for \nthe root user account in the local file, but it can also query a remote LDAP database for user \ninformation if you have configured that feature, as described in Chapter\u00a011, \u201cManaging User \nAccounts.\u201d\nSetting alias network interfaces\nSometimes you might want your network interface card listening on multiple IP addresses. \nFor example, if you were setting up a web server that was serving secure content ( https ) \nfor multiple domains ( example.com , example.org , and so on), each domain would \nrequire a separate IP address (associated with a separate certificate). In that case, instead \nof adding multiple network interface cards to the computer, you could simply create mul -\ntiple aliases on a single NIC.\nTo create an alias network interface in RHEL 6 and earlier Fedora releases, you just have to \ncreate another ifcfg-  file. Following the example of an eth0  interface on a RHEL system, ", "doc_id": "7f26319e-1d75-4581-9d6c-3eec050cfcb4", "embedding": null, "doc_hash": "74e032d4edbd30d185ae9c055584d81a1571fe4b5c643f9aa467f3745eaaa4ac", "extra_info": {"page_label": "385"}, "node_info": {"start": 0, "end": 2557}, "relationships": {"1": "80f78307-bf53-4dba-91ed-33c9acadcd6c"}}, "__type__": "1"}, "7c362ae0-c47d-4ae9-b1b2-08062fdfefba": {"__data__": {"text": "Chapter 14: Administering Networking\n361\n14you could create an eth0:0  interface associated with the same network interface card. To \ndo this, create a file in the /etc/sysconfig/network-scripts  directory called ifcfg-\neth0:0  that contains information such as the following:\nDEVICE=eth0:0\nONPARENT=yes\nIPADDR=192.168.0.141\nNETMASK=255.255.255.0\nThe example code creates an alias for the network interface eth0  called eth0:0 . Instead \nof ONBOOT , the ONPARENT  entry says to bring up this interface if the parent ( eth0 ) is \nstarted and listen on address 192.168.0.141. You can bring up that interface by typing ifup \neth0:0 . You can then check that the interface came up using the ip  command:\n$ ip addr show eth0\n2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc\npfifo_fast state UP qlen 1000\nlink/ether f0:de:f1:28:46:d9 brd ff:ff:ff:ff:ff:ffinet\n192.168.0.140/24 brd 192.168.0.255 scope global\neth0inet 192.168.0.141/24 brd 192.168.0.255 scope global secondary\neth0:0inet6 fe80::f2de:f1ff:fe28:46d9/64 scope link\nvalid_lft forever preferred_lft forever\nYou can see that the network interface card represented by eth0  is listening on two \naddresses: 192.168.0.140 ( eth0 ) and 192.168.0.141 ( eth0:0 ). So, this system will respond \nto packets destined for either of those two addresses. You could add more IP addresses to \nthat interface by creating more ifcfg-eth0:?  files (ifcfg-eth0:1 , ifcfg-eth0:2 , \nand so on).\nIn more recent RHEL and Fedora systems, you can create aliases directly in the primary \nifcfg  file for an alias. For example, a primary (192.168.0.187) and alias (192.168.99.1) \naddress for a NIC interface named p4p1  might be represented by the following address  \nsettings in the ifcfg-p4p1  file:\nIPADDR=192.168.0.187\nPREFIX=24\nIPADDR1=192.168.99.1\nPREFIX1=24\nSetting up Ethernet channel bonding\nEthernet channel bonding  allows you to have more than one network interface card on a \ncomputer associated with a single IP address. There are several reasons you might want \nto do this:\nHigh availability  Multiple NICs on the same IP address can ensure that if one subnet \ngoes down or one NIC breaks, the address can still be reached on a NIC connected to \nanother subnet.\nPerformance  If there is too much network traffic to be handled by one NIC, you can \nspread that traffic across multiple NICs.", "doc_id": "7c362ae0-c47d-4ae9-b1b2-08062fdfefba", "embedding": null, "doc_hash": "a7e89cdb3aac0c3eb4c2dca6d32f7893f7ffb561b858ee4e6923aa9474daa682", "extra_info": {"page_label": "386"}, "node_info": {"start": 0, "end": 2339}, "relationships": {"1": "66f5930b-d1f6-4873-a952-f6c1d3b226c1"}}, "__type__": "1"}, "8f013150-1e5e-440c-a645-43b5e11a3298": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator362In Red Hat Enterprise Linux and Fedora on a computer with multiple NICs, you can set up \nEthernet channel bonding by creating a few ifcfg  files and loading the necessary module. \nYou can start with one bonding file (for example, ifcfg-bond0 ) and then point multiple \nifcfg-eth ? files at that bond interface. Then you can load the bond module.\nDepending on the type of bonding that you want to do, you can set your bonding inter -\nface to different modes. Using the BONDING _OPTS  variable, you define the mode and \nother bonding options (all of which are passed to the bonding module). You can read about \nthe bonding module by entering modinfo bonding or by installing the kernel-docs  \npackage and reading the bonding.txt  file from the /usr/share/doc/kernel-doc*/\nDocumentation/networking/ directory.\nHere is an example of the file that defines a bonded interface. The file in this example is  \n/etc/sysconfig/network-scripts/ifcfg-bond0 :\nDEVICE=bond0\nONBOOT=yes\nIPADDR=192.168.0.50\nNETMASK=255.255.255.0\nBOOTPROTO=none\nBONDING_OPTS=\"mode=active-backup\"\nThe bond0  interface in this example uses the IP address 192.168.0.50. It starts up on \nboot. The BONDING _ OPTS  sets the bonding mode to active-backup. This means that only \none NIC is active at a time, and the next NIC only takes over when the previous one fails \n(failover). No network interface card is associated with the bond0  interface yet. For that, \nyou must create separate ifcfg  file options. For example, create an /etc/sysconfig/\nnetwork-scripts/ifcfg-eth0  that looks like the following (then create eth1 , eth2 , \neth3 , and so on for each NIC that you want to use in the bonding interface):\nDEVICE=eth0\nMASTER=bond0\nSLAVE=yes\nBOOTPROTO=none\nONBOOT=yes\nWith the eth0  interface used as part of the bond0  interface, there is no IP address \nassigned. That\u2019s because the eth0  interface uses the IP address from the bond0  interface \nby defining itself as a slave ( SLAVE=yes ) to bond0  (MASTER=bond0 ).\nThe last thing that you want to do is to make sure that the bond0  interface is set to use \nthe bonding module. To do that, create an /etc/modprobe.d/bonding.conf  file that \ncontains the following entry:\nalias bond0 bonding\nBecause all of the interfaces are set to ONBOOT=yes , the bond0  interface starts and all of \nthe eth?  interfaces are available as they are needed.", "doc_id": "8f013150-1e5e-440c-a645-43b5e11a3298", "embedding": null, "doc_hash": "5077de58f4af06a2f70e195bef28c8042a255fa0bde8b75257e4b204df1c7c30", "extra_info": {"page_label": "387"}, "node_info": {"start": 0, "end": 2404}, "relationships": {"1": "c99e10f3-0bcf-4352-8eb3-b87933ce315f"}}, "__type__": "1"}, "28559435-68b5-47b2-afa6-ca173764b907": {"__data__": {"text": "Chapter 14: Administering Networking\n363\n14Setting custom routes\nOn a simple network configuration, communications that are destined for the local network \nare directed to the appropriate interface on your LAN, while communications for hosts out -\nside of your LAN go to a default gateway to be sent on to remote hosts. As an alternative, \nyou can set custom routes to provide alternative paths to specific networks.\nTo set a custom route in Fedora and RHEL, you create a configuration file in the  \n/etc/sysconfig/network-scripts  directory. In that route, you define the following:\nGATEWAY?  The IP address of the node on the local network that provides the route to \nthe subnetwork represented by the static route.\nADDRESS?  The IP address representing the network that can be reached by the \nstatic route.\nNETMASK?  The netmask that determines which part of the ADDRESS?  represents the \nnetwork and which represents the hosts that can be reached on that network.\nThe name of each custom route file is route-interface . So, for example, a custom route \nthat can be reached through your eth0  interface would be named route-eth0. You could \nhave multiple custom routes in that file, with each route entry replacing the ? with the \ninterface number:\nADDRESS0=192.168.99.0\nNETMASK0=255.255.255.0\nGATEWAY0=192.168.0.5\nIn this example, any packet destined for a host on the 192.168.99 network would be sent \nthrough the local eth0  interface and directed to the gateway node at 192.168.0.5. Pre -\nsumably, that node would provide a route to another network containing hosts in the \n192.168.99 address range. This route would take effect when the eth0  network interface \nwas restarted.\nTo check that the route is working after you restart the network interface, you could type \nthe following:\n# route\nKernel IP routing table\nDestination  Gateway     Genmask         Flags Metric Ref Use Iface\ndefault      192.168.0.1 0.0.0.0         UG    0      0     0 eth0\n192.168.0.0  *           255.255.255.0   U     1      0     0 eth0\n192.168.99.0 192.168.0.5 255.255.255.0   UG    0      0     0 eth0\nThe output from the route -n  command shows that the default route (anything not \ndestined for the local network 192.168.0 or the 192.168.99 network) is via the 192.168.0.1 \naddress. Any packets destined for the 192.168.99 network are directed through the address \n192.168.0.5.", "doc_id": "28559435-68b5-47b2-afa6-ca173764b907", "embedding": null, "doc_hash": "61b905dbfe89ce536a43a17884e4475dd1480daf920af51ef4eecc979651a1f7", "extra_info": {"page_label": "388"}, "node_info": {"start": 0, "end": 2370}, "relationships": {"1": "a8f94141-87fa-4630-ba17-4ff452bcd223"}}, "__type__": "1"}, "17802436-49b7-41b8-9f80-f00ba7bc3af7": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator364If you wanted to add more custom routes, you could add them to this same route-eth0  \nfile. The next set of information would be named ADDRESS1 , NETMASK1 , GATEWAY1 , \nand so on.\nConfiguring Networking in the Enterprise\nSo far, the network configuration described in this chapter has centered on setting up \nsingle systems to connect to a network. Features available in Linux can go well beyond that \nby providing software that supports the actual network infrastructure needed by host com-\nputers to communicate.\nThe following sections introduce you to a few of the network infrastructure types of ser -\nvices available in Linux. Full implementation of these features is beyond the scope of \nthis book, but know that if you find yourself needing to manage network infrastructure \nfeatures, the following sections will give you a sense of how those features are imple -\nmented in Linux.\nConfiguring Linux as a router\nIf you have more than one network interface on a computer (typically two or more NICs), \nyou can configure Linux as a router. To make this happen, all that is needed is a change to \none kernel parameter that allows packet forwarding. To turn on the ip_forward param -\neter immediately and temporarily, enter the following as root:\n# cat /proc/sys/net/ipv4/ip_forward\n0\n# echo 1 > /proc/sys/net/ipv4/ip_forward\n# cat /proc/sys/net/ipv4/ip_forward\n1\nPacket forwarding (routing) is disabled by default, with the value of ip_forward set to 0. \nBy setting it to 1 , packet forwarding is immediately enabled. To make this change perma -\nnent, you must add that value to the /etc/sysctl.conf  file, so that it appears as follows:\nnet.ipv4.ip_forward = 1\nWith that file modified as shown, each time the system reboots, the value for ip_forward \nis reset to 1 . (Notice that net.ipv4.ip _ forward  reflects the actual location of the \nip _ forward  file, minus /proc/sys , and with dots replacing slashes. You can change \nany kernel parameters set in the /proc/sys  directory structure in this way.)\nWhen a Linux system is used as a router, it is often used as a firewall between a private \nnetwork and a public network, such as the Internet. If that is the case, you might also \nwant to use that same system as a firewall that does network address translation (NAT) and \nprovides DHCP service, so the systems on the private network can route through the Linux \nsystem using private IP addresses. (See Chapter\u00a025, \u201cSecuring Linux on a Network,\u201d for \ninformation on working with Linux firewall rules using the iptables  facility.)", "doc_id": "17802436-49b7-41b8-9f80-f00ba7bc3af7", "embedding": null, "doc_hash": "a3c7d3337cd859de4aef4da668d52910803ec4ed0c780e77c03fdb1f224e24b7", "extra_info": {"page_label": "389"}, "node_info": {"start": 0, "end": 2587}, "relationships": {"1": "3013bdca-a7e5-49d6-84a7-bc05c8a12589"}}, "__type__": "1"}, "bd272091-0078-4a35-8e66-e9aae344c400": {"__data__": {"text": "Chapter 14: Administering Networking\n365\n14Configuring Linux as a DHCP server\nNot only can a Linux system use a DHCP server to get its IP address and other informa -\ntion, it can also be configured to act as a DHCP server itself. In its most basic form, a DHCP \nserver can hand out IP addresses from a pool of addresses to any system that requests an IP \naddress. Usually, however, the DHCP server also distributes the locations of DNS servers and \nthe default gateway.\nConfiguring a DHCP server is not something that should be done without some thought. \nDon\u2019t add a DHCP server on a network that is not under your control and that already has \na working DHCP server. Many clients are set up to get address information from any DHCP \nserver that will hand it out.\nDHCP service is provided by the dhcp-server  package in Fedora and RHEL. The service \nis named dhcpd . The primary configuration file is /etc/dhcp/dhcpd.conf  for IPv4 net -\nworks (there is a dhcpd6.conf  file in the same directory to provide DHCP service for IPv6 \nnetworks). By default, the dhcpd  daemon listens on UDP port 67, so remember to keep that \nport open on your firewall.\nTo configure a DHCP server, you could copy the dhcpd.conf.example  file from the  \n/usr/share/doc/dhcp-server  directory and replace the /etc/dhcp/dhcpd.conf  \nfile. Then modify it as you like. Before using that file, however, you want to change the \ndomain-name options to reflect your domain and IP address ranges to suit those you are \nusing. The comments in the file will help you do this.\nWhen you install some virtualization and cloud services on a Linux system, a DHCP server \nis set up by default for you within that system. For example, when you install KVM and \nstart the libvirtd  service in RHEL or Fedora, it automatically configures a default private \nnetwork in the 192.168.122.0/24 address range. When you launch virtual machines, they are \ngiven IP addresses in that range. When you install and start the Docker service on those \nLinux distributions, it likewise sets up a private network and hands out IP addresses to \nDocker containers launched on that system.\nConfiguring Linux as a DNS server\nIn Linux, most professional Domain Name System (DNS) servers are implemented using the \nBerkeley Internet Name Domain (BIND) service. This is implemented in Fedora and RHEL \nby installing the bind , bind-utils , and bind-libs  packages. For added security, some \npeople install the bind-chroot  package.\nBy default, bind  is configured by editing the /etc/named.conf  file. Hostname-to-IP-\naddress mapping is done in zone files located in the /var/named  directory. If you install \nthe bind-chroot  package, bind  configuration files are moved under the /var/named/\nchroot  directory, which attempts to replicate the files from /etc  and /var  that are \nneeded to configure bind  so that the named daemon (which provides the service) is con -\nfined to the /etc/named/chroot  directory structure.", "doc_id": "bd272091-0078-4a35-8e66-e9aae344c400", "embedding": null, "doc_hash": "734cf6fa20b5e5c34209791e675b8ccafc3a949f4f82897f31ad3851e85ddea7", "extra_info": {"page_label": "390"}, "node_info": {"start": 0, "end": 2959}, "relationships": {"1": "2c8618b8-93d2-4610-9720-064b0c3f1464"}}, "__type__": "1"}, "576d8cc0-e40e-45fd-90fa-1a1b3e686e53": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator366If you are interested in trying out bind , I recommend that you first try it out by config -\nuring DNS for a small home network behind a firewall as a way to make it easier for the peo -\nple in your household to communicate with each other. You can lock down the IP addresses \nof the machines in your home by attaching MAC addresses of each computer\u2019s network \ninterface card to specific IP addresses on a DHCP server and then mapping those names to \naddresses in a DNS server.\nCaution\nBefore you create a public DNS server, keep in mind that it is very important to secure your DNS server properly. A \ncracked public DNS server can be used to redirect traffic to any server the bad guys choose. So, if you are using that \nserver, you are in danger of being presented with sites that are not the sites you think they are.\nConfiguring Linux as a proxy server\nA proxy server provides a means of restricting network traffic from a private network to a \npublic one, such as the Internet. Such servers provide an excellent way to lock down a com-\nputer lab at a school or restrict websites that employees can visit from work.\nBy physically setting up Linux as a router but configuring it as a proxy server, all of the \nsystems on your home or business network can be configured to access the Internet using \nonly certain protocols and only after you filter the traffic.\nUsing the Squid Proxy Server, which comes with most Linux systems ( squid  package in \nFedora and RHEL), you can enable the system to accept requests to web servers (HTTP and \nHTTPS), file servers (FTP), and other protocols. You can restrict which systems can use your \nproxy server (by hostname or IP address) and even limit which sites they can visit (by spe -\ncific address, range of addresses, hostname, or domain names).\nConfiguring a squid proxy server can be as simple as installing the squid  package, editing \nthe /etc/squid/squid.conf  file, and starting the squid  service. The file comes with a \nrecommended minimal configuration. However, you might want to define the hosts (based \non IP address or name) that you want to allow to use the service. There are blacklists avail -\nable with squid  that allow you to deny access to whole sets of sites that might be inappro -\npriate for children to visit.\nSummary\nMost network connections from a Linux desktop or laptop system can be made with little or \nno user intervention. If you use NetworkManager over a wired or wireless Ethernet connec -\ntion, address and server information needed to start up can be automatically obtained from \na DHCP server.\nWith NetworkManager\u2019s graphical interface, you can do some network configuration, if you \nlike. You can set static IP addresses and select the name server and gateway computers to ", "doc_id": "576d8cc0-e40e-45fd-90fa-1a1b3e686e53", "embedding": null, "doc_hash": "a8d90dffbb42ab53426b5e365cdef678bf91024707d46f7f9fe355db44a5f600", "extra_info": {"page_label": "391"}, "node_info": {"start": 0, "end": 2805}, "relationships": {"1": "66221f6c-1f53-40ec-87cc-92e89317da75"}}, "__type__": "1"}, "2398eec9-672e-448f-af57-a48c470ef7b3": {"__data__": {"text": "Chapter 14: Administering Networking\n367\n14use. To do more manual and complex network configuration, consider working more directly \nwith network configuration files.\nNetwork configuration files in Linux can be used to set up more advanced features such as \nEthernet channel bonding.\nBeyond the basics of network connectivity in Linux, features are available that enable you \nto provide network infrastructure types of services. This chapter introduced services and \nfeatures such as routing, DHCP, and DNS that you need to know when working with more \nadvanced networking features in Linux.\nWith your networking configured, you can now begin configuring services to run over your \nnetworks. Chapter\u00a015, \u201cStarting and Stopping Services,\u201d describes the tools that you need \nto enable, disable, start, stop, and check the status of the services that are configured for \nyour Linux system.\nExercises\nThe exercises in this section help you to examine and change the network interfaces on \nyour Linux system as well as understand how to configure more advanced networking fea -\ntures. Start these exercises on a Linux system that has an active network connection but \nthat is not  in the middle of some critical network activity.\nI recommend that you do these exercises directly from your computer console (in other \nwords, don\u2019t ssh into the computer to do them). Some of the commands that you run may \ninterrupt your network connectivity, and some of the configuration you do, if you make a \nmistake, can result in your computer being temporarily unavailable from the network.\nThere are often multiple ways to complete the tasks described in these exercises. If you are \nstuck, refer to the task solutions that are provided in Appendix B.\n1. Use the desktop to check that NetworkManager has successfully started your net -\nwork interface (wired or wireless) to the network. If it has not, then try to start \nyour network interface.\n2. Run a command to check the active network interfaces available on your computer.\n3. Try to contact google.com  from the command line in a way that ensures that DNS \nis working properly.\n4. Run a command to check the routes being used to communicate outside of your \nlocal network.\n5. Trace the route being taken to connect to google.com .\n6. View the network activity of your Linux system from the Cockpit web user \ninterface.\n7. Create a host entry that allows you to communicate with your local host system \nusing the name myownhost .", "doc_id": "2398eec9-672e-448f-af57-a48c470ef7b3", "embedding": null, "doc_hash": "8688193ab8f7cf336693080d0273a4c391db0aec11a36241711972bdddfbdcd9", "extra_info": {"page_label": "392"}, "node_info": {"start": 0, "end": 2468}, "relationships": {"1": "857787f7-6343-48f2-b530-0008b241bd78"}}, "__type__": "1"}, "15a0707f-8121-4d61-b430-e9f26ddf0e79": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator3688. Determine the addresses of the DNS name servers that are being used to resolve \nhostnames to IP addresses on your system, then check which is queried from your \nsystem to find the IP address for google.com .\n9. Create a custom route that directs traffic destined for the 192.168.99.0/ \n255.255.255.0 network to some IP address on your local network, such as 192.168.0.5 \n(first ensuring that the 192.168.99 network is not being used at your location).\n10. Check to see if your system has been configured to allow IPv4 packets to be routed \nbetween network interfaces on your system.", "doc_id": "15a0707f-8121-4d61-b430-e9f26ddf0e79", "embedding": null, "doc_hash": "3ab580a6539790959a6f4a687c7cd8d8a845c6b950b7827ed135e53c6c05f092", "extra_info": {"page_label": "393"}, "node_info": {"start": 0, "end": 634}, "relationships": {"1": "82504d51-b83a-495b-a272-90ca096b323b"}}, "__type__": "1"}, "6fa67f41-dc9b-4c0f-b291-a3975563b4e8": {"__data__": {"text": "369\nCHAPTER15\nStarting and Stopping Services\nIN THIS CHAPTER\nUnderstanding the various Linux init services\nAuditing Linux daemon-controlled services\nStopping and starting services\nChanging the Linux server\u2019s default runlevel\nRemoving services\nThe primary job of a Linux server system is to offer services to local or remote users. A server \ncan provide access to web pages, files, database information, streaming music, or other types \nof content. Name servers can provide access to lists of host computer or usernames. Hundreds \nof these and other types of services can be configured on your Linux systems.\nOngoing services offered by a Linux system, such as access to a printer service or login service, \nare typically implemented by what is referred to as a daemon  process. Most Linux systems have a \nmethod of managing each daemon process as a service  using one of several popular initialization \nsystems (also referred to as init systems). Advantages of using init systems include the ability to do \nthe following:\nIdentify runlevels: Put together sets of services in what are referred to as runlevels  or targets .\nEstablish dependencies: Set service dependencies so, for example, a service that requires \nnetwork interfaces won\u2019t start until all network startup services have started \nsuccessfully.\nSet the default runlevel: Select which runlevel or target starts up when the system boots  \n(a default runlevel ).\nManage services: Run commands that tell individual services to start, stop, pause, restart, or \neven reload configuration files.\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "6fa67f41-dc9b-4c0f-b291-a3975563b4e8", "embedding": null, "doc_hash": "1cf4fd9e2257057fbfaa84e843be0e929064842620861ed9ed6f1af03f432311", "extra_info": {"page_label": "394"}, "node_info": {"start": 0, "end": 1674}, "relationships": {"1": "a1be4f0e-4488-4b6f-af84-2f8c554b1019"}}, "__type__": "1"}, "3a1a651e-86af-488e-93f9-a1b3711ccda7": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator370Several different init systems are in use with Linux systems today. The one you use depends \non the Linux distribution and release that you are using. In this chapter, I cover the follow -\ning init systems that have been used in Fedora, Red Hat Enterprise Linux, Ubuntu, and many \nother Linux distributions:\nSysVinit: This traditional init system was created for UNIX System V systems in the \nearly 1980s. It offers an easy-to-understand method of starting and stopping ser -\nvices based on runlevel. Most UNIX and Linux systems up until a few years ago \nused SysVinit.\nSystemd: The latest versions of Fedora and RHEL use the systemd  init system. It is \nthe most complex of the init systems, but it also offers much more flexibility. Sys -\ntemd  offers not only features for starting and working with services, but also lets \nyou manage sockets, devices, mount points, swap areas, and other unit types.\nThis chapter describes the SysVinit  and systemd  init systems. In the process of using the \ninit system that matches your Linux distribution, you learn how the boot process works to \nstart services, how you can start and stop services individually, and how you enable and dis -\nable services.\nUnderstanding the Initialization Daemon (init \nor systemd)\nIn order to understand service management, you need to understand the initialization \ndaemon. The initialization daemon can be thought of as the \u201cmother of all processes.\u201d \nThis daemon is the first process to be started by the kernel on the Linux server. For Linux \ndistributions that use SysVinit, the init daemon is literally named init . For systemd , the \ninit daemon is named systemd .\nThe Linux kernel has a process ID (PID) of 0. Thus, the initialization process ( init  or \nsystemd ) daemon has a parent process ID (PPID) of 0, and a PID of 1. Once started, init  \nis responsible for spawning (launching) processes configured to be started at the server\u2019s \nboot time, such as the login shell ( getty  or mingetty  process). It is also responsible for \nmanaging services.\nThe Linux init  daemon was based on the UNIX System V init  daemon. Thus, it is called \nthe SysVinit daemon. However, it was not the only classic init  daemon. The init  daemon \nis not part of the Linux kernel. Therefore, it can come in different flavors, and Linux \ndistributions can choose which flavor to use. Another classic init  daemon was based on Note\nIf you are using an older version of Ubuntu, you probably used Upstart as your initialization system. Beginning with \nUbuntu 15.04 (released April 28, 2015), Upstart was replaced by the systemd  initialization daemon. Thus, Upstart \nwill not be described in this book.", "doc_id": "3a1a651e-86af-488e-93f9-a1b3711ccda7", "embedding": null, "doc_hash": "b5dcc7dc31431d6ee7d0fc09a3a69f102bdc934d0db61c725a2f08e34b3acc9b", "extra_info": {"page_label": "395"}, "node_info": {"start": 0, "end": 2713}, "relationships": {"1": "c1f48f0c-df73-4b0a-9962-b6976cfdbc73"}}, "__type__": "1"}, "8fca5be4-6a79-4db7-a13f-9a21335b3a85": {"__data__": {"text": "Chapter 15: Starting and Stopping Services\n371\n15Berkeley UNIX, also called BSD. Therefore, the two original Linux init  daemons were BSD \ninit  and SysVinit.\nThe classic init  daemons worked without problems for many years. However, these dae -\nmons were created to work within a static environment. As new hardware, such as USB \ndevices, came along, the classic init  daemons had trouble dealing with these and other \nhot-plug devices. Computer hardware had changed from static to event based. New init  \ndaemons were needed to deal with these fluid environments.\nIn addition, as new services came along, the classic init  daemons had to deal with \nstarting more and more services. Thus, the entire system initialization process was less \nefficient and ultimately slower.\nThe modern initialization daemons have tried to solve the problems of inefficient system \nboots and non-static environments. The most popular of the new initialization daemons is \nsystemd . Ubuntu, RHEL, and Fedora distributions have made the move to the systemd  \ndaemon while maintaining backward compatibility to the classic SysVinit, Upstart, or BSD \ninit  daemons.\nThe systemd  daemon, available from http://docs.fedoraproject.org/en-US/\nquick-docs/understanding-and-administering-systemd , was written primarily \nby Lennart Poettering, a Red Hat developer. It is currently used by all of the latest versions \nof Fedora, RHEL, OpenSUSE, and Ubuntu.\nIn order to manage your services properly, you need to know which initialization daemon \nyour server has. Figuring that out can be a little tricky. The initialization process running \non a SysVinit or Upstart is named init . For the first systemd  systems, it was also called \ninit  but is now named systemd . Running ps -e  can immediately tell you if yours is a \nsystemd  system:\n# ps -e | head\n  PID TTY          TIME CMD\n    1 ?        00:04:36 systemd\n    2 ?        00:00:03 kthreadd\n    3 ?        00:00:15 ksoftirqd/0\nIf PID 1 is the init  daemon for your system, try looking on the init Wikipedia  page \n(http://wikipedia.org/wiki/Init ) under \u201cOther implementations.\u201d This will help you \nunderstand if your init  daemon is SysVinit, Upstart, or some other initialization system.\nUnderstanding the classic init daemons\nThe classic init  daemons, SysVinit and BSD init , are worth understanding, even if your \nLinux server has a different init  daemon. Not only is backward compatibility to the clas -\nsics often used in the newer init  daemons, but many are based upon them.\nThe classic SysVinit and BSD init  daemons operate in a very similar fashion. Although \nin the beginning they may have been rather different, over time very few significant dif -\nferences remained. For example, the older BSD init  daemon would obtain configuration ", "doc_id": "8fca5be4-6a79-4db7-a13f-9a21335b3a85", "embedding": null, "doc_hash": "889a015e99ca5a411d43d6dd0f673cf208c95cd02d05c46e2d990c0d22aee20f", "extra_info": {"page_label": "396"}, "node_info": {"start": 0, "end": 2777}, "relationships": {"1": "e3818040-c64a-4ab1-9c1b-4372f3ad15dc"}}, "__type__": "1"}, "4759422d-360e-45c7-a73f-4b44fea06d24": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator372information from the /etc/ttytab  file. Now, like the SysVinit daemon, the BSD init  \ndaemon\u2019s configuration information is taken at boot time from the /etc/inittab  file. The \nfollowing is a classic SysVinit /etc/inittab  file:\n# cat /etc/inittab\n# inittab  This file describes how the INIT process should set up\n# Default runlevel. The runlevels used by RHS are:\n#   0 - halt (Do NOT set initdefault to this)\n#   1 - Single user mode\n#   2 - Multiuser, no NFS (Same as 3, if you do not have networking)\n#   3 - Full multiuser mode\n#   4 - unused\n#   5 - X11\n#   6 - reboot (Do NOT set initdefault to this)\n#\nid:5:initdefault:\n \n# System initialization.\nsi::sysinit:/etc/rc.d/rc.sysinit\n \nl0:0:wait:/etc/rc.d/rc 0\nl1:1:wait:/etc/rc.d/rc 1\nl2:2:wait:/etc/rc.d/rc 2\nl3:3:wait:/etc/rc.d/rc 3\nl4:4:wait:/etc/rc.d/rc 4\nl5:5:wait:/etc/rc.d/rc 5\nl6:6:wait:/etc/rc.d/rc 6\n \n# Trap CTRL-ALT-DELETE\nca::ctrlaltdel:/sbin/shutdown -t3 -r now\npf::powerfail:/sbin/shutdown -f -h +2\n\"Power Failure; System Shutting Down\"\n \n \n# If power was restored before the shutdown kicked in, cancel it.\npr:12345:powerokwait:/sbin/shutdown -c\n\"Power Restored; Shutdown Cancelled\"\n \n \n# Run gettys in standard runlevels\n1:2345:respawn:/sbin/mingetty tty1\n2:2345:respawn:/sbin/mingetty tty2\n3:2345:respawn:/sbin/mingetty tty3\n4:2345:respawn:/sbin/mingetty tty4\n5:2345:respawn:/sbin/mingetty tty5\n6:2345:respawn:/sbin/mingetty tty6\n \n# Run xdm in runlevel 5\nx:5:respawn:/etc/X11/prefdm -nodaemon", "doc_id": "4759422d-360e-45c7-a73f-4b44fea06d24", "embedding": null, "doc_hash": "72f93d4141e232ac89c83116617f10f77cf3e53c81b5c40f4656ec9c421c7edb", "extra_info": {"page_label": "397"}, "node_info": {"start": 0, "end": 1514}, "relationships": {"1": "26fe248a-9a34-4b4f-8a75-5b31899c4314"}}, "__type__": "1"}, "32bf1bb9-8f70-4dac-b084-8b86b57985b0": {"__data__": {"text": "Chapter 15: Starting and Stopping Services\n373\n15The /etc/inittab  file tells the init  daemon which runlevel is the default runlevel.  \nA runlevel  is a categorization number that determines what services are started and what \nservices are stopped. In the preceding example, a default runlevel of 5 is set with the line \nid:5:initdefault: . Table\u00a015.1 shows the standard seven Linux runlevels.\nLinux distributions can differ slightly on the definition of each runlevel as well as which \nrunlevels are offered.\nThe runlevels are not only used as a default runlevel in the /etc/inittab  file. They can \nalso be called directly using the init  daemon itself. Thus, if you want to halt your server \nimmediately, you type init 0  at the command line:\n# init 0\n...\nSystem going down for system halt NOW!\nThe init  command accepts any of the runlevel numbers in Table\u00a015.1, allowing you to \nswitch your server quickly from one runlevel category to another. For example, if you need Cautio N\nThe only runlevels that should be used in the /etc/inittab  file are 2 through 5. The other runlevels could cause \nproblems. For example, if you put runlevel 6 in the /etc/inittab  file as the default, when the server reboots, it \nwould go into a loop and continue to reboot over and over again.TABLE 15.1  Standard Linux Runlevels\nRunlevel # Name Description\n0 Halt All services are shut down, and the server is stopped.\n1 or S Single User Mode The root account is automatically logged in to the server. \nOther users cannot log in to the server. Only the command-\nline interface is available. Network services are not started.\n2 Multiuser Mode Users can log in to the server, but only the command-line \ninterface is available. On some systems, network interfaces \nand services are started; on others they are not. Originally, \nthis runlevel was used to start dumb terminal devices so that \nusers could log in (but no network services were started).\n3 Extended  \nMultiuser ModeUsers can log in to the server, but only the command-line \ninterface is available. Network interfaces and services are \nstarted. This is a common runlevel for servers.\n4 User Defined Users can customize this runlevel.\n5 Graphical Mode Users can log in to the server. Command-line and graphical \ninterfaces are available. Network services are started. This is a \ncommon runlevel for desktop systems.\n6 Reboot The server is rebooted.", "doc_id": "32bf1bb9-8f70-4dac-b084-8b86b57985b0", "embedding": null, "doc_hash": "16f093ab0c994bd4d615161e50628e50f316c272e88fe6258e9002dfadd1a997", "extra_info": {"page_label": "398"}, "node_info": {"start": 0, "end": 2393}, "relationships": {"1": "fffc0b79-a704-41eb-8760-d15f63522300"}}, "__type__": "1"}, "a98c25d9-0bff-494e-b96f-56b010620a1d": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator374to perform troubleshooting that requires the graphical interface to be down, you can type \ninit 3  at the command line:\n# init 3\nINIT: Sending processes the TERM signal\nstarting irqbalance:                     [ OK ]\nStarting setroubleshootd:\nStarting fuse:  Fuse filesystem already available.\n...\nStarting console mouse services:         [ OK ]\nTo see your Linux server\u2019s current runlevel, simply type in the command runlevel . The \nfirst item displayed is the server\u2019s previous runlevel, which in the following example is 5 . \nThe second item displayed shows the server\u2019s current runlevel, which in this example is 3 .\n$ runlevel\n5 3\nIn addition to the init  command, you can use the telinit  command, which is \nfunctionally the same. In the example that follows, the telinit  command is used to \nreboot the server by taking it to runlevel 6 :\n# telinit 6\nINIT: Sending processes the TERM signal\nShutting down smartd:                         [ OK ]\nShutting down Avahi daemon:                   [ OK ]\nStopping dhcdbd:                              [ OK ]\nStopping HAL daemon:                          [ OK ]\n...\nStarting killall:\nSending all processes the TERM signal...      [ OK ]\nSending all processes the KILL signal...      [ OK ]\n...\nUnmounting filesystems                        [ OK ]\nPlease stand by while rebooting the system\n...\nOn a freshly booted Linux server, the current runlevel number should be the same as the \ndefault runlevel number in the /etc/inittab  file. However, notice that the previous run -\nlevel in the example that follows is N . The N stands for \u201cNonexistent\u201d and indicates that \nthe server was freshly booted to the current runlevel.\n$ runlevel\nN 5\nHow does the server know which services to stop and which ones to start when a particular \nrunlevel is chosen? When a runlevel is chosen, the scripts located in the /etc/rc.d/rc #.d \ndirectory (where # is the chosen runlevel) are run. These scripts are run whether the run -\nlevel is chosen via a server boot and the /etc/inittab initdefault  setting or the \ninit  or telinit  command is used. For example, if runlevel 5 is chosen, then all of the ", "doc_id": "a98c25d9-0bff-494e-b96f-56b010620a1d", "embedding": null, "doc_hash": "16a13b1f2fb78cd01a95725c7d98b1000fc904b53cf1d6bd434fe43f886d019f", "extra_info": {"page_label": "399"}, "node_info": {"start": 0, "end": 2181}, "relationships": {"1": "6eb252d5-e95e-4085-ab80-83249ac71664"}}, "__type__": "1"}, "d6f7f8f3-9056-4f23-ad50-e7d7b69cc02c": {"__data__": {"text": "Chapter 15: Starting and Stopping Services\n375\n15scripts in the /etc/rc.d/rc5.d  directory are run; your list will be different, depending \non what services you have installed and enabled.\n# ls /etc/rc.d/rc5.d\nK01smolt                     K88wpa_supplicant   S22messagebus\nK02avahi-dnsconfd            K89dund             S25bluetooth\nK02NetworkManager            K89netplugd         S25fuse\nK02NetworkManagerDispatcher  K89pand             S25netfs\nK05saslauthd                 K89rdisc            S25pcscd\nK10dc_server                 K91capi             S26hidd\nK10psacct                    S00microcode_ctl    S26udev-post\nK12dc_client                 S04readahead_early  S28autofs\nK15gpm                       S05kudzu            S50hplip\nK15httpd                     S06cpuspeed         S55cups\nK20nfs                       S08ip6tables        S55sshd\nK24irda                      S08iptables         S80sendmail\nK25squid                     S09isdn             S90ConsoleKit\nK30spamassassin              S10network          S90crond\nK35vncserver                 S11auditd           S90xfs\nK50netconsole                S12restorecond      S95anacron\nK50tux                       S12syslog           S95atd\nK69rpcsvcgssd                S13irqbalance       S96readahead_later\nK73winbind                   S13mcstrans         S97dhcdbd\nK73ypbind                    S13rpcbind          S97yum-updatesd\nK74nscd                      S13setroubleshoot   S98avahi-daemon\nK74ntpd                      S14nfslock          S98haldaemon\nK84btseed                    S15mdmonitor        S99firstboot\nK84bttrack          ", "doc_id": "d6f7f8f3-9056-4f23-ad50-e7d7b69cc02c", "embedding": null, "doc_hash": "d4073455a2d733d12808c993f179652a0ac3a4cab43d05e8b6ce1a0d24073864", "extra_info": {"page_label": "400"}, "node_info": {"start": 0, "end": 1613}, "relationships": {"1": "2f788e98-c40f-4611-98f0-f5491d8c85b4", "3": "c1541ff4-69cb-40d7-ade5-283b065c0e0c"}}, "__type__": "1"}, "c1541ff4-69cb-40d7-ade5-283b065c0e0c": {"__data__": {"text": "    S97dhcdbd\nK73ypbind                    S13rpcbind          S97yum-updatesd\nK74nscd                      S13setroubleshoot   S98avahi-daemon\nK74ntpd                      S14nfslock          S98haldaemon\nK84btseed                    S15mdmonitor        S99firstboot\nK84bttrack                   S18rpcidmapd        S99local\nK87multipathd                S19rpcgssd          S99smartd\nNotice that some of the scripts within the /etc/rc.d/rc5.d  directory start with a K and \nsome start with an S . The K refers to a script that will kill (stop) a process. The S refers to \na script that will start a process. Also, each K and S script has a number before the name of \nthe service or daemon that they control. This allows the services to be stopped or started in \na particular controlled order. You would not want your Linux server\u2019s network services to be \nstarted before the network itself was started.\nAn /etc/rc.d/rc #.d directory exists for all the standard Linux runlevels. Each one con -\ntains scripts to start and stop services for its particular runlevel.\n# ls -d /etc/rc.d/rc?.d\n/etc/rc.d/rc0.d  /etc/rc.d/rc2.d  /etc/rc.d/rc4.d  /etc/rc.d/rc6.d\n/etc/rc.d/rc1.d  /etc/rc.d/rc3.d  /etc/rc.d/rc5.d\nActually, the files in the /etc/rc.d/rc #.d directories are not scripts but instead symbolic \nlinks to scripts in the /etc/rc.d/init.d  directory. Thus, there is no need to have multiple  \ncopies of particular scripts.\n# ls -l /etc/rc.d/rc5.d/K15httpd\nlrwxrwxrwx 1 root root 15 Oct 10 08:15", "doc_id": "c1541ff4-69cb-40d7-ade5-283b065c0e0c", "embedding": null, "doc_hash": "1534e48538e01c52f211639d659441ef84bf213cd66391680da19a2d42581aea", "extra_info": {"page_label": "400"}, "node_info": {"start": 1325, "end": 2820}, "relationships": {"1": "2f788e98-c40f-4611-98f0-f5491d8c85b4", "2": "d6f7f8f3-9056-4f23-ad50-e7d7b69cc02c"}}, "__type__": "1"}, "4135503a-1baf-4f7c-b608-6f76e482cc8e": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator376 /etc/rc.d/rc5.d/K15httpd -> ../init.d/httpd\n# ls /etc/rc.d/init.d\nanacron            functions  multipathd               rpcidmapd\natd                fuse       netconsole               rpcsvcgssd\nauditd             gpm        netfs                    saslauthd\nautofs             haldaemon  netplugd                 sendmail\navahi-daemon       halt       network                  setroubleshoot\navahi-dnsconfd     hidd       NetworkManager           single\nbluetooth          hplip      NetworkManagerDispatcher smartd\nbtseed             hsqldb     nfs                      smolt\nbttrack            httpd      nfslock                  spamassassin\ncapi               ip6tables  nscd                     squid\nConsoleKit         iptables   ntpd                     sshd\ncpuspeed           irda       pand                     syslog\ncrond              irqbalance pcscd                    tux\ncups               isdn       psacct                   udev-post\ncups-config-daemon killall    rdisc                    vncserver\ndc_client          kudzu      readahead_early          winbind\ndc_server          mcstrans   readahead_later          wpa_supplicant\ndhcdbd             mdmonitor  restorecond              xfs\ndund               messagebus rpcbind                  ypbind\nfirstboot          microcode  rpcgssd                  yum-updatesd\nNotice that each service has a single script in /etc/rc.d/init.d . There aren\u2019t separate \nscripts for stopping and starting a service. These scripts will stop or start a service depend -\ning upon what parameter is passed to them by the init  daemon.\nEach script in /etc/rc.d/init.d  takes care of all that is needed for starting or stopping a \nparticular service on the server. The following is a partial example of the httpd  script on a \nLinux system that uses the SysVinit daemon. It", "doc_id": "4135503a-1baf-4f7c-b608-6f76e482cc8e", "embedding": null, "doc_hash": "449b9bf412649486deabd249470417ec6f43779e8ab47f83018d6a2dd26f814f", "extra_info": {"page_label": "401"}, "node_info": {"start": 0, "end": 1879}, "relationships": {"1": "85a5cd97-b020-47cc-9fa7-ca44e22229ca", "3": "eb8a7af5-8359-49eb-afb5-3b05ef2582ce"}}, "__type__": "1"}, "eb8a7af5-8359-49eb-afb5-3b05ef2582ce": {"__data__": {"text": "  messagebus rpcbind                  ypbind\nfirstboot          microcode  rpcgssd                  yum-updatesd\nNotice that each service has a single script in /etc/rc.d/init.d . There aren\u2019t separate \nscripts for stopping and starting a service. These scripts will stop or start a service depend -\ning upon what parameter is passed to them by the init  daemon.\nEach script in /etc/rc.d/init.d  takes care of all that is needed for starting or stopping a \nparticular service on the server. The following is a partial example of the httpd  script on a \nLinux system that uses the SysVinit daemon. It contains a case statement for handling the \nparameter ( $1) that was passed to it, such as start , stop , status , and so on.\n# cat /etc/rc.d/init.d/httpd\n#!/bin/bash\n#\n# httpd        Startup script for the Apache HTTP Server\n#\n# chkconfig: - 85 15\n# description: Apache is a World Wide Web server.\n#              It is used to serve \\\n#              HTML files and CGI.\n# processname: httpd\n# config: /etc/httpd/conf/httpd.conf\n# config: /etc/sysconfig/httpd\n# pidfile: /var/run/httpd.pid\n \n# Source function library.\n. /etc/rc.d/init.d/functions\n...", "doc_id": "eb8a7af5-8359-49eb-afb5-3b05ef2582ce", "embedding": null, "doc_hash": "293961ec5e2ade6f4e2009710f9e01ce83edd2a72c929b9d5632c35770797400", "extra_info": {"page_label": "401"}, "node_info": {"start": 1280, "end": 2431}, "relationships": {"1": "85a5cd97-b020-47cc-9fa7-ca44e22229ca", "2": "4135503a-1baf-4f7c-b608-6f76e482cc8e"}}, "__type__": "1"}, "d14bdb64-557f-4198-945f-fb39462f38d7": {"__data__": {"text": "Chapter 15: Starting and Stopping Services\n377\n15# See how we were called.\ncase \"$1\" in\n  start)\n        start\n        ;;\n  stop)\n        stop\n        ;;\n  status)\n        status $httpd\n        RETVAL=$?\n        ;;\n...\nesac\n \nexit $RETVAL\nAfter the runlevel scripts linked from the appropriate /etc/rc.d/rc#.d  directory are \nexecuted, the SysVinit daemon\u2019s process spawning is complete. The final step the init  pro-\ncess takes at this point is to do anything else indicated in the /etc/inittab  file (such as \nspawn mingetty  processes for virtual consoles and start the desktop interface, if you are \nin runlevel 5 ).\nUnderstanding systemd initialization\nThe systemd  initialization daemon is the newer replacement for the SysVinit and the \nUpstart init  daemons. This modern initialization daemon was introduced in Fedora 15 \nand RHEL 7, and it is still in use today. It is backward compatible with both SysVinit and \nUpstart. System initialization time is reduced by systemd  because it can start services in \na parallel manner.\nLearning systemd basics\nWith the SysVinit daemon, services are stopped and started based upon runlevels. The \nsystemd  service is concerned with runlevels, but it implements them in a different way \nwith what are called target units . Although the main job of systemd  is to start and stop \nservices, it can manage other types of things referred to as units. A unit  is a group con -\nsisting of a name, type, and configuration file, and it is focused on a particular service or \naction. There are 12 systemd  unit types:\n\u25a0\u25a0automount\n\u25a0\u25a0device\n\u25a0\u25a0mount\n\u25a0\u25a0path\n\u25a0\u25a0service\n\u25a0\u25a0snapshot\n\u25a0\u25a0socket", "doc_id": "d14bdb64-557f-4198-945f-fb39462f38d7", "embedding": null, "doc_hash": "c664f8a07db3033c1f8449a1671ff2afb3b1aaeaba127f3c79355ed3f08824d5", "extra_info": {"page_label": "402"}, "node_info": {"start": 0, "end": 1620}, "relationships": {"1": "4ecb43a5-27a8-42af-bd05-87783e7635dd"}}, "__type__": "1"}, "c8cf0cd9-8acf-4532-9b4d-3dff91007429": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator378\u25a0\u25a0target\n\u25a0\u25a0timer\n\u25a0\u25a0swap\n\u25a0\u25a0slice\n\u25a0\u25a0scope\nThe two primary systemd  units with which you need to be concerned for dealing with \nservices are service units and target units. A service unit  is for managing daemons on your \nLinux server. A target unit  is simply a group of other units.\nThe example that follows shows several systemd  service units and target units. The  \nservice units have familiar daemon names, such as cups  and sshd . Note that each service \nunit name ends with .service . The target units shown have names like sysinit .  \n(sysinit  is used for starting up services at system initialization.) The target unit names \nend with .target .\n# systemctl list-units | grep .service\n...\ncups.service           loaded active running CUPS Printing Service\ndbus.service           loaded active running D-Bus Message Bus\n...\nNetworkManager.service loaded active running Network Manager\nprefdm.service         loaded active running Display Manager\nremount-rootfs.service loaded active exited  Remount Root FS\nrsyslog.service        loaded active running System Logging\n...\nsshd.service           loaded active running OpenSSH server daemon\nsystemd-logind.service loaded active running Login Service\n...\n# systemctl list-units | grep .target\nbasic.target           loaded active active  Basic System\ncryptsetup.target      loaded active active  Encrypted Volumes\ngetty.target           loaded active active  Login Prompts\ngraphical.target       loaded active active  Graphical Interface\nlocal-fs-pre.target    loaded active active  Local File Systems (Pre)\nlocal-fs.target        loaded active active  Local File Systems\nmulti-user.target      loaded active active  Multi-User\nnetwork.target         loaded active active  Network\nremote-fs.target       loaded active active  Remote File Systems\nsockets.target         loaded active active  Sockets\nsound.target           loaded active active  Sound Card\nswap.target            loaded active active  Swap\nsysinit.target         loaded active active  System Initialization\nsyslog.target          loaded active active  Syslog", "doc_id": "c8cf0cd9-8acf-4532-9b4d-3dff91007429", "embedding": null, "doc_hash": "bc778917703f2a1a7e6a79a9918f8179c4001c6634497cd60b4f09c9d174bdba", "extra_info": {"page_label": "403"}, "node_info": {"start": 0, "end": 2124}, "relationships": {"1": "7d7ded6b-beb5-4c41-a0c8-26f0d2be74cf"}}, "__type__": "1"}, "d1db909f-71e4-4826-b372-588b5e9f4d92": {"__data__": {"text": "Chapter 15: Starting and Stopping Services\n379\n15The Linux system unit configuration files are located in the /lib/systemd/system  and  \n/etc/systemd/system  directories. You could use the ls  command to look through those \ndirectories, but the preferred method is to use an option on the systemctl  command \nas follows:\n# systemctl list-unit-files --type=service\nUNIT FILE                                   STATE\n...\ncups.service                                enabled\n...\ndbus.service                                static\n...\nNetworkManager.service                      enabled\n...\npoweroff.service                            static\n...\nsshd.service                                enabled\nsssd.service                                disabled\n...\n276 unit files listed.\nThe unit configuration files shown in the preceding code are all associated with a service \nunit. Configuration files for target units can be displayed via the following method:\n# systemctl list-unit-files --type=target\nUNIT FILE                  STATE\nanaconda.target            static\nbasic.target               static\nbluetooth.target           static\ncryptsetup.target          static\nctrl-alt-del.target        disabled\ndefault.target             enabled\n...\nshutdown.target            static\nsigpwr.target              static\nsmartcard.target           static\nsockets.target             static\nsound.target               static\nswap.target                static\nsysinit.target             static\nsyslog.target              static\ntime-sync.target           static\numount.target              static\n43 unit files listed.\nNotice that both of the configuration units\u2019 file examples display units with a status of \nstatic, enabled, or disabled. The enabled status means that the unit is currently enabled. \nThe disabled status means that the unit is currently disabled. The next status, static, is \nslightly confusing. It stands for \u201cstatically enabled,\u201d and it means that the unit is enabled \nby default and cannot be disabled, even by root.", "doc_id": "d1db909f-71e4-4826-b372-588b5e9f4d92", "embedding": null, "doc_hash": "56d8c050632a102f9f0a7a5bbed56c782258194fac1abcee0586bffa7ea94542", "extra_info": {"page_label": "404"}, "node_info": {"start": 0, "end": 2016}, "relationships": {"1": "d4b88def-a5f6-49a2-b5eb-9f211d3327c6"}}, "__type__": "1"}, "a32a0a79-2582-46c4-b801-68360e2d6b51": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator380The service unit configuration files contain lots of information, such as what other services \nmust be started, when this service can be started, which environmental file to use, and so \non. The following example shows the sshd  daemon\u2019s unit configuration file:\n# cat /lib/systemd/system/sshd.service\n[Unit]\nDescription=OpenSSH server daemon\nDocumentation=man:sshd(8) man:sshd_config(5)\nAfter=network.target sshd-keygen.target\n \n[Service]\nType=notify\nEnvironmentFile=-/etc/crypto-policies/back-ends/opensshserver.config\nEnvironmentFile=-/etc/sysconfig/sshd\nExecStart=/usr/sbin/sshd -D $OPTIONS $CRYPTO_POLICY\nExecReload=/bin/kill -HUP $MAINPID\nKillMode=process\nRestart=on-failure\nRestartSec=42s\n \n[Install]\nWantedBy=multi-user.target\n \n[Install]\nWantedBy=multi-user.target\nThis basic service unit configuration file has the following options:\nDescription : A free-form description (comment line) of the service.\nDocumentation : Lists man pages for the sshd  daemon and configuration file.\nAfter : Configures ordering. In other words, it lists which units should be activated \nbefore this service is started.\nEnvironment File : The service\u2019s configuration files.\nExecStart : The command used to start this service.\nExecReload : The command used to reload this service.\nWantedBy : The target unit to which this service belongs.\nNotice that the target unit, multi-user.target , is used in the sshd  service unit config -\nuration file. The sshd  service unit is wanted by the multi-user.target . In other words, \nwhen the multi-user.target  unit is activated, the sshd  service unit is started.\nYou can view the various units that a target unit will activate by using the follow -\ning command:\n# systemctl show --property \"Wants\" multi-user.target\nWants=irqbalance.service firewalld.service plymouth-quit.service\nsystemd-update-utmp-runlevel.service systemd-ask-password-wall.path...\n(END) q", "doc_id": "a32a0a79-2582-46c4-b801-68360e2d6b51", "embedding": null, "doc_hash": "d1a68627adcdd0ea69179eda3f46f6c2421f555a23df9fc215944bc2e81d7f21", "extra_info": {"page_label": "405"}, "node_info": {"start": 0, "end": 1937}, "relationships": {"1": "a4fe7ba1-b1cc-4b23-858b-9da8475b3cf5"}}, "__type__": "1"}, "55d12e1f-24ce-408e-810a-e6f8a0da9662": {"__data__": {"text": "Chapter 15: Starting and Stopping Services\n381\n15Unfortunately, the systemctl  command does not format the output for this well. It liter -\nally runs off the right edge of the screen so you cannot see the full results. Also, you must \nenter q to return to the command prompt. To fix this problem, pipe the output through \nsome formatting commands to produce a nice, alphabetically sorted display, as shown in \nthe example that follows:\n# systemctl show --property \"Wants\" multi-user.target \\\n     | fmt -10 | sed 's/Wants=//g' | sort\natd.service\nauditd.service\navahi-daemon.service\nchronyd.service\ncrond.service\n...\nThis display shows all of the services and other units that will be activated (started), \nincluding sshd , when the multi-user.target  unit is activated. Remember that a target \nunit is simply a grouping of other units, as shown in the preceding example. Also notice \nthat the units in this group are not all service units. There are path units and other target \nunits as well.\nA target unit has both Wants  and requirements, called Requires . A Wants  means that all \nof the units listed are triggered to activate (start). If they fail or cannot be started, no \nproblem\u2014the target unit continues on its merry way. The preceding example is a display of \nWants only.\nA Requires is much more stringent than a Wants and potentially catastrophic. A Requires  \nmeans that all of the units listed are triggered to activate (start). If they fail or cannot be \nstarted, the entire unit (group of units) is deactivated.\nYou can view the various units a target unit Requires (must activate or the unit will fail), \nusing the command in the example that follows. Notice that the Requires output is much \nshorter than the Wants for the multi-user.target . Thus, no special formatting of the \noutput is needed.\n# systemctl show --property \"Requires\" multi-user.target\nRequires=basic.target\nThe target  units also have configuration files, as do the service  units. The following \nexample shows the contents of the multi-user.target  configuration file.\n# cat /lib/systemd/system/multi-user.target\n#  This file is part of systemd.\n#\n...\n \n[Unit]\nDescription=Multi-User\nDocumentation=man:systemd.special(7)\nRequires=basic.target", "doc_id": "55d12e1f-24ce-408e-810a-e6f8a0da9662", "embedding": null, "doc_hash": "e75a483f9ed6725eeb97c2e0b09ea8132eae1cf74bb947023b0470285be74934", "extra_info": {"page_label": "406"}, "node_info": {"start": 0, "end": 2229}, "relationships": {"1": "75eb82a0-3dc9-4a16-b580-56f58c235a91"}}, "__type__": "1"}, "87ec1bf3-84bc-4e63-8f29-d777dbc13667": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator382Conflicts=rescue.service rescue.target\nAfter=basic.target rescue.service rescue.target\nAllowIsolate=yes\nThis basic target unit configuration file has the following options:\nDescription : This is just a free-form description of the target.\nDocumentation : Lists the appropriate systemd man page.\nRequires : If this multi-user.target  gets activated, the listed target unit is \nalso activated. If the listed target unit is deactivated or fails, then multi-user.\ntarget  is deactivated. If there are no After and Before options, then both multi-\nuser.target  and the listed target unit activate simultaneously.\nConflicts : This setting avoids conflicts in services. Starting multi-user.target  \nstops the listed targets and services, and vice versa.\nAfter : This setting configures ordering. In other words, it determines which units \nshould be activated before starting this service.\nAllowIsolate : This option is a Boolean setting of yes  or no . If this option is set  \nto yes , then this target unit, multi-user.target , is activated along with its  \ndependencies and all others are deactivated.\nTo get more information on these configuration files and their options, enter man sys -\ntemd.service , man systemd.target , and man systemd.unit  at the command line.\nFor the Linux server using systemd , the boot process is easier to follow now that you \nunderstand systemd  target units. At boot, systemd  activates the default.target  \nunit. This unit is aliased either to multi-user.target  or graphical.target . Thus, \ndepending upon the alias  set, the services targeted by the target unit are started.\nIf you need more help understanding the systemd  daemon, you can enter man -k  \nsystemd  at the command line to get a listing of the various systemd  utilities\u2019  \ndocumentation in the man pages.\nLearning systemd\u2019s backward compatibility to SysVinit\nThe systemd  daemon has maintained backward compatibility to the SysVinit daemon. This \nallows Linux distributions time to migrate slowly to systemd .\nWhile runlevels are not truly part of systemd , the systemd  infrastructure has been cre -\nated to provide compatibility with the concept of runlevels. There are seven target unit \nconfiguration files specifically created for backward compatibility to SysVinit:\n\u25a0\u25a0runlevel0.target\n\u25a0\u25a0runlevel1.target\n\u25a0\u25a0runlevel2.target\n\u25a0\u25a0runlevel3.target\n\u25a0\u25a0runlevel4.target", "doc_id": "87ec1bf3-84bc-4e63-8f29-d777dbc13667", "embedding": null, "doc_hash": "ba9bf7bbb95feab5a4d2098ef09c0ec65289a84fc81811838a9aea734555d74a", "extra_info": {"page_label": "407"}, "node_info": {"start": 0, "end": 2410}, "relationships": {"1": "3a14a3c3-ba77-4fb7-84ac-200309c9b29e"}}, "__type__": "1"}, "43a32980-d40f-4633-af3c-23e32de66f34": {"__data__": {"text": "Chapter 15: Starting and Stopping Services\n383\n15\u25a0\u25a0runlevel5.target\n\u25a0\u25a0runlevel6.target\nAs you probably have already figured out, there is a target unit configuration file for each \nof the seven classic SysVinit runlevels. These target unit configuration files are symboli-\ncally linked to target unit configuration files that most closely match the idea of the origi-\nnal runlevel. In the example that follows, the symbolic links are shown for runlevel target \nunits. Notice that the runlevel target units for runlevel 2, 3, and 4 are all symbolically \nlinked to multi-user.target . The multi-user.target  unit is similar to the legacy \nextended multi-user mode.\n# ls -l /lib/systemd/system/runlevel*.target\nlrwxrwxrwx. 1 root root 15 Apr  9 04:25 /lib/systemd/system/runlevel0.target\n    -> poweroff.target\nlrwxrwxrwx. 1 root root 13 Apr  9 04:25 /lib/systemd/system/runlevel1.target\n    -> rescue.target\nlrwxrwxrwx. 1 root root 17 Apr  9 04:25 /lib/systemd/system/runlevel2.target\n    -> multi-user.target\nlrwxrwxrwx. 1 root root 17 Apr  9 04:25 /lib/systemd/system/runlevel3.target\n    -> multi-user.target\nlrwxrwxrwx. 1 root root 17 Apr  9 04:25 /lib/systemd/system/runlevel4.target\n    -> multi-user.target\nlrwxrwxrwx. 1 root root 16 Apr  9 04:25 /lib/systemd/system/runlevel5.target\n    -> graphical.target\nlrwxrwxrwx. 1 root root 13 Apr  9 04:25 /lib/systemd/system/runlevel6.target\n    -> reboot.target\nThe /etc/inittab file still exists, but it contains only comments stating that this \n configuration file is not used, and it gives some basic systemd information. The  \n/etc/inittab file no longer has any true functional use. This is an example  \nof an /etc/inittab file on a Linux server that uses systemd.\n# cat /etc/inittab\n# inittab is no longer used.\n#\n# ADDING CONFIGURATION HERE WILL HAVE NO EFFECT ON YOUR SYSTEM.\n#\n# Ctrl-Alt-Delete is handled by\n# /etc/systemd/system/ctrl-alt-del.target\n#\n# systemd uses 'targets' instead of runlevels.\n# By default, there are two main targets:\n#\n# multi-user.target: analogous to runlevel 3\n# graphical.target: analogous to runlevel 5\n#\n# To view current default target, run:\n# systemctl get-default\n#", "doc_id": "43a32980-d40f-4633-af3c-23e32de66f34", "embedding": null, "doc_hash": "85794deac14125a1c3708d69cb0ddcf5f2e78c61eb25d1cb0ef01b010c4886a3", "extra_info": {"page_label": "408"}, "node_info": {"start": 0, "end": 2157}, "relationships": {"1": "a4628ac8-2033-4dd1-9085-1b5c927896c1"}}, "__type__": "1"}, "77386cfd-d52e-4340-96e4-ee73f8a478b5": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator384# To set a default target, run:\n# systemctl set-default TARGET.target\n \nThe /etc/inittab  explains that if you want something similar to a classic 3 or 5 runlevel \nas your default runlevel, you need run systemctl default.target  to set the runlevel \ntarget to the one you want. To check what default.target  is currently symbolically \nlinked to (or in legacy terms, to check the default runlevel), use the command shown here. \nYou can see that on this Linux server, the default is to start up at legacy runlevel 3.\n# ls -l /etc/systemd/system/default.target\nlrwxrwxrwx. 1 root root 36 Mar 13 17:27\n /etc/systemd/system/default.target ->\n   /lib/systemd/system/runlevel3.target\nThe capability to switch runlevels using the init  or telinit  command is still available. \nWhen issued, either of the commands is translated into a systemd  target unit activation \nrequest. Therefore, typing init 3  at the command line really issues the command  \nsystemctl isolate multi-user.target . Also, you can still use the runlevel  \ncommand to determine the current legacy runlevel, but it is strongly discouraged.\nThe classic SysVinit /etc/inittab  handled spawning the getty  or mingetty  processes. \nThe systemd  init handles this via the getty.target  unit. The getty.target  is \nactivated by the multi-user.target  unit. You can see how these two target units are \nlinked by the following command:\n# systemctl show --property \"WantedBy\" getty.target\nWantedBy=multi-user.target\nNow that you have a basic understanding of classic and modern init  daemons, it\u2019s time to \ndo some practical server administrator actions that involve the initialization daemon.\nChecking the Status of Services\nAs a Linux administrator, you need to check the status of the services being offered \non your server. For security reasons, you should disable and remove any unused system \nservices discovered through the process. Most important for troubleshooting purposes, \nyou need to be able to know quickly what should and should not be running on your \nLinux server.\nOf course, knowing which initialization service is being used by your Linux server is the \nfirst piece of information to obtain. How to determine this was covered in the section \n\u201cUnderstanding the Initialization Daemon\u201d earlier in this chapter. The following sections \nare organized into subsections on the various initialization daemons.", "doc_id": "77386cfd-d52e-4340-96e4-ee73f8a478b5", "embedding": null, "doc_hash": "af911d112787e9bc65c9300b1ab8dc6a19467deced530605999cfadfd64dd0d5", "extra_info": {"page_label": "409"}, "node_info": {"start": 0, "end": 2423}, "relationships": {"1": "d1100a26-771a-414a-b9f6-d2c49fca3e42"}}, "__type__": "1"}, "0911a4be-7086-4ee3-8572-8ba976afb873": {"__data__": {"text": "Chapter 15: Starting and Stopping Services\n385\n15Checking services for SysVinit systems\nTo see all of the services that are being offered by a Linux server using the classic SysVinit \ndaemon, use the chkconfig  command. The example that follows shows the services avail -\nable on a classic SysVinit Linux server. Note that each runlevel (0\u20136) is shown for each ser -\nvice with a status of on or off. The status denotes whether a particular service is started \n(on) or not (off) for that runlevel.\n# chkconfig --list\nConsoleKit      0:off  1:off  2:off  3:on   4:on   5:on   6:off\nNetworkManager  0:off  1:off  2:off  3:off  4:off  5:off  6:off\n...\ncrond           0:off  1:off  2:on   3:on   4:on   5:on   6:off\ncups            0:off  1:off  2:on   3:on   4:on   5:on   6:off\n...\nsshd            0:off  1:off  2:on   3:on   4:on   5:on   6:off\nsyslog          0:off  1:off  2:on   3:on   4:on   5:on   6:off\ntux             0:off  1:off  2:off  3:off  4:off  5:off  6:off\nudev-post       0:off  1:off  2:off  3:on   4:on   5:on   6:off\nvncserver       0:off  1:off  2:off  3:off  4:off  5:off  6:off\nwinbind         0:off  1:off  2:off  3:off  4:off  5:off  6:off\nwpa_supplicant  0:off  1:off  2:off  3:off  4:off  5:off  6:off\nxfs             0:off  1:off  2:on   3:on   4:on   5:on   6:off\nypbind          0:off  1:off  2:off  3:off  4:off  5:off  6:off\nyum-updatesd    0:off  1:off  2:off  3:on   4:on   5:on   6:off\nSome services in the example are never started, such as vncserver . Other services, such \nas the cups  daemon, are started on runlevels 2 through 5.\nUsing the chkconfig  command, you cannot tell if a service is currently running. To do \nthat, you need to use the service  command. To help isolate only those services that are \ncurrently running, the service  command is piped into the grep  command and then \nsorted, as follows:\n# service --status-all | grep running... | sort\nanacron (pid 2162) is running...\natd (pid 2172) is running...\nauditd (pid 1653) is running...\nautomount (pid 1952) is running...\nconsole-kit-daemon (pid 2046) is running...\ncrond (pid 2118) is running...\ncupsd (pid 1988) is running...\n...\nsshd (pid 2002) is running...\nsyslogd (pid 1681) is running...\nxfs (pid 2151) is running...\nyum-updatesd (pid 2205) is running...", "doc_id": "0911a4be-7086-4ee3-8572-8ba976afb873", "embedding": null, "doc_hash": "d0cb7919c48ab97155ebceb6bab36aa23e99d00d45f7389967fef2a7872ceda8", "extra_info": {"page_label": "410"}, "node_info": {"start": 0, "end": 2265}, "relationships": {"1": "55e6e77b-61b0-4cdc-8151-2d72d2229418"}}, "__type__": "1"}, "3c9075f0-bf15-4c4b-ac6e-50a8f1981aac": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator386You can also use both the chkconfig  and the service  commands to view an individual \nservice\u2019s settings. Using both commands in the example that follows, you can view the \ncups  daemon\u2019s settings.\n# chkconfig --list cups\ncups            0:off   1:off   2:on    3:on    4:on    5:on    6:off\n#\n# service cups status\ncupsd (pid 1988) is running...\nYou can see that the cupsd  daemon is set to start on every runlevel but 0, 1, and 6, and \nfrom the service  command, you can see that it is currently running. Also, the process ID \n(PID) number is given for the daemon.\nTo see all of the services that are being offered by a Linux server using systemd , use the \nfollowing command:\n# systemctl list-unit-files --type=service | grep -v disabled\nUNIT FILE                                   STATE\nabrt-ccpp.service                           enabled\nabrt-oops.service                           enabled\nabrt-vmcore.service                         enabled\nabrtd.service                               enabled\nalsa-restore.service                        static\nalsa-store.service                          static\nanaconda-shell@.service                     static\narp-ethers.service                          enabled\natd.service                                 enabled\nauditd.service                              enabled\navahi-daemon.service                        enabled\nbluetooth.service                           enabled\nconsole-kit-log-system-restart.service      static\nconsole-kit-log-system-start.service        static\nconsole-kit-log-system-stop.service         static\ncrond.service                               enabled\ncups.service                                enabled\n...\nsshd-keygen.service                         enabled\nsshd.service                                enabled\nsystem-setup-keyboard.service               enabled\n...\n134 unit files listed.\nRemember that the three status possibilities for a systemd  service are enabled, disabled, \nor static. There\u2019s no need to include disabled to see which services are set to be active, \nwhich is effectively accomplished by using the -v  option on the grep  command, as \nshown in the preceding example. The state of static is essentially enabled and thus", "doc_id": "3c9075f0-bf15-4c4b-ac6e-50a8f1981aac", "embedding": null, "doc_hash": "c3ac55e9fea46988804a36b7cc9ac86a54594bc48197749b2d0067e5dfcfe51a", "extra_info": {"page_label": "411"}, "node_info": {"start": 0, "end": 2256}, "relationships": {"1": "747bf1c6-c3a2-4ac6-a486-e838151e32eb", "3": "c323df0f-6e74-4428-ac57-bea94f8b5fff"}}, "__type__": "1"}, "c323df0f-6e74-4428-ac57-bea94f8b5fff": {"__data__": {"text": "          enabled\n...\nsshd-keygen.service                         enabled\nsshd.service                                enabled\nsystem-setup-keyboard.service               enabled\n...\n134 unit files listed.\nRemember that the three status possibilities for a systemd  service are enabled, disabled, \nor static. There\u2019s no need to include disabled to see which services are set to be active, \nwhich is effectively accomplished by using the -v  option on the grep  command, as \nshown in the preceding example. The state of static is essentially enabled and thus should \nbe included.", "doc_id": "c323df0f-6e74-4428-ac57-bea94f8b5fff", "embedding": null, "doc_hash": "74f9605ba969bb3e1b4dc9875c58d457e3b6c49df3dabf635fb2eb2e1f1a392a", "extra_info": {"page_label": "411"}, "node_info": {"start": 1700, "end": 2277}, "relationships": {"1": "747bf1c6-c3a2-4ac6-a486-e838151e32eb", "2": "3c9075f0-bf15-4c4b-ac6e-50a8f1981aac"}}, "__type__": "1"}, "50791452-b4ec-486f-9cea-1fc4639111b8": {"__data__": {"text": "Chapter 15: Starting and Stopping Services\n387\n15To see if a particular service is running, use the following command:\n# systemctl status cups.service\ncups.service - CUPS Scheduler\n  Loaded: loaded (/lib/systemd/system/cups.service; enabled)\n  Active: active (running) since Wed 2019-09-18 17:32:27 EDT; 3 days ago\n     Docs: man:cupsd(8)\n Main PID: 874 (cupsd)\n   Status: \"Scheduler is running...\"\n    Tasks: 1 (limit: 12232)\n   Memory: 3.1M\n   CGroup: /system.slice/cups.service\n           \u2514\u2500874 /usr/sbin/cupsd -l\nThe systemctl  command can be used to show the status of one or more services. In the \npreceding example, the printing service was chosen. Notice that the name of the service is \ncups.service . A great deal of helpful information about the service is given here, such \nas the fact that it is enabled and active, its start time, and its process ID (PID) as well.\nNow that you can check the status of services and determine some information about them, \nyou need to know how to accomplish starting, stopping, and reloading the services on your \nLinux server.\nStopping and Starting Services\nThe tasks of starting, stopping, and restarting services typically refer to immediate \nneeds\u2014in other words, managing services without a server reboot. For example, if you \nwant to stop a service temporarily, then you are in the right place. However, if you want to \nstop a service and not allow it to be restarted at server reboot, then you actually need to \ndisable the service, which is covered in the section \u201cEnabling Persistent Services\u201d later in \nthis chapter.\nStopping and starting SysVinit services\nThe primary command for stopping and starting SysVinit services is the service  \ncommand. With the service  command, the name of the service that you want to control \ncomes second in the command line. The last option is what you want to do to the service: \nstop , start , restart , and so on. The following example shows how to stop the cups  \nservice. Notice that an OK  is given, which lets you know that cupsd  has been success -\nfully stopped:\n# service cups status\ncupsd (pid 5857) is running...\n# service cups stop\nStopping cups:        [  OK  ]\n# service cups status\ncupsd is stopped", "doc_id": "50791452-b4ec-486f-9cea-1fc4639111b8", "embedding": null, "doc_hash": "14b13803446a97bb28f41cfdc11a6bd630e41c381c3c4f4d800464bede781083", "extra_info": {"page_label": "412"}, "node_info": {"start": 0, "end": 2203}, "relationships": {"1": "b6c48281-99f0-410f-b7e2-b94cca3d6594"}}, "__type__": "1"}, "fd9724e3-16a4-4cbf-a8b3-616efb0d21df": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator388To start a service, you simply use a start  option instead of a stop  option on the end of \nthe service  command, as follows:\n# service cups start\nStarting cups:         [  OK  ]\n# service cups status\ncupsd (pid 6860) is running...\nTo restart a SysVinit service, the restart  option is used. This option stops the service and \nthen immediately starts it again:\n# service cups restart\nStopping cups:          [  OK  ]\nStarting cups:          [  OK  ]\n# service cups status\ncupsd (pid 7955) is running...\nWhen a service is already stopped, a restart  generates a FAILED status on the attempt to \nstop it. However, as shown in the example that follows, the service is successfully started \nwhen a restart is attempted:\n# service cups stop\nStopping cups:           [  OK  ]\n# service cups restart\nStopping cups:           [FAILED]\nStarting cups:           [  OK  ]\n# service cups status\ncupsd (pid 8236) is running...\nReloading a service is different from restarting a service. When you reload  a service, the \nservice itself is not stopped. Only the service\u2019s configuration files are loaded again. The fol -\nlowing example shows how to reload the cups  daemon:\n# service cups status\ncupsd (pid 8236) is running...\n# service cups reload\nReloading cups:            [  OK  ]\n# service cups status\ncupsd (pid 8236) is running...\nIf a SysVinit service is stopped when you attempt to reload it, you get a FAILED status. This \nis shown in the following example:\n# service cups status\ncupsd is stopped\n# service cups reload\nReloading cups: [FAILED]\nStopping and starting systemd services\nFor the systemd  daemon, the systemctl  command works for stopping, starting, reload -\ning, and restarting services. The options to the systemctl  command should look familiar.", "doc_id": "fd9724e3-16a4-4cbf-a8b3-616efb0d21df", "embedding": null, "doc_hash": "04840037a0907ba7cf4c09ac36a77e291ebc73ba843045bfb5f1feecdfd6b348", "extra_info": {"page_label": "413"}, "node_info": {"start": 0, "end": 1802}, "relationships": {"1": "57099382-0e90-41dc-8091-1826d4c87a99"}}, "__type__": "1"}, "f92e5a04-cf62-42c0-ad84-fb32ffc32b43": {"__data__": {"text": "Chapter 15: Starting and Stopping Services\n389\n15Stopping a service with systemd\nIn the example that follows, the status of the cups  daemon is checked and then stopped \nusing the systemctl stop cups.service  command:\n# systemctl status cups.service\ncups.service - CUPS Printing Service\n    Loaded: loaded (/lib/systemd/system/cups.service; enabled)\n    Active: active (running) since Mon, 20 Apr 2020 12:36:3...\n  Main PID: 1315 (cupsd)\n    CGroup: name=systemd:/system/cups.service\n            1315 /usr/sbin/cupsd -f\n# systemctl stop cups.service\n# systemctl status cups.service\ncups.service - CUPS Printing Service\n    Loaded: loaded (/lib/systemd/system/cups.service; enabled)\n    Active: inactive (dead) since Tue, 21 Apr 2020 04:43:4...\n    Process: 1315 ExecStart=/usr/sbin/cupsd -f\n (code=exited, status=0/SUCCESS)\n    CGroup: name=systemd:/system/cups.service\nNotice that when the status is taken, after stopping the cups  daemon, the service is inac -\ntive (dead) but still considered enabled. This means that the cups  daemon is still started \nupon server boot.\nStarting a service with systemd\nStarting the cups  daemon is just as easy as stopping it. The example that follows demon -\nstrates this ease:\n# systemctl start cups.service\n# systemctl status cups.service\ncups.service - CUPS Printing Service\n    Loaded: loaded (/lib/systemd/system/cups.service; enabled)\n    Active: active (running) since Tue, 21 Apr 2020 04:43:5...\n  Main PID: 17003 (cupsd)\n    CGroup: name=systemd:/system/cups.service\n           \u2514  17003 /usr/sbin/cupsd -f\nAfter the cups  daemon is started, using systemctl  with the status option shows the ser -\nvice is active (running). Also, its process ID (PID) number, 17003, is shown.\nRestarting a service with systemd\nRestarting a service means that a service is stopped and then started again. If the service \nwas not currently running, restarting it simply starts the service.\n# systemctl restart cups.service\n# systemctl status cups.service\ncups.service - CUPS Printing Service\n   Loaded: loaded (/lib/systemd/system/cups.service; enabled)\n   Active: active (running) since Tue, 21 Apr 2020 04:45:2...", "doc_id": "f92e5a04-cf62-42c0-ad84-fb32ffc32b43", "embedding": null, "doc_hash": "20b5a69fab2c5971e3e0ae6e207a31f8db09459cfd8d740e02513395f558164c", "extra_info": {"page_label": "414"}, "node_info": {"start": 0, "end": 2142}, "relationships": {"1": "3102d551-2716-4785-84af-4988f93b834a"}}, "__type__": "1"}, "0de00b3e-d14f-458f-b754-487c205aeda2": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator390  Main PID: 17015 (cupsd)\n   CGroup: name=systemd:/system/cups.service\n          \u2514  17015 /usr/sbin/cupsd -f\nYou can also perform a conditional restart of a service using systemctl . A conditional \nrestart only restarts a service if it is currently running. Any service in an inactive state is \nnot started.\n# systemctl status cups.service\ncups.service - CUPS Printing Service\n  Loaded: loaded (/lib/systemd/system/cups.service; enabled)\n  Active: inactive (dead) since Tue, 21 Apr 2020 06:03:32...\n Process: 17108 ExecStart=/usr/sbin/cupsd -f\n (code=exited, status=0/SUCCESS)\n  CGroup: name=systemd:/system/cups.service\n# systemctl condrestart cups.service\n# systemctl status cups.service\ncups.service - CUPS Printing Service\n  Loaded: loaded (/lib/systemd/system/cups.service; enabled)\n  Active: inactive (dead) since Tue, 21 Apr 2020 06:03:32...\n Process: 17108 ExecStart=/usr/sbin/cupsd -f\n (code=exited, status=0/SUCCESS)\n  CGroup: name=systemd:/system/cups.service\nNotice in the example that the cups  daemon was in an inactive state. When the condi-\ntional restart was issued, no error messages were generated! The cups  daemon was not \nstarted because conditional restarts affect active services. Thus, it is always a good prac -\ntice to check the status of a service after stopping, starting, conditionally restarting, \nand so on.\nReloading a service with systemd\nReloading a service is different from restarting a service. When you reload  a service, the \nservice itself is not stopped. Only the service\u2019s configuration files are loaded again. Note \nthat not all services are implemented to use the reload feature.\n# systemctl status sshd.service\nsshd.service - OpenSSH server daemon\n   Loaded: loaded (/usr/lib/systemd/system/sshd.service; enabled)\n   Active: active (running) since Wed 2019-09-18 17:32:27 EDT; 3 days ago\n Main PID: 1675 (sshd)\n   CGroup: /system.slice/sshd.service\n           \u2514\u25001675 /usr/sbin/sshd -D\n# systemctl reload sshd.service\n# systemctl status sshd.service\nsshd.service - OpenSSH server daemon\n   Loaded: loaded (/lib/systemd/system/sshd.service; enabled)\n   Active: active (running) since Wed 2019-09-18 17:32:27 EDT; 3 days ago\n  Process: 21770 ExecReload=/bin/kill -HUP $MAINPID (code=exited, status=0/SUCCESS)\n      (code=exited, status=0/SUCCESSd)", "doc_id": "0de00b3e-d14f-458f-b754-487c205aeda2", "embedding": null, "doc_hash": "b3d6f0877b37986dae2499f7439d10003c26feed9906f89f88dd1af8fff9e3b4", "extra_info": {"page_label": "415"}, "node_info": {"start": 0, "end": 2339}, "relationships": {"1": "61d9bf6b-0c7c-4d95-b245-a1b2122d03c0"}}, "__type__": "1"}, "28031fae-3eb5-4247-8da3-6c9d6638db02": {"__data__": {"text": "Chapter 15: Starting and Stopping Services\n391\n15 Main PID: 1675 (sshd)\n   CGroup: /system.slice/sshd.service\n           \u2514\u25001675 /usr/sbin/sshd -D ...\nDoing a reload  of a service, instead of a restart  prevents any pending service opera -\ntions from being aborted. A reload  is a better method for a busy Linux server.\nNow that you know how to stop and start services for troubleshooting and emergency pur -\nposes, you can learn how to enable and disable services.\nEnabling Persistent Services\nYou use stop  and start  for immediate needs, not for services that need to be persistent. \nA persistent service  is one that is started at server boot time or at a particular runlevel. \nServices that need to be set as persistent are typically new services that the Linux server \nis offering.\nConfiguring persistent services for SysVinit\nOne of the nice features of the classic SysVinit daemon is that making a particular service \npersistent or removing its persistence is very easy to do. Consider the following example:\n# chkconfig --list cups\ncups            0:off  1:off  2:off  3:off  4:off  5:off  6:off\nOn this Linux server, the cups  service is not started at any runlevel, as shown with the \nchkconfig  command. You can also check and see if any start (S) symbol links are set up \nin each of the seven runlevel directories, /etc/rc.d/rc ?.d. Remember that SysVinit keeps \nsymbolic links here for starting and stopping various services at certain runlevels. Each \ndirectory represents a particular runlevel; for example, rc5.d  is for runlevel 5. Notice that \nonly files starting with a K are listed, so there are links for killing off the cups  daemon. \nNone are listed with S , which is consistent with chkconfig  because the cups  daemon \ndoes not start at any runlevel on this server.\n# ls /etc/rc.d/rc?.d/*cups\n/etc/rc.d/rc0.d/K10cups  /etc/rc.d/rc3.d/K10cups\n/etc/rc.d/rc1.d/K10cups  /etc/rc.d/rc4.d/K10cups\n/etc/rc.d/rc2.d/K10cups  /etc/rc.d/rc5.d/K10cups\n/etc/rc.d/rc6.d/K10cups\nTo make a service persistent at a particular runlevel, the chkconfig  command is used \nagain. Instead of the --list  option, the --level  option is used, as shown in the fol -\nlowing code:\n# chkconfig --level 3 cups on\n# chkconfig --list cups\ncups            0:off  1:off  2:off  3:on   4:off  5:off  6:off\n# ls /etc/rc.d/rc3.d/S*cups\n/etc/rc.d/rc3.d/S56cups", "doc_id": "28031fae-3eb5-4247-8da3-6c9d6638db02", "embedding": null, "doc_hash": "f257b6060522eaacf9b0278260e87ef4b93e473fa3cc19902046c90ca0406050", "extra_info": {"page_label": "416"}, "node_info": {"start": 0, "end": 2347}, "relationships": {"1": "41524748-e290-4087-9098-c8d5b51f8e86"}}, "__type__": "1"}, "bb0aeb52-a3ba-4c5d-84f1-8a2a0a6b2b85": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator392The service\u2019s persistence at runlevel 3 is verified by using both the chkconfig --list  \ncommand and looking at the rc3.d  directory for any files starting with the letter S .\nTo make a service persistent on more than one runlevel, you can do the following:\n# chkconfig --level 2345 cups on\n# chkconfig --list cups\ncups            0:off  1:off  2:on   3:on   4:on   5:on   6:off\n# ls /etc/rc.d/rc?.d/S*cups\n/etc/rc.d/rc2.d/S56cups  /etc/rc.d/rc4.d/S56cups\n/etc/rc.d/rc3.d/S56cups  /etc/rc.d/rc5.d/S56cups\nDisabling a service is just as easy as enabling one with SysVinit. You just need to change \nthe on  in the chkconfig  command to off . The following example demonstrates using the \nchkconfig  command to disable the cups  service at runlevel 5:\n# chkconfig --level 5 cups off\n# chkconfig --list cups\ncups            0:off  1:off  2:on   3:on   4:on   5:off   6:off\n# ls /etc/rc.d/rc5.d/S*cups\nls: cannot access /etc/rc.d/rc5.d/S*cups: No such file or directory\nAs expected, there is now no symbolic link, starting with the letter S , for the cups  service \nin the /etc/rc.d/rc5.d  directory.\nFor the systemd  daemon, again the systemctl  command is used. With it, you can dis -\nable and enable services on the Linux server.\nEnabling a service with systemd\nUsing the enable  option on the systemctl  command sets a service to always start at \nboot (be persistent). The following shows exactly how to accomplish this:\n# systemctl status cups.service\ncups.service - CUPS Printing Service\n   Loaded: loaded (/lib/systemd/system/cups.service; disabled)\n   Active: inactive (dead) since Tue, 21 Apr 2020 06:42:38 ...\n Main PID: 17172 (code=exited, status=0/SUCCESS)\n   CGroup: name=systemd:/system/cups.service\n# systemctl enable cups.service\nCreated symlink /etc/systemd/system/printer.target.wants/cups.service\n    \u2192 /usr/lib/systemd/system/cups.service.\nCreated symlink /etc/systemd/system/sockets.target.wants/cups.socket\n    \u2192 /usr/lib/systemd/system/cups.socket.\nCreated symlink /etc/systemd/system/multi-user.target.wants/cups.path\n    \u2192 /usr/lib/systemd/system/cups.path.\n# systemctl status cups.service\ncups.service - CUPS Printing Service\n   Loaded: loaded (/lib/systemd/system/cups.service; enabled)\n   Active: inactive (dead) since Tue, 21 Apr 2020 06:42:38...\n Main PID: 17172 (code=exited, status=0/SUCCESS)\n   CGroup: name=systemd:/system/cups.service", "doc_id": "bb0aeb52-a3ba-4c5d-84f1-8a2a0a6b2b85", "embedding": null, "doc_hash": "72e067c143ce13d17be1794fcb2d22dd6da7c0bdeaf2c22da24641d2cd437572", "extra_info": {"page_label": "417"}, "node_info": {"start": 0, "end": 2413}, "relationships": {"1": "019f8739-0a8b-4024-bdcc-9c5459be863b"}}, "__type__": "1"}, "795816c6-66f9-46a4-a29f-19aff2eaff92": {"__data__": {"text": "Chapter 15: Starting and Stopping Services\n393\n15Notice that the status of cups.service  changes from disabled to enabled after using the \nenable  option on systemctl . Also, notice that the enable  option simply creates a few \nsymbolic links. You may be tempted to create these links yourself. However, the preferred \nmethod is to use the systemctl  command to accomplish this.\nDisabling a service with systemd\nYou can use the disable  option on the systemctl  command to keep a service from \nstarting at boot. However, it does not immediately stop the service. You need to use the \nstop  option discussed in the section \u201cStopping a service with systemd .\u201d The following \nexample shows how to disable  a currently enabled  service:\n# systemctl disable cups.service\nrm '/etc/systemd/system/printer.target.wants/cups.service'\nrm '/etc/systemd/system/sockets.target.wants/cups.socket'\nrm '/etc/systemd/system/multi-user.target.wants/cups.path'\n# systemctl status cups.service\ncups.service - CUPS Printing Service\n   Loaded: loaded (/lib/systemd/system/cups.service; disabled)\n   Active: active (running) since Tue, 21 Apr 2020 06:06:41...\n Main PID: 17172 (cupsd)\n   CGroup: name=systemd:/system/cups.service\n            17172 /usr/sbin/cupsd -f\nThe disable  option simply removes a few files via the preferred method of the system -\nctl command. Notice also in the preceding example that although the cups  service is now \ndisabled, the cups  daemon is still active (running) and needs to be stopped manually. With \nsystemd , some services cannot be disabled. These services are static services. Consider the \nfollowing service, dbus.service :\n# systemctl status dbus.service\ndbus.service - D-Bus System Message Bus\n  Loaded: loaded (/lib/systemd/system/dbus.service; static)\n  Active: active (running) since Mon, 20 Apr 2020 12:35:...\n Main PID: 707 (dbus-daemon)\n...\n# systemctl disable dbus.service\n# systemctl status dbus.service\ndbus.service - D-Bus System Message Bus\n  Loaded: loaded (/lib/systemd/system/dbus.service; static)\n  Active: active (running) since Mon, 20 Apr 2020 12:35:...\n Main PID: 707 (dbus-daemon)\n...\nWhen the systemctl disable command is issued on dbus.service , it is simply \nignored. Remember that static means that the service is enabled by default and cannot be \ndisabled, even by root. Sometimes, disabling a service is not enough to make sure that it \ndoes not run. For example, you might want network.service  to replace NetworkMan -\nager.service  for starting network interfaces on your system. Disabling NetworkManager ", "doc_id": "795816c6-66f9-46a4-a29f-19aff2eaff92", "embedding": null, "doc_hash": "c885a43902137efb74553b2e3050531ba31f61e2475b112c8dd8955258e89d06", "extra_info": {"page_label": "418"}, "node_info": {"start": 0, "end": 2554}, "relationships": {"1": "0b917cc6-6e32-4b6c-a304-8f95b98cacdc"}}, "__type__": "1"}, "df6da787-8c73-474c-885e-5624268d9b88": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator394would keep the service from starting on its own. However, if some other service listed \nNetworkManager as a dependency, that service would try to start NetworkManager when \nit started.\nTo disable a service in a way that prevents it from ever running on your system, you can \nuse the mask  option. For example, to set the NetworkManager service so that it never runs, \ntype the following:\n# systemctl mask NetworkManager.service\nln -s '/dev/null' '/etc/systemd/system/NetworkManager.service'\n \nAs the output shows, the NetworkManager.service  file in /etc  is linked to  \n/dev/null . So even if someone tried to run that service, nothing would happen.  \nTo be able to use the service again, you could type systemctl unmask \n Network Manager.service .\nNow that you understand how to enable individual services to be persistent (and how to \ndisable or mask individual services), you need to look at service groups as a whole. Next,  \nI cover how to start groups of services at boot time.\nConfiguring a Default Runlevel or Target Unit\nWhereas a persistent service is one that is started at server boot time, a persistent (default) \nrunlevel or target unit is a group of services that are started at boot time. Both classic Sys -\nVinit and Upstart define these groups of services as runlevels, while systemd  calls them \ntarget units.\nConfiguring the SysVinit default runlevel\nYou set the persistent runlevel for a Linux server using SysVinit in the /etc/inittab  file. \nA portion of this file is shown here:\n# cat /etc/inittab\n#\n# inittab       This file describes how the INIT process should\n#               set up the system in a certain run-level.\n...\nid:5:initdefault:\n...\nThe initdefault  line in the example shows that the current default runlevel is runlevel \n5. To change this, simply edit the /etc/inittab  file using your favorite editor and change \nthe 5 to one of the following runlevels: 2, 3, or 4. Do not use the runlevels 0 or 6 in this \nfile! This would cause your server either to halt or reboot when it is started up.", "doc_id": "df6da787-8c73-474c-885e-5624268d9b88", "embedding": null, "doc_hash": "9959062c44a2caaa7d227db3154f72cf374a473a274db04a4eb9cdaa219e1947", "extra_info": {"page_label": "419"}, "node_info": {"start": 0, "end": 2081}, "relationships": {"1": "7b8e263e-7f9f-4005-aced-fe66d49a8ed7"}}, "__type__": "1"}, "718d9f37-ef65-4900-bc0d-1ce3a2507751": {"__data__": {"text": "Chapter 15: Starting and Stopping Services\n395\n15For systemd , the term target units  refers to groups of services to be started. The following \nshows the various target units that you can configure to be persistent and their equivalent \nbackward-compatible, runlevel-specific target units:.\n\u25a0\u25a0multi-user.target  =\n\u25a0\u25a0runlevel2.target\n\u25a0\u25a0runlevel3.target\n\u25a0\u25a0runlevel4.target\n\u25a0\u25a0graphical.target  = runlevel5.target\nThe persistent target unit is set via a symbolic link to the default.target  unit file. Con -\nsider the following:\n# ls -l /etc/systemd/system/default.target\nlrwxrwxrwx. 1 root root 36 Mar 13 17:27\n /etc/systemd/system/default.target ->\n /lib/systemd/system/runlevel5.target\n# ls -l /lib/systemd/system/runlevel5.target\nlrwxrwxrwx. 1 root root 16 Mar 27 15:39\n /lib/systemd/system/runlevel5.target ->\n graphical.target\nThe example shows that the current persistent target unit on this server is  \nrunlevel5.target  because default.target  is a symbolic link to the runlevel5.target   \nunit file. However, notice that runlevel5.target  is also a symbolic link and it points to \ngraphical.target . Thus, this server\u2019s current persistent target unit is graphical.target .\nTo set a different target unit to be persistent, you simply need to change the symbolic link \nfor default.target . To be consistent, stick with the runlevel target units if they are \nused on your server.\nThe following systemctl  example changes the server\u2019s persistent target unit from \ngraphical.target  to multi-user.target :\n# systemctl get-default\ngraphical.target\n#\n systemctl set-default runlevel3.target\n Removed /etc/systemd/system/default.target.\n Created symlink /etc/systemd/system/default.target \u2192  \n/usr/lib/systemd/system/multi-user.target.\n# systemctl get-default\n multi-user.target\nWhen the server is rebooted, the multi-user.target  is the persistent target unit. Any \nservices in the multi-user.target  unit are started (activated) at that time.", "doc_id": "718d9f37-ef65-4900-bc0d-1ce3a2507751", "embedding": null, "doc_hash": "90999a94658cbe42461ea8fb84c0e08dd50b682bce9ea12ad57c01208af68dbd", "extra_info": {"page_label": "420"}, "node_info": {"start": 0, "end": 1943}, "relationships": {"1": "09ae08a6-fb82-4723-8d92-82ee38374081"}}, "__type__": "1"}, "7384abe3-ee42-4537-b1dd-d06db1cce554": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator396Adding New or Customized Services\nOccasionally, you need to add a new service to your Linux server. Also, you may have to \ncustomize a particular service. When these needs arise, you must follow specific steps for \nyour Linux server\u2019s initialization daemon to either take over the management of the ser -\nvice or recognize the customization of it.\nAdding new services to SysVinit\nWhen adding a new or customized service to a Linux SysVinit server, you must complete \nthree steps in order to have the service managed by SysVinit:.\n1. Create a new or customized service script file.\n2. Move the new or customized service script to the proper location for SysVinit \nmanagement.\n3. Set appropriate permission on the script.\n4. Add the service to a specific runlevel.\nStep 1: Create a new or customized service script file\nIf you are customizing a service script, simply make a copy of the original unit file from  \n/etc/rc.d/init.d  and add any desired customizations.\nIf you are creating a new script, you need to make sure you handle all of the various \noptions that you want the service  command to accept for your service, such as start , \nstop , restart , and so on.\nFor a new script, especially if you have never created a service script before, it would be \nwise to make a copy of a current service script from /etc/rc.d/init.d  and modify it to \nmeet your new service\u2019s needs. Consider the following partial example of the cupsd  ser-\nvice\u2019s script:\n# cat /etc/rc.d/init.d/cups\n#!/bin/sh\n#\n...\n#   chkconfig: 2345 25 10\n \n...\nstart () {\n        echo -n $\"Starting $prog: \"\n        # start daemon\n        daemon $DAEMON\n        RETVAL=$?\n        echo\n        [ $RETVAL = 0 ] && touch /var/lock/subsys/cups\n        return $RETVAL\n}\n ", "doc_id": "7384abe3-ee42-4537-b1dd-d06db1cce554", "embedding": null, "doc_hash": "51b8b393a2e7da5d183d6fc905c29a52df4c00bbc5500eca59db8947b10f762a", "extra_info": {"page_label": "421"}, "node_info": {"start": 0, "end": 1784}, "relationships": {"1": "65d0afab-5167-4ef0-8a9d-f8d8970a97ea"}}, "__type__": "1"}, "ea572e80-afeb-4076-9a1f-e434151edd2b": {"__data__": {"text": "Chapter 15: Starting and Stopping Services\n397\n15stop () {\n        # stop daemon\n        echo -n $\"Stopping $prog: \"\n        killproc $DAEMON\n        RETVAL=$?\n        echo        [ $RETVAL = 0 ] && rm -f /var/lock/subsys/cups\n}\n \nrestart() {\n        stop\n        start\n}\n \ncase $1 in\n...\nThe cups  service script starts out by creating functions for each of the start , stop , and \nrestart  options. If you feel uncomfortable with shell script writing, review Chapter\u00a07, \n\u201cWriting Simple Shell Scripts,\u201d to improve your skills.\nOne line you should be sure to check and possibly modify in your new script is the  \nchkconfig  line that is commented out; for example:\n#   chkconfig: 2345 25 10\nWhen you add the service script in a later step, the chkconfig  command reads that line \nto set runlevels at which the service starts (2, 3, 4, and 5), its run order when the script is \nset to start (25), and its kill order when it is set to stop (10).\nCheck the boot order in the default runlevel before adding your own script, as shown in \nthis example:\n# ls /etc/rc5.d\n...\n/etc/rc5.d/S22messagebus\n/etc/rc5.d/S23NetworkManager\n/etc/rc5.d/S24nfslock\n/etc/rc5.d/S24openct\n/etc/rc5.d/S24rpcgssd\n/etc/rc5.d/S25blk-availability\n/etc/rc5.d/S25cups\n/etc/rc5.d/S25netfs\n/etc/rc5.d/S26acpid\n/etc/rc5.d/S26haldaemon\n/etc/rc5.d/S26hypervkvpd\n/etc/rc5.d/S26udev-post\n \n...", "doc_id": "ea572e80-afeb-4076-9a1f-e434151edd2b", "embedding": null, "doc_hash": "fd47b37c0f22d6b910ed982289ab18ba83bad9feea154f4bbc95c1bf2178a637", "extra_info": {"page_label": "422"}, "node_info": {"start": 0, "end": 1355}, "relationships": {"1": "aa686e92-a2e5-4dea-9447-49e5a3f6f1f3"}}, "__type__": "1"}, "e4aa2d95-894b-4ee8-8147-e8f29a8fb1b4": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator398In this case, the chkconfig  line in the S25My_New_Service  script will cause the script \nto be added after S25cups  and before S25netfs  in the boot order. You can change the \nchkconfig  line in the service script if you want the service to start earlier (use a smaller \nnumber) or later (use a larger number) in the list of service scripts.\nStep 2: Add the service script to /etc/rc.d/init.d\nAfter you have modified or created and tested your service\u2019s script file, you can move it to \nthe proper location, /etc/rc.d/init.d :\n# cp My_New_Service /etc/rc.d/init.d\n# ls /etc/rc.d/init.d/My_New_Service\n/etc/rc.d/init.d/My_New_Service\nStep 3: Set appropriate permission on the script\nThe script should be executable:\n# chmod 755 /etc/rc.d/init.d/My_New_Service\nStep 4: Add the service to runlevel directories\nThis final step sets up the service script to start and stop at different runlevels and checks \nthat the service script works.\n1. To add the script based on the chkconfig  line in the service script, type the \nfollowing:\n    # chkconfig --add My_New_Service\n    # ls /etc/rc?.d/*My_New_Service\n    /etc/rc0.d/K10My_New_Service  /etc/rc4.d/S25My_New_Service\n    /etc/rc1.d/K10My_New_Service  /etc/rc5.d/S25My_New_Service\n    /etc/rc2.d/S25My_New_Service  /etc/rc6.d/K10My_New_Service\n    /etc/rc3.d/S25My_New_Service\nBased on the previous example ( chkconfig: 2345 25 10 ), symbolic links to the \nscript set the service to start in the position 25 ( S25) for runlevels 2, 3, 4, and 5. \nAlso, links are set to stop (or not start) at runlevels 0, 1, and 6.\n2. After you have made the symbolic link(s), test that your new or modified service \nworks as expected before performing a server reboot.\n    # service My_New_Service start\n    Starting My_New_Service:       [  OK  ]\n    # service My_New_Service stop\nAfter everything is in place, your new or modified service starts at every runlevel that \nyou have selected on your system. Also, you can start or stop it manually using the ser -\nvice  command.", "doc_id": "e4aa2d95-894b-4ee8-8147-e8f29a8fb1b4", "embedding": null, "doc_hash": "f0b2b1b115146bfa40ebef5c70555ff7214c0fb634a0043e6d639c32fd513555", "extra_info": {"page_label": "423"}, "node_info": {"start": 0, "end": 2056}, "relationships": {"1": "d1fbd355-b68a-4644-aacf-c912bfb58210"}}, "__type__": "1"}, "ffb8821c-361b-4e5d-b592-6c4d183b9d1b": {"__data__": {"text": "Chapter 15: Starting and Stopping Services\n399\n15Adding new services to systemd\nWhen adding a new or customized service to a Linux systemd  server, you have to com-\nplete three steps in order to have the service managed by systemd :\n1. Create a new or customized service configuration unit file for the new or custom-\nized service.\n2. Move the new or customized service configuration unit file to the proper location \nfor systemd  management.\n3. Add the service to a specific target unit\u2019s Wants to have the new or customized ser -\nvice start automatically with other services.\nStep 1: Create a new or customized service configuration unit file\nIf you are customizing a service configuration unit file, simply make a copy of the original \nunit file from /lib/systemd/system  and add any desired customizations.\nFor new files, obviously, you are creating a service unit configuration file from scratch. Con -\nsider the following basic service unit file template. At bare minimum, you need Descrip -\ntion  and ExecStart  options for a service unit configuration file:\n# cat My_New_Service.service\n[Unit]\nDescription=My New Service\n[Service]\nExecStart=/usr/bin/My_New_Service\nFor additional help on customizing or creating a new configuration unit file and the various \nneeded options, you can use the man pages. At the command line, type man systemd  \n.service  to find out more about the various service unit file options.\nStep 2: Move the service configuration unit file\nBefore you move the new or customized service configuration unit file, you need to be \naware that there are two potential locations to store service configuration unit files. The \none you choose determines whether the customizations take effect and if they remain per -\nsistent through software upgrades.\nYou can place your system service configuration unit file in one of the following two locations:\n\u25a0\u25a0/etc/systemd/system\n\u25a0\u25a0This location is used to store customized local service configuration unit files.\n\u25a0\u25a0Files in this location are not overwritten by software installations or upgrades.\nFiles here are used by the system even  if there is a file of the same name in the \n/lib/systemd/system  directory.\n\u25a0\u25a0/lib/systemd/system\n\u25a0\u25a0This location is used to store system service configuration unit files.\n\u25a0\u25a0Files in this location are overwritten by software installations and upgrades.", "doc_id": "ffb8821c-361b-4e5d-b592-6c4d183b9d1b", "embedding": null, "doc_hash": "228932dea1a15d07ff599ac1085c57f18b93269af8aefd2cb8c15b99b935cd68", "extra_info": {"page_label": "424"}, "node_info": {"start": 0, "end": 2355}, "relationships": {"1": "7102958b-9325-40c1-8f4b-7d35edaee533"}}, "__type__": "1"}, "da246d65-9a3e-4c2b-a4a5-88e1728a2217": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator400Files here are used by the system only if there is no file of the same name in the  \n/etc/systemd/system  directory.\nThus, the best place to store your new or customized service configuration unit file is in  \n/etc/systemd/system .\nStep 3: Add the service to the Wants directory\nThis final step is optional. It needs to be done only if you want your new service to start \nwith a particular systemd  target unit. For a service to be activated (started) by a particu -\nlar target unit, it must be in that target unit\u2019s Wants  directory.\nFirst, add the line WantedBy=desired.target  to the bottom of your service configura -\ntion unit file. The following example shows that the desired target unit for this new service \nis multi-user.target :\n# cat /etc/systemd/system/My_New_Service.service\n[Unit]\nDescription=My New Fake Service\n[Service]\nExecStart=/usr/bin/My_New_Service\n[Install]\nWantedBy=multi-user.target\nTo add a new service unit to a target unit, you need to create a symbolic link. The following \nexample shows the files located in the multi-user.target  unit\u2019s Wants  directory. Pre -\nviously, in the section \u201cUnderstanding systemd  initialization,\u201d the systemctl  command \nwas used to list Wants, and it is still the preferred method. Notice that in this directory, \nthe files are symbolic links pointing to service unit configuration files in the  \n/lib/systemd/system  directory.\n# ls /etc/systemd/system/multi-user.target.wants\nabrt-ccpp.service     cups.path           remote-fs.target\nabrtd.service         fcoe.service        rsyslog.service\nabrt-oops.service     irqbalance.service  sendmail.service\nabrt-vmcore.service   lldpad.service      sm-client.service\natd.service           mcelog.service      sshd-keygen.service\nauditd.service        mdmonitor.service   sshd.service\n...\n# ls -l /etc/systemd/system/multi-user.target.wants\ntotal 0\nlrwxrwxrwx. 1 root root 37 Nov  2 22:29 abrt-ccpp.service ->\n    /lib/systemd/system/abrt-ccpp.service\nlrwxrwxrwx. 1 root root 33 Nov  2 22:29 abrtd.service ->\n    /lib/systemd/system/abrtd.service\n...tip\nWhen you create a new or customized service, in order for the change to take effect without a server reboot, you need \nto issue a special command. At the command line, type systemctl daemon-reload .", "doc_id": "da246d65-9a3e-4c2b-a4a5-88e1728a2217", "embedding": null, "doc_hash": "2592ddd0d98816e3f9acc00cffbccd2b550e43ba20195152ba5e5d86cc96b5b3", "extra_info": {"page_label": "425"}, "node_info": {"start": 0, "end": 2309}, "relationships": {"1": "79187b5e-608c-4163-a542-2453672f13e7"}}, "__type__": "1"}, "896dc42a-5387-4e77-8e5d-b66c0ba82e4b": {"__data__": {"text": "Chapter 15: Starting and Stopping Services\n401\n15lrwxrwxrwx. 1 root root 32 Apr 26 20:05 sshd.service ->\n    /lib/systemd/system/sshd.service\nThe following illustrates the process of adding a symbolic link file for My_New_Service :\n# ln -s /etc/systemd/system/My_New_Service.service\n /etc/systemd/system/multi-user.target.wants/My_New_Service.service\nA symbolic link is created in the multi-user.target.wants  directory. Now the new \nservice, My_New_Service , is activated (started) when the multi-user.target  unit is \nactivated.\nTogether, the three steps get your new or customized service added to a Linux systemd  \nserver. Remember that at this point, a new service is not running until a server reboot. To \nstart the new service before a reboot, review the commands in the section \u201cStopping and \nStarting Services.\u201d\nSummary\nHow you start and stop services is dependent upon what initialization daemon is used by \nyour Linux server: SysVinit, Upstart, or Systemd. Before you do any service management, \nbe sure to use the examples in this chapter to help you determine your Linux server\u2019s ini-\ntialization daemon.\nThe concepts of starting and stopping services go along with other service management \nconcepts, such as making a service persistent, starting certain services at server boot time, \nreloading a service, and restarting a service. Understanding these concepts is very helpful \nas you learn about configuring and managing a Linux print server in the next chapter.\nExercises\nRefer to the material in this chapter to complete the tasks that follow. If you are stuck, \nsolutions to the tasks are shown in Appendix B (although in Linux, there are often multiple \nways to complete a task). Try each of the exercises before referring to the answers. These \ntasks assume that you are running a Fedora or Red Hat Enterprise Linux system (although \nsome tasks work on other Linux systems as well).\n1. Determine which initialization daemon your server is currently using.\n2. What command can you use to check the status of the sshd  daemon, depending on \nthe initialization daemon in use on your Linux server?tip\nIf you want to change the systemd  target unit for a service, you need to change the symbol link to point to a new \ntarget Wants  directory location. Use the ln -sf  command to force any current symbolic link to be broken and the \nnew designated symbolic link to be enforced.", "doc_id": "896dc42a-5387-4e77-8e5d-b66c0ba82e4b", "embedding": null, "doc_hash": "d8d87c1d6a6114f6e8b71ac24a3881cc7903cfd287b339db600de314b64bb6d0", "extra_info": {"page_label": "426"}, "node_info": {"start": 0, "end": 2393}, "relationships": {"1": "ff4e3f29-eaf3-4d29-a3bb-899d5f111fc3"}}, "__type__": "1"}, "b8b3705d-9b39-42cd-8ea3-834d366d83e4": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator4023. Determine your server\u2019s previous and current runlevel.\n4. How can you change the default runlevel or target unit on your Linux server?\n5. For each initialization daemon, what commands list services running (or active) on \nyour server?\n6. List the running (or active) services on your Linux server.\n7. For each initialization daemon, what commands show a particular service\u2019s \ncurrent status?\n8. Show the status of the cups  daemon on your Linux server.\n9. Attempt to restart the cups  daemon on your Linux server.\n10. Attempt to reload the cups  daemon on your Linux server.", "doc_id": "b8b3705d-9b39-42cd-8ea3-834d366d83e4", "embedding": null, "doc_hash": "e8d14d6fdbbaa61f350a6c16585b124214b2e3756526b7d5edfafb557e0bd9d4", "extra_info": {"page_label": "427"}, "node_info": {"start": 0, "end": 626}, "relationships": {"1": "4e750904-ad0f-4c78-b5ee-8394526be24f"}}, "__type__": "1"}, "f7bc1b83-a8c1-40e3-9f0b-b92b2b76b49d": {"__data__": {"text": "403\nCHAPTER16\nConfiguring a Print Server\nIN THIS CHAPTER\nUnderstanding printing in Linux\nSetting up printers\nUsing printing commands\nManaging document printing\nSharing printers\nYou can configure your Linux system to use printers that are connected directly to it (via a USB \nport) or that are available for printing over the network. Likewise, any printer that you con -\nfigure on your local system can be shared with users on other Linux, Windows, or Mac systems \nby opening up your printer as a print server.\nYou configure a printer as a native Linux printer in Fedora, RHEL, Ubuntu, and other Linux systems \nwith the Common UNIX Printing System (CUPS) . To configure a printer to work as a Microsoft Windows \nstyle of print server, you can use the Samba service in Linux.\nThis chapter focuses on CUPS. In particular, it shows you the graphical front end to CUPS, called \nthe Print Settings window , which comes with Fedora, Red Hat Enterprise Linux, and other Linux \ndistributions. Using Print Settings, you can also configure your printers as print servers so that peo -\nple can print to your printer from their own computers.\nIf you don\u2019t have a desktop, or you want to print from within a shell script, this chapter shows you \nhow to use printing commands. From the command line, print commands such as lp  are available \nfor carrying out printing. Commands also exist for querying print queues ( lpq), manipulating print \nqueues (cupsenable , cupsdisable , and cupsreject ), and removing print queues ( lprm ).\nCommon UNIX Printing System\nCUPS has become the standard for printing from Linux and other UNIX-like operating systems. It \nwas designed to meet today\u2019s needs for standardized printer definitions and sharing on Internet \nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "f7bc1b83-a8c1-40e3-9f0b-b92b2b76b49d", "embedding": null, "doc_hash": "18ebf0543d7ad656cdd17c66094ad01ca901881d0b18e0d34dfd0b38b7bc0da6", "extra_info": {"page_label": "428"}, "node_info": {"start": 0, "end": 1861}, "relationships": {"1": "e2460752-3287-4b9a-8f61-b64e9b92fd42"}}, "__type__": "1"}, "1e4907b4-eca0-48cb-b0d4-45a951e9225b": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator404Protocol\u2013based networks (as most computer networks are today). Nearly every Linux \ndistribution today comes with CUPS as its printing service. Here are some of the ser -\nvice\u2019s features:\nIPP CUPS is based on the Internet Printing Protocol ( http://www.pwg.org/ipp ), a \nstandard that was created to simplify how printers can be shared over IP networks. In \nthe IPP model, printer servers and clients who want to print can exchange informa -\ntion about the model and features of a printer using the HTTP (that is, web content) \nprotocol. A server can also broadcast the availability of a printer so that a printing \nclient can easily find a list of locally available printers without configuration.\nDrivers  CUPS also standardized how printer drivers are created. The idea was to have \na common format that could be used by printer manufacturers so that a driver could \nwork across all different types of UNIX systems. That way, a manufacturer had \nto create the driver only once to work for Linux, Mac OS X, and a variety of UNIX \nderivatives.\nPrinter classes  You can use printer classes to create multiple print server entries \nthat point to the same printer or one print server entry that points to multiple \nprinters. In the first case, multiple entries can each allow different options (such as \npointing to a particular paper tray or printing with certain character sizes or mar -\ngins). In the second case, you can have a pool of printers so that printing is distrib -\nuted. In this instance, a malfunctioning printer, or a printer that is dealing with \nvery large documents, won\u2019t bring all printing to a halt. CUPS also supports implicit \nclasses , which are print classes that form by merging identical network printers \nautomatically.\nPrinter browsing  With printer browsing, client computers can see any CUPS printers \non your local network with browsing enabled. As a result, clients can simply select \nthe printers that they want to use from the printer names broadcast on the net -\nwork, without needing to know in advance what the printers are named and where \nthey are connected. You can turn off the feature to prevent others on the local net -\nwork from seeing a printer.\nUNIX print commands To integrate into Linux and other UNIX environments, CUPS \noffers versions of standard commands for printing and managing printers that have \nbeen traditionally offered with UNIX systems.\nInstead of using the Print Settings window, you can configure CUPS printing in other \nways as well:\nConfiguring CUPS from a browser The CUPS project itself offers a web-based  \ninterface for adding and managing printers. With the cupsd  service running, type \nlocalhost:631  from a web browser on the computer running the CUPS service to \nmanage printing. (See the section \u201cUsing web-based CUPS administration\u201d later in \nthis chapter.)\nConfiguring CUPS manually You also can configure CUPS manually (that is, edit \nthe configuration files and start the cupsd  daemon from the command line). ", "doc_id": "1e4907b4-eca0-48cb-b0d4-45a951e9225b", "embedding": null, "doc_hash": "9b427b81a715e7ebe2f0ff51719792d83399376e963cef47068ab776a60343aa", "extra_info": {"page_label": "429"}, "node_info": {"start": 0, "end": 3039}, "relationships": {"1": "40a89f9b-a773-4015-8ad6-af2b18bbea1a"}}, "__type__": "1"}, "e534d45f-c7b8-420b-bc79-48073101a833": {"__data__": {"text": "Chapter 16: Configuring a Print Server\n405\n16Configuration files for CUPS are contained in the /etc/cups  directory. In particu -\nlar, you might be interested in the cupsd.conf  file, which identifies permissions, \nauthentication, and other information for the printer daemon, and printers.\nconf , which identifies addresses and options for configured printers. Use the \nclasses.conf  file to define local printer classes.\nTo use CUPS, you must have the cups  package installed in Fedora or RHEL. Most desktop \nLinux distributions include CUPS during the initial system install. If it is not installed in a \nFedora or RHEL install, install it by typing the following:\n# yum install cups cups-client\nSetting Up Printers\nAlthough using the printer administration tools specifically built for your distribution is \nusually best, many Linux systems simply rely on the tools that come with the CUPS soft -\nware package.\nThe following sections explore how to use CUPS web-based administration tools that come \nwith every Linux distribution. Then it examines the Print Settings tool system-config-\nprinter , which is available with Fedora systems to enable you to set up printers. In some \ncases, no configuration is necessary, because connected printers can be automatically \ndetected and configured. To install the Print Settings tool in Fedora, as root, enter the  \nfollowing dnf  (or yum ) command:\n# yum install system-config-printer\nAdding a printer automatically\nCUPS printers can be configured to broadcast their availability on the network automat -\nically so that a client system can detect and use them without configuration. Connect a \nUSB printer to your computer, and the printer can be automatically detected and made Printing Directly from Windows to CUPS\nYou can print to CUPS from non-UNIX systems as well. For example, you can use a PostScript printer driver \nto print directly from a Windows system to your CUPS server. You can use CUPS without modification by \nconfiguring the Windows computer with a PostScript driver that uses http://printservername:631/\nprinters/targetPrinter  as its printing port.\nYou may also be able to use the native Windows printer drivers for the printer instead of the PostScript \ndriver. If the native Windows driver does not work right out of the box on your CUPS print queue, you \ncan create a Raw Print Queue under CUPS and use that instead. The Raw Print Queue directly passes \nthrough the data from the Windows native print driver to the printer.", "doc_id": "e534d45f-c7b8-420b-bc79-48073101a833", "embedding": null, "doc_hash": "d323f3fc223bfd04f631c79812c7ca200279683a8ae48d74c0669369d711c3ae", "extra_info": {"page_label": "430"}, "node_info": {"start": 0, "end": 2494}, "relationships": {"1": "e67ddf3f-0f2a-4f22-92b4-6f721015835f"}}, "__type__": "1"}, "5d15c07f-13ed-47b6-86e7-b88054e3b197": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator406available. In fact, if you attach a local printer in Fedora and the print driver is not yet \ninstalled, you are prompted to install the software packages needed to use the printer.\nThe first time that you go to print a document or view your Print Settings tool, the printers \nare ready to use. Further configuration can be done using the web-based CUPS administra -\ntion tool or the Print Settings window.\nUsing web-based CUPS administration\nCUPS offers its own web-based administrative tool for adding, deleting, and modifying \nprinter configurations on your computer. The CUPS print service (using the cupsd  daemon) \nlistens on port 631 to provide access to the CUPS web-based administrative interface and \nshare printers.\nIf CUPS is already running on your computer, you can immediately use CUPS web-based \nadministration from your web browser. To see whether CUPS is running and to start setting \nup your printers, open a web browser on the local computer and type this into its location \nbox: http://localhost:631/ .\nA prompt for a valid login name and password may appear when you request functions \nthat require it. If so, type the root login name and the root user\u2019s password and click OK. A \nscreen similar to the one shown in Figure\u00a016.1 appears.\nAllow remote printing administration\nBy default, web-based CUPS administration is available only from the local host. To access \nweb-based CUPS administration from another computer, from the main CUPS page:\n1. Select the Administration tab.\nFIGURE 16.1\nCUPS provides a web-based administration tool.", "doc_id": "5d15c07f-13ed-47b6-86e7-b88054e3b197", "embedding": null, "doc_hash": "75b67bfe4d77446da921730542852aa60cadab506a5c5b07cc42bfbddbb5a5aa", "extra_info": {"page_label": "431"}, "node_info": {"start": 0, "end": 1606}, "relationships": {"1": "232fd370-97e9-4d09-aa4e-fe39d2d88d41"}}, "__type__": "1"}, "5e0e88c0-d99c-4644-b2a5-34d037b16c4b": {"__data__": {"text": "Chapter 16: Configuring a Print Server\n407\n162. Select the check box next to Allow remote administration.\n3. Select the Change Settings button.\nThen open your computer\u2019s firewall to allow connections to TCP port 631 to allow access to \nthe service. After that, from any browser that has access to your local network, you can \naccess the CUPS Administration page by going to port 631 on the CUPS server (for example, \nhttp://host.example.com:631 ).\nYou may need to restart CUPS for the change to take effect: systemctl restart cups.\nservice . If you are not already running the browser as the root user, you must also enter \nthe root username and password.\nAdd a printer not automatically detected\nTo configure a printer that is not automatically detected, you can add a printer from the \nAdministration screen. With the Administration screen displayed, you can add a printer \nas follows:\n1. Click the Add Printer button. The Add New Printer screen appears.\n2. Select the device to which the printer is connected. The printer can be connected \nlocally to a parallel, SCSI, serial, or USB port directly on the computer. Alterna -\ntively, you can select a network connection type for Apple printers (AppSocket or \nHP JetDirect), Internet Printing Protocol ( http , https , ipps , or ipp ), or a Win -\ndows printer (using Samba or SMB).\n3. If prompted for more information, you may need to describe the connection to the \nprinter further. For example, you might be asked for the network address for an IPP \nor Samba printer.\n4. Type a name, location, and description for the printer; select if you want to share \nthis printer and click Continue.\n5. Select the make of the print driver. If you don\u2019t see the manufacturer of your \nprinter listed, choose PostScript for a PostScript printer or HP for a PCL printer. For \nthe manufacturer you choose, you can select a specific model.\n6. Set options. If you are asked to set options for your printer, you may do so. Then \nselect Set Printer Options to continue.\n7. Your printer should be available. If the printer is added successfully, click the name \nof your printer to have the new printer page appear; from the printer page, you can \nselect Maintenance or Administration to print a test page or modify the printer \nconfiguration.\nWith the basic printer configuration done, you can now do further work with your printers. \nHere are a few examples of what you can do:\nList print jobs Click Show All Jobs to see what print jobs are currently active from \nany of the printers configured for this server. Click Show Completed Jobs to see \ninformation about jobs that are already printed.", "doc_id": "5e0e88c0-d99c-4644-b2a5-34d037b16c4b", "embedding": null, "doc_hash": "66a455a0867fc4b92e901797cfbf32c74206a07a3df93ce926a7cefc6b43295d", "extra_info": {"page_label": "432"}, "node_info": {"start": 0, "end": 2627}, "relationships": {"1": "26c70035-6b5a-44ac-ac8d-30dcb30f884a"}}, "__type__": "1"}, "3f166149-b782-43ca-9c69-4cacd3f0837e": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator408Create a printer class Click the Administration tab, choose Add Class, and identify \na name, description, and location for a printer class. From the list of Printers (Mem-\nbers) configured on your server, select the ones to go into this class.\nCancel or move a print job If you print a 100-page job by mistake, or if the printer \nis spewing out junk, the Cancel feature can be very handy. Likewise, if you sent \na print job to the wrong printer, the Move Job selection can be useful. From the \nAdministration tab, click Manage Jobs; then click Show Active Jobs to see what \nprint jobs are currently in the queue for the printer. Select the Cancel Job button \nnext to the print job that you want to cancel or select Move Job to move the print \njob to a different printer.\nView printers  You can click the Printers tab from the top of any of the CUPS web-\nbased administration pages to view the printers that you have configured. For each \nprinter that appears, you can select Maintenance or Administrative tasks. Under \nMaintenance, click Pause Printer (to stop the printer from printing but still accept \nprint jobs for the queue), Reject Jobs (to not accept any further print jobs for the \nmoment), Move All Jobs (to move them to another printer), Cancel All Jobs (to delete \nall print jobs), or Print Test Page (to print a page). Figure\u00a016.2 shows the information \non the Printers tab for a specific printer.\nFIGURE 16.2\nYou can do administration tasks from the Printers tab.", "doc_id": "3f166149-b782-43ca-9c69-4cacd3f0837e", "embedding": null, "doc_hash": "45586ab5b6c7aee9370d0b190afb05ab87c5cd2d377515ad2b06cafd5a31b143", "extra_info": {"page_label": "433"}, "node_info": {"start": 0, "end": 1526}, "relationships": {"1": "499cf0a2-3303-44ff-b6ce-1667ce65aa52"}}, "__type__": "1"}, "03d0512f-3378-400a-9646-3d60083f2cf4": {"__data__": {"text": "Chapter 16: Configuring a Print Server\n409\n16Using the Print Settings window\nIf you are using Fedora, you can use the Print Settings window to set up your printers. In \nfact, I recommend that you use it instead of CUPS web administration because the resulting \nprinter configuration files are tailored to work with the way the CUPS service is started on \nthose systems in Fedora. After the package is installed ( dnf install system-config-\nprinter ), to install a printer from your GNOME desktop, start the Print Settings window \nby typing Print Settings  from the Activity screen, or as root user by typing system-\nconfig-printer . This tool enables you to add and delete printers and edit printer prop -\nerties. It also enables you to send test pages to those printers to make sure that they are \nworking properly.\nThe key here is that you are configuring printers that are managed by your print daemon \n(cupsd  for the CUPS service). After a printer is configured, users on your local system can \nuse it. You can refer to the section \u201cConfiguring Print Servers\u201d to learn how to make the \nserver available to users from other computers on your network.\nThe printers that you set up can be connected directly to your computer (as on a USB port) \nor to another computer on the network (for example, from another UNIX system or Win -\ndows system).\nConfiguring local printers with the Print Settings window\nAdd a local printer (in other words, a printer connected directly to your computer) with the \nPrinters window using the procedure that follows.\nAdding a local printer\nTo add a local printer from a GNOME desktop in the latest version of Fedora, follow \nthese steps:\n1. Type the following to open the Print Settings window :\n        # system-config-printer &\nThe Printing window appears.\n2. Click Add . (If asked, click the Adjust Firewall button to allow access to the printer \nport 631.) A New Printer window appears.\n3. If the printer that you want to configure is detected, simply select it and click \nForward . If it is not detected, choose the device to which the printer is connected \n(LPT #1 and Serial Port #1 are the first parallel and serial ports, respectively) and \nclick Forward. (Type /usr/sbin/lpinfo -v | less in a shell to see printer \nconnection types.) You are asked to identify the printer\u2019s driver.\n4. To use an installed driver for your printer, choose Select Printer From Data -\nbase, and then choose the manufacturer of your printer . As an alternative, you \ncould select Provide PPD File and supply your own PPD file (for example, if you have ", "doc_id": "03d0512f-3378-400a-9646-3d60083f2cf4", "embedding": null, "doc_hash": "e0f0a6863a9d7488e31aa90b85e2027dabba99889474c5c8a0f2158abedc0d78", "extra_info": {"page_label": "434"}, "node_info": {"start": 0, "end": 2572}, "relationships": {"1": "ed629947-36db-4485-89ee-f141022e7968"}}, "__type__": "1"}, "3fce0be2-52ec-4ea9-be7b-1561002de646": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator410a printer that is not supported in Linux and you have a driver that was supplied \nwith the printer). (PPD stands for PostScript Printer Description.) Select Forward to \nsee a list of printer models from which you can choose.\nTip\nIf your printer doesn\u2019t appear on the list but supports PCL (HP\u2019s Printer Control Language), try selecting one of the HP \nprinters (such as HP LaserJet). If your printer supports PostScript, select PostScript printer from the list. Selecting \nRaw Print Queue enables you to send documents that are already formatted for a particular printer type to a specific \nprinter.\n5. With your printer model selected, click the driver that you want to use with it \nand then click Forward to continue .\n6. Add the following information, and click Forward :\na. Printer Name : Add the name that you want to give to identify the printer. The \nname must begin with a letter, but after the initial letter, it can contain a com-\nbination of letters, numbers, dashes ( -), and underscores ( _). For example, an \nHP printer on a computer named maple  could be named hp-maple .\nb. Description : Add a few words describing the printer, such as its features (for \nexample, an HP LaserJet 2100M with PCL and PS support).\nc. Location : Add some words that describe the printer\u2019s location (for example, \u201cIn \nRoom 205 under the coffee maker\u201d).\n7. When the printer is added, click No or Yes if you\u2019re prompted to print a test \npage.  The new printer entry appears in the Print Settings window. Double-click the \nprinter to see the Properties window for that printer, as shown in Figure\u00a016.3.\nFIGURE 16.3\nThe Printer Properties window after adding a printer", "doc_id": "3fce0be2-52ec-4ea9-be7b-1561002de646", "embedding": null, "doc_hash": "c0ed32ef106746cc3439c075118a9be6bd0f30153d0056c6d54dccc807838477", "extra_info": {"page_label": "435"}, "node_info": {"start": 0, "end": 1706}, "relationships": {"1": "3ac5cbf5-8f3e-41b3-8ff0-c5484db6cec5"}}, "__type__": "1"}, "a868ade9-4954-4cc9-b71d-5f25e92a55fc": {"__data__": {"text": "Chapter 16: Configuring a Print Server\n411\n168. If you want the printer to be your default printer, right-click the printer and \nselect Set As Default . As you add other printers, you can change the default \nprinter by selecting the one you want and selecting Set As Default again.\n9. Make sure that the printing is working . Open a Terminal window and use the \nlp command to print a file (such as lp /etc/hosts ). (If you want to share this \nprinter with other computers on your network, refer to the section \u201cConfiguring \nPrint Servers\u201d later in this chapter.)\nEditing a local printer\nAfter double-clicking the printer that you want to configure, choose from the following \nmenu options to change its configuration:\nSettings : The Description, Location, Device URI, and Make and Model information you \ncreated earlier are displayed in this dialog box.\nPolicies : Click Policies to set the following items:\nState : Select check boxes to indicate whether the printer will print jobs that are \nin the queue (Enabled), accept new jobs for printing (Accepting Jobs), and be \navailable to be shared with other computers that can communicate with your \ncomputer (Shared). You also must select Server Settings and click the \u201cShare Pub -\nlished printers connected to this system\u201d check box before the printer will accept \nprint jobs from other computers.\nPolicies : In case of error, the stop-printer selection causes all printing to that \nprinter to stop. You can also select to have the job discarded (abort-job) or retried \n(retry-job) in the event of an error condition.\nBanner : There are no starting or ending banner pages by default for the printer. \nChoose starting or ending banner pages that include text such as Classified ,  \nConfidential , Secret , and so on.\nAccess Control : If your printer is a shared printer, you can select this window to create \na list that either allows users access to the printer (with all others denied) or denies \nusers access to the printer (with all others allowed).\nPrinter Options : Click Printer Options to set defaults for options related to the printer \ndriver. The available options are different for different printers. Many of these \noptions can be overridden when someone prints a document. Here are examples of a \nfew of the options that you might (or might not) have available:\nWatermark : Several Watermark settings are available to enable you to add and \nchange watermarks on your printed pages. By default, Watermark and Overlay are \noff (None). By selecting Watermark (behind the text) or Overlay (over the text), \nyou can set the other Watermark settings to determine how watermarks and \noverlays are done. Watermarks can go on every page (All) or only the first page \n(First Only). Select Watermark Text to choose what words are used for the water -\nmark or overlay (Draft, Copy, Confidential, Final, and so on). You can then select \nthe font type, size, style, and intensity of the watermark or overlay.", "doc_id": "a868ade9-4954-4cc9-b71d-5f25e92a55fc", "embedding": null, "doc_hash": "b3dbec6d23f9f100e90bf8d2e4a3e43f86fe98e5c34f1bb5aa322f13648eba62", "extra_info": {"page_label": "436"}, "node_info": {"start": 0, "end": 2957}, "relationships": {"1": "3135567f-fe28-44ca-b871-7e8af3e77c05"}}, "__type__": "1"}, "e6c2ffb2-51f2-447c-815e-96b576dd9a33": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator412Resolution Enhancement : You can use the printer\u2019s current settings or choose to \nturn resolution enhancement on or off.\nPage Size : The default is US letter size, but you can also ask the printer to print \nlegal size, envelopes, ISO A4 standard, or several other page sizes.\nMedia Source : Choose which tray to print from. Select Tray 1 to insert \npages manually.\nLevels of Gray : Choose to use the printer\u2019s current levels of gray or have enhanced \nor standard gray levels turned on.\nResolution : Select the default printing resolution (such as 300, 600, or 1,200 dots \nper inch). Higher resolutions result in better quality but take longer to print.\nEconoMode : Either use the printer\u2019s current setting or choose a mode where you \nsave toner or one where you have the highest possible quality.\nJob Options : Click Job Options to set common default options that will be used for this \nprinter if the application printing the job doesn\u2019t already set them. These include \nCommon Options (number of copies, orientation, scale to fit, and pages per side), \nImage Options (scaling, saturation, hue, and gamma), and Text Options (characters/\ninch, lines/inch, and margin settings).\nInk/Toner Levels : Click Ink/Toner Levels to see information on how much ink or toner \nyour printer has left. (Not all printers report these values.)\nClick Apply when you are satisfied with the changes you made to the local printer.\nConfiguring remote printers\nTo use a printer that is available on your network, you must identify that printer to \nyour Linux system. Supported remote printer connections include Networked CUPS (IPP) \nprinters, Networked UNIX (LPD) printers, Networked Windows (Samba) printers, and JetDi-\nrect printers. (Of course, both CUPS and UNIX print servers can be run from Linux systems \nas well as other UNIX systems.)\nIn each case, you need a network connection from your Linux system to the servers to \nwhich those printers are connected. To use a remote printer requires that someone set up \nthat printer on the remote server computer. See the section \u201cConfiguring Print Servers\u201d \nlater in this chapter for information on how to do that on your Linux server.\nUse the Print Settings window ( system-config-printer ) to configure each of the \nremote printer types. This is how it is done:\n1. From the GNOME 3 Activities screen, type Print Settings and press Enter .\n2. Click Add . The New Printer window appears.\n3. Depending on the type of ports that you have on your computer, select one of \nthe following :\na. LPT #1: Use this for a printer connected to your parallel port.\nb. Serial Port #1 : Use this for a printer connected to your serial port.", "doc_id": "e6c2ffb2-51f2-447c-815e-96b576dd9a33", "embedding": null, "doc_hash": "3372121f49f87ae72312499cd4921d91ea732cada31ff9a0952c690cb024f51c", "extra_info": {"page_label": "437"}, "node_info": {"start": 0, "end": 2704}, "relationships": {"1": "bb70bd7f-7277-4420-b40b-4ed2f350e643"}}, "__type__": "1"}, "65e23da8-fb6e-4fbe-acbd-ad013430c4c6": {"__data__": {"text": "Chapter 16: Configuring a Print Server\n413\n16c. Network Printer : Under this heading, you can search for network printers (by \nhostname or IP address) or type in the URI for several different printer types:\ni. Find Network Printer : Instead of entering a printer URI, you can provide \na hostname or IP address for the system that has the printer to which you \nwant to print. Any printers found on that host appear on the window, ready \nfor you to add.\nii. AppleSocket/HP JetDirect : Use this for a JetDirect printer.\niii. Internet Printing Protocol (IPP) : Use this for a CUPS or other IPP printer. \nMost Linux and Mac OS X printers fall into this category.\niv. Internet Printing Protocol (HTTPS) : Use this for a CUPS or other IPP \nprinter being shared over a secure connection (valid certificates required).\nv. LPD/LPR Host or Printer : Use this for a UNIX printer.\nvi. Windows Printer via SAMBA : Use this for a Windows system printer.\nContinue with the steps in whichever of the following sections is appropriate.\nAdding a remote CUPS printer\nIf you chose to add a CUPS (IPP) printer that is accessible over your local network from \nthe Print Settings window, you must add the following information to the window \nthat appears:\nHost This is the hostname of the computer to which the printer is attached (or other -\nwise accessible). This can be an IP address or TCP/IP hostname for the computer. The \nTCP/IP name is accessible from your /etc/hosts  file or through a DNS name server.\nQueue  This is the printer name on the remote CUPS print server. CUPS supports \nprinter instances, which allows each printer to have several sets of options. If the \nremote CUPS printer is configured this way, you can choose a particular path to a \nprinter, such as hp/300dpi  or hp/1200dpi . A slash character separates the print \nqueue name from the printer instance.\nComplete the rest of the procedure as you would for a local printer (see the section \u201cAdding \na local printer\u201d earlier in this chapter).\nAdding a remote UNIX (LDP/LPR) printer\nIf you chose to add a UNIX printer (LPD/LPR) from the Print Settings window, you must add \nthe following information to the window that appears:\nHost This is the hostname of the computer to which the printer is attached (or other -\nwise accessible). This is the IP address or hostname for the computer (the hostname \nis accessible from your /etc/hosts  file or through a DNS name server). Select the \nProbe button to search for the host.\nQueue  This is the printer name on the remote UNIX computer.\nComplete the rest of the procedure as you would for a local printer (see the section \u201cAdding \na local printer\u201d earlier in this chapter).", "doc_id": "65e23da8-fb6e-4fbe-acbd-ad013430c4c6", "embedding": null, "doc_hash": "af06c4292165c6d6dcaae2dd1f88ab235cb47b51e97f10bb7d9981cb16481c60", "extra_info": {"page_label": "438"}, "node_info": {"start": 0, "end": 2669}, "relationships": {"1": "63490de5-d4d5-45b4-8436-445d7b841129"}}, "__type__": "1"}, "62f76dbd-c7f5-4538-9942-aec36c595963": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator414Adding a Windows (SMB) printer\nEnabling your computer to access an SMB printer (the Windows printing service) involves \nadding an entry for the printer in the Select Connection window.\nWhen you choose to add a Windows printer to the Print Settings window (Windows Printer \nvia Samba), select Browse to see a list of computers on your network that have been \ndetected as offering SMB services (file and/or printing service). You can configure the \nprinter from this window as follows:\n1. Type the URI of the printer, excluding the leading smb:// . For example, you \nmight type /host1/myprinter  or /mygroup/host1/myprinter .\n2. Select either \u201cPrompt user if authentication is required\u201d or \u201cSet authentication \ndetails now .\u2019\n3. If you chose \u201cSet authentication details now,\u201d fill in the username and pass -\nword needed to access the SMB printer; then click Verify to check that you can \nauthenticate to the server .\n4. Click Forward to continue .\nAlternatively, you can identify a server that does not appear on the list of servers. Type the \ninformation needed to create an SMB URI that contains the following information:\nWorkgroup  This is the workgroup name assigned to the SMB server. Using the work -\ngroup name isn\u2019t necessary in all cases.\nServer  This is the NetBIOS name or IP address for the computer, which may or may \nnot be the same as its TCP/IP name. To translate this name into the address needed \nto reach the SMB host, Samba checks several places where the name may be assigned \nto an IP address. Samba checks the following (in the order shown) until it finds \na match: the local /etc/hosts  file, the local /etc/lmhosts  file, a WINS server \non the network, and responses to broadcasts on each local network interface to \nresolve the name.\nShare This is the name under which the printer is shared with the remote computer. \nIt may be different from the name by which local users of the SMB printer know \nthe printer.\nUser A username is required by the SMB server system to give you access to the SMB \nprinter. A username is not necessary if you are authenticating the printer based on \nshare-level rather than user-level access control. With share-level access, you can \nadd a password for each shared printer or file system.Tip\nIf the print job you send to test the printer is rejected, the print server computer may not have allowed you access to \nthe printer. Ask the remote computer\u2019s administrator to add your hostname to the /etc/lpd.perms  file. (Enter \nlpstat -d  printer  to see the status of your print job.)", "doc_id": "62f76dbd-c7f5-4538-9942-aec36c595963", "embedding": null, "doc_hash": "99a36429b194ccc59ac6fb2d165ed5567296d37efa7cfe46bdc644488a639828", "extra_info": {"page_label": "439"}, "node_info": {"start": 0, "end": 2586}, "relationships": {"1": "43442a2a-ca31-472d-8223-47d7666217cb"}}, "__type__": "1"}, "e932fa8b-5677-466d-a3a7-7a917295b4b7": {"__data__": {"text": "Chapter 16: Configuring a Print Server\n415\n16Password  Use the password associated with the SMB username or the shared \nresource, depending on the kind of access control being used.\nCauTion\nWhen you enter a username and password for SMB, the information is stored unencrypted in the /etc/cups/\nprinters.conf  file. Be sure that the file remains readable only by root.\nThe following is an example of the SMB URI that you could add to the SMB://  box:\njjones:my9passswd@FSTREET/NS1/hp\nThe URI shown here identifies the username ( jjones ), the user\u2019s password ( my9passswd ), \nthe workgroup ( FSTREET ), the server ( NS1), and the printer queue name ( hp).\nComplete the rest of the procedure as you would for a local printer (see the section \u201cAdding \na local printer\u201d earlier in this chapter).\nIf everything is set up properly, you can use the standard lp  command to print the file to \nthe printer. Using this example, employ the following form for printing:\n$ cat file1.ps | lp -P NS1-PS\nTip\nIf you are receiving failure messages, make sure that the computer to which you are printing is accessible. For \nthe Printer NS1 hp example, you can type smbclient -L NS1 -U jjones . Then type the password \n(my9passswd , in this case). The \u2013L  asks for information about the server; the \u2013U jjones  says to log in the \nuser jjones . If you get a positive name query response after you enter a password, you should see a list of shared \nprinters and files from that server. Check the names and try printing again.\nWorking with CUPS Printing\nTools such as CUPS web-based administration and the Print Settings window effectively \nhide the underlying CUPS facility. Sometimes, however, you want to work directly with the \ntools and configuration files that come with CUPS. The following sections describe how to \nuse some special CUPS features.\nConfiguring the CUPS server (cupsd.conf)\nThe cupsd  daemon process listens for requests to your CUPS print server and responds to \nthose requests based on settings in the /etc/cups/cupsd.conf  file. The configuration \nvariables in the cupsd.conf  file are in the same form as those in the Apache configura -\ntion file (httpd.conf  or apache2.conf ). Type man cupsd.conf  to see details on any \nof the settings.", "doc_id": "e932fa8b-5677-466d-a3a7-7a917295b4b7", "embedding": null, "doc_hash": "113967e0b4030a7ae09738d22b0799bb24a642862ee05447bdbca1a4e1cfe885", "extra_info": {"page_label": "440"}, "node_info": {"start": 0, "end": 2242}, "relationships": {"1": "b0237b78-e6d4-482b-b782-e958e5d1f622"}}, "__type__": "1"}, "03d69c1f-1d2d-40e5-99a4-cf97fa7b0ee8": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator416The Print Settings window adds access information to the cupsd.conf  file. For other \nLinux systems, or if you don\u2019t have a desktop on your server, you may need to configure the \ncupsd.conf  file manually. You can step through the cupsd.conf  file to tune your CUPS \nserver further. Most of the settings are optional or can just be left as the default. Let\u2019s look \nat some of the settings that you can use in the cupsd.conf  file.\nNo classification is set by default. With the classification set to topsecret , you can have \nTop Secret displayed on all pages that go through the print server:\nClassification topsecret\nOther classifications you can substitute for topsecret  include classified , confiden -\ntial , secret , and unclassified .\nThe term browsing  refers to the act of broadcasting information about your printer on \nyour local network and listening for other print servers\u2019 information. The cups-browsed  \nsetting is used to browse shared, remote printers. Browsing is on by default for all local \nnetworks ( @LOCAL ). You can allow CUPS browser information ( BrowseAllow ) for addi-\ntional selected addresses. Browsing information is broadcast, by default, on address \n255.255.255.255 . Here are examples of several browsing settings:\nBrowsing On\nBrowseProtocols cups\nBrowseOrder Deny,Allow\nBrowseAllow from @LOCAL\nBrowseAddress 255.255.255.255\nListen *:631\nTo enable web-based CUPS administration and to share printers with others on the net -\nwork, the cupsd  daemon can be set to listen on port 631 for all network interfaces to your \ncomputer based on this entry: Listen *:631 . By default, it listens on the local interface \nonly on many Linux systems ( Listen localhost:631 ). For Fedora, CUPS listens on all \ninterfaces by default.\nThis is a good way to enable users on several connected LANs to discover and use printers \non other nearby LANs.\nYou can allow or deny access to different features of the CUPS server. An access definition \nfor a CUPS printer (created from the Print Settings window) might appear as follows:\n<Location /printers/ns1-hp1>\nOrder Deny,Allow\nDeny From All\nAllow From 127.0.0.1\nAuthType None\n</Location>\nHere, printing to the ns1-hp1  printer is allowed only for users on the local host \n(127.0.0.1 ). No password is needed ( AuthType None ). To allow access to the administra -\ntion tool, CUPS must be configured to prompt for a password ( AuthType Basic ).", "doc_id": "03d69c1f-1d2d-40e5-99a4-cf97fa7b0ee8", "embedding": null, "doc_hash": "b82bb1ff6830da32812afe61a662afae0a747302afdf206e5b62c7bdc428e47a", "extra_info": {"page_label": "441"}, "node_info": {"start": 0, "end": 2454}, "relationships": {"1": "95ed55f1-f696-4e2a-8fee-c8b8937400fd"}}, "__type__": "1"}, "54f45e69-96da-4ee8-a859-3fb273385438": {"__data__": {"text": "Chapter 16: Configuring a Print Server\n417\n16Starting the CUPS server\nFor Linux systems that use System V\u2013style startup scripts (such as earlier releases of  \nFedora and RHEL), starting and shutting down the CUPS print service is pretty easy. Use \nthe chkconfig  command to turn on CUPS so that it starts at each reboot. Run the cups  \nstartup script to have the CUPS service start immediately. In RHEL 6.x or earlier, type the \nfollowing as root user:\n# chkconfig cups on\n# service cups start\nIf the CUPS service was already running, you should use restart  instead of start . Using \nthe restart  option is also a good way to reread any configuration options that you may \nhave changed in the cupsd.conf  file (although, if CUPS is already running, service \ncups reload  rereads configuration files without restarting).\nIn Fedora 30 and RHEL 8, you use the systemctl  command instead of service  to start \nand stop services:\n# systemctl status cups.service\n \n* cups.service - CUPS Printing Service\n   Loaded: loaded (/usr/lib/systemd/system/cups.service; enabled)\n   Active: active (running) since Sat 2016-07-23 22:41:05 EDT; 18h ago\n Main PID: 20483 (cupsd)\n   Status: \"Scheduler is running...\"\n   CGroup: /system.slice/cups.service\n           \u251c\u250020483 /usr/sbin/cupsd -f\nYou can tell the CUPS service is running because the status shows the cupsd  daemon \nactive with PID 20483. If that service were not running, you could start the CUPS service \nas follows:\n# systemctl start cups.service\nSee Chapter\u00a015, \u201cStarting and Stopping Services,\u201d for more information on the systemctl  \nand service  commands for working with services.\nConfiguring CUPS printer options manually\nIf your Linux distribution doesn\u2019t have a graphical means of configuring CUPS, you can edit \nconfiguration files directly. For example, when a new printer is created from the Print Set -\ntings window, it is defined in the /etc/cups/printers.conf  file. This is what a printer \nentry looks like:\n<DefaultPrinter printer>\nInfo HP LaserJet 2100M\nLocation HP LaserJet 2100M in hall closet\nDeviceURI parallel:/dev/lp0\nState Idle", "doc_id": "54f45e69-96da-4ee8-a859-3fb273385438", "embedding": null, "doc_hash": "6d711185df0036847fd2e1756313accb79455827d2a697ae6e89d3d5f538773f", "extra_info": {"page_label": "442"}, "node_info": {"start": 0, "end": 2097}, "relationships": {"1": "a98ebeb8-d33f-40ab-a775-e01a9e60b6cf"}}, "__type__": "1"}, "57d51f92-a15e-4cc9-bc17-9de862fe9279": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator418Accepting Yes\nShared No\nJobSheets none none\nQuotaPeriod 0\nPageLimit 0\nKLimit 0\n</Printer>\nThis is an example of a local printer that serves as the default printer for the local system. \nThe Shared No  value is set because the printer is currently available only on the local \nsystem. The most interesting information relates to DeviceURI , which shows that the \nprinter is connected to parallel port /dev/lp0 . The state is Idle  (ready to accept printer \njobs), and the Accepting  value is Yes  (the printer is accepting print jobs by default).\nThe DeviceURI  has several ways to identify the device name of a printer, reflecting where \nthe printer is connected. Here are some examples listed in the printers.conf  file:\nDeviceURI parallel:/dev/plp\nDeviceURI serial:/dev/ttyd1?baud=38400+size=8+parity=none+flow=soft\nDeviceURI scsi:/dev/scsi/sc1d6l0\nDeviceURI usb://hostname:port\nDeviceURI socket://hostname:port\nDeviceURI tftp://hostname/path\nDeviceURI ftp://hostname/path\nDeviceURI http://hostname[:port]/path\nDeviceURI ipp://hostname/path\nDeviceURI smb://hostname/printer\nThe first four examples show the form for local printers ( parallel , serial , scsi , and \nusb). The other examples are for remote hosts. In each case, hostname  can be the host\u2019s \nname or IP address. Port numbers or paths identify the locations of each printer on the \nhost. For example, hostname  could be myhost.example.com :631 and path  could be \nreplaced by any name you like, such as printers/myprinter .\nUsing Printing Commands\nTo remain backward compatible with older UNIX and Linux printing facilities, CUPS sup -\nports many of the old commands for working with printing. Most command-line printing \nwith CUPS can be performed with the lp  command. Word processing applications such as \nLibreOffice, OpenOffice, and AbiWord are set up to use this facility for printing.\nYou can use the Print Settings window to define the filters needed for each printer so that \nthe text can be formatted properly. Options to the lp  command can add filters to pro -\ncess the text properly. Other commands for managing printed documents include lpq  (for \nviewing the contents of print queues), lprm  (for removing print jobs from the queue), and \nlpstat -t  (for controlling printers).", "doc_id": "57d51f92-a15e-4cc9-bc17-9de862fe9279", "embedding": null, "doc_hash": "ba232faf12fc5091e8a14fb366ec020358ed10da48ce2731d541af4a49e28d2e", "extra_info": {"page_label": "443"}, "node_info": {"start": 0, "end": 2305}, "relationships": {"1": "1019b346-d906-448c-bb1e-4ed44f2fece0"}}, "__type__": "1"}, "f241386f-0176-41df-9d80-2b44b6acd227": {"__data__": {"text": "Chapter 16: Configuring a Print Server\n419\n16Printing with lp\nYou can use the lp  command to print documents to both local and remote printers (pro -\nvided the printers are configured locally). Document files can be either added to the end of \nthe lp  command line or directed to the lp  command using a pipe ( |). Here\u2019s an example of \na simple lp  command:\n$ lp doc1.ps\nWhen you specify just a document file with lp , output is directed to the default printer. As \nan individual user, you can change the default printer by setting the value of the PRINTER  \nvariable. Typically, you add the PRINTER  variable to one of your startup files, such as \n$HOME/.bashrc . Adding the following line to your . bashrc  file, for example, sets your \ndefault printer to lp3 :\nexport PRINTER=lp3\nTo override the default printer, specify a particular printer on the lp  command line. The \nfollowing example uses the -P  option to select a different printer:\n$ lp -P canyonps doc1.ps\nThe lp  command has a variety of options that enable lp  to interpret and format several \ndifferent types of documents. These include -# num , where num  is replaced by the number \nof copies to print (from 1 to 100) and -l  (which causes a document to be sent in raw mode, \npresuming that the document has already been formatted). To learn more options to lp , \ntype man lp .\nListing status with lpstat -t\nUse the lpstat -t  command to list the status of your printers. Here is an example:\n$ /usr/sbin/lpstat -t\nprinter hp disabled since Wed 10 Jul 2019 10:53:34 AM EDT\nprinter deskjet-555 is idle.  enabled since Wed 10 Jul 2019 \n10:53:34 AM EDT\nThis output shows two active printers. The hp  printer is currently disabled (offline). The \ndeskjet-555  printer is enabled.\nRemoving print jobs with lprm\nUsers can remove their own print jobs from the queue with the lprm  command. Used alone \non the command line, lprm  removes all of the user\u2019s print jobs from the default printer. To \nremove jobs from a specific printer, use the -P  option, as follows:\n$ lprm -P lp0\nTo remove all print jobs for the current user, type the following:\n$ lprm -", "doc_id": "f241386f-0176-41df-9d80-2b44b6acd227", "embedding": null, "doc_hash": "b92235c7111003f88acb15ee6f3833dd156cb562d8741ad345a9f7d4be63d555", "extra_info": {"page_label": "444"}, "node_info": {"start": 0, "end": 2114}, "relationships": {"1": "f0b91540-4d28-4514-9378-5f06bb147d45"}}, "__type__": "1"}, "e69bf53b-b373-4038-b0bf-796e908443f6": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator420The root user can remove all of the print jobs for a specific user by indicating that user on \nthe lprm  command line. For example, to remove all print jobs for the user named mike , \nthe root user types the following:\n# lprm \u2013U mike\nTo remove an individual print job from the queue, indicate its job number on the lprm  \ncommand line. To find the job number, type the lpq  command. Here\u2019s what the output of \nthat command may look like:\n# lpq\nprinter is ready and printing\nRank   Owner                Job Files                Total Size Time\nactive root                 133 /home/jake/pr1         467\n2      root                 197 /home/jake/mydoc     23948\nThe output shows two printable jobs waiting in the queue. (The printer is ready and \nprinting the job listed as active.) Under the Job  column, you can see the job number asso -\nciated with each document. To remove the first print job, type the following:\n# lprm 133\nConfiguring Print Servers\nYou\u2019ve configured a printer so that you and the other users on your computer can print to \nit. Now you want to share that printer with other people in your home, school, or office. \nBasically, that means configuring the printer as a print server.\nThe printers configured on your Linux system can be shared in different ways with other \ncomputers on your network. Not only can your computer act as a Linux print server (by \nconfiguring CUPS), but it can also appear as an SMB (Windows) print server to client com-\nputers. After a local printer is attached to your Linux system and your computer is con -\nnected to your local network, you can use the procedures in the following sections to share \nthe printer with client computers using a Linux (UNIX) or SMB interface.\nConfiguring a shared CUPS printer\nMaking the local printer added to your Linux computer available to other computers on \nyour network is fairly easy. If a TCP/IP network connection exists between the computers \nsharing the printer, you simply grant permission to all hosts, individual hosts, or users \nfrom remote hosts to access your computer\u2019s printing service.\nTo configure a printer entry manually in the /etc/cups/printers.conf  file to accept \nprint jobs from all other computers, make sure that the Shared Yes line is set. The fol -\nlowing example from a printers.conf  entry earlier in this chapter demonstrates what \nthe new entry would look like:\n<DefaultPrinter printer>\nInfo HP LaserJet 2100M\nLocation HP LaserJet 2100M in hall closet", "doc_id": "e69bf53b-b373-4038-b0bf-796e908443f6", "embedding": null, "doc_hash": "9e3316843514b597bd6b3eae232944c6ac368c517ea623e13048c821ea70fa54", "extra_info": {"page_label": "445"}, "node_info": {"start": 0, "end": 2518}, "relationships": {"1": "9f3f8ee8-4573-4efc-afcd-60a2480a5946"}}, "__type__": "1"}, "41bd75d8-75f4-4e3a-8513-a46942cdba68": {"__data__": {"text": "Chapter 16: Configuring a Print Server\n421\n16DeviceURI parallel:/dev/lp0\nState Idle\nAccepting Yes\nShared Yes\nJobSheets none none\nQuotaPeriod 0\nPageLimit 0\nKLimit 0\n</Printer>\nOn Linux systems that use the Print Settings window described earlier in this chapter, it\u2019s \nbest to set up your printer as a shared printer using that window. Here\u2019s how to do that \nusing Fedora 30:\n1. From the Activities screen on a GNOME 3 desktop in Fedora, type Print Settings \nand press Enter . The Print Settings window appears.\n2. To allow all of your printers to be shared, select Server \u27aa Settings . If you are \nnot the root user, you are prompted for the root password. The Basic Server Set -\ntings pop-up appears.\n3. Select the check box next to \u201cPublish shared printers connected to this \nsystem\u201d and click OK . You may be asked to modify your firewall to open the neces -\nsary ports for remote systems to access your printers.\n4. To allow or restrict printing for a particular printer further, double-click the \nname of the printer that you want to share . (If the printer is not yet configured, \nrefer to the section \u201cSetting Up Printers\u201d earlier in this chapter.)\n5. Choose the Policies heading and select Shared so that a check mark appears \nin the box .\n6. If you want to restrict access to the printer to selected users, select the Access \nControl heading and choose one of the following options:\na. Allow Printing for Everyone Except These Users . With this selected, all users \nare allowed access to the printer. By typing usernames into the Users box and \nclicking Add, you exclude selected users.\nb. Deny Printing for Everyone Except These Users . With this selected, all users \nare excluded from using the printer. Type usernames into the Users box, and \nclick Add to allow access to the printer for only those names that you enter.\nNow you can configure other computers to use your printer, as described in the section \n\u201cSetting Up Printers\u201d of this chapter. If you try to print from another computer and it \ndoesn\u2019t work, try these troubleshooting tips:\nOpen your firewall . If you have a restrictive firewall, it may not permit printing. You \nmust enable access to TCP port 631 to allow access to printing on your computer.\nCheck names and addresses . Make sure that you entered your computer\u2019s name and \nprint queue properly when you configured it on the other computer. Try using the IP ", "doc_id": "41bd75d8-75f4-4e3a-8513-a46942cdba68", "embedding": null, "doc_hash": "bf480597db8c612fbdc42647cd0348fa4b23986740c1a64363f5921a8bbadc96", "extra_info": {"page_label": "446"}, "node_info": {"start": 0, "end": 2391}, "relationships": {"1": "91513ded-e7e2-4276-a455-ca96b52382a7"}}, "__type__": "1"}, "b8b06100-019e-48a2-b757-be825b7e07de": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator422address instead of the hostname. (If that works, it indicates a DNS name resolution \nproblem.) Running a tool such as tcpdump  enables you to see where the transac -\ntion fails.\nCheck which addresses cupsd  is listening on . The cupsd  daemon must be listen -\ning outside of the localhost for remote systems to print to it. Use the netstat  \ncommand (as the root user) as follows to check this. The first example shows cupsd  \nonly listening on local host ( 127.0.0.1:631 ); the second shows cupsd  listening on \nall network interfaces ( 0 0.0.0.0:631 ):\n# netstat -tupln | grep 631\ntcp        0      0 127.0.0.1:631     0.0.0.0:*         LISTEN       \n6492/cupsd\n# netstat -tupln | grep 631\ntcp        0      0 0.0.0.0:631       0.0.0.0:*         LISTEN      \n6492/cupsd\nAccess changes to your shared printer are made in the cupsd.conf  and printers.conf  \nfiles in your /etc/cups  directory.\nConfiguring a shared Samba printer\nYour Linux printers can be configured as shared SMB printers so that they appear to be \navailable from Windows systems. To share your printer as if it were a Samba (SMB) printer, \nsimply configure basic Samba server settings as described in Chapter\u00a019, \u201cConfiguring a \nWindows File Sharing (Samba) Server.\u201d All your printers should be shared on your local net -\nwork by default. The next section shows what the resulting settings look like and how you \nmight want to change them.\nUnderstanding smb .conf for printing\nWhen you configure Samba, the /etc/samba/smb.conf  file is constructed to enable all \nof your configured printers to be shared. Here are a few lines from the smb.conf  file that \nrelate to printer sharing:\n[global]\n     ...\n  load printers = yes\n  cups options = raw\n  printcap name = /etc/printcap\n  printing = cups\n    ...\n[printers]\n        comment = All Printers\n        path = /var/spool/samba\n        browseable = yes\n        writeable = no\n        printable = yes", "doc_id": "b8b06100-019e-48a2-b757-be825b7e07de", "embedding": null, "doc_hash": "3868b36a6ec0a14ac0ab167dfb2051fbb378684879b0fdbd153230e3a648a066", "extra_info": {"page_label": "447"}, "node_info": {"start": 0, "end": 1965}, "relationships": {"1": "6ab8118a-f1d2-4004-a9aa-700ec1a3f720"}}, "__type__": "1"}, "75934dfa-1f6d-4b33-8916-7a60b2069777": {"__data__": {"text": "Chapter 16: Configuring a Print Server\n423\n16You can read the comment lines to learn more about the file\u2019s contents. Lines beginning \nwith a semicolon ( ;) indicate the default setting for the option on a comment line. Remove \nthe semicolon to change the setting.\nThe selected lines show that printers from /etc/printcap  were loaded and that the CUPS \nservice is being used. With cups options  set to raw , Samba assumes that print files have \nalready been formatted by the time they reach your print server. This allows the Linux or \nWindows clients to provide their own print drivers.\nThe last few lines are the actual printers\u2019 definition. By changing the browseable  option \nfrom no  to yes , you give users the ability to print to all printers ( printable = yes ). \nYou can also store Windows native print drivers on your Samba server. When a Windows \nclient uses your printer, the driver automatically becomes available. You do not need to \ndownload a driver from the vendor\u2019s website. To enable the printer driver share, add a \nSamba share called print$  that looks like the following:\n[print$]\ncomment = Printer Drivers\npath = /var/lib/samba/drivers\nbrowseable = yes\nguest ok = no\nread only = yes\nwrite list = chris, dduffey\nAfter you have the share available, you can start copying Windows print drivers to the  \n/var/lib/samba/drivers  directory.\nSetting up SMB clients\nChances are good that if you are configuring a Samba printer on your Linux computer, you \nwant to share it with Windows clients. If Samba is set up properly on your computer and \nthe client computers can reach you over the network, users should have no trouble finding \nand using your printer.\nFor many Windows 10 systems, click Start \u27aa Printers and Scanners and select the printer \nfrom the list to configure it.\nWith Windows Vista, you open the Network icon. The name of your host computer (the \nNetBIOS name, which is probably also your TCP/IP name) appears on the screen or within a \nworkgroup folder on the screen. Open the icon that represents your computer. The window \nthat opens shows your shared printers and folders.\nTip\nIf your computer\u2019s icon doesn\u2019t appear in Network Neighborhood or My Network Places, try using the Search window. \nFrom Windows XP, choose Start \u27aa Search \u27aa Computer or People \u27aa A Computer on the Network. Type your comput -\ner\u2019s name into the Computer Name box and click Search. Double-click your computer in the Search window results \npanel. A window displaying the shared printers and folders from your computer appears.", "doc_id": "75934dfa-1f6d-4b33-8916-7a60b2069777", "embedding": null, "doc_hash": "1895b052f0e3be4a58f790dd0a5acd0e9a652f6e9a59bb1607df74a5ec883983", "extra_info": {"page_label": "448"}, "node_info": {"start": 0, "end": 2534}, "relationships": {"1": "2f3c182b-ecaa-4c53-8f1b-180d87b96b60"}}, "__type__": "1"}, "d1529401-4370-4de9-a9bb-1a7200a77f35": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator424After your shared printer appears in the window, configure a pointer to that printer by \nopening (double-clicking) the printer icon. A message tells you that you must set up the \nprinter before you can use it. Click Yes to proceed to configure the printer for local use. The \nAdd Printer Wizard appears. Answer the questions that ask you how you intend to use the \nprinter and add the appropriate drivers. When you are finished, the printer appears in your \nprinter window.\nAnother way to configure an SMB printer from a Windows XP operating system is to go to \nStart \u27aa Printers and Faxes. In the Printers and Faxes window that appears, click the Add a \nPrinter icon in the upper-left portion of the window, and select Network Printer from the \nfirst window. From there, you can browse and/or configure your SMB printer.\nSummary\nProviding networked printing services is essential on today\u2019s business networks. With the \nuse of a few network-attached devices, you can focus your printer spending on a few high-\nquality devices that multiple users can share instead of numerous lower-cost devices. In \naddition, a centrally located printer can make it easier to maintain the printer while still \nenabling everyone to get their printing jobs done.\nThe default printing service in nearly every major Linux distribution today is the Common \nUNIX Printing System (CUPS). Any Linux system that includes CUPS offers the CUPS web-\nbased administrative interface for configuring CUPS printing. It also offers configuration \nfiles in the /etc/cups  directory for configuring printers and the CUPS service ( cupsd  \ndaemon).\nIn RHEL, Fedora, Ubuntu, and other Linux systems, you can configure your printer with \nthe printing configuration windows available in both KDE and GNOME desktops. A variety \nof drivers makes it possible to print to different kinds of printers as well as to printers that \nare connected to computers on the network.\nYou can set up your computer as a Linux print server, and you can also have your computer \nemulate an SMB (Windows) print server. After your network is configured properly and a \nlocal printer is installed, sharing that printer over the network as a UNIX or SMB print \nserver is not very complicated.\nExercises\nUse these exercises to test your knowledge of configuring printers in Linux. These tasks \nassume that you are running a Fedora or Red Hat Enterprise Linux system (although some \ntasks work on other Linux systems as well). If you are stuck, solutions to the tasks are \nshown in Appendix B (although in Linux, you can often complete a task in multiple ways).", "doc_id": "d1529401-4370-4de9-a9bb-1a7200a77f35", "embedding": null, "doc_hash": "eb8f5c1a56f14800d1b94c0d27c56de16abeafb87a6fa79dd38006b736f81b2d", "extra_info": {"page_label": "449"}, "node_info": {"start": 0, "end": 2645}, "relationships": {"1": "097c4c55-d972-4c83-8c65-b10cc113ce3e"}}, "__type__": "1"}, "d53fafec-e911-46b8-87eb-7046839b86bd": {"__data__": {"text": "Chapter 16: Configuring a Print Server\n425\n161. Use the Print Settings window ( system-config-printer  package) to add a new \nprinter called myprinter  to your system. (The printer does not have to be con -\nnected to set up a print queue for the new printer.) Make it a generic PostScript \nprinter connected to a local serial, LPT, or other port.\n2. Use the lpstat -t  command to see the status of all of your printers.\n3. Use the lp  command to print the /etc/hosts  file to that printer.\n4. Check the print queue for that printer to see that the print job is there.\n5. Remove the print job from the queue (cancel it).\n6. Using the Printing window, set the basic server setting that publishes your printers \nso that other systems on your local network can print to your printers.\n7. Allow remote administration of your system from a web browser.\n8. Demonstrate that you can do remote administration of your system by opening a \nweb browser to port 631 from another system to the Linux system running your \nprint server.\n9. Use the netstat  command to see on which addresses the cupsd  daemon is listen -\ning (the printing port is 631).\n10. Delete the myprinter  printer entry from your system.", "doc_id": "d53fafec-e911-46b8-87eb-7046839b86bd", "embedding": null, "doc_hash": "ecaaf57de5d1ef5249e3b2bee28f44d033ff3cc6f7df198c5d0ebaade869330e", "extra_info": {"page_label": "450"}, "node_info": {"start": 0, "end": 1194}, "relationships": {"1": "87930f5d-ffff-41a9-9466-9604183dff0b"}}, "__type__": "1"}, "4446c0fd-8188-49e8-8479-8d6c80863842": {"__data__": {"text": "427\nCHAPTER17\nConfiguring a Web Server\nIN THIS CHAPTER\nInstalling an Apache web server\nConfiguring Apache\nSecuring Apache with iptables and SELinux\nCreating virtual hosts\nBuilding a secure (HTTPS) website\nChecking Apache for errors\nWeb servers are responsible for serving up the content you view on the Internet every day. \nBy far, the most popular web server is the Apache (HTTPD) web server, which is spon -\nsored by the Apache Software Foundation ( http://apache.org ). Because Apache is an \nopen source project, it is available with every major Linux distribution, including Fedora, RHEL, \nand Ubuntu.\nYou can configure a basic web server to run in Linux in just a few minutes. However, you can con -\nfigure your Apache web server in a tremendous number of ways. You can configure an Apache web \nserver to serve content for multiple domains (virtual hosting), provide encrypted communications \n(HTTPS), and secure some or all of a website using different kinds of authentication.\nThis chapter takes you through the steps to install and configure an Apache web server. These steps \ninclude procedures for securing your server as well as using a variety of modules so that you can \nincorporate different authentication methods and scripting languages into your web server. Then I \ndescribe how to generate certificates to create an HTTPS Secure Sockets Layer (SSL) website.\nUnderstanding the Apache Web Server\nApache HTTPD (also known as the Apache HTTPD Server ) provides the service with which the client \nweb browsers communicate. The daemon process ( httpd ) runs in the background on your server \nand waits for requests from web clients. Web browsers provide those connections to the HTTP \ndaemon and send requests, which the daemon interprets, sending back the appropriate data (such \nas a web page or other content).\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "4446c0fd-8188-49e8-8479-8d6c80863842", "embedding": null, "doc_hash": "8ed16401b8ede5591c2136e5f30f58b1e853a6a509811b9f60e734d62a15ecb3", "extra_info": {"page_label": "451"}, "node_info": {"start": 0, "end": 1948}, "relationships": {"1": "70fc0b80-effb-40ce-a772-a2fc92f2ff41"}}, "__type__": "1"}, "d3a353bc-94e8-4c76-9aa2-976e19d3c363": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator428Apache HTTPD includes an interface that allows modules to tie into the process to handle \nspecific portions of a request. Among other things, modules are available to handle the \nprocessing of scripting languages, such as Perl or PHP, within web documents and to add \nencryption to connections between clients and the server.\nApache began as a collection of patches and improvements from the National Center for \nSupercomputing Applications (NCSA), University of Illinois, Urbana-Champaign, to the HTTP \ndaemon. The NCSA HTTP daemon was the most popular HTTP server at the time, but it had \nstarted to show its age after its author, Rob McCool, left NCSA in mid-1994.\nNote\nAnother project that came from NCSA is Mosaic. Most modern web browsers can trace their origins to Mosaic.\nIn early 1995, a group of developers formed the Apache Group and began making extensive \nmodifications to the NCSA HTTPD code base. Apache soon replaced NCSA HTTPD as the most \npopular web server, a title it still holds today.\nThe Apache Group later formed the Apache Software Foundation (ASF) to promote the \ndevelopment of Apache and other free software. With the start of new projects at ASF, the \nApache server became known as Apache HTTPD, although the two terms are still used inter -\nchangeably. Currently, ASF has more than 350 open source initiatives, including Tomcat \n(which includes open source Java Servlet and JavaServer Pages technologies), Hadoop (a \nproject providing highly available, distributed computing), and SpamAssassin (an email fil -\ntering program).\nGetting and Installing Your Web Server\nAlthough Apache is available with every major Linux distribution, it is often packaged \nin different ways. In most cases, all you need to start a simple Apache web server is the \npackage containing the Apache daemon itself ( /usr/sbin/httpd ) and its related files. In \nFedora, RHEL, and others, the Apache web server comes in the httpd  package.\nUnderstanding the httpd package\nTo examine the httpd  package in Fedora or RHEL before you install it, download the \npackage using the yumdownloader  command and run a few rpm  commands on it to view \nits contents:\n# yumdownloader httpd\n# rpm -qpi httpd-*rpm\nName        : httpd\nVersion     : 2.4.41\nRelease     : 1.fc30\nArchitecture: x86_64\nInstall Date: (not installed)", "doc_id": "d3a353bc-94e8-4c76-9aa2-976e19d3c363", "embedding": null, "doc_hash": "f2189d2b4ad5b031555067f63f9fcba6da93bf6f0c0a5a6aeca6e2fa0e36b03d", "extra_info": {"page_label": "452"}, "node_info": {"start": 0, "end": 2363}, "relationships": {"1": "4a2cb916-2943-42f9-8001-23509b21a3f8"}}, "__type__": "1"}, "1f9d783b-9248-42d7-9c43-a7dd30fb99ed": {"__data__": {"text": "Chapter 17: Configuring a Web Server\n429\n17Group       : Unspecified\nSize        : 5070831\nLicense     : ASL 2.0\nSignature   : RSA/SHA256, Mon 19 Aug 2019 06:06:09 AM EDT, Key ID \nef3c111fcfc659b9\nSource RPM  : httpd-2.4.41-1.fc30.src.rpm\nBuild Date  : Thu 15 Aug 2019 06:07:29 PM EDT\nBuild Host  : buildvm-30.phx2.fedoraproject.org\nRelocations : (not relocatable)\nPackager    : Fedora Project\nVendor      : Fedora Project\nURL         : http://httpd.apache.org/\nBug URL     : https://bugz.fedoraproject.org/httpd\nSummary     : Apache HTTP Server\nDescription :\nThe Apache HTTP Server is a powerful, efficient, and extensible\nweb server.\nThe yumdownloader  command downloads the latest version of the httpd  package to the \ncurrent directory. The rpm -qpi  command queries the httpd  RPM package you just down -\nloaded for information. You can see that the package was created by the Fedora project and \nthat it is indeed the Apache HTTP Server package. Next, look inside the package to see the \nconfiguration files:\n# rpm -qpc httpd-*rpm\n/etc/httpd/conf.d/autoindex.conf\n/etc/httpd/conf.d/userdir.conf\n/etc/httpd/conf.d/welcome.conf\n/etc/httpd/conf.modules.d/00-base.conf\n/etc/httpd/conf.modules.d/00-dav.conf\n...\n/etc/httpd/conf/httpd.conf\n/etc/httpd/conf/magic\n/etc/logrotate.d/httpd\n/etc/sysconfig/htcacheclean\nThe main configuration file is /etc/httpd/conf/httpd.conf  for Apache. The welcome.\nconf  file defines the default home page for your website, until you add some content. The \nmagic  file defines rules that the server can use to figure out a file\u2019s type when the server \ntries to open it.\nThe /etc/logrotate.d/httpd  file defines how log files produced by Apache are rotated. \nThe /usr/lib/tmpfiles.d/httpd.conf  file defines a directory that contains temporary \nruntime files (no need to change that file).\nSome Apache modules drop configuration files ( *.conf ) into the /etc/httpd/conf.\nmodules.d/  directory. Any file in that directory that ends in .conf  is pulled into the \nmain httpd.conf  file and used to configure Apache. Most module packages that come with \nconfiguration files put those configuration files in the /etc/httpd/conf.d  directory. For ", "doc_id": "1f9d783b-9248-42d7-9c43-a7dd30fb99ed", "embedding": null, "doc_hash": "7ac4e2b4cad6cd6326b4fb494fc8f1a81f2daaa50581c50ba9d209248032559f", "extra_info": {"page_label": "453"}, "node_info": {"start": 0, "end": 2173}, "relationships": {"1": "853bc384-6435-4a44-9bd5-3ccd09d61817"}}, "__type__": "1"}, "c483594a-08ea-4117-8c3d-e3eb0de19f57": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator430example, the mod_ssl  (for secure web servers) and mod_python  (for interpreting python \ncode) modules have related configuration files in the /etc/httpd/conf.d  directory named \nssl.conf  and python.conf , respectively.\nYou can just install the httpd  package to begin setting up your web server. However, you \nmight prefer to add some other packages that are often associated with the httpd  package. \nOne way to do that is to install the entire Web Server (in Fedora) or Basic Web Server group \n(in RHEL), as in the following example:\n# yum groupinstall \"Web Server\"\nBesides installing some packages that are peripheral to httpd  (such as rsyslogd , \nirqbalance , and others), here are other packages in the Web Server group in Fedora that \nyou get by default along with httpd :\nhttpd-manual  Fills the /var/www/manual  directory with the Apache documen -\ntation manuals. After you start the httpd service (as shown in later steps), you \ncan access this set of manuals from a web browser on the local machine by typing \nhttp://localhost/manual  into the location box.\nExternally, instead of localhost, you could use the fully qualified domain name or IP \naddress of the system. The Apache Documentation screen then appears, as shown in \nFigure\u00a017.1.\nFIGURE 17.1\nAccess Apache documentation directly from the local Apache server.", "doc_id": "c483594a-08ea-4117-8c3d-e3eb0de19f57", "embedding": null, "doc_hash": "eb297febcdb71078573f33e9402611b891d3f367d095578890c42790d39347d2", "extra_info": {"page_label": "454"}, "node_info": {"start": 0, "end": 1380}, "relationships": {"1": "37993fdf-3d0e-440c-809c-6de8afaa142b"}}, "__type__": "1"}, "3f0af890-0c41-4deb-baa9-101ce86687ba": {"__data__": {"text": "Chapter 17: Configuring a Web Server\n431\n17mod_ssl  Contains the module and configuration file needed for the web server to pro -\nvide secure connections to clients using Secure Sockets Layer (SSL) and Transport \nLayer Security (TLS) protocols. These features are necessary if you need encrypted \ncommunications for online shopping or other data that you want to keep private. \nThe configuration file is located at /etc/httpd/conf.d/ssl.conf .\ncrypto-utils  Contains commands for generating keys and certificates needed to do \nsecure communications with the Apache web server.\nmod_perl  Contains the Perl module ( mod_perl ), configuration file, and associated \nfiles needed to allow the Apache web server to execute any Perl code directly.\nphp Contains the PHP module and configuration file needed to run PHP scripts \ndirectly in Apache. Related packages include php-ldap  (for running PHP code that \nneeds to access LDAP databases) and php-mysql  (to add database support to the \nApache server).\nphp-ldap  Adds support for Lightweight Directory Access Protocol (LDAP) to the PHP \nmodule, allowing directory service access over networks.\nsquid  Provides proxy services for specific protocols (such as HTTP), as mentioned in \nChapter\u00a014, \u201cAdministering Networking.\u201d Although it doesn\u2019t provide HTTP content \nitself, a Squid proxy server typically forwards requests from proxy clients to the \nInternet or other network providing web content. This provides a means of con -\ntrolling or filtering content that clients can reach from a home, school, or place \nof business.\nwebalizer  Contains tools for analyzing web server data.\nOptional packages in the Web Server group come from the web-server sub-group. Run yum \ngroupinfo web-server  to display those packages. Some of those packages offer special \nways of providing content, such as wikis ( moin ), content management systems ( drupal7 ), \nand blogs ( wordpress ). Others include tools for graphing web statistics ( awstats ) or offer \nlightweight web server alternatives to Apache ( lighttpd  and cherokee ).\nInstalling Apache\nAlthough you only need httpd  to get started with an Apache web server, if you are just \nlearning about Apache, you should install the manuals ( httpd-manual ) as well. If you are \nthinking of creating a secure (SSL) site and possibly generating some statistics about your \nwebsite, you can just install the entire group in Fedora 30:\n# yum groupinstall \"Web Server\"\nAssuming that you have an Internet connection to the Fedora repository (or RHEL reposi-\ntory, if you are using RHEL), all of the mandatory and default packages from that group are \ninstalled. You have all of the software that you need to do the procedures and exercises \ndescribed in this chapter.", "doc_id": "3f0af890-0c41-4deb-baa9-101ce86687ba", "embedding": null, "doc_hash": "4fc5028b83d89cb9d2ade354a2a7a3e1f486205f97ce451287a022c091ee6bcf", "extra_info": {"page_label": "455"}, "node_info": {"start": 0, "end": 2744}, "relationships": {"1": "36565ad5-8026-4eb5-8257-6b26d7f8ca0d"}}, "__type__": "1"}, "7366fd00-8b8b-47a7-b47b-977ac1527a43": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator432Starting Apache\nTo get the Apache web server going, you want to enable the service to start on every \nreboot, and you want to start it immediately. In Red Hat Enterprise Linux (up to RHEL 6) \nand in older Fedora distributions, you could type the following as root:\n# chkconfig httpd on\n# service httpd start\nStarting httpd:                [  OK  ]\nIn Fedora 30 and RHEL 8 systems, you enable and start httpd  using the system -\nctl command:\n# systemctl enable httpd.service\n# systemctl start httpd.service\n# systemctl status httpd.service\n\u2022 httpd.service - The Apache HTTP Server\n   Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled;\n    vendor preset: disabled)\n  Drop-In: /usr/lib/systemd/system/httpd.service.d\n           \u2514\u2500php-fpm.conf\n   Active: active (running) since Mon 2019-09-02 16:16:56 EDT;\n    21min ago\n     Docs: man:httpd.service(8)\n Main PID: 11773 (/usr/sbin/httpd)\n   Status: \"Total requests: 14; Idle/Busy workers 100/0;Requests/sec:\n    0.0111; Bytes served/s>\n    Tasks: 214 (limit: 2294)\n   Memory: 24.6M\n   CGroup: /system.slice/httpd.service\n           \u251c\u250011773 /usr/sbin/httpd -DFOREGROUND\n           \u251c\u250011774 /usr/sbin/httpd -DFOREGROUND\n           \u251c\u250011775 /usr/sbin/httpd -DFOREGROUND\n           \u251c\u250011776 /usr/sbin/httpd -DFOREGROUND\n           \u251c\u250011777 /usr/sbin/httpd -DFOREGROUND\n           \u2514\u250011778 /usr/sbin/httpd -DFOREGROUND\n    ...\nWhen the httpd  service starts, five or six httpd  daemon processes are launched by default \n(depending on your Linux system) to respond to requests for the web server. You can configure  \nmore or fewer httpd  daemons to be started based on settings in the httpd.conf  file \n(described in the section \u201cUnderstanding the Apache configuration files\u201d later in this chapter).\nTo change the behavior of the httpd  daemon, you can edit the httpd  service by running \nsystemctl edit httpd .\nBecause there are different versions of httpd  around, check the man page ( man httpd ) to \nsee what options can be passed to the httpd  daemon. For example, run systemctl edit \nhttpd  and add an entry as follows:\n[Service]\nEnvironment=OPTIONS='-e debug'", "doc_id": "7366fd00-8b8b-47a7-b47b-977ac1527a43", "embedding": null, "doc_hash": "02b799d66c4f0afdc2be4bb76fdf6d24369e78009571ba08276c310e3337a51f", "extra_info": {"page_label": "456"}, "node_info": {"start": 0, "end": 2163}, "relationships": {"1": "b967fd86-cc0a-47f2-a128-ff533bff7c9c"}}, "__type__": "1"}, "23de6620-8de3-4b8b-b419-77d926829fc3": {"__data__": {"text": "Chapter 17: Configuring a Web Server\n433\n17Save the changes (Ctrl+O, Ctrl+X). Adding -e debug  increases the log level so that \nthe maximum number of Apache messages are sent to log files. Restart the httpd  ser-\nvice for the changes to take effect. Type the ps  command to make sure that the options \ntook effect:\n$ ps -ef | grep httpd\nroot   14575 1     0 08:49 ? 00:00:01 /usr/sbin/httpd -e debug \n-DFOREGROUND\napache 14582 14575 0 08:49 ? 00:00:00 /usr/sbin/httpd -e debug \n-DFOREGROUND\nIf you added a debug option ( -e debug ), remember to remove that option by running \nsystemctl edit httpd again and removing the entry when you are done debugging \nApache, and restart the service. Leaving debugging on will quickly fill up your log files.\nSecuring Apache\nTo secure Apache, you need to be aware of standard Linux security features (permissions, \nownership, firewalls, and Security Enhanced Linux) as well as security features that are \nspecific to Apache. The following sections describe security features that relate to Apache.\nApache file permissions and ownership\nThe httpd  daemon process runs as the user apache  and group apache . By default, HTML \ncontent is stored in the /var/www/html  directory (as determined by the value of Docu -\nmentRoot  in the httpd.conf  file).\nFor the httpd  daemon to be able to access that content, standard Linux permissions apply: \nIf read permission is not on for \u201cother\u201d users, it must be on for the apache  user or group \nfor the files to be read and served to clients. Likewise, any directory the httpd  daemon \nmust traverse to get to the content must have execute permission on for the apache  user, \napache  group, or other user.\nAlthough you cannot log in as the apache  user (/sbin/nologin  is the default shell), \nyou can create content as root and change its ownership ( chown  command) or permission \n(chmod  command). Often, however, separate user or group accounts are added to create \ncontent that is readable by everyone (other) but only writable by that special user or group.\nApache and firewalls\nIf you have locked down your firewall in Linux, you need to open several ports for clients \nto be able to talk to Apache through the firewall. Standard web service (HTTP) is accessible \nover TCP port 80; secure web service (HTTPS) is accessible via TCP port 443. (Port 443 only \nappears if you have installed the mod_ssl  package, as described later.)\nTo verify which ports are being used by the httpd  server, use the netstat  command:\n# netstat -tupln | grep httpd\ntcp6   0      0 :::80           :::*                 LISTEN      29169/httpd\ntcp6   0      0 :::443          :::*                 LISTEN      29169/httpd", "doc_id": "23de6620-8de3-4b8b-b419-77d926829fc3", "embedding": null, "doc_hash": "16f7f6cd27e9fe05c51a26febce705ec00dc0dfebe9c18eca947c5e63c22c272", "extra_info": {"page_label": "457"}, "node_info": {"start": 0, "end": 2680}, "relationships": {"1": "a787aeed-3d0f-49a7-a8c4-c76bfddbbe38"}}, "__type__": "1"}, "c9a68b45-2f9e-462d-ba66-b20d47a0f9e9": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator434The output shows that the httpd  daemon (process ID 29169) is listening on all addresses \nfor port 80 ( :::80 ) and port 443 ( :::443 ). Both ports are associated with the TCP protocol \n(tcp6 ). To open those ports in Fedora or Red Hat Enterprise Linux, you need to add some \nfirewall rules.\nOn a current Fedora 30 or RHEL 7 or 8 system, open the Firewall window (type Firewall and \npress Enter from the Activities screen on the GNOME 3 desktop). From there, select Perma -\nnent as the configuration. Then, with the public zone selected, click the check boxes next \nto the http and https service boxes. Those ports immediately become open.\nFor RHEL 6 or older Fedora releases, add rules to the /etc/sysconfig/iptables  file \n(somewhere before a final DROP  or REJECT ) such as the following:\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 443 -j ACCEPT\nRestart iptables  (service iptables restart ) for the new rules to take effect.\nApache and SELinux\nIf Security Enhanced Linux (SELinux)  is set to enforcing (as it is by default in Fedora and Red \nHat Enterprise Linux), SELinux adds another layer of security over your httpd  service. In \nessence, SELinux actually sets out to protect the system from being damaged by someone \nwho may have cracked the httpd  daemon. SELinux does this by creating policies that do \nthe following:\n\u25a0\u25a0Deny access to files that are not set to the right file contexts. For httpd  in \nSELinux, there are different file contexts for content, configuration files, log files, \nscripts, and other httpd -related files. Any file that is not set to the proper context \nis not accessible to the httpd  daemon.\n\u25a0\u25a0Prevent insecure features from being used, such as file uploading and clear-text \nauthentication, by setting Booleans for such features to the off position. You \ncan selectively turn on Booleans as they are needed\u2014if they meet your security \nrequirements.\n\u25a0\u25a0Keep the httpd  daemon from accessing nonstandard features, such as a port out -\nside of the default ports the service would expect to use.\nA full description of SELinux is contained in Chapter\u00a024, \u201cEnhancing Linux Security with \nSELinux.\u201d However, here are a few specifics you should know about using SELinux with the \nApache httpd  service:\nTurn off SELinux You don\u2019t have to use SELinux. You can set SELinux to permissive \nmode if you feel that it is too difficult and unnecessary to create the SELinux pol -\nicies needed to get your web server to work with SELinux in enforcing mode. You \ncan change the mode to permissive by editing the /etc/sysconfig/selinux  file \nso that the SELINUX  value is set as follows. With this set, the next time you reboot \nthe system, it is in permissive mode. This means that if you break SELinux policies, \nthat event is logged but not prevented (as it would be in enforcing mode).\nSELINUX=permissive", "doc_id": "c9a68b45-2f9e-462d-ba66-b20d47a0f9e9", "embedding": null, "doc_hash": "5261cc06ce7713a7eebaf6a57d07aaf27946addecd534f2737ac4223a8f42449", "extra_info": {"page_label": "458"}, "node_info": {"start": 0, "end": 2951}, "relationships": {"1": "caf67602-181d-4975-85ae-57f6d7316635"}}, "__type__": "1"}, "5dba078c-e733-48d5-9e76-c035cb0f9103": {"__data__": {"text": "Chapter 17: Configuring a Web Server\n435\n17Read the httpd_selinux man page Type man httpd_selinux  from the shell. This \nman page shows you the proper file contexts and available Booleans. (If the man \npage is not there, install it with yum install selinux-policy-doc .)\nUse standard locations for files When you create new files, those files inherit the \nfile contexts of the directories in which they are stored. Because /etc/httpd  is set \nto the right file context for configuration files, /var/www/html  is right for con -\ntent files, and so on. Simply copying files to or creating new files in those locations \ncauses the file contexts to be set properly.\nModify SELinux to allow non-standard features You may want to serve web content \nfrom the /mystuff  directory or put configuration files in the /etc/whatever  \ndirectory. Likewise, you may want to allow users of your server to upload files, run \nscripts, or enable other features that are disabled by SELinux by default. In those \ncases, you can use SELinux commands to set the file contexts and Booleans that you \nneed to get SELinux working the way you want.\nBe sure to read Chapter\u00a024, \u201cEnhancing Linux Security with SELinux,\u201d to learn more \nabout SELinux.\nUnderstanding the Apache configuration files\nThe configuration files for Apache HTTPD are incredibly flexible, meaning that you can \nconfigure the server to behave in almost any manner you want. This flexibility comes at \nthe cost of increased complexity in the form of a large number of configuration options \n(called directives ). In practice, however, you need to be familiar with only a few directives \nin most cases.\nNote\nSee http://httpd.apache.org/docs/current/mod/directives.html  for a complete list of directives \nsupported by Apache. If you have httpd-manual  installed, you can reach descriptions of these directives and other \nApache features by opening the manual from the server you have running Apache: http://localhost/ manual/ .\nIn Fedora and RHEL, the basic Apache server\u2019s primary configuration file is in /etc/httpd/\nconf/httpd.conf . Besides this file, any file ending in .conf  in the /etc/httpd/conf.d  \ndirectory is also used for Apache configuration (based on an Include  line in the httpd.\nconf  file). In Ubuntu, the Apache configuration is stored in text files read by the Apache \nserver, beginning with /etc/apache2/apache2.conf . Configuration is read from start to \nfinish, with most directives being processed in the order in which they are read.\nUsing directives\nThe scope of many configuration directives can be altered based on context. In other words, \nsome parameters may be set on a global level and then changed for a specific file, direc -\ntory, or virtual host. Other directives are always global in nature, such as those specifying \non which IP addresses the server listens. Still others are valid only when applied to a spe -\ncific location.", "doc_id": "5dba078c-e733-48d5-9e76-c035cb0f9103", "embedding": null, "doc_hash": "0e4fa4a14e07d94188c724398f37a4bf9258ea3d834c1d39c59fb8d4a79de258", "extra_info": {"page_label": "459"}, "node_info": {"start": 0, "end": 2907}, "relationships": {"1": "5aff0cc5-bf6f-45d5-8dac-a2cc16e2e011"}}, "__type__": "1"}, "2fda79e1-dc38-4312-961e-82df15af96d1": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator436Locations are configured in the form of a start tag containing the location type and a \nresource location, followed by the configuration options for that location, and finishing \nwith an end tag. This form is often called a configuration block , and it looks very similar to \nHTML code. A special type of configuration block, known as a location block , is used to limit \nthe scope of directives to specific files or directories. These blocks take the following form:\n<locationtag specifier>\n(options specific to objects matching the specifier go within this \nblock)\n</locationtag>\nDifferent types of location tags exist and are selected based on the type of resource loca -\ntion that is being specified. The specifier included in the start tag is handled based on the \ntype of location tag. The location tags that you generally use and encounter are Direc -\ntory , Files , and Location , which limit the scope of the directives to specific direc -\ntories, files, or locations, respectively.\n\u25a0\u25a0Directory  tags are used to specify a path based on the location on the filesystem. \nFor instance, <Directory />  refers to the root directory on the computer. Direc -\ntories inherit settings from directories above them, with the most specific Direc -\ntory  block overriding less-specific ones, regardless of the order in which they \nappear in the configuration files.\n\u25a0\u25a0Files  tags are used to specify files by name. Files  tags can be contained within \na Directory  block to limit them to files under that directory. Settings within a \nFiles  block override the ones in Directory  blocks.\n\u25a0\u25a0Location  tags are used to specify the URI used to access a file or directory. This \nis different from Directory  in that it relates to the address contained within the \nrequest and not to the real location of the file on the drive. Location  tags are pro -\ncessed last and override the settings in Directory  and Files  blocks.\nMatch versions of these tags\u2014 DirectoryMatch , FilesMatch , and LocationMatch \u2014\nhave the same function but can contain regular expressions in the resource specification. \nFilesMatch  and LocationMatch  blocks are processed at the same time as Files  and \nLocation , respectively. DirectoryMatch  blocks are processed after Directory  blocks.\nApache can also be configured to process configuration options contained within files \nwith the name specified in the AccessFileName  directive (which is generally set to \n.htaccess ). Directives in access configuration files are applied to all objects under the \ndirectory they contain, including subdirectories and their contents. Access configuration \nfiles are processed at the same time as Directory  blocks, using a similar \u201cmost specific \nmatch\u201d order.", "doc_id": "2fda79e1-dc38-4312-961e-82df15af96d1", "embedding": null, "doc_hash": "cc50107a5c04a715eb4979cfef7c2a83cd1dd2e3a36230e61cf168902a8d8636", "extra_info": {"page_label": "460"}, "node_info": {"start": 0, "end": 2766}, "relationships": {"1": "7ce586d9-5182-475b-ae18-37870ea75fe6"}}, "__type__": "1"}, "60b1ea8f-aae4-4c98-8038-e1cad00adff8": {"__data__": {"text": "Chapter 17: Configuring a Web Server\n437\n17Three directives commonly found in location blocks and access control files are Directo -\nryIndex , Options , and ErrorDocument :\n\u25a0\u25a0DirectoryIndex  tells Apache which file to load when the URI contains a direc -\ntory but not a filename. This directive doesn\u2019t work in Files  blocks.\n\u25a0\u25a0Options  is used to adjust how Apache handles files within a directory. The Exec -\nCGI option tells Apache that files in that directory can be run as CGI scripts, and \nthe Includes  option tells Apache that server-side includes (SSIs) are permitted. \nAnother common option is the Indexes  option, which tells Apache to generate \na list of files if one of the filenames found in the DirectoryIndex  setting is \nmissing. An absolute list of options can be specified, or the list of options can \nbe modified by adding +  or - in front of an option name. See http://httpd.\napache.org/docs/mod/core.html#options  for more information.\n\u25a0\u25a0ErrorDocument  directives can be used to specify a file containing messages to \nsend to web clients when a particular error occurs. The location of the file is rela -\ntive to the /var/www  directory. The directive must specify an error code and the \nfull URI for the error document. Possible error codes include 403  (access denied), \n404 (file not found), and 500  (server internal error). You can find more informa -\ntion about the ErrorDocument  directive at http://httpd.apache.org/docs/\nmod/core.html#errordocument . As an example, when a client requests a URL \nfrom the server that is not found, the following ErrorDocument  line causes the \n404 error code to send the client an error message that is listed in the /var/www/\nerror/HTTP_NOT_FOUND.html.var  file.\nErrorDocument 404 /error/HTTP_NOT_FOUND.html.var\nAnother common use for location blocks and access control files is to limit or expand access \nto a resource. The Allow  directive can be used to permit access to matching hosts, and \nthe Deny  directive can be used to forbid it. Both of these options can occur more than \nonce within a block and are handled based on the Order  setting. Setting Order  to Deny, \nAllow  permits access to any host that is not listed in a Deny  directive. A setting of \nAllow , Deny  denies access to any host not allowed in an Allow  directive.Note\nAccess control files are useful for allowing users to change specific settings without having access to the server \n configuration files. The configuration directives permitted within an access configuration file are determined by the  \nAllowOverride  setting on the directory in which they are contained. Some directives do not make sense at that \nlevel and generally result in a \u2033 server internal error \u2033 message when trying to access the URI. The AllowOverride  \noption is covered in detail at http://httpd.apache.org/docs/mod/core.html#allowoverride .", "doc_id": "60b1ea8f-aae4-4c98-8038-e1cad00adff8", "embedding": null, "doc_hash": "cb15ace979b9e132a5fa2174bc9ad5766ad52f4ba8a5d64f00135bcce5cadf76", "extra_info": {"page_label": "461"}, "node_info": {"start": 0, "end": 2863}, "relationships": {"1": "1a9a02fd-75d8-473e-89f6-24c26f4bfeea"}}, "__type__": "1"}, "6a1fbc99-97ef-4f12-95f6-b20460a8a5df": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator438As with most other options, the most specific Allow  or Deny  option for a host is used, \nmeaning that you can Deny  access to a range and Allow  access to subsets of that range. \nBy adding the Satisfy  option and some additional parameters, you can add password \nauthentication. For more information on Allow  or Deny , Satisfy , or other directives, \nrefer to the Apache Directive Index: http://httpd.apache.org/docs/current/mod/\ndirectives.html.\nUnderstanding default settings\nThe reason you can start using your Apache web server as soon as you install it is that the \nhttpd.conf  file includes default settings that tell the server where to find web content, \nscripts, log files, and other items that the server needs to operate. It also includes settings \nthat tell the server how many server processes to run at a time and how directory contents \nare displayed.\nIf you want to host a single website (such as for the example.com  domain), you can sim-\nply add content to the /var/www/html  directory and add the address of your website to a \nDNS server so that others can browse to it. You can then change directives, such as those \ndescribed in the previous section, as needed.\nTo help you understand the settings that come in the default httpd.conf  file, I\u2019ve dis -\nplayed some of those settings with descriptions below. I have removed comments and rear -\nranged some of the settings for clarity.\nThe following settings show locations where the httpd  server is getting and putting con -\ntent by default:\nServerRoot \"/etc/httpd\"\nInclude conf.d/*.conf\nErrorLog logs/error_log\nCustomLog \"logs/access_log\" combined\nDocumentRoot \"/var/www/html\"\nScriptAlias /cgi-bin/ \"/var/www/cgi-bin/\"\nThe ServerRoot  directive identifies /etc/httpd  as the location where configuration files \nare stored.\nAt the point in the file where the Include  line appears, any files ending in .conf  from \nthe /etc/httpd/conf.d  directory are included in the httpd.conf  file. Configura -\ntion files are often associated with Apache modules (and are often included in the soft -\nware package with a module) or with virtual host blocks (which you might add yourself \nto virtual host configurations in separate files). See the section \u201cAdding a virtual host to \nApache\u201d later in this chapter.\nAs errors are encountered and content is served, messages about those activities are placed \nin files indicated by the ErrorLog  and CustomLog  entries. From the entries shown here, \nthose logs are stored in the /etc/httpd/logs/error_log  and /etc/httpd/logs/\naccess_log  directories, respectively. Those logs are also hard linked to the /var/log/\nhttpd  directory, so you can access the same file from there as well.", "doc_id": "6a1fbc99-97ef-4f12-95f6-b20460a8a5df", "embedding": null, "doc_hash": "1954f266ed61d8c94f09e369347b1eb304d33cd4e667e9b8ba38423d7cf3bc87", "extra_info": {"page_label": "462"}, "node_info": {"start": 0, "end": 2738}, "relationships": {"1": "8b9a67d7-e2c0-4853-9b30-4a0cf16a682b"}}, "__type__": "1"}, "15473392-b4f4-4f4f-be3f-6836ff55968f": {"__data__": {"text": "Chapter 17: Configuring a Web Server\n439\n17The DocumentRoot  and ScriptAlias  directives determine where content that is served \nby your httpd  server is stored. Traditionally, you would place an index.html  file in the \nDocumentRoot  directory ( /var/www/html , by default) as the home page and add other \ncontent as needed. The ScriptAlias  directive tells the httpd  daemon that any scripts \nrequested from the cgi-bin  directory should be found in the /var/www/cgi-bin  direc -\ntory. For example, a client could access a script located in /var/www/cgi-bin/script.\ncgi by entering a URL such as http://example.com/cgi-bin/script.cgi .\nIn addition to file locations, you can find other information in the httpd.conf  file. Here \nare some examples:\nListen 80\nUser apache\nGroup apache\nServerAdmin root@localhost\nDirectoryIndex index.html index.php\nAccessFileName .htaccess\nThe Listen 80  directive tells httpd  to listen for incoming requests on port 80 (the \ndefault port for the HTTP web server protocol). By default, it listens on all network inter -\nfaces, although you could restrict it to selected interfaces by IP address (for example,  \nListen 192.168.0.1:80 ).\nThe User  and Group  directives tell httpd  to run as apache  for both the user and group. \nThe value of ServerAdmin  (root@localhost , by default) is published on some web \npages to tell users where to email if they have problems with the server.\nThe DirectoryIndex  lists files that httpd  will serve if a directory is requested. For \nexample, if a web browser requested http://host/whatever/ , httpd  would see whether \n/var/www/html/whatever/index.html  existed and serve it if so. If it didn\u2019t exist, in \nthis example, httpd  would look for index.php . If that file couldn\u2019t be found, the con -\ntents of the directory would be displayed. An AccessFileName  directive can be added \nto tell httpd  to use the contents of the .htaccess  file if it exists in a directory to read \nin settings that apply to access to that directory. For example, the file could be used to \nrequire password protection for the directory or to indicate that the contents of the direc -\ntory should be displayed in certain ways. For this file to work, however, a Directory  \ncontainer (described next) would have to have AllowOverride  opened. (By default, the \nAllowOverride None  setting prevents the .htaccess  file from being used for any \ndirectives.)\nThe following Directory  containers define behavior when the root directory ( /),  \n/var/www , and /var/www/html  directories are accessed:\n<Directory/>\n    AllowOverride none\n    Require all denied\n</Directory>\n<Directory \"/var/www\">\n    AllowOverride None", "doc_id": "15473392-b4f4-4f4f-be3f-6836ff55968f", "embedding": null, "doc_hash": "e6975ef34ba66fc004cf717bdad476447caae199029b776cd461651e54d8a961", "extra_info": {"page_label": "463"}, "node_info": {"start": 0, "end": 2664}, "relationships": {"1": "61bd7d6e-2568-4363-b252-72ec2a5ccc50"}}, "__type__": "1"}, "3672b6b7-e060-480b-8361-7c9ab6b3d7a5": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator440    # Allow open access:\n    Require all granted\n</Directory>\n<Directory \"/var/www/html\">\n    Options Indexes FollowSymLinks\n    AllowOverride None\n    Require all granted\n</Directory>\nThe first Directory  container ( /) indicates that if httpd  tries to access any files  \nin the Linux filesystem, access is denied. The AllowOverride none  directive prevents \n.htaccess  files from overriding settings for that directory. Those settings apply to any \nsubdirectories that are not defined in other Directory  containers.\nContent access is relaxed within the /var/www  directory. Access is granted to content \nadded under that directory, but overriding settings is not allowed.\nThe /var/www/html Directory  container follows symbolic links and does not allow \noverrides. With Require all granted set, httpd  doesn\u2019t prevent any access to \nthe server.\nIf all of the settings just described work for you, you can begin adding the content that you \nwant to the /var/www/html  and /var/www/cgi-bin html  directories. One reason you \nmight not be satisfied with the default setting is that you might want to serve content for \nmultiple domains (such as example.com , example.org , and example.net ). To do that, \nyou need to configure virtual hosts. Virtual hosts, which are described in greater detail in \nthe next section, are a convenient (and almost essential) tool for serving different content \nto clients based on the server address or name to which a request is directed. Most global \nconfiguration options are applied to virtual hosts, but they can be overridden by directives \nwithin the VirtualHost  block.\nAdding a virtual host to Apache\nApache supports the creation of separate websites within a single server to keep content \nseparate. Individual sites are configured on the same server in what are referred to as vir -\ntual hosts .\nVirtual hosts  are really just a way to have the content for multiple domain names avail -\nable from the same Apache server. Instead of needing to have one physical system to \nserve content for each domain, you can serve content for multiple domains from the same \noperating system.\nAn Apache server that is doing virtual hosting may have multiple domain names that \nresolve to the IP address of the server. The content that is served to a web client is based \non the name used to access the server.\nFor example, if a client got to the server by requesting the name www.example.com , \nthe client would be directed to a virtual host container that had its ServerName  set to ", "doc_id": "3672b6b7-e060-480b-8361-7c9ab6b3d7a5", "embedding": null, "doc_hash": "79302d91c417eb873687c46e2f2fcf26b9b4da10fe8a12d64eadc367023fa0ed", "extra_info": {"page_label": "464"}, "node_info": {"start": 0, "end": 2563}, "relationships": {"1": "cba3c393-97ed-485e-bc1b-405a1f6529a1"}}, "__type__": "1"}, "0c01c99a-4c9c-40a1-bc16-0ebac457785a": {"__data__": {"text": "Chapter 17: Configuring a Web Server\n441\n17respond to www.example.com . The container would provide the location of the content \nand possibly different error logs or Directory  directives from the global settings. This \nway, each virtual host could be managed as if it were on a separate machine.\nTo use name-based virtual hosting, add as many VirtualHost  containers as you like. \nHere\u2019s how to configure a virtual host:\nNote\nAfter you enable your first VirtualHost , your default DocumentRoot  (/var/www/html ) is no longer used \nif someone accesses the server by IP address or some name that is not set in a VirtualHost  container. Instead, \nthe first VirtualHost  container is used as the default location for the server.\n1. In Fedora or RHEL, create a file named /etc/httpd/conf.d/example.org.\nconf  using this template:\n \n<VirtualHost *:80>\n    ServerAdmin     webmaster@example.org\n    ServerName      www.example.org\n    ServerAlias     web.example.org\n    DocumentRoot    /var/www/html/example.org/\nDirectoryIndex  index.php index.html index.htm\n</VirtualHost>\nThis example includes the following settings:\n\u25a0\u25a0The *:80  specification in the VirtualHost  block indicates to what address and \nport this virtual host applies. With multiple IP addresses associated with your \nLinux system, the *  can be replaced by a specific IP address. The port is optional \nfor VirtualHost  specifications but should always be used to prevent interfer -\nence with SSL virtual hosts (which use port 443 by default).\n\u25a0\u25a0The ServerName  and ServerAlias  lines tell Apache which names this vir -\ntual host should be recognized as, so replace them with names appropriate to \nyour site. You can leave out the ServerAlias  line if you do not have any \nalternate names for the server, and you can specify more than one name per \nServerAlias  line or have multiple ServerAlias  lines if you have several \nalternate names.\n\u25a0\u25a0The DocumentRoot  specifies where the web documents (content served for \nthis site) are stored. Although shown as a subdirectory that you create under \nthe default DocumentRoot  (/var/www/html ), often sites are attached to the \nhome directories of specific users (such as /home/chris/public_html ) so \nthat each site can be managed by a different user.", "doc_id": "0c01c99a-4c9c-40a1-bc16-0ebac457785a", "embedding": null, "doc_hash": "dd61438d9ebf10f435da7608895b77be6a7dab27a34c3fba0506f39ae2754ace", "extra_info": {"page_label": "465"}, "node_info": {"start": 0, "end": 2258}, "relationships": {"1": "dd08245f-a602-4b5f-8bbc-8c6868d74684"}}, "__type__": "1"}, "f39337d5-aae2-47ff-b422-d96496e290e7": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator4422. With the host enabled, use apachectl  to check the configuration, and then do \na graceful  restart:\n# apachectl configtest\nSyntax OK\n# apachectl graceful\nProvided that you have registered the system with a DNS server, a web browser should be \nable to access this website using either www.example.org  or web.example.org . If that \nworks, you can start adding other virtual hosts to the system as well.\nAnother way to extend the use of your website is to allow multiple users to share their \nown content on your server. You can enable users to add content that they want to \nshare via your web server in a subdirectory of their home directories, as described in the \nnext section.\nNote\nKeeping individual virtual hosts in separate files is a convenient way to manage virtual hosts. However, you should \nbe careful to keep your primary virtual host in a file that will be read before the others because the first virtual host \nreceives requests for site names that don\u2019t match any in your configuration. In a commercial web-hosting environ -\nment, it is common to create a special default virtual host that contains an error message indicating that no site by \nthat name has been configured.\nAllowing users to publish their own web content\nIn situations where you do not have the ability to set up a virtual host for every user  \nfor whom you want to provide web space, you can easily make use of the mod_userdir  \nmodule in Apache. With this module enabled (which it is not by default), the  \npublic_html directory under every user\u2019s home directory is available to the web at  \nhttp://servername/~username/.\nFor example, a user named wtucker  on www.example.org  stores web content in  \n/home/wtucker/public_html . That content would be available from  \nhttp://www.example.org/~wtucker .\nMake these changes to the /etc/httpd/conf/httpd.conf  file to allow users to publish \nweb content from their own home directories. Not all versions of Apache have these blocks \nin their httpd.conf  file, so you might have to create them from scratch:\n1. Create a <IfModule mod_userdir.c>  block . Change chris  to any username \nyou want to allow users to create their own public_html  directory. You can add \nmultiple usernames.\n<IfModule mod_userdir.c>\n     UserDir enabled chris\n     UserDir public_html\n</IfModule>", "doc_id": "f39337d5-aae2-47ff-b422-d96496e290e7", "embedding": null, "doc_hash": "5ce3c055e42e5cd4c4f5735dc8af3375cc89f85c3fd4e3ea8a81d7be63cf432c", "extra_info": {"page_label": "466"}, "node_info": {"start": 0, "end": 2356}, "relationships": {"1": "9b4d510c-465c-4aa7-8ab2-1338342cac7c"}}, "__type__": "1"}, "43b9cf79-b0ab-4894-a630-178a09c586ef": {"__data__": {"text": "Chapter 17: Configuring a Web Server\n443\n172. Create a <Directory /home/*/public_html> directive block and change \nany settings you like . This is how the block will look:\n \n<Directory \"/home/*/public_html\">\n    Options Indexes Includes FollowSymLinks\n    Require all granted\n</Directory>\n3. Have your users create their own public_html directories in their own home \ndirectories .\n$ mkdir $HOME/public_html\n4. Set the execute permission (as root user) to allow the httpd  daemon to access \nthe home directory :\n# chmod +x /home /home/*\n5. If SELinux is in enforcing mode (which it is by default in Fedora and RHEL),  \na proper SELinux file context ( httpd_user_content_t) should already be set \non the following directories so that SELinux allows the httpd  daemon  \nto access the content automatically: /home/*/www , /home/*/web , and  \n/home/*/public_html . If for some reason the context is not set, you  \ncan set it as follows:\nttpd_user_content_t to /home/*/ \n# chcon -R --reference=/var/www/html/ /home/*/public_html\n6. Set the SELinux Boolean to allow users to share HTML content from their home \ndirectories :\n# setsebool \u2013P httpd_enable_homedirs true\n7. Restart or reload the httpd  service .\nAt this point, you should be able to access content placed in a user\u2019s  \npublic_html  directory by pointing a web browser to http:  \n//hostname/~user.\nSecuring your web traffic with SSL/TLS\nAny data that you share from your website using standard HTTP protocol is sent in clear \ntext. This means that anyone who can watch the traffic on a network between your server \nand your client can view your unprotected data. To secure that information, you can add \ncertificates to your site (so a client can validate who you are) and encrypt your data (so \nnobody can sniff your network and see your data).\nElectronic commerce applications, such as online shopping and banking, should always be \nencrypted using either the Secure Sockets Layer (SSL) or Transport Layer Security (TLS) \nspecification. TLS is based on version 3.0 of the SSL specifications, so they are very similar \nin nature. Because of this similarity\u2014and because SSL is older\u2014the SSL acronym is often \nused to refer to either variety. For web connections, the SSL connection is established first, \nand then normal HTTP communication is \u201ctunneled\u201d through it.", "doc_id": "43b9cf79-b0ab-4894-a630-178a09c586ef", "embedding": null, "doc_hash": "716035b788f648326673ea5f2f70696a139eb9cbf7ab49e84667d58cb13f4a66", "extra_info": {"page_label": "467"}, "node_info": {"start": 0, "end": 2321}, "relationships": {"1": "9c8faed4-72c6-4fa0-8e29-3cd39ea646b5"}}, "__type__": "1"}, "1ae59746-d0a6-4597-bb2b-c54e3a9a72d7": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator444While you are establishing a connection between an SSL client and an SSL server, asym-\nmetric (public key) cryptography is used to verify identities and establish the session \nparameters and the session key. A symmetric encryption algorithm is then used with the \nnegotiated key to encrypt the data that are transmitted during the session. The use of \nasymmetric encryption during the handshaking phase allows safe communication without \nthe use of a preshared key, and the symmetric encryption is faster and more practical for \nuse on the session data.\nFor the client to verify the identity of the server, the server must have a previously gen -\nerated private key as well as a certificate containing the public key and information \nabout the server. This certificate must be verifiable using a public key that is known to \nthe client.\nCertificates are generally digitally signed by a third-party certificate authority (CA)  that has \nverified the identity of the requester and the validity of the request to have the certifi-\ncate signed. In most cases, the CA is a company that has made arrangements with the web \nbrowser vendor to have its own certificate installed and trusted by default client installa -\ntions. The CA then charges the server operator for its services.\nCommercial certificate authorities vary in price, features, and browser support, but remem-\nber that price is not always an indication of quality. Some popular CAs are InstantSSL \n(https://www.instantssl.com ), Let\u2019s Encrypt ( https://www.letsencrypt.org ), and \nDigiCert (https://www.digicert.com ).\nYou also have the option of creating self-signed certificates, although these should be used \nonly for testing or when a very small number of people will be accessing your server and \nyou do not plan to have certificates on multiple machines. Directions for generating a self-\nsigned certificate are included in the section \u201cGenerating an SSL key and self-signed certif -\nicate\u201d later in this chapter.\nThe last option is to run your own certificate authority. This is probably practical only if \nyou have a small number of expected users and the means to distribute your CA certificate \nto them (including assisting them with installing it in their browsers). The process for cre -\nating a CA is too elaborate to cover in this book, but it is a worthwhile alternative to gener -\nating self-signed certificates.\nThe following sections describe how HTTPS communications are configured by default in \nFedora and RHEL when you install the mod_ssl  package. After that, I describe how to \nconfigure SSL communications better by generating your own SSL keys and certificates to \nuse with the web server (running on a Fedora or RHEL system) configured in this chapter.Note\nBecause SSL negotiation takes place before any HTTP communication, name-based virtual hosting (which occurs at \nthe HTTP layer) does not work easily with SSL. As a consequence, every SSL virtual host you configure should have \na unique IP address. (See the Apache site for more information: httpd.apache.org/docs/vhosts/name-\nbased.html .)", "doc_id": "1ae59746-d0a6-4597-bb2b-c54e3a9a72d7", "embedding": null, "doc_hash": "4b38590ea831084a77dfca14a5ab67985757a4425355c3128b5777c9b035b0d4", "extra_info": {"page_label": "468"}, "node_info": {"start": 0, "end": 3131}, "relationships": {"1": "ec815257-65da-43a7-8ff1-2ca25a11859d"}}, "__type__": "1"}, "54d24904-1db7-4510-ac35-6a777d9ab8e1": {"__data__": {"text": "Chapter 17: Configuring a Web Server\n445\n17Understanding how SSL is configured\nIf you have installed the mod_ssl  package in Fedora or RHEL (which is done by default if \nyou installed the Basic Web Server group), a self-signed certificate and private key are cre -\nated when the package is installed. This allows you to use HTTPS protocol immediately to \ncommunicate with the web server.\nAlthough the default configuration of mod_ssl  allows you to have encrypted communica -\ntions between your web server and clients, because the certificate is self-signed, a client \naccessing your site is warned that the certificate is untrusted. To begin exploring the \nSSL configuration for your Apache web server, make sure that the mod_ssl  package is \ninstalled on the server running your Apache (httpd)  service:\n# yum install mod_ssl\nThe mod_ssl package includes the module needed to implement SSLon your web server \n(mod_ssl.so ) and a configuration file for your SSL hosts: /etc/httpd/conf.d/ssl.conf . \nThere are many comments in this file to help you understand what to change. Those lines \nthat are not commented out define some initial settings and a default virtual host. Here are \nsome of those lines:\nListen 443 https\n...\n<VirtualHost _default_:443>\nErrorLog logs/ssl_error_log\nTransferLog logs/ssl_access_log\nLogLevel warn\nSSLEngine on\n...\nSSLCertificateFile /etc/pki/tls/certs/localhost.crt\nSSLCertificateKeyFile /etc/pki/tls/private/localhost.key\n...\n</VirtualHost>\nThe SSL service is set to listen on standard SSL port 443 on all the system's network \ninterfaces.\nA VirtualHost  block is created that causes error messages and access messages  \nto be logged to log files that are separate from the standard logs used by the server  \n(ssl_error_log  and ssl_access_log  in the /var/log/httpd/  directory). The level \nof log messages is set to warn  and the SSLEngine is turned on.\nIn the preceding sample code, two entries associated with SSL Certificates in the Virtu -\nalHost  block identify the key and certificate information. As mentioned previously, a key \nis generated when mod_ssl  is installed and placed in the file /etc/pki/tls/private/\nlocalhost.key . A self-signed certificate, /etc/pki/tls/certs/localhost.crt , is \ncreated using that key. When you create your own key and certificate later, you need to \nreplace the values of SSLCertificateFile  and SSLCertificateKeyFile  in this file.", "doc_id": "54d24904-1db7-4510-ac35-6a777d9ab8e1", "embedding": null, "doc_hash": "94f85638f158f47fc2c057167c14e8d7406c8c340f2262369eff527d9932ccdb", "extra_info": {"page_label": "469"}, "node_info": {"start": 0, "end": 2407}, "relationships": {"1": "ddd0d686-8d51-4943-927c-a877647e69bb"}}, "__type__": "1"}, "7de6e759-de29-48d6-a428-1b6e79f0ca4e": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator446After installing the mod_ssl  package and reloading the configuration file, you can test \nthat the default certificate is working by following these steps:\n1. Open a connection to the website from a web browser, using the HTTPS  pro-\ntocol. For example, if you are running Firefox on the system where the web server \nis running, type https://localhost  into the location box and press Enter. \nFigure\u00a017.2 shows an example of the page that appears.\n2. This page warns you that there is no way of verifying the authenticity of this site. \nThat is because there is no way to know who created the certificate that you are \naccepting.\n3. Because you are accessing the site via a browser on the local host, click \nAdvanced and then View to see the certificate that was generated. It includes \nyour hostname, information on when the certificate was issued and when it \nexpires, and lots of other organization information.\n4. Select Accept the Risk and Continue to allow connections to this site.\n5. Close that window, and then select Confirm Security Exception to accept the \nconnection. You should now see your default web page using HTTPS protocol. From \nnow on, your browser will accept HTTPS connections to the web server using that \ncertificate and encrypt all communications between the server and browser.\nFIGURE 17.2\nAccessing an SSL website with a default certificate", "doc_id": "7de6e759-de29-48d6-a428-1b6e79f0ca4e", "embedding": null, "doc_hash": "1b1115ecee66678b43a299a6a72810f6695234b870e24b08e84e4fd3486e4f56", "extra_info": {"page_label": "470"}, "node_info": {"start": 0, "end": 1418}, "relationships": {"1": "1ed0302b-f918-4c02-a8f3-e85e286b2a10"}}, "__type__": "1"}, "7f9c1356-c276-4be5-81db-ef63584267bb": {"__data__": {"text": "Chapter 17: Configuring a Web Server\n447\n17Because you don\u2019t want your website to scare off users, the best thing to do is to get a valid \ncertificate to use with your site. The next best thing to do is to create a self-signed certifi-\ncate that at least includes better information about your site and organization. The follow -\ning section describes how to do that.\nGenerating an SSL key and self-signed certificate\nTo begin setting up SSL, use the openssl  command, which is part of the openssl  \npackage, to generate your public and private key. After that, you can generate your own \nself-signed certificate to test the site or to use internally.\n1. If the openssl  package is not already installed, install it as follows:\n# yum install openssl\n2. Generate a 2048-bit RSA private key and save it to a file:\n# cd /etc/pki/tls/private\n# openssl genrsa -out server.key 2048\n# chmod 600 server.key\nNote\nYou can use a filename other than server.key  and should do so if you plan to have more than one SSL host on \nyour machine (which requires more than one IP address). Just make sure that you specify the correct filename in the \nApache configuration later.\nOr, in higher-security environments, encrypting the key by adding the -des3  \nargument after the genrsa  argument on the openssl  command line is a good \nidea. When prompted for a passphrase, press Enter:\n# openssl genrsa -des3 -out server.key 1024\n3. If you don\u2019t plan to have your certificate signed, or if you want to test your \nconfiguration, generate a self-signed certificate and save it in a file named \nserver.crt  in the /etc/pki/tls/certs  directory:\n# cd /etc/pki/tls/certs\n# openssl req -new -x509 -nodes -sha1 -days 365 \\\n   -key /etc/pki/tls/private/server.key \\\n   -out server.crt\nCountry Name (2 letter code) [AU]: US\nState or Province Name (full name) [Some-State]: NJ\nLocality Name (eg, city) [Default City]: Princeton\nOrganization Name (eg, company) [Default Company Ltd\nLtd]:TEST USE ONLY\nOrganizational Unit Name (eg, section) []:TEST USE ONLY\nCommon Name (eg, YOUR name) []:secure.example.org\nEmail Address []:dom@example.org", "doc_id": "7f9c1356-c276-4be5-81db-ef63584267bb", "embedding": null, "doc_hash": "187f1c07f721c32d6afbed5e159c90024bc8df6dd7d17efde77d68f0b03648e2", "extra_info": {"page_label": "471"}, "node_info": {"start": 0, "end": 2106}, "relationships": {"1": "f44ef2f0-abb1-4330-8bc8-e07bae79fa48"}}, "__type__": "1"}, "fd568aab-842b-41b6-ada3-1182e60a77e9": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator4484. Edit the /etc/httpd/conf.d/ssl.conf  file to change the key and certificate \nlocations to use the ones that you just created. For example:\nSSLCertificateFile /etc/pki/tls/certs/server.crt\nSSLCertificateKeyFile /etc/pki/tls/private/server.key\n5. Restart or reload the httpd  server.\n6. Open https://localhost  from a local browser again, repeat the procedure to \nreview, and accept the new certificate.\nFor internal use or testing, a self-signed certificate might work for you. However, for public \nwebsites, you should use a certificate that is validated by a certificate authority (CA). The \nprocedure for doing that is covered next.\nGenerating a certificate signing request\nIf you plan to have your certificate signed by a CA (including one that you run yourself), \nyou can use your private key to generate a certificate signing request (CSR):\n1. Create a directory for storing your CSR.\n# mkdir /etc/pki/tls/ssl.csr\n# cd /etc/pki/tls/ssl.csr/\n2. Use the openssl  command to generate the CSR. The result is a CSR file in \nthe current directory named server.csr . When you enter the information, the \nCommon Name entry should match the name that clients will use to access your \nserver. Be sure to get the other details right so that it can be validated by a third-\nparty CA. Also, if you had entered a passphrase for your key, you are prompted to \nenter it here to use the key.\n# openssl req -new -key ../private/server.key -out server.csr\n \nCountry Name (2 letter code) [AU]:US\nState or Province Name (full name) [Some-State]:Washington\nLocality Name (eg, city) []:Bellingham\nOrganization Name (eg, company) [Internet Widgits Pty\nLtd]:Example Company, LTD.\nOrganizational Unit Name (eg, section) []:Network\n Operations\nCommon Name (eg, YOUR name) []:secure.example.org\nEmail Address []:dom@example.org\n \nPlease enter the following 'extra' attributes\nto be sent with your certificate request\nA challenge password []:\nAn optional company name []:\n3. Visit the website of the certificate signing authority that you choose and \nrequest a signed certificate. At some point, the CA site will probably ask you to ", "doc_id": "fd568aab-842b-41b6-ada3-1182e60a77e9", "embedding": null, "doc_hash": "6b08c88b1bc33dd20964b0a8a2b403e2de6bebd3668ce9ca820dfd2480539a7e", "extra_info": {"page_label": "472"}, "node_info": {"start": 0, "end": 2161}, "relationships": {"1": "96f9a3f8-d908-44bd-b7e6-88cbecd4ddd1"}}, "__type__": "1"}, "383797b2-155e-46a4-8db8-a8c2566cc8ca": {"__data__": {"text": "Chapter 17: Configuring a Web Server\n449\n17copy and paste the contents of your CSR ( server.csr  file in this example) into a \nform needed to make the request.\n4. When the CA sends you the certificate (probably via email), save it in the  \n/etc/pki/tls/certs/  directory using a name based on the site you are  \nhosting \u2014 for example, example.org.crt .\n5. Change the value of SSLCertificateFile  in the /etc/httpd/conf.d/ssl.\nconf  file to point to your new CRT file. Or, if you have multiple SSL hosts, you \nmight want to create a separate entry (possibly in a separate .conf  file) that looks \nlike the following:\nListen 192.168.0.56:443\n<VirtualHost *:443>\n    ServerName      secure.example.org\n    ServerAlias     web.example.org\n    DocumentRoot    /home/username/public_html/\n    DirectoryIndex  index.php index.html index.htm\n    SSLEngine       On\n    SSLCertificateKeyFile /etc/pki/tls/private/server.key\n    SSLCertificateFile /etc/pki/tls/certs/example.org.crt\n</VirtualHost>\nThe IP address shown in the Listen  directive should be replaced by the public IP address \nrepresenting the SSL host you are serving. Remember that each SSL host should have its \nown IP address.\nTroubleshooting Your Web Server\nIn any complex environment, you occasionally run into problems. The following sections \ninclude tips for isolating and resolving the most common errors that you may encounter.\nChecking for configuration errors\nYou may occasionally run into configuration errors or script problems that prevent Apache \nfrom starting or that prevent specific files from being accessible. Most of these problems \ncan be isolated and resolved using two Apache-provided tools: the apachectl  program and \nthe system error log.\nWhen encountering a problem, first use the apachectl  program with the configtest  \nparameter to test the configuration. In fact, it\u2019s a good idea to develop the habit of running \nthis every time you make a configuration change:\n# apachectl configtest\nSyntax OK\n# apachectl graceful\n/usr/sbin/apachectl graceful: httpd gracefully restarted", "doc_id": "383797b2-155e-46a4-8db8-a8c2566cc8ca", "embedding": null, "doc_hash": "a381465727ed722c78b1996a403614eb8d1e95342655e70fe48bab88ddd58757", "extra_info": {"page_label": "473"}, "node_info": {"start": 0, "end": 2059}, "relationships": {"1": "705726c1-b46e-46ff-aefe-67f5ed4e4687"}}, "__type__": "1"}, "83fb0024-42a7-4e06-8a54-4abbc8be700e": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator450In the event of a syntax error, apachectl  indicates where the error occurs and also does \nits best to give a hint about the nature of the problem. You can then use the graceful  \nrestart option ( apachectl graceful ) to instruct Apache to reload its configuration \nwithout disconnecting any active clients.\nNote\nThe graceful  restart option in apachectl  automatically tests the configuration before sending the reload \nsignal to apache , but getting in the habit of running the manual configuration test after making any configuration \nchanges is still a good idea.\nSome configuration problems pass the syntax tests performed by apachectl  but cause the \nHTTP daemon to exit immediately after reloading its configuration. If this happens, use the \ntail  command to check Apache\u2019s error log for useful information. On Fedora and RHEL sys -\ntems, the error log is in /var/log/httpd/error.log . On other systems, you can find the \nlocation by looking for the ErrorLog  directive in your Apache configuration.\nYou might encounter an error message that looks something like this:\n[crit] (98)Address already in use: make_sock: could not bind to port \n80\nThis error often indicates that something else is bound to port 80, that another Apache \nprocess is already running ( apachectl  usually catches this), or that you have told Apache \nto bind the same IP address and port combination in more than one place.\nYou can use the netstat  command to view the list of programs (including Apache) with \nTCP ports in the LISTEN  state:\n# netstat -nltp\nActive Internet connections (only servers)\nProto  Local Address  Foreign Address  State   PID/Program name\ntcp6   :::80          :::*             LISTEN  2105/httpd\nThe output from netstat  (which was shortened to fit here) indicates that an instance of \nthe httpd  process with a process ID of 2105  is listening (as indicated by the LISTEN  state) \nfor connections to any local IP address (indicated by :::80 ) on port 80 (the standard HTTP \nport). If a different program is listening to port 80, it is shown there. You can use the kill  \ncommand to terminate the process, but if it is something other than httpd , you should \nalso find out why it is running.\nIf you don\u2019t see any other processes listening on port 80, it could be that you have acci-\ndentally told Apache to listen on the same IP address and port combination in more than \none place. Three configuration directives can be used for this: BindAddress , Port , \nand Listen :\n\u25a0\u25a0BindAddress  enables you to specify a single IP address on which to listen, or you \ncan specify all IP addresses using the *  wildcard. You should never have more than \none BindAddress  statement in your configuration file.", "doc_id": "83fb0024-42a7-4e06-8a54-4abbc8be700e", "embedding": null, "doc_hash": "8ea594c710fc82b81f84e078fd79513285cf0186c348abc5d8a66dc054cc4f83", "extra_info": {"page_label": "474"}, "node_info": {"start": 0, "end": 2755}, "relationships": {"1": "d64a9582-efae-4b98-9733-55093dded487"}}, "__type__": "1"}, "5373a23b-42c8-49c8-94b1-6adc6bb67caf": {"__data__": {"text": "Chapter 17: Configuring a Web Server\n451\n17\u25a0\u25a0Port  specifies on which TCP port to listen, but it does not enable you to specify \nthe IP address. Port  is generally not used more than once in the configuration.\n\u25a0\u25a0Listen  enables you to specify both an IP address and a port to bind to. The IP \naddress can be in the form of a wildcard, and you can have multiple Listen  state -\nments in your configuration file.\nTo avoid confusion, it is generally a good idea to use only one of these directive types. Of \nthe three, Listen  is the most flexible, so it is probably the one you want to use the most. \nA common error when using Listen  is to specify a port on all IP addresses ( *:80) as well \nas that same port on a specific IP address ( 1.2.3.4:80 ), which results in the error from \nmake_sock .\nConfiguration errors relating to SSL commonly result in Apache starting improperly. Make \nsure that all key and certificate files exist and that they are in the proper format (use \nopenssl  to examine them).\nFor other error messages, try doing a web search to see whether somebody else has encoun -\ntered the problem. In most cases, you can find a solution within the first few matches.\nIf you aren\u2019t getting enough information in the ErrorLog , you can configure it to log \nmore information using the LogLevel  directive. The options available for this directive, \nin increasing order of verbosity, are emerg , alert , crit , error , warn , notice , info , \nand debug . Select only one of these.\nAny message that is at least as important as the LogLevel  that you select are stored in \nthe ErrorLog . On a typical server, LogLevel  is set to warn . You should not set it to any \nvalue lower than crit , and you should avoid leaving it set to debug  because that can slow \ndown the server and result in a very large ErrorLog .\nAs a last resort, you can also try running httpd -X  manually to check for crashes or \nother error messages. The -X  runs httpd  so that it displays debug and higher messages on \nthe screen.\nAccessing forbidden and server internal errors\nThe two common types of errors that you may encounter when attempting to view specific \npages on your server are permission errors and server internal errors. Both types of errors \ncan usually be isolated using the information in the error log. After making any of the \nchanges described in the following list to attempt to solve one of these problems, try the \nrequest again and check the error log to see whether the message has changed (for exam-\nple, to show that the operation completed successfully).\nNote\n\u2033File not found\u2033 errors can be checked in the same way as \u2033 access forbidden \u2033 and \u2033 server internal errors. \u2033 You may \nsometimes find that Apache is not looking where you think it is for a specific file. Generally, the entire path to the file \nshows up in the error log. Make sure that you are accessing the correct virtual host, and check for any Alias  set-\ntings that might be directing your location to a place you don\u2019t expect.", "doc_id": "5373a23b-42c8-49c8-94b1-6adc6bb67caf", "embedding": null, "doc_hash": "e066179866c115ab2ffc2aeb42ec526e5df89062e6369aad6484be2f3f60f8ff", "extra_info": {"page_label": "475"}, "node_info": {"start": 0, "end": 3005}, "relationships": {"1": "bfa8c08f-6930-474e-9015-782caee22249"}}, "__type__": "1"}, "8ac09f96-fab6-405a-8b6f-5581fe9c7713": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator452File permissions A \u201cFile permissions prevent access\u201d error indicates that the apache  \nprocess is running as a user that is unable to open the requested file. By default, \nhttpd  is run by the Apache  user and group. Make sure that the account has exe -\ncute permissions on the directory, and every directory above it, as well as read per -\nmissions on the files themselves. Read permissions on a directory are also necessary \nif you want Apache to generate an index of files. See the manual page for chmod  for \nmore information about how to view and change permissions.\nNote\nRead permissions are not necessary for compiled binaries, such as those written in C or C++, but they can be safely \nadded unless a need exists to keep the contents of the program secret.\nAccess denied  A \u201cClient denied by server configuration\u201d error indicates that Apache \nwas configured to deny access to the object. Check the configuration files for Loca -\ntion  and Directory  sections that might affect the file that you are trying to \naccess. Remember that settings applied to a path are also applied to any paths below \nit. You can override these by changing the permissions only for the more specific \npath to which you want to allow access.\nIndex not found The \u201cDirectory index forbidden by rule\u201d error indicates that \nApache could not find an index file with a name specified in the DirectoryIndex  \ndirective and was configured not to create an index containing a list of files in a \ndirectory. Make sure that your index page, if you have one, has one of the names \nspecified in the relevant DirectoryIndex  directive, or add an Options Indexes  \nline to the appropriate Directory  or Location  section for that object.\nScript crashed  \u201cPremature end of script headers\u201d errors can indicate that a script is \ncrashing before it finishes. On occasion, the errors that caused this also show up in \nthe error log. When using suexec  or suPHP , this error may also be caused by a file \nownership or permissions error. These errors appear in log files in the /var/log/\nhttpd  directory.\nSELinux errors  If file permissions are open but messages denying permission appear \nin log files, SELinux could be causing the problem. Set SELinux to permissive mode \ntemporarily ( setenforce 0 ) and try to access the file again. If the file is now \naccessible, set SELinux to enforcing mode again ( setenforce 1 ) and check file \ncontexts and Booleans. File contexts must be correct for httpd  to be able to access \na file. A Boolean might prevent a file being served from a remotely mounted direc -\ntory or prevent a page from sending an email or uploading a file. Type man  \nhttpd_selinux  for details about SELinux configuration settings associated with \nthe httpd  services. (Install the selinux-policy-devel  package to have that \nman page added to your system.)", "doc_id": "8ac09f96-fab6-405a-8b6f-5581fe9c7713", "embedding": null, "doc_hash": "05f290952fa1600fa2f6c71e78b2b0970131f637e1626fc6cbd1b92fff93c9ef", "extra_info": {"page_label": "476"}, "node_info": {"start": 0, "end": 2888}, "relationships": {"1": "5769e258-8f9a-47cf-b14d-6e09f936d966"}}, "__type__": "1"}, "e80b5fbd-ad7a-4bb9-9c98-e467b81b3dbf": {"__data__": {"text": "Chapter 17: Configuring a Web Server\n453\n17Summary\nThe open source Apache project is the world\u2019s most popular web server. Although Apache \noffers tremendous flexibility, security, and complexity, a basic Apache web server can be \nconfigured in just a few minutes in Fedora, RHEL, and most other Linux distributions.\nThe chapter described the steps for installing, configuring, securing, and troubleshooting \na basic Apache web server. You learned how to configure virtual hosting and secure SSL \nhosts. You also learned how to configure Apache to allow any user account on the system to \npublish content from their own public_html  directory.\nContinuing on the topic of server configuration, in Chapter\u00a018, \u201cConfiguring an FTP Server,\u201d \nyou will learn how to set up an FTP server in Linux. The examples illustrate how to con -\nfigure an FTP server using the vsftpd  package.\nExercises\nThe exercises in this section cover topics related to installing and configuring an Apache \nweb server. As usual, I recommend that you use a spare Fedora or Red Hat Enterprise Linux \nsystem to do the exercises. Don\u2019t do these exercises on a production machine because these \nexercises modify the Apache configuration files and service, and they could damage ser -\nvices that you have currently configured. Try to use a virtual machine or find a computer \nwhere it will do no harm to interrupt services on the system.\nThese exercises assume that you are starting with a Fedora or RHEL installation on which \nthe Apache server ( httpd  package) is not yet installed.\nIf you are stuck, solutions to the tasks are shown in Appendix B. These show you one \napproach to each task, although Linux may offer multiple ways to complete a task.\n1. From a Fedora system, install all of the packages associated with the Basic Web \nServer group.\n2. Create a file called index.html  in the directory assigned to DocumentRoot  in \nthe main Apache configuration file. The file should have the words \u201cMy Own Web \nServer\u201d inside.\n3. Start the Apache web server and set it to start up automatically at boot time. Check \nthat it is available from a web browser on your local host. (You should see the words \n\u201cMy Own Web Server\u201d displayed if it is working properly.)\n4. Use the netstat  command to see on which ports the httpd  server is listening.\n5. Try to connect to your Apache web server from a web browser that is outside of the \nlocal system. If it fails, correct any problems that you encounter by investigating \nthe firewall, SELinux, and other security features.", "doc_id": "e80b5fbd-ad7a-4bb9-9c98-e467b81b3dbf", "embedding": null, "doc_hash": "8b1175444790d31d6aba171148149dff6b7a7095f43a26f75d0c91ca7c5b19cf", "extra_info": {"page_label": "477"}, "node_info": {"start": 0, "end": 2534}, "relationships": {"1": "79b8419a-ced7-4cdc-9be9-73f00bc35e28"}}, "__type__": "1"}, "303c6456-f637-441a-80ee-1ec54d2be014": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator4546. Using the openssl  or similar command, create your own private RSA key and self-\nsigned SSL certificate.\n7. Configure your Apache web server to use your key and self-signed certificate to \nserve secure (HTTPS) content.\n8. Use a web browser to create an HTTPS connection to your web server and view the \ncontents of the certificate that you created.\n9. Create a file named /etc/httpd/conf.d/example.org.conf , which turns on \nname-based virtual hosting and creates a virtual host that does these things:\n\u25a0\u25a0Listens on port 80 on all interfaces\n\u25a0\u25a0Has a server administrator of joe@example.org\n\u25a0\u25a0Has a server name of joe.example.org\n\u25a0\u25a0Has a DocumentRoot  of /var/www/html/example.org\n\u25a0\u25a0Has a DirectoryIndex  that includes at least index.html\nCreate an index.html  file in DocumentRoot  that contains the words  \n\u201cWelcome to the House of Joe\u201d inside.\n10. Add the text joe.example.org  to the end of the localhost entry in your /etc/\nhosts  file on the machine that is running the web server. Then type http://joe.\nexample.org  into the location box of your web browser. You should see \u201cWelcome \nto the House of Joe\u201d when the page is displayed.", "doc_id": "303c6456-f637-441a-80ee-1ec54d2be014", "embedding": null, "doc_hash": "5ef8f94d38774d075360211d0467c2c1bebb3c935c497d0c1f99d9318430e670", "extra_info": {"page_label": "478"}, "node_info": {"start": 0, "end": 1190}, "relationships": {"1": "07772b93-e5c0-4b0b-881f-3f009f97283d"}}, "__type__": "1"}, "7ac2ee76-da4d-4842-be82-e77c61f7d369": {"__data__": {"text": "455\nCHAPTER18\nConfiguring an FTP Server\nIN THIS CHAPTER\nLearning how FTP works\nGetting a vsftpd server installed\nChoosing security settings for vsftpd\nSetting up vsftpd configuration files\nRunning FTP clients\nThe File Transfer Protocol (FTP) is one of the oldest protocols in existence for sharing files over \nnetworks. Although there are more secure protocols for network file sharing, FTP is still used \nquite often for making files freely available on the Internet.\nSeveral FTP server projects are available with Linux today. However, the one often used with Fedora, \nRed Hat Enterprise Linux, CentOS, Ubuntu, and other Linux distributions is the Very Secure FTP \nDaemon (vsftpd  package). This chapter describes how to install, configure, use, and secure an FTP \nserver using the vsftpd  package.\nUnderstanding FTP\nFTP operates in a client/server model. An FTP server daemon listens for incoming requests (on TCP \nport 21) from FTP clients. The client presents a login and password. If the server accepts the login \ninformation, the client can interactively traverse the filesystem, list files and directories, and then \ndownload (and sometimes upload) files.\nWhat makes FTP insecure is that everything sent between the FTP client and server is done in clear \ntext. The FTP protocol was created at a time when most computer communication was done on private \nlines or over dial-up, where encryption was not thought to be critical. If you use FTP over a public \nnetwork, someone sniffing the line anywhere between the client and server would be able to see not \nonly the data being transferred but also the authentication process (login and password information).\nSo, FTP is not good for sharing files privately (use SSH commands such as sftp , scp , or rsync  \nif you need private, encrypted file transfers). However, if you are sharing public documents, open \nsource software repositories, or other openly available data, FTP is a good choice. Regardless of the \noperating system people use, they surely have an FTP file transfer application available to get files \nthat you offer from your FTP server.\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "7ac2ee76-da4d-4842-be82-e77c61f7d369", "embedding": null, "doc_hash": "4ad1d94a79fb0882359dba95a8520b8d9d3b6afa1a721d0a26dca5833aff215d", "extra_info": {"page_label": "479"}, "node_info": {"start": 0, "end": 2230}, "relationships": {"1": "acc83c0b-fb30-4f73-9e34-96fd0d8b13f4"}}, "__type__": "1"}, "6bef7bff-8dc3-437f-b283-cbaefc1cb7f3": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator456When users authenticate to an FTP server in Linux, their usernames and passwords are \nauthenticated against the standard Linux user accounts and passwords. There is also a spe -\ncial, non-authenticated account used by the FTP server called anonymous. The anonymous \naccount can be accessed by anyone because it does not require a valid password. In fact, \nthe term anonymous FTP server  is often used to describe a public FTP server that does not \nrequire (or even allow) authentication of a legitimate user account.\nAfter the authentication phase (on the control port, TCP port 21), a second connection \nis made between the client and server. FTP supports both active and passive connection \ntypes. With an active FTP connection , the server sends data from its TCP port 20 to some \nrandom port the server chooses above port 1023 on the client. With a passive FTP connec -\ntion, the client requests the passive connection and requests a random port from the server.\nMany browsers support passive FTP mode so that if the client has a firewall, it doesn\u2019t \nblock the data port that the FTP server might use in active mode. Supporting passive mode \nrequires some extra work on the server\u2019s firewall to allow random connections to ports \nabove 1023 on the server. The section \u201cOpening up your firewall for FTP,\u201d later in this chap -\nter, describes what you need to do to your Linux firewall to make both passive and active \nFTP connections work.\nAfter the connection is established between the client and server, the client\u2019s current \ndirectory is established. For the anonymous user, the /var/ftp  directory is the home \ndirectory for Fedora or RHEL, and it\u2019s /srv/ftp  for Ubuntu and most Debian-based \ndistributions. The anonymous user cannot go outside of the /var/ftp  directory structure. \nIf a regular user, let\u2019s say joe, logs in to the FTP server, /home/joe  is joe\u2019s current direc -\ntory, but joe can change to any part of the filesystem for which he has permission.\nCommand-oriented FTP clients (such as lftp  and ftp  commands) go into an interactive \nmode after connecting to the server. From the prompt you see, you can run many com-\nmands that are similar to those that you would use from the shell. You could use pwd  to \nsee your current directory, ls  to list directory contents, and cd  to change directories. \nWhen you see a file that you want, you use the get  and put  commands to download files \nfrom or upload them to the server, respectively.\nWith graphical tools for accessing FTP servers (such as a web browser), you type the URL of the \nsite that you want to visit (such as ftp://docs.example.com ) into the location box of the \nbrowser. If you don\u2019t add a username or password, an anonymous connection is made and the \ncontents of the home directory of the site are displayed. Click links to directories to change to \nthose directories. Click links to files to display or download those files to your local system.Note\nAlthough the ability to log in to the vsftpd  server using a regular Linux user account is enabled by default in Fedora \nand Red Hat Enterprise Linux, if SELinux is set to enforcing mode, it prevents the logins and file transfers from suc -\nceeding. If you want to keep SELinux in enforcing mode yet still allow Linux logins, you can change a Boolean (see the \nsection \u201cConfiguring SELinux for your FTP server\u201d later in this chapter) to allow regular user logins to succeed.", "doc_id": "6bef7bff-8dc3-437f-b283-cbaefc1cb7f3", "embedding": null, "doc_hash": "a56c5a257904f58110bd1b3ad61e3251a324ee62c884e6bfc90ef2f0069cb48a", "extra_info": {"page_label": "480"}, "node_info": {"start": 0, "end": 3468}, "relationships": {"1": "d13efa88-add7-4300-bac7-9a56006a4252"}}, "__type__": "1"}, "ddff8166-e0ca-4edc-bcd1-3f53457b4377": {"__data__": {"text": "Chapter 18: Configuring an FTP Server\n457\n18Armed with some understanding of how FTP works, you are now ready to install an FTP \nserver (vsftpd  package) on your Linux system.\nInstalling the vsftpd FTP Server\nSetting up the Very Secure FTP server requires only one package in Fedora, RHEL, and other \nLinux distributions: vsftpd . Assuming you have a connection to your software repository, \njust type the following as root for Fedora or RHEL to install vsftpd :\n# yum install vsftpd\nIf you are using Ubuntu (or another Linux distribution based on Debian packaging), type \nthe following to install vsftpd :\n$ sudo apt-get install vsftpd\nHere are some commands that you can run after the vsftpd  package is installed to famil -\niarize yourself with the contents of that package. From Fedora or RHEL, run this command \nto get some general information about the package:\n# rpm -qi vsftpd\n...\nPackager    : Fedora Project\nVendor      : Fedora Project\nURL         : https://security.appspot.com/vsftpd.html\nSummary     : Very Secure Ftp Daemon\nDescription : vsftpd is a Very Secure FTP daemon. It was written\n              completely from scratch.\nIf you want to get more information about vsftpd , follow the URL listed to the related \nwebsite (https://security.appspot.com/vsftpd.html ). You can get additional docu -\nmentation and information about the latest revisions of vsftpd .\nYou can view the full contents of the vsftpd  package (rpm -ql vsftpd ), or you can \nview just the documentation ( -qd) or configuration ( -qc) files. To see the documentation \nfiles in the vsftpd  package, use the following:\n# rpm -qd vsftpd\n/usr/share/doc/vsftpd/EXAMPLE/INTERNET_SITE/README\n...\n/usr/share/doc/vsftpd/EXAMPLE/PER_IP_CONFIG/README\n...\n/usr/share/doc/vsftpd/EXAMPLE/VIRTUAL_HOSTS/README\n/usr/share/doc/vsftpd/EXAMPLE/VIRTUAL_USERS/README\n...\n/usr/share/doc/vsftpd/FAQ\n...\n/usr/share/doc/vsftpd/vsftpd.xinetd\n/usr/share/man/man5/vsftpd.conf.5.gz\n/usr/share/man/man8/vsftpd.8.gz", "doc_id": "ddff8166-e0ca-4edc-bcd1-3f53457b4377", "embedding": null, "doc_hash": "9e64c72321991dee2366ef6d20e582e114dec40a33e27cae0216e8ddc138b693", "extra_info": {"page_label": "481"}, "node_info": {"start": 0, "end": 1973}, "relationships": {"1": "725d2cec-08dd-4ac3-9578-69e0ebb6face"}}, "__type__": "1"}, "a2f37b49-48c0-40a9-95ac-c1f179c8dbfe": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator458In the /usr/share/doc/vsftpd/EXAMPLE  directory structure, there are sample configura -\ntion files included to help you configure vsftpd  in ways that are appropriate for an Internet \nsite, multiple IP address site, and virtual hosts. The main /usr/share/doc/vsftpd  direc -\ntory contains an FAQ (frequently asked questions), installation tips, and version information.\nThe man pages might have the most useful information when you set out to configure the \nvsftpd  server. Type man vsftpd.conf  to read about the configuration file and man \nvsftpd  to read about the daemon process and how to manage it as a systemd  service.\nTo list the configuration files, type the following:\n# rpm -qc vsftpd\n/etc/logrotate.d/vsftpd\n/etc/pam.d/vsftpd\n/etc/vsftpd/ftpusers\n/etc/vsftpd/user_list\n/etc/vsftpd/vsftpd.conf\nThe main configuration file is /etc/vsftpd/vsftpd.conf  (in RHEL and Fedora) or  \n/etc/vsftpd.conf  (in Ubuntu). The ftpusers  and user _ list  (Fedora and RHEL, \nbut not Ubuntu) files in the same directory store information about user accounts that are \nrestricted from accessing the server. The /etc/pam.d/vsftpd  file sets how authentication \nis done to the FTP server. The /etc/logrotate.d/vsftpd  file configures how log files \nare rotated over time.\nNow you have vsftpd  installed and have taken a quick look at its contents. The next step \nis to start up and test the vsftpd  service.\nStarting the vsftpd Service\nNo configuration is required to launch the vsftpd  service if you just want to use the default \nsettings. If you start vsftpd  as it is delivered with Fedora, the following is what you get:\n\u25a0\u25a0The vsftpd  service starts the vsftpd  daemon, which runs in the background.\n\u25a0\u25a0The standard port on which the vsftpd  daemon listens is TCP port 21. By default, \ndata is transferred to the user, after the connection is made, on TCP port 20. TCP \nport 21 must be open in the firewall to allow new connections to access the service. \nBoth IPv4 and IPv6 connections are available by default. This procedure changes to \nthe TCP IPv4 service. (See the section \u201cSecuring Your FTP Server\u201d later in this chap -\nter for details on opening ports, enabling connection tracking needed for passive \nFTP, and setting other firewall rules related to FTP.)\n\u25a0\u25a0The vsftpd  daemon reads vsftpd.conf  to determine what features the ser -\nvice allows.\n\u25a0\u25a0Linux user accounts (excluding administrative users) can access the FTP server. The \nanonymous user account (no password required) can be enabled. (If SELinux is in \nenforcing mode, you need to set a Boolean to allow regular users to log in to the \nFTP server. See the section \u201cSecuring Your FTP Server\u201d for details.)", "doc_id": "a2f37b49-48c0-40a9-95ac-c1f179c8dbfe", "embedding": null, "doc_hash": "0337877fe81cd66a4b0701c3924618b7212598affdfb2ec586b10d40ddf32545", "extra_info": {"page_label": "482"}, "node_info": {"start": 0, "end": 2717}, "relationships": {"1": "bdaeeccd-42b2-4757-8853-928c43e9cea8"}}, "__type__": "1"}, "b720cabe-b491-49f1-a2da-2a756e4d5363": {"__data__": {"text": "Chapter 18: Configuring an FTP Server\n459\n18\u25a0\u25a0The anonymous user has access only to the /var/ftp  directory and its sub -\ndirectories. A regular user starts with their home directory as the current \ndirectory but can access any directory to which the user would be able to gain \naccess via a regular login or SSH session. Lists of users in the /etc/vsftpd/\nuser _ list  and /etc/vsftpd/ftpusers  files define some administrative \nand special users who do not have access to the FTP server (root, bin, daemon, \nand others).\n\u25a0\u25a0By default, the anonymous user can download files from the server but not \nupload them. A regular user can upload or download files, based on regular Linux \npermissions.\n\u25a0\u25a0Log messages detailing file uploads or downloads are written in the /var/log/\nxferlogs  file. Those log messages are stored in a standard xferlog format.\nIf you are ready to start your server using the defaults just described, the following exam-\nples show you how to do that. If you want to change some additional settings first, go to \nthe section \u201cConfiguring Your FTP Server,\u201d later in this chapter, finalize your settings, and \nthen come back here for instructions on how to enable and start your server.\n1. Check the vsftpd  service. Before you start the vsftpd  service, you can check out \nwhether it is running already. In Fedora or Red Hat Enterprise Linux 7 or 8, you do \nthe following:\n        # systemctl status vsftpd.service\n        vsftpd.service - Vsftpd ftp daemon\n               Loaded: loaded (/usr/lib/systemd/system/vsftpd.\nservice; disabled)\n               Active: inactive (dead)\nIn Red Hat Enterprise Linux 6, you need two commands to see the same \ninformation:\n        # service vsftpd status\n        vsftpd is stopped\n        # chkconfig --list vsftpd\n        vsftpd  0:off  1:off  2:off  3:off  4:off  5:off  6:off\nIn both the Fedora and RHEL examples above, the service , chkconfig , and \nsystemctl  commands show the status as stopped. You can also see that it is \ndisabled in Fedora and RHEL 7 or 8 and off at every runlevel for RHEL 6. Disabled \n(off)  means that the service will not turn on automatically when your start \nthe system.\n2. To start and enable vsftpd  in Fedora or RHEL 7 or 8 (then check the status), type \nthe following:\n        # systemctl start vsftpd.service\n        # systemctl enable vsftpd.service", "doc_id": "b720cabe-b491-49f1-a2da-2a756e4d5363", "embedding": null, "doc_hash": "7278a84e81c4193be844812b7c67cedefa818d86e37720597357cc55150e6d0e", "extra_info": {"page_label": "483"}, "node_info": {"start": 0, "end": 2348}, "relationships": {"1": "aeea95e3-efd0-4470-8eb1-63c997b1b1f0"}}, "__type__": "1"}, "01b85149-2bec-48c3-8d9c-04b18de185f2": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator460        ln -s '/lib/systemd/system/vsftpd.service'\n          '/etc/systemd/system/multi-user.target.wants/vsftpd.\nservice'\n        # systemctl status vsftpd.service\n        vsftpd.service - Vsftpd ftp daemon\n               Loaded: loaded (/usr/lib/systemd/system/vsftpd.\nservice;\n                  enabled vendor preset: disabled))\n               Active: active (running) since Wed, 2019-09-18 \n00:09:54 EDT; 22s ago\n               Main PID: 4229 (vsftpd)\n                  Tasks: 1 (limit: 12232)\n                 Memory: 536.0K\n                  CGroup: /system.slice/vsftpd.service\n               \u2514 4229 /usr/sbin/vsftpd /etc/vsftpd/vsftpd.conf\nIn Red Hat Enterprise Linux 6, start and turn on (enable) vsftpd  (then check the status), \nas follows:\n        # service vsftpd start\n        Starting vsftpd for vsftpd:                 [  OK  ]\n        # chkconfig vsftpd on ; chkconfig --list vsftpd\n        vsftpd       0:off    1:off    2:on    3:on    4:on    5:on    \n6:off\n3. Now, on either system, you could check that the service is running using the net -\nstat  command:\n        # netstat -tupln | grep vsftpd\n        tcp  0   0 0.0.0.0:21  0.0.0.0:*  LISTEN   4229/vsftpd\nFrom the netstat  output, you can see that the vsftpd  process (process ID of \n4229) is listening ( LISTEN ) on all IP addresses for incoming connections on port 21 \n(0.0.0.0:21) for the TCP ( tcp) protocol.\n4. A quick way to check that vsftpd  is working is to put a file in the /var/ftp  \ndirectory and try to open it from your web browser on the local host:\n        # echo \"Hello From Your FTP Server\" > /var/ftp/hello.txt\nFrom a web browser on the local system, type the following into the location box of \nFirefox or another browser:\n        ftp://localhost/hello.txt\nIf the text Hello From Your FTP Server appears in the web browser, the vsftpd  \nserver is working and accessible from your local system. Next, try this again from a web \nbrowser on another system, replacing localhost  with your host\u2019s IP address or fully ", "doc_id": "01b85149-2bec-48c3-8d9c-04b18de185f2", "embedding": null, "doc_hash": "62bfc24218b6838952c0d8760305cdff5fd77de2b22e74f077f840f8b32c1764", "extra_info": {"page_label": "484"}, "node_info": {"start": 0, "end": 2058}, "relationships": {"1": "2edfd473-006d-40b2-8363-ff2f2a97e0a2"}}, "__type__": "1"}, "2c542e3d-20f7-4e1f-9ce9-fe0f93ec312e": {"__data__": {"text": "Chapter 18: Configuring an FTP Server\n461\n18qualified host name. If that works, the vsftpd  server is publicly accessible. If it doesn\u2019t, \nwhich it quite possibly may not, see the next section, \u201cSecuring Your FTP Server.\u201d That sec -\ntion tells you how to open firewalls and modify other security features to allow access and \notherwise secure your FTP server.\nSecuring Your FTP Server\nEven though it is easy to get a vsftpd  FTP server started, that doesn\u2019t mean that it is \nimmediately fully accessible. If you have a firewall in place on your Linux system, it is \nprobably blocking access to all services on your system except for those that you have \nexplicitly allowed.\nIf you decide that the default vsftpd  configuration works for you as described in the \nprevious section, you can set to work allowing the appropriate access and providing secu-\nrity for your vsftpd  service. To help you secure your vsftpd  server, the next sections \ndescribe how to configure your firewall and SELinux (Booleans and file contexts).\nOpening up your firewall for FTP\nIf you have a firewall implemented on your system, you need to add firewall rules that \nallow incoming requests to your FTP site and allow packets to return to your system on \nestablished connections. Firewalls are implemented using iptables  rules and managed \nwith the iptables  service or firewalld  service (see Chapter\u00a025, \u201cSecuring Linux on a \nNetwork,\u201d for details about firewall services).\nIn Fedora and Red Hat Enterprise Linux, firewall rules have traditionally been stored in the \n/etc/sysconfig/iptables  file and the underlying service was iptables  (RHEL 6) or \niptables.service  (Fedora). Modules are loaded into your firewall from the /etc/sys -\nconfig/iptables-config  file. In RHEL 7 and Fedora 21 or later, the new firewalld  \nservice manages those rules and rules are stored in the /etc/firewalld/zones  directory.\nIn RHEL 7 and Fedora 20 or later, you can use the Firewall Configuration window to enable \nyour firewall and open access to your FTP service. Install the firewall-config  package \nand run firewall-config  to start the Firewall Configuration window, as shown in \nFigure\u00a018.1.Note\nIt is best to work on your firewall directly from a system console, if possible, instead of over a remote login (such as \nssh) because a small error can immediately lock you out of your server. After that, you must go over to the console \nto get back into the server and fix the problem. You need to add a few things to your firewall to allow access to your \nFTP server without opening up access to other services. First, you need to allow your system to accept requests on \nTCP port 21; then you need to make sure that the connection tracking module is loaded.", "doc_id": "2c542e3d-20f7-4e1f-9ce9-fe0f93ec312e", "embedding": null, "doc_hash": "c586cb39f74f8e12a6b3992d2ed771a851e817b9018e9c1dc56c4daf21bbad52", "extra_info": {"page_label": "485"}, "node_info": {"start": 0, "end": 2732}, "relationships": {"1": "879611b6-20b8-44f3-9b61-5a916fe8fe7d"}}, "__type__": "1"}, "cb524e71-195a-4383-9e45-76db28a34e41": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator462Next, to open access permanently to your FTP service, click the Configuration box and \nselect Permanent. Then select the check box next to ftp under the Services tab. This auto -\nmatically opens TCP port 21 (FTP) on your firewall and loads kernel modules needed to allow \naccess to passive FTP service. Select Options \u27aa Reload Firewalld to apply the firewall rule \npermanently.\nFor RHEL 6 and earlier systems, add rules directly to the /etc/sysconfig/iptables  file. \nIf you are using a default firewall, rules in the beginning open access to requests for any \nservices coming from the local host and allow packets to come in that are associated with, \nor related to, established connections. In the middle are rules that open ports for service \nrequests that you have already allowed, such as the secure shell service ( sshd  on TCP port \n22). At the end of the rules, a final rule usually DROP s or REJECT s any request that has not \nexplicitly been allowed.\nTo allow public access to someone requesting your FTP server, you want to allow new \nrequests to TCP port 21. You typically want to add the rule somewhere before the final DROP  \nor REJECT  rule. The following output shows partial contents of the /etc/sysconfig/\niptables  file with the rule allowing access to your FTP server in bold:\nFIGURE 18.1\nOpen access to your FTP service from the Firewall Configuration window.", "doc_id": "cb524e71-195a-4383-9e45-76db28a34e41", "embedding": null, "doc_hash": "def20050659421dac23be68624763e534d742d0ad7a00be2cadfa95a7971991f", "extra_info": {"page_label": "486"}, "node_info": {"start": 0, "end": 1429}, "relationships": {"1": "db786f4d-abb2-4b95-bc75-580445707589"}}, "__type__": "1"}, "d6cfd8dc-02af-4ed4-a276-8c60752e3b3d": {"__data__": {"text": "Chapter 18: Configuring an FTP Server\n463\n18*filter\n:INPUT ACCEPT [0:0]\n:FORWARD ACCEPT [0:0]\n:OUTPUT ACCEPT [0:0]\n-A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT\n-A INPUT -i lo -j ACCEPT\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 21 -j ACCEPT\n...\n-A INPUT -j REJECT --reject-with icmp-host-prohibited\nCOMMIT\nThis example shows that, for the filter table, the firewall accepts packets from established \nconnections, connections from local hosts, and any new requests on TCP port 22 (SSH ser -\nvice). The line we just added ( --dport 21 ) allows any packets on new connections to TCP \nport 21 to be accepted.\nThe next thing that you must do on RHEL 6 and earlier systems is set up the FTP connec -\ntion tracking module to be loaded each time the firewall starts up. Edit this line at the \nbeginning of the /etc/sysconfig/iptables-config  file to appear as follows:\nIPTABLES_MODULES=\"nf_conntrack_ftp\"\nAt this point, you can restart your firewall (keeping in mind that a mistake could lock you \nout if you are logged in remotely). Use one of the following two commands to restart your \nfirewall, depending on whether your system is using the older iptables  service or the \nnewer firewalld  service:\n# service iptables restart\nor\n# systemctl restart firewalld.service\nTry again to access your FTP server from a remote system (using a web browser or some \nother FTP client).\nConfiguring SELinux for your FTP server\nIf SELinux is set to permissive or disabled, it does not block access to the vsftpd  service \nin any way. However, if SELinux is in enforcing mode, a few SELinux issues could cause \nyour vsftpd  server not to behave as you would like. Use the following commands to check \nthe state of SELinux on your system:Note\nIt is important to have the ESTABLISHED, RELATED  line in your iptables  firewall rules. Without that line, \nusers would be able to connect to your SSH (port 22) and FTP (port 21) services, but they would not be able to com -\nmunicate after that. So, a user could get authenticated but not be able to transfer data.", "doc_id": "d6cfd8dc-02af-4ed4-a276-8c60752e3b3d", "embedding": null, "doc_hash": "b23f3500640e4401a75aedc11d3664e66489273585ea2c0a878bf027289202f9", "extra_info": {"page_label": "487"}, "node_info": {"start": 0, "end": 2122}, "relationships": {"1": "1c98eefc-6e16-48c0-8b7e-922f5fd85982"}}, "__type__": "1"}, "aa08c70f-f2ae-449a-b18a-047b6ea39109": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator464# getenforce\nEnforcing\n# grep ^SELINUX= /etc/sysconfig/selinux\nSELINUX=enforcing\nThe getenforce  command shows how SELinux is currently set. (Here, it\u2019s in enforcing \nmode.) The SELINUX=  variable in /etc/sysconfig/selinux  shows how SELinux is \nset when the system comes up. If it is in enforcing mode, as it is here, check the ftpd _\nselinux  man page for information about SELinux settings that can impact the operation \nof your vsftpd  service. Install the selinux-policy-doc  package to get the ftpd _\nselinux  man page as well as man pages for other services with SELinux policies.\nHere are some examples of file contexts that must be set for SELinux to allow files and \ndirectories to be accessed by vsftpd :\n\u25a0\u25a0To share content so that it can be downloaded to FTP clients, that content must be \nmarked with a public_content_t file context. Files created in the /var/ftp  \ndirectory or its subdirectories inherit public_content_t file context automat -\nically. (Be sure to create new content or copy existing content to the /var/ftp  \ndirectories. Moving the files there may not change the file context properly.)\n\u25a0\u25a0To allow files to be uploaded by anonymous users, the file context on the directory \nto which you upload must be set to public_content_rw_t. (Other permis -\nsions, SELinux Booleans, and vsftpd.conf  settings must be in place for this to \nwork as well.)\nIf you have files in the /var/ftp  directory structure that have the wrong file contexts \n(which can happen if you move files there from other directories instead of copying them), \nyou can change or restore the file context on those files so that they can be shared. For \nexample, to recursively change the file context of the /var/ftp/pub/stuff  directory so \nthat the content can be readable from the FTP server through SELinux, enter the following:\n# semanage fcontext -a -t public_content_t \"/var/ftp/pub/stuff(/.*)?\"\n# restorecon -F -R -v /var/ftp/pub/stuff\nIf you wanted to allow users also to write to a directory as well as to read from it, you \nwould need to assign the public _ content _ rw _ t  file context to the directory to \nwhich you want to allow uploads. This example tells SELinux to allow uploading of files to \nthe /var/ftp/pub/uploads  directory:\n# semanage fcontext -a -t public_content_rw_t\\ \n   \"/var/ftp/pub/uploads(/.*)?\"\n# restorecon -F -R -v /var/ftp/pub/uploads\nFTP server features that are considered insecure by SELinux have Booleans that let you \nallow or disallow those features. Here are some examples:\n\u25a0\u25a0For SELinux to allow anonymous users to read and write files and directories, you \nneed to turn on the allow _ ftpd _ anon _ write  (RHEL 6) or ftpd _ anon _\nwrite  (RHEL 7 or later) Boolean:\n        # setsebool -P ftpd_anon_write on", "doc_id": "aa08c70f-f2ae-449a-b18a-047b6ea39109", "embedding": null, "doc_hash": "32220c4fb62e9e453a733d2f646b5cbfa3b133b04607c73682366a55ddb5f718", "extra_info": {"page_label": "488"}, "node_info": {"start": 0, "end": 2798}, "relationships": {"1": "13911268-47df-427f-a664-a4152a93f002"}}, "__type__": "1"}, "65ffb4a8-088d-4783-957d-90df6add4cb2": {"__data__": {"text": "Chapter 18: Configuring an FTP Server\n465\n18\u25a0\u25a0To be able to mount remote NFS or CIFS (Windows) shared filesystems and share \nthem from your vsftpd  server, you need to turn on the following two Booleans, \nrespectively:\n        # setsebool -P allow_ftpd_use_nfs on\n        # setsebool -P allow_ftpd_use_cifs on\nIf you ever find that you cannot access files or directories from your FTP server that you \nbelieve should be accessible, try turning off SELinux temporarily:\n# setpenforce 0\nIf you can access the files or directories with SELinux now in permissive mode, put the \nsystem back in enforcing mode ( setenforce 1 ). Now you know you have to go back \nthrough your SELinux settings and find out what is preventing access. (See Chapter\u00a024, \n\u201cEnhancing Linux Security with SELinux,\u201d for more information on SELinux.)\nRelating Linux file permissions to vsftpd\nThe vsftpd  server relies on standard Linux file permissions to allow or deny access to files \nand directories. As you would expect, for an anonymous user to view or download a file, \nat least read permission must be open for other  (------r--). To access a directory, at least \nexecute permission must be on for other  (--------x).\nFor regular user accounts, the general rule is that if a user can access a file from the shell, \nthat user can access the same file from an FTP server. So, typically, regular users should at \nleast be able to get  (download) and put  (upload) files to and from their own home direc -\ntories, respectively. After permissions and other security provisions are in place for your \nFTP server, you may want to consider other configuration settings for your FTP server.\nConfiguring Your FTP Server\nMost of the configuration for the vsftpd  service is done in the /etc/vsftpd/vsftpd  \n.conf  file. Examples of vsftpd.conf  for different types of sites are included in the  \n/usr/share/doc/vsftpd  directory. Depending on how you want to use your FTP site,  \nthe following sections discuss a few ways to configure your FTP server.\nRemember to restart the vsftpd  service after making any configuration changes.\nSetting up user access\nThe vsftpd  server comes with all local Linux users (those listed in the /etc/passwd  file) \nconfigured to access the server and the anonymous user prevented. This is based on the fol -\nlowing vsftpd.conf  settings:\nanonymous_enable=NO\nlocal_enable=YES", "doc_id": "65ffb4a8-088d-4783-957d-90df6add4cb2", "embedding": null, "doc_hash": "8a7cfbe0d6cb3d19404d0e78039cf53ddb1374ee2f9b9aab7363476c78bce43f", "extra_info": {"page_label": "489"}, "node_info": {"start": 0, "end": 2372}, "relationships": {"1": "11ab501b-8b90-4ef7-b488-65a39ba08944"}}, "__type__": "1"}, "640d7a25-0eee-41bc-be68-5764b1ae0618": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator466Some web server companies let users use FTP to upload the content for their own web \nservers. In some cases, the users have FTP-only accounts, meaning that they cannot log in \nto a shell, but they can log in via FTP to manage their content. Creating a user account that \nhas no default shell (actually, /sbin/nologin ) is how you can keep a user from logging \ninto a shell but still allow FTP access. For example, the /etc/passwd  entry for the FTP-\nonly user account bill  might look something like the following:\nbill:x:1000:1000:Bill Jones:/home/bill:/sbin/nologin\nWith the user account set with /sbin/nologin  as the default shell, any attempts to log \nin from a console or via ssh  as the user bill  are denied. However, as long as bill  has a \npassword and local account access to the FTP server is enabled, bill  should be able to log \nin to the FTP server via an FTP client.\nNot every user with an account on the Linux system has access to the FTP server. The \nsetting userlist _ enable=YES  in vsftpd.conf  says to deny access to the FTP server \nto all accounts listed in the /etc/vsftpd/user _ list  file. That list includes admin -\nistrative users root , bin , daemon , adm , lp, and others. You can add to that list other \nusers to whom you would like to deny access.\nIf you change userlist _ enable  to NO , the user _ list  file becomes a list of only \nthose users who do have access to the server. In other words, setting userlist _\nenable=NO , removing all usernames from the user _ list  file, and adding the user -\nnames chris , joe , and mary  to that file cause the server to allow only those three users \nto log in to the server.\nNo matter how the value of userlist _ enable  is set, the /etc/vsftpd/ftpusers  file \nalways includes users who are denied access to the server. Like the userlist _ enable  \nfile, the ftpusers  file includes a list of administrative users. You can add more users to \nthat file if you want them to be denied FTP access.\nOne way to limit access to users with regular user accounts on your system is to use \nchroot  settings. Here are examples of some chroot  settings:\nchroot_local_user=YES\nchroot_list_enable=YES\nchroot_list_file=/etc/vsftpd/chroot_list\nWith the settings just shown uncommented, you could create a list of local users and add \nthem to the /etc/vsftpd/chroot _ list  file. After one of those users logged in, that \nuser would be prevented from going to places in the system that were outside of that user\u2019s \nhome directory structure.\nIf uploads to your FTP server are allowed, the directories a user tries to upload to must be \nwriteable by that user. However, uploads can be stored under a username other than that \nof the user who uploaded the file. This is one of the features discussed next, in the section \n\u201cAllowing uploading.\u201d", "doc_id": "640d7a25-0eee-41bc-be68-5764b1ae0618", "embedding": null, "doc_hash": "73ed61816cbd5586d209fe08e8ac2d69af482c72441acfec548aae5cb72a6825", "extra_info": {"page_label": "490"}, "node_info": {"start": 0, "end": 2848}, "relationships": {"1": "58fffb2b-02fd-4529-ba71-9abc38e20808"}}, "__type__": "1"}, "168f34c4-67a1-4099-9ee7-b6df32b205ed": {"__data__": {"text": "Chapter 18: Configuring an FTP Server\n467\n18Allowing uploading\nTo allow any form of writing to the vsftpd  server, you must have write _ enable=YES  \nset in the vsftpd.conf  file (which it is, by default). Because of that, if local accounts are \nenabled, users can log in and immediately begin uploading files to their own home direc -\ntories. However, anonymous users are denied the ability to upload files by default.\nTo allow anonymous uploads with vsftpd , you must have the first option in the follow -\ning code example, and you may want the second line of code as well (both can be enabled \nby uncommenting them from the vsftpd.conf  file). The first allows anonymous users to \nupload files; the second allows them to create directories:\nanon_upload_enable=YES\nanon_mkdir_write_enable=YES\nThe next step is to create a directory where anonymous users can write. Any directory \nunder the /var/ftp  directory that has write permissions for the user ftp , the ftp  group, \nor other  can be written to by an anonymous user. A common thing is to create an uploads \ndirectory with permission open for writing. The following are examples of commands to run \non the server:\n# mkdir /var/ftp/uploads\n# chown ftp:ftp /var/ftp/uploads\n# chmod 775 /var/ftp/uploads\nAs long as the firewall is open and SELinux Booleans are set properly, an anonymous user \ncan cd  to the uploads directory and put a file from the user\u2019s local system into the uploads \ndirectory. On the server, the file would be owned by the ftp  user and ftp  group. The per -\nmissions set on the directory (775) would allow you to see the files that were uploaded but \nnot change or overwrite them.\nOne reason for allowing anonymous FTP, and then enabling it for anonymous uploads, is to \nallow people you don\u2019t know to drop files into your uploads folder. Because anyone who can \nfind the server can write to this directory, some form of security needs to be in place. You \nwant to prevent an anonymous user from seeing files uploaded by other users, taking files, \nor deleting files uploaded by other anonymous FTP users. One form of security is the chown  \nfeature of FTP.\nBy setting the following two values, you can allow anonymous uploads. The result of these \nsettings is that when an anonymous user uploads a file, that file is immediately assigned \nownership of a different user. The following is an example of some chown  settings that you \ncould put in your vsftpd.conf  file to use with your anonymous upload directory:\nchown_uploads=YES\nchown_username=joe\nIf an anonymous user were to upload a file after vsftpd  was restarted with these settings, \nthe uploaded file would be owned by the user joe  and the ftp  group. Permissions would be \nread/write for the owner and nothing for anyone else ( rw------- ).", "doc_id": "168f34c4-67a1-4099-9ee7-b6df32b205ed", "embedding": null, "doc_hash": "b7607df4eae79c9abed340d0b10d9848ef4e71e451dd20c2731d4fe5b3bb2169", "extra_info": {"page_label": "491"}, "node_info": {"start": 0, "end": 2781}, "relationships": {"1": "b73b90bc-47a6-48ec-b832-04ecb57e3035"}}, "__type__": "1"}, "9653f3c0-ed3a-463d-b0e3-6b5d7ffa9f16": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator468So far, you have seen configuration options for individual features on your vsftpd  server. \nSome sets of vsftp.conf  variables can work together in ways that are appropriate for \ncertain kinds of FTP sites. The next section contains one of these examples, represented by \na sample vsftpd.conf  configuration file that comes with the vsftpd  package. That file \ncan be copied from a directory of sample files to the /etc/vsftpd/vsftpd.conf  file to \nuse for an FTP server that is available on the Internet.\nSetting up vsftpd for the Internet\nTo share files from your FTP server safely to the Internet, you can lock down your server by \nlimiting it to only allow downloads and only from anonymous users. To start with a configu -\nration that is designed to share vsftpd  files safely over the Internet, back up your current \n/etc/vsftpd/vsftpd.conf  file and copy this file to overwrite your vsftpd.conf :\n/usr/share/doc/vsftpd/EXAMPLE/INTERNET_SITE/vsftpd.conf\nThe following paragraphs describe the contents of that vsftpd.conf . Settings in the first \nsection set the access rights for the server:\n# Access rights\nanonymous_enable=YES\nlocal_enable=NO\nwrite_enable=NO\nanon_upload_enable=NO\nanon_mkdir_write_enable=NO\nanon_other_write_enable=NO\nTurning on anonymous _ enable (YES) and turning off local_ enable (NO) ensures \nthat no one can log in to the FTP server using a regular Linux user account. Everyone must \ncome in through the anonymous account. No one can upload files ( write _ enable=NO ). \nThen, the anonymous user cannot upload files ( anon _ upload _ enable=NO ), create \ndirectories ( a n o n_mk d i r_w r i t e_e n a b l e = N O ), or otherwise write to the server \n(anon _ other _ write _ enable=NO ). Here are the Security settings:\n# Security\nanon_world_readable_only=YES\nconnect_from_port_20=YES\nhide_ids=YES\npasv_min_port=50000\npasv_max_port=60000\nBecause the vsftpd  daemon can read files assigned to the ftp  user and group, setting \nanon _ world _ readable _ only=YES  ensures that anonymous users can see files where \nthe read permission bit is turned on for other (------r--) , but not write files. The con -\nn e c t_f r om_po rt_2 0 = YE S  setting gives the vsftpd  daemon slightly more permission \nto send data the way a client might request by allowing PORT -style data communications.\nUsing hide _ ids=YES  hides the real permissions set on files, so to the user accessing the \nFTP site, everything appears to be owned by the ftp  user. The two pasv  settings restrict \nthe range of ports that can be used with passive FTP (where the server picks a higher \nnumber port on which to send data) to between 50000 and 60000.", "doc_id": "9653f3c0-ed3a-463d-b0e3-6b5d7ffa9f16", "embedding": null, "doc_hash": "8075e7938a9af8382ac6a02979944ed65b3db920c8a63a509187a88ebc160aec", "extra_info": {"page_label": "492"}, "node_info": {"start": 0, "end": 2700}, "relationships": {"1": "2d705883-ec5d-41bc-90fc-62f01d59ee9c"}}, "__type__": "1"}, "c9e6cb81-6b56-4aac-846b-b998afd66609": {"__data__": {"text": "Chapter 18: Configuring an FTP Server\n469\n18The next section contains features of the vsftpd  server:\n# Features\nxferlog_enable=YES\nls_recurse_enable=NO\nascii_download_enable=NO\nasync_abor_enable=YES\nWith xferlog _ enable=YES , all file transfers to and from the server are logged to the  \n/var/log/xferlog  file. Setting ls _ recurse _ enable=NO  prevents users from recur -\nsively listing the contents of an FTP directory (in other words, it prevents the type of \nlisting that you could get with the ls -R  command) because on a large site, that could \ndrain resources. Disabling ASCII downloads forces all downloads to be in binary mode (pre -\nventing files from being translated in ASCII, which is inappropriate for binary files). The \nasync _ abor _ enable=YES  setting ensures that some FTP clients, which might hang \nwhen aborting a transfer, will not hang.\nThe following settings have an impact on performance:\n# Performance\none_process_model=YES\nidle_session_timeout=120\ndata_connection_timeout=300\naccept_timeout=60\nconnect_timeout=60\nanon_max_rate=50000\nWith one _ process _ model=YES  set, performance can improve because vsftpd  \nlaunches one process per connection. Reducing the idle _ session _ timeout  from the \ndefault 300 seconds to 120 seconds causes FTP clients that are idle more than 2 minutes to \nbe disconnected. Thus, less time is spent managing FTP sessions that are no longer in use. \nIf a data transfer stalls for more than data _ connection _ timeout  seconds (300 sec -\nonds here), the connection to the client is dropped.\nThe accept _ timeout  setting of 60 seconds allows 1 minute for a PASV connection to be \naccepted by the remote client. The connect _ timeout  sets how long a remote client has \nto respond to a request to establish a PORT -style data connection. Limiting the transfer \nrate to 50000 (bytes per second) with anon _ max _rate  can improve overall perfor -\nmance of the server by limiting how much bandwidth each client can consume.\nUsing FTP Clients to Connect to Your Server\nMany client programs come with Linux, which you can use to connect to your FTP server. \nIf you simply want to do an anonymous download of some files from an FTP server, your \nFirefox web browser provides an easy interface to do that. For more complex interactions \nbetween your FTP client and server, you can use command-line FTP clients. The following \nsections describe some of these tools.", "doc_id": "c9e6cb81-6b56-4aac-846b-b998afd66609", "embedding": null, "doc_hash": "1c4e915901deab792e7f3f6116df6ad584d7c86b51549ec67b55ae1745367e80", "extra_info": {"page_label": "493"}, "node_info": {"start": 0, "end": 2420}, "relationships": {"1": "5ab02fa1-6a86-4def-a89b-28775226dca2"}}, "__type__": "1"}, "ce11222d-7569-4797-9871-2ce7de3e78f0": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator470Accessing an FTP server from Firefox\nThe Firefox web browser provides a quick and easy way to test access to your FTP server or \nto access any public FTP server. On your own system, type ftp://localhost  into the loca -\ntion box. You are prompted to log in, which you can do as a regular user or the anonymous \nuser if your server is accessible via anonymous FTP. As the anonymous user, you should see \nsomething similar to the example shown in Figure\u00a018.2.\nTo log in to an FTP server as a particular user from Firefox, you can precede the host name \nwith a username:password@  notation, as shown in the following example:\nftp://chris:MypassWd5@localhost\nIf you provide the correct username and password, you should immediately see the contents \nof your home directory. Click a folder to open it. Click a file to download or view the file.\nAccessing an FTP server with the lftp command\nTo test your FTP server from the command line, you can use the lftp  command. To install \nthe lftp  command in Fedora or RHEL, enter the following from the command line:\n# yum install lftp\nIf you use the lftp  command with just the name of the FTP server you are trying to \naccess, the command tries to connect to the FTP server as the anonymous user. By adding \nthe -u username , you can enter the user\u2019s password when prompted and gain access to the \nFTP server as the user you logged in as.\nFIGURE 18.2\nAccessing an FTP server from Firefox", "doc_id": "ce11222d-7569-4797-9871-2ce7de3e78f0", "embedding": null, "doc_hash": "c12fbb45b519c8d122edfb97728d0fe71fa0320c6c13dd2a6e427368db2bce7c", "extra_info": {"page_label": "494"}, "node_info": {"start": 0, "end": 1477}, "relationships": {"1": "54c18693-9d61-472c-b4aa-a2a2b9603ce9"}}, "__type__": "1"}, "8063fde7-bace-4648-b543-c05e60c6ec55": {"__data__": {"text": "Chapter 18: Configuring an FTP Server\n471\n18After you have added your user and password information, you get an lftp  prompt, ready \nfor you to start typing commands. The connection is made to the server when you type \nyour first command. You can use the commands to move around the FTP server and then \nuse the get  and put  commands to download and upload files.\nThe following example shows how to use commands as just described. It assumes that the \nFTP server (and associated security measures) has been configured to allow local users to \nconnect and to read and write files:\n# lftp -u chris localhost\nPassword:\n********\nlftp chris@localhost:~> pwd\nftp://chris@localhost/%2Fhome/chris\nlftp chris@localhost:~> cd stuff/state/\nlftp chris@localhost:~/stuff/state> ls\n-rw-r--r--    1 13597    13597        1394 Oct 23  2014 \nenrolled-20141012\n-rw-r--r--    1 13597    13597         514 Oct 23  2014 \nenrolled-20141013\nlftp chris@localhost:~/stuff/state> !pwd\n/root\nlftp chris@localhost:~/stuff/state> get survey-20141023.txt\n3108 bytes transferred\nlftp chris@localhost:~/stuff/state> put /etc/hosts\n201 bytes transferred\nlftp chris@localhost:~/stuff/state> ls\n-rw-r--r--    1 13597    13597        1394 Oct 23  2014 \nenrolled-20141012\n-rw-r--r--    1 13597    13597         514 Oct 23  2014 \nenrolled-20141013\n-rw-r--r--    1 0        0             201 May 03 20:22 hosts\nlftp chris@localhost:~/stuff/state> !ls\nanaconda-ks.cfg          bin           install.log\ndog                      Pictures      sent\nDownloads                Public        survey-20141023.txt\nlftp chris@localhost:~/stuff/state> quit\nAfter providing the username ( -u chris ), lftp  prompts for chris\u2019s Linux user password. \nTyping pwd  shows that chris is logged in to the local host and that /home/chris  is the \ncurrent directory. Just as you would from a regular Linux command-line shell, you can use \ncd to change to another directory and ls  to list that directory\u2019s contents.\nTo have the commands you run interpreted by the client system, you can simply put an excla -\nmation mark ( !) in front of a command. For example, running !pwd  shows that the current \ndirectory on the system that initiated the lftp  is /root . This is good to know because if \nyou get a file from the server without specifying its destination, it goes to the client\u2019s current \ndirectory (in this case, /root ). Other commands you might run so that they are interpreted \nby the client system include !cd  (to change directories) and !ls  (to list files).", "doc_id": "8063fde7-bace-4648-b543-c05e60c6ec55", "embedding": null, "doc_hash": "374a134046d38afdcf78f1197d01cfd9a74176d57ca6c762f786aa21d2815581", "extra_info": {"page_label": "495"}, "node_info": {"start": 0, "end": 2510}, "relationships": {"1": "aee9432e-a670-489f-93a3-54efce08279c"}}, "__type__": "1"}, "322f7966-0d2d-427b-8a75-2eea9363af12": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator472Assuming that you have read permission for a file on the server and write permission from \nthe current directory on the initiating system, you can use the get  command to download \na file from the server ( get survey-20141023.txt ). If you have write and upload per -\nmission on the current directory on the server, you can use put  to copy a file to the server \n(put /etc/hosts ).\nRunning an ls  command shows that the /etc/hosts  file was uploaded to the server. \nRunning the !ls  command lets you see that the survey-20141023.txt  file was down -\nloaded from the server to the initiating system.\nUsing the gFTP client\nMany other FTP clients are available with Linux as well. Another FTP client that you could \ntry is gFTP. The gFTP client provides an interface that lets you see both the local and \nremote sides of your FTP session. To install gFTP in Fedora, run the following command to \ninstall the gftp  package:\n# yum install gftp\nTo start gFTP, launch it from the applications menu or run gftp &  from the shell. To use \nit, type the URL of the FTP server to which you wish to connect, enter the username you \nwant to use (such as anonymous), and press Enter. Figure\u00a018.3 shows an example of gFTP \nbeing used to connect to the gnome.org  site: ftp.gnome.org .\nFIGURE 18.3\nThe gFTP FTP client lets you see both sides of an FTP session.", "doc_id": "322f7966-0d2d-427b-8a75-2eea9363af12", "embedding": null, "doc_hash": "2525da008f305cde5be778904dcb2797ec71a7bdf3a841b638a941bef1a6c852", "extra_info": {"page_label": "496"}, "node_info": {"start": 0, "end": 1392}, "relationships": {"1": "58c749ac-5f89-4265-b05d-aa26c9473a05"}}, "__type__": "1"}, "38843e45-e339-4d63-8fd4-e528a1d1dece": {"__data__": {"text": "Chapter 18: Configuring an FTP Server\n473\n18To traverse the FTP site from gFTP, just double-click folders (just as you would from a file \nmanager window). The full paths to the local directory (on the left) and remote directory \n(on the right) are shown above the listings of files and folders below.\nTo transfer a file from the remote side to the local side, select the file that you want from \nthe right and click the arrow in the middle of the screen pointing to the left. Watch the \nprogress of the file transfer from messages on the bottom of the screen. When the transfer \ncompletes, the file appears in the left pane.\nYou can bookmark the address information that you need to connect to an FTP site. That \naddress is added to a set of bookmarks already stored under the Bookmarks menu. You can \nselect sites from the list to try out the gFTP. Most of the sites are for Linux distributions \nand other open source software sites.\nSummary\nSetting up an FTP server is an easy way to share files over a TCP network. The Very Secure \nFTP Daemon ( vsftpd  package) is available for Fedora, Red Hat Enterprise Linux, Ubuntu, \nand other Linux systems.\nA default vsftpd  server allows anonymous users to download files from the server and \nregular Linux users to upload or download files (provided the correct security settings are \napplied). Moving around on an FTP server is similar to moving around a Linux filesystem. \nYou move up and down the directory structure to find the content that you want.\nThere are both graphical and text-based FTP clients. A popular text-based client for Linux \nis lftp . As for graphical FTP clients, you can use a regular web browser, such as Firefox, or \ndedicated FTP clients, such as gFTP.\nFTP servers are not the only way to share files over a network from Linux. The Samba ser -\nvice provides a way to share files over a network so that the shared Linux directory looks \nlike a shared directory from a Windows system. Chapter\u00a019, \u201cConfiguring a Windows File \nSharing (Samba) Server,\u201d describes how to use Samba to offer Windows-style file sharing.\nExercises\nThe exercises in this section describe tasks related to setting up an FTP server in RHEL or \nFedora and connecting to that server using an FTP client. If you are stuck, solutions to the \ntasks are shown in Appendix B. Keep in mind that the solutions shown in Appendix B are \nusually just one of multiple ways to complete a task.\nDon\u2019t do these exercises on a Linux system running a public FTP server because they almost \ncertainly will interfere with that server.\n1. Determine which package provides the Very Secure FTP Daemon service.\n2. Install the Very Secure FTP Daemon package on your system, and search for the \nconfiguration files in that package.", "doc_id": "38843e45-e339-4d63-8fd4-e528a1d1dece", "embedding": null, "doc_hash": "cde4ac7d7e33de574a9bf4d341c8753473df63611fabf2798908d0c1ec1d0f54", "extra_info": {"page_label": "497"}, "node_info": {"start": 0, "end": 2749}, "relationships": {"1": "224b1cf7-2c74-4358-84a8-c16d8d730a4b"}}, "__type__": "1"}, "19e45eb1-0ee6-4e79-855a-44de8cb57bd4": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator4743. Enable anonymous FTP and disable local user login for the Very Secure FTP \nDaemon service.\n4. Start the Very Secure FTP Daemon service and set it to start when the system boots.\n5. On the system running your FTP server, create a file named test  in the anonymous \nFTP directory that contains the words \u201cWelcome to your vsftpd server.\u201d\n6. From a web browser on the system running your FTP server, open the test  \nfile from the anonymous FTP home directory. Be sure that you can see that \nfile\u2019s contents.\n7. From a web browser outside of the system that is running the FTP server, try to \naccess the test  file in the anonymous FTP home directory. If you cannot access \nthe file, check that your firewall, SELinux, and TCP wrappers are configured to allow \naccess to that file.\n8. Configure your vsftpd  server to allow file uploads by anonymous users to a direc -\ntory named in .\n9. Install the lftp  FTP client (if you don\u2019t have a second Linux system, install lftp  \non the same host running the FTP server). If you cannot upload files to the in  \ndirectory, check that your firewall, SELinux, and TCP wrappers are configured to \nallow access to that file.\n10. Using any FTP client you choose, visit the /pub/debian-meetings  directory on \nthe ftp.gnome.org  site and list the contents of that directory.", "doc_id": "19e45eb1-0ee6-4e79-855a-44de8cb57bd4", "embedding": null, "doc_hash": "0e1b6f208b7f5ab6ce71f2263232c6c05bea25d856531547b4b0f60be0faef98", "extra_info": {"page_label": "498"}, "node_info": {"start": 0, "end": 1358}, "relationships": {"1": "e758bd70-2e60-43d7-8b42-2aa4c9e14530"}}, "__type__": "1"}, "a98fa7dd-0582-4c08-a929-948ec13c72d8": {"__data__": {"text": "475\nCHAPTER19\nConfiguring a Windows File \nSharing (Samba) Server\nIN THIS CHAPTER\nGetting and installing Samba\nUsing Samba security features\nEditing the smb.conf  configuration file\nAccessing Samba from Linux and Windows clients\nUsing Samba in the enterprise\nSamba is the project that implements open source versions of protocols used to share files \nand printers among Windows systems as well as authenticate users and restrict hosts. Samba \noffers a number of ways to share files among Windows, Linux, and MacOS systems that are \nwell known and readily available to users of those systems.\nThis chapter steps you through the process of installing and configuring a Samba server. It describes \nthe security features that you need to know to share your file and printer resources and describes \nhow to access those resources from Linux and Windows systems.\nUnderstanding Samba\nSamba  (https://samba.org ) is a suite of programs that allows Linux, UNIX, and other systems to \ninteroperate with Microsoft Windows file and printer sharing protocols. Windows, MacOS, and other \nclient systems can access Samba servers to share files and printers in the same ways that they \nwould from Windows file and print servers.\nWith Samba, you can use standard TCP/IP networking to communicate with clients. For name service, \nSamba supports regular TCP/IP hostnames as well as NetBIOS names. For that reason, Samba doesn\u2019t \nrequire the NetBEUI (Microsoft Raw NetBIOS frame) protocol. File sharing is done using Server Mes -\nsage Block (SMB) protocol, which is sometimes referred to as the Common Internet File System (CIFS) .\nThe Samba project has gone to great lengths to make its software secure and robust. In fact, many peo -\nple prefer using Samba servers over Windows file servers because of the added security that is inherent \nin running Windows-style file sharing services on Linux or other UNIX-like operating systems.\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "a98fa7dd-0582-4c08-a929-948ec13c72d8", "embedding": null, "doc_hash": "e994e422795ce975e453a63e1e32a5a3d1965e744c088676de6315b5c16025c0", "extra_info": {"page_label": "499"}, "node_info": {"start": 0, "end": 2036}, "relationships": {"1": "c0644d39-0c18-4a19-b2c0-c8e3f6f1efe3"}}, "__type__": "1"}, "558187ce-9729-4c0d-ad2a-d5d0afbc3ff5": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator476Beyond all of the technical mumbo-jumbo, however, the end result is that Samba makes \nit easy to share files and printers between Linux servers and Windows desktop systems. \nFor the server, only a few configuration files and tools are needed to manage Samba. For \nthe clients, shared resources just show up under Network selection in the File Explorer \n(formerly Windows Explorer) application or in the Network Neighborhood on older Win -\ndows systems.\nTo configure the Samba service, you directly edit Samba configuration files (particularly \nsmb.conf ) and run a few commands. Graphical and web-based interfaces, such as sys -\ntem-config-samba  and Samba SWAT, are no longer included with the latest Fedora and \nRHEL systems.\nTo begin using Samba on your Linux system, you need to install a few software packages, \nas described in the next section.\nInstalling Samba\nIn Red Hat Enterprise Linux and Fedora, to configure a Samba file and print server, \ninstalling the samba  package gets you everything you need to start. Among other com-\nponents, the samba  package includes the Samba service daemon ( /usr/sbin/smbd ) and \nNetBIOS name server daemon ( /usr/sbin/nmbd ). Installing the samba  package pulls \nin the samba-common  package, which contains server configuration files ( smb.conf , \nlmhosts , and others) and commands for adding passwords and testing configuration files, \nalong with other Samba features.\nFeatures from other packages are referenced in this chapter, so I describe how to install \nthose packages as well. Those packages include the following:\nsamba-client  package : Contains command-line tools such as smbclient  (for \nconnecting to Samba or Windows shares), nmblookup  (for looking up host \naddresses), and findsmb  (to find SMB hosts on the network).\nsamba-winbind  package : Includes components that allow your Samba server in \nLinux to become a complete member of a Windows domain, including using Windows \nuser and group accounts in Linux.\nTo install all the packages just mentioned ( samba-common  is installed as a dependency \nof samba , so it doesn\u2019t need to be noted specifically), enter the following as root from the \ncommand line in Fedora or RHEL:\n# yum install samba samba-client samba-winbind\n...\nLast metadata expiration check: 0:01:44 ago on Sun 24 Jan 2020 \n11:35:37 AM EST.\nDependencies resolved.", "doc_id": "558187ce-9729-4c0d-ad2a-d5d0afbc3ff5", "embedding": null, "doc_hash": "0914ce0d7186c8a83f94f799e4cef063d07fcb7941c1b162215085467c97a091", "extra_info": {"page_label": "500"}, "node_info": {"start": 0, "end": 2393}, "relationships": {"1": "fd289f34-a684-4ff6-9e09-cbcf600c64e8"}}, "__type__": "1"}, "19c47ad2-f1e5-49f6-a010-c8619bc9a10c": {"__data__": {"text": "Chapter 19: Configuring a Windows File Sharing (Samba) Server\n477\n19=====================================================================\n Package       Architecture     Version  Repository                    \nSize\n=====================================================================\nInstalling:\n samba         x86_64  4.10.4-101.el8_1  rhel-8-for-x86_64-baseos-\nrpms 739 k\n samba-winbind x86_64  4.10.4-101.el8_1  rhel-8-for-x86_64-baseos-\nrpms 570 k\nInstalling dependencies:\n samba-common-tools\n               x86_64  4.10.4-101.el8_1  rhel-8-for-x86_64-baseos-\nrpms 469 k\n samba-libs    x86_64  4.10.4-101.el8_1  rhel-8-for-x86_64-baseos-\nrpms 185 k\n samba-winbind-modules\n               x86_64  4.10.4-101.el8_1  rhel-8-for-x86_64-baseos-\nrpms 122 k\n samba-client  x86_64  4.10.4-101.el8_1  rhel-8-for-x86_64-baseos-\nrpms 658 k\n \nTransaction Summary\n=====================================================================\nInstall  6 Packages\n \nTotal download size: 2.5 M\nInstalled size: 6.8 M\nIs this ok [y/d/N]: y\nAfter you have installed the Samba packages, look at the configuration files in the samba-\ncommon  package:\n# rpm -qc samba-common\n/etc/logrotate.d/samba\n/etc/samba/lmhosts\n/etc/samba/smb.conf\n/etc/sysconfig/samba\nThe /etc/logrotate.d/samba  and /etc/sysconfig/samba  files are usually not mod -\nified. The first sets how files in /var/log/samba  log files are rotated (copied to other \nfiles and removed) over time. The second is a file where you could put options that are \npassed to the smbd , nmbd , or winbindd  daemon, so you could turn off features such as \ndebugging.\nMost configuration files that you would modify for Samba are in the /etc/samba  direc -\ntory. The smb.conf  file is the primary configuration file where you put global settings \nfor the Samba server as well as individual file and printer share information (more on \nthat later). The lmhosts  file enables the Samba NetBIOS hostname to be mapped into IP \naddresses.", "doc_id": "19c47ad2-f1e5-49f6-a010-c8619bc9a10c", "embedding": null, "doc_hash": "5c39f9f2391b2b298b5b02145d2f43b45a96734473120be7a484201d56b31cd8", "extra_info": {"page_label": "501"}, "node_info": {"start": 0, "end": 1958}, "relationships": {"1": "2b4ddbce-1b3f-4aa6-8da5-01aa3b3b1b30"}}, "__type__": "1"}, "06ef845b-2125-44a8-b638-0a153b27cecb": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator478Although it doesn\u2019t exist by default, you can create a file named /etc/samba/smbusers  \nto map Linux usernames into Windows usernames. As you configure your Samba server, \nyou can refer to the smb.conf  man page ( man smb.conf ). There are also man pages for \nSamba commands, such as smbpasswd  (to change passwords), smbclient  (to connect to \na Samba server), and nmblookup  (to look up NetBIOS information).\nAfter you have installed Samba packages and completed a quick survey of what they con -\ntain, try starting up the Samba service and see what you get in a default configuration.\nStarting and Stopping Samba\nWith samba  and samba-common  installed, you can start the server and investigate how \nit runs in the default configuration. Two main services are associated with a Samba server, \neach of which has its own service daemon:\nsmb: This service controls the smbd daemon process, which provides the file and print \nsharing services that can be accessed by Windows clients.\nnmb: This service controls the nmbd  daemon. By providing NetBIOS name service \nname-to-address mapping, nmbd  can map requests from Windows clients for NetBIOS \nnames so that they can be resolved into IP addresses.\nTo share files and printers with other Linux systems with Samba, only the smb service is \nrequired. The next section describes how to start and enable the smb service.\nStarting the Samba (smb) service\nThe smb service is what starts the smbd server and makes files and printers available from \nyour local system to other computers on the network. As usual, services are enabled and \nstarted differently on different Linux systems. For different Linux systems, you need to \nfind the name of the service and the correct tool to start the smbd daemon.\nIn Fedora and RHEL, to enable Samba to start immediately when the system boots, enter \nthe following from the command line as root:\n# systemctl enable smb.service\n# systemctl start smb.service\n# systemctl status smb.service\nsmb.service - Samba SMB Daemon\n  Loaded: loaded (/usr/lib/systemd/system/smb.service; enabled)\n  Active: active (running) since Fri 2020-01-31 07:23:37 EDT; 6s ago\n     Docs: man:smbd(8)\n           man:samba(7)\n           man:smb.conf(5)\n   Status: \"smbd: ready to serve connections...\"\n    Tasks: 4 (limit: 12216)\n   Memory: 20.7M\n Main PID: 4838 (smbd)\nCGroup: /system.slice/smb.service", "doc_id": "06ef845b-2125-44a8-b638-0a153b27cecb", "embedding": null, "doc_hash": "3f8047b35fca2f0ef7e1ba2b06c60e75037aae182b18f428ee88638532874714", "extra_info": {"page_label": "502"}, "node_info": {"start": 0, "end": 2408}, "relationships": {"1": "a3621a50-4f14-4b2f-9dfd-a8367464268f"}}, "__type__": "1"}, "69c0ace7-157d-47c7-b265-9fa529625fe9": {"__data__": {"text": "Chapter 19: Configuring a Windows File Sharing (Samba) Server\n479\n19  \u251c 4838 /usr/sbin/smbd --foreground --no-process-group\n  \u2514 4840 /usr/sbin/smbd --foreground --no-process-group\nThe first systemctl  command enables the service, the second starts it immediately, and \nthe third shows the status. To investigate further, notice that the service file is located at \n/usr/lib/systemd/system/smb.service . Look at the contents of that file:\n# cat /usr/lib/systemd/system/smb.service\n[Unit]\nDescription=Samba SMB Daemon\nDocumentation=man:smbd(8) man:samba(7) man:smb.conf(5)\nWants=network-online.target\nAfter=network.target network-online.target nmb.service winbind.\nservice\n[Service]\nType=notify\nNotifyAccess=all\nPIDFile=/run/smbd.pid\nLimitNOFILE=16384\nEnvironmentFile=-/etc/sysconfig/samba\nExecStart=/usr/sbin/smbd --foreground --no-process-group $SMBDOPTIONS\nExecReload=/bin/kill -HUP $MAINPID\nLimitCORE=infinity\nEnvironment=KRB5CCNAME=FILE:/run/samba/krb5cc_samba\n[Install]\nWantedBy=multi-user.target\nThe Samba daemon process ( smbd ) starts up after the network , network-online , nmb , \nand winbind  targets. The /etc/sysconfig/samba  file contains variables that are \npassed as arguments to the smbd , nmbd , and winbindd  daemons when they start. No \noptions are set by default for any of those daemons. The WantedBy  line indicates that \nsmb.service  should start when the system boots up into multi-user mode ( multi-user.\ntarget ), which it does by default.\nIn RHEL 6 and earlier, you can start the Samba service as follows:\n# service smb start\nStarting SMB services:        [  OK  ]\n# chkconfig smb on\n# service smb status\nsmbd (pid  28056) is running...\n# chkconfig --list smb\nsmb              0:off  1:off  2:on  3:on  4:on  5:on  6:off\nWhether you are running your Samba server on RHEL, Fedora, or another Linux system, you \ncan check access to the Samba server using the smbclient  command (from the samba-\nclient  package). You can get basic information from a Samba server using the follow -\ning command:\n# smbclient -L localhost\nEnter SAMBA\\root's password: <ENTER>", "doc_id": "69c0ace7-157d-47c7-b265-9fa529625fe9", "embedding": null, "doc_hash": "3acf05a2364698e56386c9ca40f8a0f028df9ef754629c57fa59024f42be24f2", "extra_info": {"page_label": "503"}, "node_info": {"start": 0, "end": 2080}, "relationships": {"1": "43aee3c9-3962-487f-9f6e-06a284bdf3bd"}}, "__type__": "1"}, "f9c5dfd8-0104-4b58-a51b-5a6c8fa536b6": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator480Anonymous login successful\n \n   Sharename  Type    Comment\n   ---------  ----    -------\n   print$     Disk    Printer Drivers\n   IPC$       IPC     IPC Service\n (Samba Server Version 4.10.10)\n   deskjet    Printer deskjet\nReconnecting with SMB1 for workgroup listing.\nAnonymous login successful\n    Server               Comment\n    ---------            -------\n    Workgroup            Master\n    ---------            -------\nThe smbclient  output allows you to see what services are available from the server. By \ndefault, anonymous login is allowed when querying the server (so I just pressed Enter when \nprompted for a password).\nYou can discern a number of things about the default Samba server setup from this output:\n\u25a0\u25a0All printers that are shared via the CUPS server on your Linux system are, by \ndefault, also made available from the Samba server running on that same system.\n\u25a0\u25a0No directories are shared yet from the server.\n\u25a0\u25a0There is no NetBIOS name service running yet from the Samba server.\nNext, you can decide whether you want to run the NetBIOS name service on your \nSamba server.\nStarting the NetBIOS (nmbd) name server\nIf no Windows domain server is running on the network, as is the case here, you can start \nthe nmb  service on the Samba host to provide that service. To start the nmb  service (nmbd  \ndaemon) in Fedora or RHEL 7, type the following:\n# systemctl enable nmb.service\n# systemctl start nmb.service\n# systemctl status nmb.service\nIn RHEL 6 and earlier, you would type the following to start the nmb  service:\n# service nmb start\n# service nmb status\n# chkconfig nmb on\n# chkconfig --list nmb\nRegardless of how the NetBIOS service was started, the nmbd  daemon should now be \nrunning and ready to serve NetBIOS name-to-address mapping. Run the smbclient -L \ncommand again, followed by the IP address of the server. This time, the last few lines of ", "doc_id": "f9c5dfd8-0104-4b58-a51b-5a6c8fa536b6", "embedding": null, "doc_hash": "eb65a649ed36802083083ce0e7790da723dd064df70ee1c8049fe2d5a3946232", "extra_info": {"page_label": "504"}, "node_info": {"start": 0, "end": 1929}, "relationships": {"1": "b83c0836-b1be-4c8a-ac1c-4895bd232512"}}, "__type__": "1"}, "5a86d1ac-bb03-444e-b44b-424a427266b1": {"__data__": {"text": "Chapter 19: Configuring a Windows File Sharing (Samba) Server\n481\n19the output should show the information obtained from the NetBIOS server now running on \nthe Samba server. In this case, the last few lines look like this:\n# smbclient -L localhost\n    ... \n    Workgroup   Master\n    ---------   -------\n    SAMBA       FEDORA30\nYou can see that the new NetBIOS server\u2019s name is FEDORA30  and that it is the master \nserver for the workgroup. To query the nmbd  server for the IP address of FEDORA30 , you \nwould enter the following:\n# nmblookup -U localhost FEDORA30\nquerying FEDORA30 on 127.0.0.1\n192.168.122.81 FEDORA30<00>\nYou should be able to see your Samba server running from the local system now. The host -\nname assigned to the system (in this case FEDORA30 ) is assigned by default.\nHowever, if you have a firewall configured or SELinux enabled, you may not be able to \naccess the Samba server fully from a remote system yet. The next section should help you \nto open Samba to systems outside of the local system as well as to allow some Samba fea -\ntures that may be turned off by SELinux.\nStopping the Samba (smb) and NetBIOS (nmb) services\nTo stop the smb and nmb  services in Fedora or RHEL, you can use the same systemctl  \ncommand that you used to start them. You can use the same command to disable the ser -\nvices as well so that they do not start up again when the system boots. Here are examples \nof how to stop the smb and nmb  services immediately:\n# systemctl stop smb.service\n# systemctl stop nmb.service\nIn RHEL 6 and earlier, you would enter the following to stop the smb and nmb  services:\n# service smb stop\n# service nmb stop\nTo prevent the smb and nmb  services from starting the next time the system reboots, enter \nthe following commands in Fedora or RHEL:\n# systemctl disable smb.service\n# systemctl disable nmb.service\nIn Red Hat Enterprise Linux 6 and earlier, enter the following commands to disable the \nsmb and nmb  services:\n# chkconfig smb off\n# chkconfig nmb off", "doc_id": "5a86d1ac-bb03-444e-b44b-424a427266b1", "embedding": null, "doc_hash": "c9550562be57cf9ef21c8c4cc94b81b6cc470a5292a10d403e03f6b462f5a43e", "extra_info": {"page_label": "505"}, "node_info": {"start": 0, "end": 2003}, "relationships": {"1": "d8e883b9-bcd4-4baa-8788-30af6c449733"}}, "__type__": "1"}, "656ea19e-ef35-489f-a7e1-2185a8f9c9d1": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator482Of course, you only want to stop or disable the smb and nmb  services if you no longer want \nto use the Samba service. If you are ready to continue to configure your Samba service, you \ncan continue on and begin to configure your Linux security features to allow the Samba \nservice to become available to others on your network.\nSecuring Samba\nIf you cannot access your Samba server immediately after starting it, you probably have \nsome security work to do. Because many default installations of Linux prevent, rather than \nallow, access to the system, dealing with security for a service such as Samba usually has \nmore to do with making it available than making it secure.\nHere are the security features that you should be aware of when configuring your \nSamba system:\nFirewalls\u00a0The default firewall for Fedora, RHEL, and other Linux systems prevents any \naccess to local services from outside systems. So, to allow users from other com-\nputers to access your Samba service, you must create firewall rules that open one or \nmore ports for selected protocols (TCP in particular).\nSELinux \u00a0Many features of Samba are designated as potentially insecure by SELinux. \nBecause the default SELinux Booleans (on/off switches for certain features) are set \nto provide the least access required, you need to turn Booleans on for features such \nas allowing users to access their own home directories with Samba. In other words, \nyou can configure Samba to share user home directories, but SELinux prohibits \nsomeone from trying to use that feature unless you explicitly configure SELinux to \nallow that feature.\nHost and user restrictions\u00a0Within the Samba configuration files themselves, you can \nindicate which hosts and users can have access to the Samba server as a whole or to \nparticular shared directories.\nThe next sections describe how to set up the security features just mentioned for Samba.\nConfiguring firewalls for Samba\nIf an iptables  or firewalld  firewall is configured for your system when you first install \nit, the firewall typically allows any requests for services from local users but none by outside \nusers. That\u2019s why, at the end of the installation section of this chapter, you should have been \nable to test that Samba was working using the smbclient  command from the local system. \nHowever, if the request originated from another system, it would have been rejected.\nConfiguring firewall rules for Samba mainly consists of opening up incoming ports on which \nthe smbd and nmbd  daemons are listening. These are the ports that you should open to get \na working Samba service on your Linux system:\nTCP port 445 : This is the primary port on which the Samba smbd daemon listens. Your \nfirewall must support incoming packet requests on this port for Samba to work.", "doc_id": "656ea19e-ef35-489f-a7e1-2185a8f9c9d1", "embedding": null, "doc_hash": "13b337183d48e12278276493adf684be9fabbcea13481a90c5a4e35aa52d5a0b", "extra_info": {"page_label": "506"}, "node_info": {"start": 0, "end": 2830}, "relationships": {"1": "ab01a622-1b36-45bb-ba82-b37574fadbb9"}}, "__type__": "1"}, "cc13321b-1313-4321-955d-f851313abd97": {"__data__": {"text": "Chapter 19: Configuring a Windows File Sharing (Samba) Server\n483\n19TCP port 139 : The smbd daemon also listens on TCP port 139 in order to handle \nsessions associated with NetBIOS hostnames. It is possible to use Samba over TCP \nwithout opening this port, but it is not recommended.\nUDP ports 137 and 138 : The nmbd  daemon uses these two ports for incoming NetBIOS \nrequests. If you are using the nmbd  daemon, these two ports must be open for new \npacket requests for NetBIOS name resolution.\nFor Fedora and RHEL, allowing incoming access to those four ports is easy. Simply open the \nFirewall Configuration window, and select the check boxes next to the samba  and samba-\nclient  entries on the public zone, Services tab. Those ports become immediately acces -\nsible (no restart of the firewalld  service is required).\nFor earlier Fedora and RHEL systems that use iptables  directly instead of the fire -\nwalld  service, opening the firewall is a more manual process. Consider a default firewall \nfrom Fedora that allows incoming packets from the local host, from established connec -\ntions, and related to established connections but denies all other incoming packets. The \nfollowing example represents a set of firewall rules in the /etc/sysconfig/iptables  \nfile, with four new rules (highlighted in the example that follows) added to open ports \nfor Samba:\n*filter\n:INPUT ACCEPT [0:0]\n:FORWARD ACCEPT [0:0]\n:OUTPUT ACCEPT [0:0]\n-A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT\n-A INPUT -p icmp -j ACCEPT\n-A INPUT -i lo -j ACCEPT\n-I INPUT -m state --state NEW -m udp -p udp --dport 137 -j ACCEPT\n-I INPUT -m state --state NEW -m udp -p udp --dport 138 -j ACCEPT\n-I INPUT -m state --state NEW -m tcp -p tcp --dport 139 -j ACCEPT\n-I INPUT -m state --state NEW -m tcp -p tcp --dport 445 -j ACCEPT\n-A INPUT -j REJECT --reject-with icmp-host-prohibited\n-A FORWARD -j REJECT --reject-with icmp-host-prohibited\nCOMMIT\nYour firewall may include additional rules to allow incoming packet requests for other \nservices, such as Secure Shell ( sshd ) or web (httpd ) services. You can leave those in \nplace. The main point is to have your Samba rules placed somewhere before the final \nREJECT  rules.\nIf your iptables  firewall is enabled, you can restart it to have the new rules take effect. \nTo do that, type systemctl restart iptables.service  (in older Fedora systems) or \nservice restart iptables  (in RHEL 6 or earlier). Try connecting to the Samba ser -\nvice by using the smbclient  command again, or by using other techniques described in \nthe section \u201cAccessing Samba Shares\u201d later in this chapter.\nSee Chapter\u00a025, \u201cSecuring Linux on a Network,\u201d for more information on using iptables .", "doc_id": "cc13321b-1313-4321-955d-f851313abd97", "embedding": null, "doc_hash": "172375d382ea89417139cb89a56ce69e407e8f82fce2d57123da6bd8f29842a4", "extra_info": {"page_label": "507"}, "node_info": {"start": 0, "end": 2698}, "relationships": {"1": "06c96390-be53-495c-a17f-f2acf2bfbd34"}}, "__type__": "1"}, "8b4335e7-0d2d-42d9-a3ae-29cd0db702b1": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator484Configuring SELinux for Samba\nThere are both file context and Boolean considerations related to using Samba with \nSELinux in enforcing mode. File contexts must be properly set on a directory that is \nshared by Samba. Booleans allow you to override the secure-by-default approach to certain \nSamba features.\nYou can find information on how SELinux confines Samba on the samba _ selinux  man \npage (man samba _ selinux ). You must install the selinux-policy-doc  package to \nget that man page. For a deeper understanding of SELinux, refer to Chapter\u00a024, \u201cEnhancing \nLinux Security with SELinux.\u201d\nSetting SELinux Booleans for Samba\nAn easy way to list and change SELinux Booleans for Samba is from the command line. To \nuse the semanage  command to list Samba-related Booleans, enter the following:\n# semanage boolean -l | egrep \"smb|samba\"\nThe following is a list of SELinux Booleans that apply to Samba and their descriptions. Most \nof the Booleans let you set which files and directories the Samba server can read and write \non behalf of Samba users. Others let you allow potentially insecure features:\nsamba_run_unconfined : Allows samba to run unconfined scripts from \nSamba shares.\nsmbd_anon_write : Allows Samba to let anonymous users modify public files used \nfor public file transfer services. Files and directories must be labeled public_\ncontent_rw_t .\nsamba_enable_home_dirs : Allows Samba to share users\u2019 home directories.\nsamba_export_all_ro : Allows Samba to share any file and directory read-only.\nuse_samba_home_dirs : Allows a remote Samba server to access home directories on \nthe local machine.\nsamba_create_home_dirs : Allows Samba to create new home directories (for \nexample, via PAM).\nsamba_export_all_rw : Allows Samba to share any file or directory read/write.\nThe following Booleans affect Samba\u2019s ability to share directories that are themselves \nmounted from other remote services (such as NFS) or to act as a Windows domain controller:\nsamba_share_fusefs : Allows Samba to export ntfs/fusefs  volumes.\nsamba_share_nfs : Allows Samba to export NFS volumes.\nsamba_domain_controller : Allows Samba to act as the domain controller, add \nusers and groups, and change passwords.\nThe setsebool  command is used to turn the SELinux Booleans on or off. Used with the \n-P option, setsebool  sets the Boolean you indicate permanently. For example, to allow ", "doc_id": "8b4335e7-0d2d-42d9-a3ae-29cd0db702b1", "embedding": null, "doc_hash": "d1dda9c2be41c977cee3208d2caa64cd8ed458691db646c39b5323744a44f8da", "extra_info": {"page_label": "508"}, "node_info": {"start": 0, "end": 2422}, "relationships": {"1": "f57247b5-94f3-45d3-954f-7a59a1560f4f"}}, "__type__": "1"}, "e086310c-8fca-4357-87fc-ca5dd92632cb": {"__data__": {"text": "Chapter 19: Configuring a Windows File Sharing (Samba) Server\n485\n19Samba to share any file or directory with read-only permission from the server, you could \ntype the following from a shell as root user:\n# setsebool -P samba_export_all_ro on\n# getsebool samba_export_all_ro\nsamba_export_all_ro --> on\nThe setsebool  command sets the Boolean in this case to on . The getsebool  lets you \nsee the value of the Boolean.\nSetting SELinux file contexts for Samba\nSELinux confines the files that the Samba service can access. Instead of allowing any file \nwith the proper read and write permission to be shared by the Samba server, SELinux (when \nin enforcing mode) requires that files and directories have the correct file contexts set on \nthem before the Samba service can even see that the files exist.\nIn order for the Samba service to function with SELinux immediately, some files and direc -\ntories come preset with the proper file contexts. For example, Samba configuration files  \n(/etc/samba/* ), log files ( /var/log/samba/* ), and libraries ( /var/lib/samba/* ) have \nrules assigned to ensure that they get the proper file contexts. To find files and directories \nassociated with the Samba service and smbd daemon that have file contexts preset, run \nthe following:\n# semanage fcontext -l | grep -i samba\n# semanage fcontext -l | grep -i smb\nThe file context portion in which you are interested ends with _t : for example, samba _\netc _ t , samba _ log _ t , and samba _ var _ t  for the /etc/samba , /var/log/\nsamba , and /var/lib/samba  directories, respectively.\nYou may find that you need to change file contexts\u2014for example, when you put files in \nnonstandard locations (such as moving the smb.conf  file to /root/smb.conf ) or when \nyou want to share a directory (other than home directories, which can be turned on by \nsetting a Boolean). Unlike the vsftpd  (FTP) and httpd  (web) servers that come with \nLinux, Samba has no default shared content directories (those just mentioned used  \n/var/ftp  and /var/www/html ).\nYou can change a file context permanently by creating a new file context rule and then \napplying that rule to the file or directory for which it is intended. You can do that with the \nsemanage  command (to make the rule) and restorecon  command (to apply the rule). For \nexample, if you wanted to share a directory, /mystuff , you would create that directory \nwith the proper permissions and run the following command to make it available for read/\nwrite access from Samba:\n# semanage fcontext -a -t samba_share_t \"/mystuff(/.*)?\"\n# restorecon -v /mystuff\nAfter those commands are run, the /mystuff  directory, along with any files and direc -\ntories below that point, have the file context of s a mb a_s ha r e_t . It is then up to you ", "doc_id": "e086310c-8fca-4357-87fc-ca5dd92632cb", "embedding": null, "doc_hash": "3b5f6a963275151095b8e123b51cb4eb94090a38e6915f2cc1b7542d51b174c3", "extra_info": {"page_label": "509"}, "node_info": {"start": 0, "end": 2769}, "relationships": {"1": "af5e8c6f-b6ac-4c81-a9b9-54cb02fe11ae"}}, "__type__": "1"}, "94303b51-eeb1-4faa-910d-a39e0b6e1a10": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator486to assign the correct Linux ownership and file permissions to allow access to the users \nyou choose. The upcoming section \u201cConfiguring Samba\u201d provides an example of creating a \nshare, and it shows you how to add permissions and ownership to a shared directory using \nstandard Linux commands.\nConfiguring Samba host/user permissions\nWithin the smb.conf  file itself, you can allow or restrict access to the entire Samba server \nor to specific shares based on the hosts or users trying to gain access. You can also restrict \naccess to the Samba server by providing the service only on particular interfaces.\nFor example, if you have one network interface card connected to the Internet and another \nconnected to the local network, you can tell Samba to serve requests only on the local net -\nwork interface. The next section describes how to configure Samba, including how to iden -\ntify which hosts, users, or network interfaces can access your Samba server.\nConfiguring Samba\nInside the /etc/samba/smb.conf  file are settings for configuring your Samba server, \ndefining shared printers, configuring how authentication is done, and creating shared \ndirectories. The file consists of the following predefined sections:\n[global]  Settings that apply to the Samba server as a whole are placed in this sec -\ntion. This is where you set the server\u2019s description, its workgroup (domain), the \nlocation of log files, the default type of security, and other settings.\n[homes]  This section determines whether users with accounts on the Samba server \ncan see their home directories (browseable) or write to them.\n[printers]  In this section, settings tell Samba whether to make printers available \nthrough Samba that are configured for Linux printing (CUPS).\n[print$]  This section configures a directory as a shared printer drivers folder.\nInside the smb.conf  file, lines beginning with pound signs ( #) or semicolons ( ;) are com-\nments. Removing the semicolons enables you to set up different kinds of shared informa -\ntion quickly. The # sign can also be used to comment out a line.\nWhen you begin editing your smb.conf  file, make a backup that you can go back to if \nsomething goes wrong. You can start by copying the smb.conf.example  file to smb.\nconf , if you want to start with some examples.\nConfiguring the [global] section\nHere is an example of a [global]  section of the smb.conf  file:\n[global]\n        workgroup = SAMBA\n        security = user", "doc_id": "94303b51-eeb1-4faa-910d-a39e0b6e1a10", "embedding": null, "doc_hash": "2652daabc55494dceccb039e0348598816ed27380a64eb04d5ee60dc5ac3c47d", "extra_info": {"page_label": "510"}, "node_info": {"start": 0, "end": 2500}, "relationships": {"1": "83d4b30a-adce-4fc6-85cf-34d210c9230a"}}, "__type__": "1"}, "b23307d0-d8f8-4de3-a63a-64ebd4f74b53": {"__data__": {"text": "Chapter 19: Configuring a Windows File Sharing (Samba) Server\n487\n19        passdb backend = tdbsam\n        printing = cups\n        printcap name = cups\n        load printers = yes\n        cups options = raw\n \n;       netbios name = MYSERVER\n;       interfaces = lo eth0 192.168.12.2/24 192.168.13.2/24\n;       hosts allow = 127. 192.168.12. 192.168.13.\nThe workgroup  (also used as the domain name) is set to SAMBA  in this example. When a \nclient communicates with the Samba server, this name tells the client which workgroup the \nSamba server is in.\nThe default security  type is set to user  (Samba usernames and passwords).\nThe passdb backend = tdbsam  specifies to use a Samba backend database to \nhold passwords. You can use the smbpasswd  command to set each user\u2019s password (as \ndescribed later).\nSetting printing = cups  and printcap name = cups indicates to use the print -\ncap created by the CUPS printing service. When you set load printers = yes , Samba \nknows to share any printers configured by your local CUPS printing service from Samba.\nThe cups options  lets you pass any options that you like to the CUPS printers served by \nyour Samba server. By default, only raw  is set, which allows Windows clients to use their own \nprint drivers. Printers on your Samba server print the pages they are presented in raw form.\nBy default, your server\u2019s DNS hostname (enter hostname  to see what it is) is used as your \nSamba server\u2019s NetBIOS name as well. You can override that and set a separate NetBIOS \nname by uncommenting the netbios name  line and adding the server name you want. \nFor example, netbios name = myownhost . localhost  is used as your NetBIOS name \nif it has not otherwise been set.\nIf you want to restrict access to the Samba server so that it only responds on certain inter -\nfaces, you can uncomment the interfaces  line and add either the IP address or name \n(lo, eth0 , eth1 , and so on) of the network interfaces you want.\nYou can restrict access to the Samba server to specific hosts as well. Uncomment the hosts \nallow  line (remove the semicolon) and insert the IP addresses of the hosts that you want \nto allow. To enter a range of addresses, simply end the subnetwork portion of the address, \nfollowed by a dot. For example, 127.  is associated with IP addresses that point to the local \nhost. The 192.168.12. entry matches all IP addresses from 192.168.12.1 to 192.168.12.254.\nConfiguring the [homes] section\nThe [homes]  section is configured, by default, to allow any Samba user account to be able \nto access its own home directory via the Samba server. Here is what the default homes \nentry looks like:", "doc_id": "b23307d0-d8f8-4de3-a63a-64ebd4f74b53", "embedding": null, "doc_hash": "c7178e0fc9a84f6347cfdeca56e53649fef37f785ed89416bac85045952d3c77", "extra_info": {"page_label": "511"}, "node_info": {"start": 0, "end": 2645}, "relationships": {"1": "12ee014f-85c4-4c9c-a9c4-18da3ea16d61"}}, "__type__": "1"}, "db50e996-fd33-48d9-a8fd-868c0930a951": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator488[homes] \n        comment = Home Directories\n        valid users = %S, %D%w%S\n        browseable = No\n        read only = No\n        inherit acls = Yes\nSetting valid users  to %S  substitutes the current service name, which allows any valid \nusers of the service to access their home directories. The valid users are also identified by \ndomain or workgroup ( %D), winbind separator ( %w), and name of current service ( %S).\nThe browseable = No  setting prevents the Samba server from displaying the avail -\nability of the shared home directories. Users who can provide their own Samba usernames \nand passwords can read and write in their own home directories ( read only = no ). With \ninherit acls  set to Yes , access control lists can be inherited to add another layer of \nsecurity on the shared files.\nIf after starting the smb service you cannot log in using a valid user account, you may \nneed to change some security features on your system. On Fedora and RHEL systems, in \nparticular, SELinux features need to be changed to allow users to access their home direc -\ntories if you are in SELinux enforcing mode.\nFor example, if you tried to use smbclient  to log in to your home directory, the login \nwould succeed, but when you tried to list the contents of the home directory, you might \nsee the following message:\nNT_STATUS_ACCESS_DENIED listing \\*\nTo tell SELinux to allow Samba users to access their home directories as Samba shares, turn on \nthe samba _ enable _ home _ dirs  Boolean by entering the following as root from a shell:\n# setsebool -P samba_enable_home_dirs on\nThe setsebool  command turns on the capability of Samba to share home directories \n(which is off by default). First create a password for the user with smbpasswd  and then \nlog in with smbclient . The form for using the smbclient  command to check access to \nthe user\u2019s home directory, again for the user chris , would be the following (replacing the \nIP address with the name or address of your Samba server):\n$ smbpasswd -a chris\nNew SMB password: *********\nRetype new SMB password: *********\nAdded user chris.\n \n$ smbclient -U chris //192.168.0.119/chris\n \nEnter SAMBA\\chris's password:\nTry \"help\" to get a list of possible commands.\nsmb: \\> ls file.txt\n  file.txt 149946368  Sun Jan  4 09:28:53 2020\n          39941 blocks of size 524288. 28191 blocks available\nsmb:\\>  quit", "doc_id": "db50e996-fd33-48d9-a8fd-868c0930a951", "embedding": null, "doc_hash": "d3294e068efc0022d242205acba43cffe918d99d0366c29110a46cf20a2cf700", "extra_info": {"page_label": "512"}, "node_info": {"start": 0, "end": 2410}, "relationships": {"1": "b69cbae6-8140-4bc4-9089-398fd958e121"}}, "__type__": "1"}, "277262d6-954e-4d59-89e8-42db709bf7ee": {"__data__": {"text": "Chapter 19: Configuring a Windows File Sharing (Samba) Server\n489\n19The main point to remember is that, even though the share is not browseable, you can \nrequest it by giving the Samba server\u2019s hostname or IP address, followed by the user\u2019s name \n(here, chris ), to access the user\u2019s home directory.\nConfiguring the [printers] section\nAny printer that you configure for CUPS printing on your Linux system is automatically \nshared to others over Samba, based on the [printers]  section that is added by default. \nThe global cups options = raw setting makes all printers raw printers (meaning that \nthe Windows client needs to provide the proper printer driver for each shared printer).\nHere\u2019s what the default printers section looks like in the smb.conf  file:\n[printers]\n        comment = All Printers\n        path = /var/tmp\n        printable = Yes\n        create mask = 0600\n        browseable = No\n \nThe path  tells Samba to store temporary print files in /var/tmp . The printable = Yes \nline causes all of your CUPS printers on the local system to be shared by Samba. Printers \nare writeable and allow guest printing by default. The create mask = 0600 setting used \nhere has the effect of removing write and execute bits for group and other, within the ACL, \nwhen files are created in the path directory. \nTo see that local printers are available, you could run the smbclient -L command from a \nLinux system, as shown earlier. On a Windows system, you can select Network from the File \nExplorer window and select the icon representing your Samba server. All shared printers \nand folders appear in that window. (See the section \u201cAccessing Samba Shares\u201d later in this \nchapter for details on viewing and using shared printers.)\nCreating a Samba shared folder\nBefore you can create a shared folder, that folder (directory) must exist and have the proper \npermissions set. In this example, the /var/salesdata  directory is shared. You want the \ndata to be writeable by the user named chris  but visible to anyone on your network. To \ncreate that directory and set the proper permissions and SELinux file contexts, type the \nfollowing as root user:\n# mkdir /var/salesdata\n# chmod 775 /var/salesdata\n# chown chris:chris /var/salesdata\n# semanage fcontext -a -t samba_share_t /var/salesdata\n# restorecon -v /var/salesdata\n# touch /var/salesdata/test\n# ls -lZ /var/salesdata/test\n-rw-r--r--. 1 root root\n    unconfined_u:object_r:samba_share_t:s0 0 Dec 24 14:35\n        /var/salesdata/test", "doc_id": "277262d6-954e-4d59-89e8-42db709bf7ee", "embedding": null, "doc_hash": "65dc8f7f832202b99bd4cc71aa6bfe05627b89af15bcc7510a4f77bea0fced91", "extra_info": {"page_label": "513"}, "node_info": {"start": 0, "end": 2485}, "relationships": {"1": "83c3fcd5-9850-4b78-993a-a3e061f19050"}}, "__type__": "1"}, "24e2200b-0739-44c6-b5c3-a1abc372d2ad": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator490Adding the shared folder to Samba\nWith the /var/salesdata  directory created and properly configured to be shared by \nSamba, here is what the shared folder (called salesdata ) might look like in the smb.\nconf  file:\n[salesdata]\n        comment = Sales data for current year\n        path = /var/salesdata\n        read only = no\n;       browseable = yes\n        valid users = chris\nBefore this share was created, the /var/salesdata  directory was created, with chris  \nassigned as the user and group, and the directory was set to be readable and writeable by \nchris . (The SELinux file context must also be set if SELinux is in enforcing mode.) The \nSamba username chris  must be presented along with the associated password to access \nthe share. After chris  is connected to the share, chris  has read and write access to it \n(read only = no ).\nNow that you have seen the default settings for Samba and an example of a simple shared \ndirectory (folder), read the next few sections to see how to configure shares even further. \nIn particular, the examples demonstrate how to make shares available to particular users, \nhosts, and network interfaces.\nChecking the Samba share\nFor the changes to your Samba configuration to take effect, you need to restart the smb \nservice. After that is done, check that the Samba share you created is available and that \nany user you assigned to the share can access it. To do those things, enter the following as \nroot user from a shell on the Samba server:\n# systemctl restart smb.service\n# smbclient -L localhost -U chris\nEnter SAMBA\\chris's password: *******\n    Sharename       Type      Comment\n    ---------       ----      -------\n    salesdata       Disk      Sales data for current year\n    print$          Disk      Printer Drivers\n    IPC$            IPC       IPC Service (Samba 4.10.4)\n    chris           Disk      Home Directories\nReconnecting with SMB1 for workgroup listing.\n    Server               Comment\n    ---------            -------\n \n    Workgroup            Master\n    ---------            -------\n    SAMBA                FEDORA30\n...", "doc_id": "24e2200b-0739-44c6-b5c3-a1abc372d2ad", "embedding": null, "doc_hash": "97b06bbd693afd870b0bfb563a7d4fc06a366e34332e003f3ff8b09b76dae867", "extra_info": {"page_label": "514"}, "node_info": {"start": 0, "end": 2144}, "relationships": {"1": "3dc29ed1-9840-4420-b3c0-39ba77ef7235"}}, "__type__": "1"}, "53a31e01-4bb1-4bac-9fe4-4e37937fd42c": {"__data__": {"text": "Chapter 19: Configuring a Windows File Sharing (Samba) Server\n491\n19Here you can see the share name ( salesdata ), the domain set to the workgroup name \nSAMBA , and the description entered earlier ( Sales data for current year ). Next, a \nquick way to test access to the share is to use the smbclient  command. You can use the \nhostname or IP address with smbclient  to access the share. Because I am on the local \nsystem in this example, I just use the name localhost  and the user I added ( chris ):\n# smbclient -U chris //localhost/salesdata\nEnter SAMBA\\chris's password: ********\nTry \"help\" to get a list of possible commands.\nsmb: \\> lcd /etc\nsmb: \\> put hosts\nputting file hosts as \\hosts (43.5 kb/s) (average 43.5 kb/s)\nsmb: \\> ls\n  .                              D        0  Sun Dec 29 09:52:51 2020\n  ..                             D        0  Sun Dec 29 09:11:50 2020\n  hosts                          A       89  Sun Dec 29 09:52:51 2020\n          39941 blocks of size 524288. 28197 blocks available\nsmb: \\> quit\nA Samba share is in the form //host/share  or \\\\host\\share . However, when you  \nidentify a Samba share from a Linux shell in the latter case, the backslashes need to  \nbe escaped. So, as an argument, the first example of the share would have to appear as  \n\\\\\\\\localhost\\\\salesdata . Thus, the first form is easier to use.\nWhen prompted, enter the Samba password for that user (it may be different from the \nLinux user\u2019s password). The Samba user\u2019s password was set earlier with smbpasswd  in this \nexample. You see the smb: \\> prompt after that.\nAt this point, you have a session open to the Samba host that is similar to an ftp  session \nfor traversing an FTP server. The lcd /etc  command makes /etc  the current directory \non the local system. The put hosts  command uploads the hosts file from the local system \nto the shared directory. Typing ls  shows that the file exists on the server. The quit  \ncommand ends the session.\nRestricting Samba access by network interface\nTo restrict access to all of your shares, you can set the global interfaces setting in the smb.\nconf  file. Samba is designed more for local file sharing than for sharing over wide area \nnetworks. If your computer has a network interface connected to a local network and one \nconnected to the Internet, consider allowing access only to the local network.Note\nEscaping a character that you type from the shell is done by putting a backslash ( \\) in front of that character. It tells the \nshell to use the character following the backslash literally, instead of giving the character a special meaning to the shell. \n(The * and ?  characters are examples of characters with special meaning.) Because the backslash itself has special \nmeaning to the shell, if you want to use a backslash literally, you need to precede it with a backslash. That is why when \nyou want to type a Samba address that includes two backslashes, you actually have to enter four backslashes.", "doc_id": "53a31e01-4bb1-4bac-9fe4-4e37937fd42c", "embedding": null, "doc_hash": "bb7397501324ecb49d267af7cfe6ff88d0fa5d43445820c1c8c6f6266301c51a", "extra_info": {"page_label": "515"}, "node_info": {"start": 0, "end": 2964}, "relationships": {"1": "293c9f39-6d54-47af-bc82-6ec6971ea22b"}}, "__type__": "1"}, "eb10a1ed-71a2-4272-802d-167e73e5a5a7": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator492To set which interfaces Samba listens on, uncomment the interfaces  line shown in an \nearlier example in the [global]  section of the smb.conf  file. Then add the interface \nnames or IP address ranges of those computers that you want to allow access to your com-\nputer. Here is an example:\ninterfaces = lo 192.168.22.15/24\nThis interfaces entry allows access to the Samba service to all users on the local system \n(lo). It also allows access to any systems on the 192.168.22 network. See the smb.conf  \nman page\u2019s description of different ways of identifying hosts and network interfaces.\nRestricting Samba access by host\nHost access to the Samba server can be set for the entire service or for single shares.\nHere are some examples of hosts allow  and hosts deny  entries:\nhosts allow = 192.168.22. EXCEPT 192.168.22.99\nhosts allow = 192.168.5.0/255.255.255.0\nhosts allow = .example.com market.example.net\nhosts deny = evil.example.org 192.168.99.\nThese entries can be put in the [global]  section or in any shared directory section. The \nfirst example allows access to any host in the 192.168.22. network except for 192.168.22.99, \nwhich is denied. Note that a dot is required at the end of the network number. The \n192.168.5.0/255.255.255.0 example uses netmask notation to identify 192.168.5 as the set of \naddresses that are allowed.\nIn the third line of the sample code, any host from the . example.com  network is allowed, as is \nthe individual host market.example.net . The hosts deny  example shows that you can use \nthe same form to identify names and IP addresses in order to prevent access from certain hosts.\nRestricting Samba access by user\nParticular Samba users and groups can be allowed access to specific Samba shares by identi-\nfying those users and groups within a share in the smb.conf  file. Aside from guest users, \nwhich you may or may not allow, the default user authentication for Samba requires you to \nadd a Samba (Windows) user account that maps into a local Linux user account.\nTo allow a user to access the Samba server, you need to create a password for the user. Here \nis an example of how to add a Samba password for the user jim :\n# smbpasswd -a jim\nNew SMB password: *******\nRetype new SMB password: *******\nAfter running that smbpasswd  command, jim  can use that username and password to \naccess the Samba server. The /var/lib/samba/private/passdb.tdb  file holds the \npassword just entered for jim . After that, the user jim  can change the password by simply \ntyping smbpasswd  when he is logged in. The root user can change the password by rerun -\nning the command shown in the example but dropping the -a  option.", "doc_id": "eb10a1ed-71a2-4272-802d-167e73e5a5a7", "embedding": null, "doc_hash": "01b7287ea1c34f13772c2149c5bf33f0cb247e77dbc00bd6053926e9d7c8dfd4", "extra_info": {"page_label": "516"}, "node_info": {"start": 0, "end": 2704}, "relationships": {"1": "ca53f78d-67f4-4b8e-8989-2198f976eb9d"}}, "__type__": "1"}, "f25d84b5-38e7-4e61-a735-18ecbcde6705": {"__data__": {"text": "Chapter 19: Configuring a Windows File Sharing (Samba) Server\n493\n19If you wanted to give jim  access to a share, you could add a valid users  line to that \nshared block in the smb.conf  file. For example, to provide both chris  and jim  access to \na share, you could add the following line:\nvalid users = jim, chris\nIf the read only  option is set to no  for the share, both users could potentially write files \nto the share (depending on file permissions). If read only  is set to yes , you could still \nallow access to jim  and chris  to write files by adding a write list  line as follows:\nwrite list = jim, chris\nThe write list can contain groups (that is, Linux groups contained in the /etc/group  file) \nto allow write permission to any Linux user that belongs to a particular Linux group. You \ncan add write permission for a group by putting a plus ( +) character in front of a name. For \nexample, the following adds write access for the market  group to the share with which \nthis line is associated:\nwrite list = jim, chris, +market\nThere are many ways to change and extend the features of your shared Samba resources. \nFor further information on configuring Samba, be sure to examine the smb.conf  file itself \n(which includes many useful comments) and the smb.conf  man page.\nAccessing Samba Shares\nAfter you have created some shared directories in Samba, many client tools are available in \nboth Linux and Windows for accessing those shares. Command-line tools in Linux include \nthe smbclient  command, demonstrated earlier in this chapter. For a graphical means of \naccessing shares, you can use the file managers available in both Windows (File Explorer) \nand Linux (Nautilus, with the GNOME desktop).\nAccessing Samba shares in Linux\nOnce a Samba share is available, it can be accessed from remote Linux and Windows systems \nusing file managers or remote mount commands.\nAccessing Samba shares from a Linux file manager\nOpening a file manager in Linux can provide you with access to the shared directories from \nLinux (Samba) and Windows (SMB). How you access the file manager is different on differ -\nent Linux desktops. In GNOME 3, you can click the Files icon. In other desktops, open the \nHome folder.\nWith the Nautilus window manager displayed, select Other Location in the left navigation \nbar. Available networks (such as Windows Network) should appear. Look to the box at the bot -\ntom of the window identified as Connect to Server, and then enter the location of an available \nSamba share. Given the previous examples, you would be able to use either of these shares:\nsmb://192.168.122.119/chris\nsmb://192.168.122.119/salesdata", "doc_id": "f25d84b5-38e7-4e61-a735-18ecbcde6705", "embedding": null, "doc_hash": "200a753d35fea3d2b47a246452ff7cf05621592c9c3b9606ca323c8816db99ab", "extra_info": {"page_label": "517"}, "node_info": {"start": 0, "end": 2651}, "relationships": {"1": "810a64d9-ae89-492b-b557-50fe5aa83fd6"}}, "__type__": "1"}, "58e07487-86e0-464b-b08e-0cc352b155b9": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator494The window should appear similar to Figure\u00a019.1:\nClick Connect. From the window that appears, you can select to connect as a registered \nuser. If you do that, you can enter your username, Samba domain name, and the password \nfor your user. You can also select whether or not to save that password. Figure\u00a019.2 shows \nan example of that window:\nFIGURE 19.1\nIdentify a Samba share from the Nautilus Connect to Server box.\nFIGURE 19.2\nAdd your Samba credentials.", "doc_id": "58e07487-86e0-464b-b08e-0cc352b155b9", "embedding": null, "doc_hash": "8d0b3e5be2dd311e4a75493aac2d10b3cdb3983adcc99f921088e6a38ecbb5f2", "extra_info": {"page_label": "518"}, "node_info": {"start": 0, "end": 508}, "relationships": {"1": "b1a3d09d-7f61-43a1-a48f-144bb06bdd8f"}}, "__type__": "1"}, "40ce3c2f-15b1-4296-90a8-a631873f0fea": {"__data__": {"text": "Chapter 19: Configuring a Windows File Sharing (Samba) Server\n495\n19Click Connect.\nIf the user and password are accepted, you should see the contents of the remote directory. \nIf you have write access to the share, you can open another Nautilus window and drag and \ndrop files between the two systems. Figure\u00a019.3 shows an example of the Nautilus window \nafter I have connected to the salesdata  share.\nMounting a Samba share from a Linux command line\nBecause a Samba shared directory can be viewed as a remote filesystem, you can use \ncommon Linux tools to connect a Samba share (temporarily or permanently) to your \nLinux system. Using the standard mount  command (with cifs-utils  installed), you \ncan mount a remote Samba share as a CIFS filesystem in Linux. This example mounts \nthe salesdata  share from the host at IP address 192.168.0.119 on the local directory /\nmnt/sales :\n# yum install cifs-utils -y\n# mkdir /mnt/sales\n# mount -t cifs -o user=chris \\\n      //192.168.0.119/salesdata /mnt/sales\nPassword for chris@//192.168.122.119/salesdata: *******\n# ls /mnt/sales\nhosts   memos  test  whitepapers\nWhen prompted, enter the Samba password for chris . Given that the user chris  in this \nexample has read-write permission to the shared directory, users on your system should be \nable to read and write to the mounted directory. Regardless of who saves files on the shared \nFIGURE 19.3\nDisplaying a Samba share from Connect to Server in Nautilus", "doc_id": "40ce3c2f-15b1-4296-90a8-a631873f0fea", "embedding": null, "doc_hash": "8fac94732cca26a5c1311f4182cfaf74bc582f52ad5e319a6401d5852b7f3cc3", "extra_info": {"page_label": "519"}, "node_info": {"start": 0, "end": 1455}, "relationships": {"1": "96087410-9849-4f72-8629-4ef72bc5c1e1"}}, "__type__": "1"}, "ce03c5a2-5705-4921-8f98-e3840492d771": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator496directory, on the server those files are owned by the user chris . This mount lasts until \nthe system is rebooted or you run the umount  command on the directory. If you want the \nshare to be mounted permanently (that is, every time the system boots up) in the same \nlocation, you can do some additional configuration. First, open the /etc/fstab  file and \nadd an entry similar to the following:\n//192.168.0.119/salesdata /mnt/sales cifs credentials=/root/cif.txt 0 0\nNext, create a credentials file (in this example, /root/cif.txt ). In that file, put the name \nof the user and the user\u2019s password that you want to present when the system tries to \nmount the filesystem. Here is an example of the contents of that file:\nuser=chris\npass=mypass\nBefore you reboot to check that the entry is correct, try mounting it from the command \nline. A mount -a  command tries to mount any filesystem listed in the /etc/fstab  file \nthat is not already mounted. The df  command shows information about disk space for the \nmounted directory, as in the following example:\n# mount -a\n# df -h /mnt/sales\nFilesystem                   Size  Used  Avail   Ues%  Mounted on\n//192.168.0.119/salesdata     20G  5.7G    14G    30%  /mnt/sales\nYou should now be able to use the shared Samba directory as you do any directory on the \nlocal system.\nAccessing Samba shares in Windows\nAs with Linux, you can access Samba shares from the file manager window, in this case \nWindows File Explorer. To do this, open any folder in Windows, and select Network from \nthe left panel. An icon representing the Samba server should appear on the screen. Click \nthat icon and enter a password if prompted for one. You should see all shared printers and \nfolders from that server (see Figure\u00a019.4).\nIn Figure\u00a019.4, you can see that there are two shared folders (directories): chris  and \nsalesdata . There are also several shared printers. To use the folders, double-click \nthem and enter the required authentication information. Because printers are set up \nto use raw drivers by default, you need to obtain Windows drivers to use any of the \nSamba printers.", "doc_id": "ce03c5a2-5705-4921-8f98-e3840492d771", "embedding": null, "doc_hash": "d4e4f137a508b11fa5614774281d18f828fd3eff9096e7ccf6861586b3cf699c", "extra_info": {"page_label": "520"}, "node_info": {"start": 0, "end": 2166}, "relationships": {"1": "7552719f-1bdf-4882-b906-175e91b5dc2a"}}, "__type__": "1"}, "8914572b-205b-4e5c-9285-359e84b71e83": {"__data__": {"text": "Chapter 19: Configuring a Windows File Sharing (Samba) Server\n497\n19Using Samba in the Enterprise\nAlthough it\u2019s beyond the scope of this book, Windows file and printer sharing via Samba \nservers is a very popular application in large enterprises. Despite the fact that Linux has \nbegun to dominate the enterprise-quality server market, Microsoft Windows systems are \nstill the predominant systems used on the desktop.\nThe major features needed to integrate Samba servers into a large enterprise with many \nMicrosoft Windows desktops are related to authentication. Most large enterprises use Micro -\nsoft Active Directory Services (ADS) servers for authentication. On the Linux side, that \nmeans configuring Kerberos on the Linux system and using ADS (instead of user) for the \ntype of security in the smb.conf  file.\nThe advantage of central authentication is that users have to remember only one set of cre -\ndentials throughout the enterprise and system administrators need to manage fewer user \naccounts and passwords.\nSummary\nBecause of the popularity of Windows desktops, Samba servers have become popular for \nsharing files and printers among Windows and Linux systems. Samba provides a way to \ninteroperate with Windows systems by implementing the Server Message Block (SMB) or \nCommon Internet File (CIFS) protocol for sharing resources over a network.\nFIGURE 19.4\nAccessing Samba shares from Windows", "doc_id": "8914572b-205b-4e5c-9285-359e84b71e83", "embedding": null, "doc_hash": "0ec01c52b0df75db7317ce211d9227d0debe2ab070cc23228ce032a9c84102d7", "extra_info": {"page_label": "521"}, "node_info": {"start": 0, "end": 1408}, "relationships": {"1": "7ffbbf99-1a6c-4a03-9db1-ce5cceed28d0"}}, "__type__": "1"}, "e41bb151-c0b1-45df-838e-b301832076c5": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator498This chapter stepped through the process of installing, starting, securing, configuring, and \naccessing Samba servers on a Linux system. Using command-line tools, I demonstrated how \nto set up a Samba server. I showed you both command-line and desktop tools for getting to \nSamba shares from Linux and Windows systems.\nThe next chapter describes the Network File System (NFS) facility. NFS is the native \nLinux facility for sharing and mounting filesystems over networks with other Linux and \nUNIX systems.\nExercises\nThe exercises in this section describe tasks related to setting up a Samba server in Linux \nand accessing that server using a Samba client. As usual, there are often several ways to \naccomplish some of the tasks here. So don\u2019t worry if you don\u2019t go about the exercises in \nexactly the same way as shown in the answers, as long as you get the same results. See \nAppendix B for suggested solutions.\nDon\u2019t do these exercises on a Linux system running a Samba server because they will \nalmost certainly interfere with that server. These exercises were tested on a Fedora system. \nSome of the steps might be slightly different on another Linux system.\n1. Install the samba  and samba-client  packages.\n2. Start and enable the smb and nmb  services.\n3. Set the Samba server\u2019s workgroup to TESTGROUP , the netbios name  to MYTEST , \nand the server string to Samba Test System .\n4. Add a Linux user named phil  to your system, and add a Linux password and \nSamba password for phil .\n5. Set the [homes]  section so that home directories are browseable ( yes) and write -\nable (yes), and phil  is the only valid user.\n6. Set any SELinux Boolean that is necessary to make it so that phil  can access his \nhome directory via a Samba client, then restart the smb and nmb  services.\n7. From the local system, use the smbclient  command to list that the homes  share \nis available.\n8. From a Nautilus (file manager) window on the local system, connect to the homes  \nshare for the user phil  on the local Samba server in a way that allows you to drag \nand drop files to that folder.\n9. Open up the firewall so that anyone who has access to the server can access the \nSamba service ( smbd and nmbd  daemons).\n10. From another system on your network (Windows or Linux), try to open the homes  \nshare again as the user phil , and again make sure that you can drag and drop \nfiles to it.", "doc_id": "e41bb151-c0b1-45df-838e-b301832076c5", "embedding": null, "doc_hash": "9e029142c11e2257ca95a8a4b52321a3ebdf7d7b4b7f1ea7a5b8579bfa942323", "extra_info": {"page_label": "522"}, "node_info": {"start": 0, "end": 2434}, "relationships": {"1": "34073912-15a5-4449-b99f-962cb946543b"}}, "__type__": "1"}, "e3fa7a21-5804-4d45-a11e-69b230b6df6e": {"__data__": {"text": "499\nCHAPTER20\nConfiguring an NFS File Server\nIN THIS CHAPTER\nGetting NFS server software\nEnabling and starting NFS\nExporting NFS directories\nSetting security features for NFS\nMounting remote NFS shared directories\nInstead of representing storage devices as drive letters (A, B, C, and so on), as they are in Micro -\nsoft operating systems, Linux systems invisibly connect filesystems from multiple hard disks, \nUSB drives, CD-ROMs, and other local devices to form a single Linux filesystem. The Network File \nSystem (NFS) facility enables you to extend your Linux filesystem to connect filesystems on other \ncomputers to your local directory structure.\nAn NFS file server provides an easy way to share large amounts of data among the users and com -\nputers in an organization. An administrator of a Linux system that is configured to share its filesys -\ntems using NFS has to perform the following tasks to set up NFS:\n1. Set up the network . NFS is typically used on private networks as opposed to public net -\nworks, such as the Internet.\n2. Start the NFS service . Several service daemons need to start up and run to have a fully \noperational NFS service. In Fedora and Red Hat Enterprise Linux, you can start up the nfs-\nserver  service.\n3. Choose what to share from the server . Decide which directories (folders) on your Linux \nNFS server to make available to other computers. You can choose any point in the filesys -\ntem and make all files and directories below that point accessible to other computers.\n4. Set up security on the server . You can use several different security features to apply the \nlevel of security with which you are comfortable. Mount-level security  enables you to restrict \nthe computers that can mount a resource and, for those allowed to mount it, enables you \nto specify whether it can be mounted read/write or read-only. In NFS, user-level security is \nimplemented by mapping users from the client systems to users on the NFS server (based on \nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "e3fa7a21-5804-4d45-a11e-69b230b6df6e", "embedding": null, "doc_hash": "08ad4a0a9f0ad52edaa9b78c5a569b079bafbe9fec3abbf85d44cb4fb1aee6df", "extra_info": {"page_label": "523"}, "node_info": {"start": 0, "end": 2102}, "relationships": {"1": "b9e250dd-292b-4442-947f-91f6ad08247c"}}, "__type__": "1"}, "c3925161-bb50-4016-94e9-b2df40f4d73f": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator500UID and not username) so that they can rely on standard Linux read/write/execute \npermissions, file ownership, and group permissions to access and protect files.\n5. Mount the filesystem on the client . Each client computer that is allowed access to \nthe server\u2019s NFS shared filesystem can mount it anywhere the client chooses.  \nFor example, you may mount a filesystem from a computer called oak  on the  \n/mnt/oak  directory in your local filesystem. After it is mounted, you can view the \ncontents of that directory by typing ls /mnt/oak .\nAlthough it is often used as a file server (or other type of server), Linux is a general-purpose \noperating system, so any Linux system can share, or export, filesystems as a server or use \nanother computer\u2019s filesystems (mount) as a client. In fact, both Red Hat Enterprise Linux 8 \nand Fedora 30 Workstation include the nfs-server  service in their default installations.\nNote\nA filesystem  is usually a structure of files and directories that exists on a single device (such as a hard disk parti -\ntion or CD-ROM). The term Linux filesystem  refers to the entire directory structure (which may include filesystems \nfrom several disk partitions, NFS, or a variety of network resources), beginning from root ( /) on a single computer. A \nshared directory in NFS may represent all or part of a computer\u2019s filesystem, which can be attached (from the shared \ndirectory down the directory tree) to another computer\u2019s filesystem.\nIf you already have the NFS and Cockpit services running on your system, you can mount NFS \nshares and view mounted shares from the Cockpit Web UI. Here\u2019s how to do that:\n1. Log in to your Cockpit interface (port 9090) through your web browser and select \nStorage. The URL to get to storage in the Cockpit service on your local system \nshould be something like https://host1.example.com:9090/storage .\n2. If there are mounted NFS shares on your system, they should appear under the NFS \nMounts section. Figure\u00a020.1 shows an example containing two mounted NFS shares.\n3. To mount a remote NFS share, select the plus ( +) sign on the NFS Mounts line. Fill in \nthe address or hostname of the NFS server, the shared directory on the NFS share, \nand the point on the local file system where you will mount that share. Then select \nAdd, as shown in Figure\u00a020.2.\nAt this point, you should be able to access the content from the remote NFS share from the \nmount point on your local filesystem. By default, the NFS mount information is added to the \n/etc/fstab  file, so the NFS share will be made available each time the system reboots. Now \nthat you have seen the easy way to use NFS, the rest of the chapter describes how to use NFS \nfrom the ground up.", "doc_id": "c3925161-bb50-4016-94e9-b2df40f4d73f", "embedding": null, "doc_hash": "1331d55dd16a06be2fc96dfce92df6d9f5352b7f4248a81fd6dbebd70330c838", "extra_info": {"page_label": "524"}, "node_info": {"start": 0, "end": 2764}, "relationships": {"1": "aa94825f-15ad-41b6-a30f-9eb1a12bf424"}}, "__type__": "1"}, "41ed23fc-e714-4583-8c1f-0386593884e2": {"__data__": {"text": "Chapter 20: Configuring an NFS File Server\n501\n20\nFIGURE 20.1\nView NFS shares mounted locally using Cockpit Web UI\nFIGURE 20.2\nAdd a new NFS mount using Cockpit Web UI", "doc_id": "41ed23fc-e714-4583-8c1f-0386593884e2", "embedding": null, "doc_hash": "0b48312f45a600da50b3853bf3072d7bf010cc50870d5b775d320fd4f1ad83d6", "extra_info": {"page_label": "525"}, "node_info": {"start": 0, "end": 167}, "relationships": {"1": "37c08ea8-0354-49af-9c64-31af245ae7cd"}}, "__type__": "1"}, "af8ebad4-f39e-4ea8-8ee1-5a9d2620993b": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator502Installing an NFS Server\nTo run an NFS server, you need a set of kernel modules (which are delivered with the kernel \nitself) plus some user-level tools to configure the service, run daemon processes, and query \nthe service in various ways.\nFor earlier releases of Fedora and RHEL, the components you need that are not already in \nthe kernel can be added by installing the nfs-utils  package. In RHEL 8 and Fedora 30, \nthe required components are included in the following default installation:\n# yum install nfs-utils\nBesides a few documents in the /usr/share/doc/nfs-utils  directory, most documenta -\ntion in the nfs-utils  package includes man pages for its various components. To see the \nlist of documentation, type the following:\n# rpm -qd nfs-utils | less\nThere are tools and man pages for both the NFS server side (for sharing a directory with \nothers) and the client side (for mounting a remote NFS directory locally). To configure a \nserver, you can refer to the exports man page (to set up the /etc/exports  file to share \nyour directories). The man page for the exportfs  command describes how to share and \nview the list of directories that you share from the /etc/exports  file. The nfsd  man \npage describes the options that you can pass to the rpc.nfsd  server daemon, which lets \nyou do such things as run the server in debugging mode.\nMan pages on the client side include the mount.nfs  man page (to see what mount options \nyou can use when mounting remote NFS directories on your local system). There is also an \nnfsmount.conf  man page, which describes how to use the /etc/nfsmount.conf  file to \nconfigure how your system behaves when you mount remote resources locally. The show -\nmount  man page describes how to use the showmount  command to see what shared direc -\ntories are available from NFS servers.\nTo find out more about the nfs-utils  package, you can run the following commands to \nsee information about the package, configuration files, and commands, respectively:\n# rpm -qi nfs-utils\n# rpm -qc nfs-utils\n# rpm -ql nfs-utils | grep bin\nStarting the NFS service\nStarting the NFS server involves launching several service daemons. The basic NFS service  \nin Fedora and RHEL 8 is called nfs-server . To start that service, enable it (so it starts  \neach time your system boots) and check the status by running the following three  \ncommands:\n# systemctl start nfs-server.service\n# systemctl enable nfs-server.service", "doc_id": "af8ebad4-f39e-4ea8-8ee1-5a9d2620993b", "embedding": null, "doc_hash": "8b928e0f1da877dbb5505096c516073b7afd12734c0aa6f0e14177fe0a5b166b", "extra_info": {"page_label": "526"}, "node_info": {"start": 0, "end": 2497}, "relationships": {"1": "d9d9fc7d-e9fa-4375-971f-0231221eb43c"}}, "__type__": "1"}, "e31b450b-0bcc-42c7-84c8-ef42e0628fa7": {"__data__": {"text": "Chapter 20: Configuring an NFS File Server\n503\n20# systemctl status nfs-server.service\n\u2022 nfs-server.service - NFS server and services\n     Loaded: loaded (/lib/systemd/system/nfs-server.service; enabled\n             vendor preset: disabled)\n     Active: active (exited) since Mon 2019-9-02 15:15:11 EDT; 24s \nago\n   Main PID: 7767 (code=exited, status=0/SUCCESS)\n      Tasks: 0 (limit: 12244)\n     Memory: 0B\n     CGroup: /system.slice/nfs-server.service\nYou can see from the status that the nfs-server  service is enabled and active. The NFS \nservice also requires that the RPC service be running ( rpcbind ). The nfs-server  service \nautomatically starts the rpcbind  service, if it is not already running.\nIn Red Hat Enterprise Linux 6, you need the service  and chkconfig  commands to \ncheck, start, and enable the NFS service ( nfs). The following commands show the nfs  ser-\nvice not running currently and disabled:\n# service nfs status\nrpc.svcgssd is stopped\nrpc.mountd is stopped\nnfsd is stopped\n# chkconfig --list nfs\nnfs  0:off  1:off  2:off  3:off  4:off  5:off  6:off\nAs mentioned earlier, the rpcbind  service must be running for NFS to work. In RHEL 6, \nyou could use the following commands to start and permanently enable both the rpcbind  \nand nfs  services:\n# service rcpbind start\nStarting rpcbind:                    [  OK  ]\n# service nfs start\nStarting NFS services:               [  OK  ]\nStarting NFS quotas:                 [  OK  ]\nStarting NFS daemon:                 [  OK  ]\nStarting NFS mountd:                 [  OK  ]\n# chkconfig rpcbind on\n# chkconfig nfs on\nAfter the service is running, the commands ( mount , exportfs , and so on) and files  \n(/etc/exports , /etc/fstab , and so on) for actually configuring NFS are basically the \nsame on every Linux system. So, after you have NFS installed and running, just follow the \ninstructions in this chapter to start using NFS.\nSharing NFS Filesystems\nTo share an NFS filesystem from your Linux system, you need to export it from the server \nsystem. Exporting is done in Linux by adding entries into the /etc/exports  file. Each ", "doc_id": "e31b450b-0bcc-42c7-84c8-ef42e0628fa7", "embedding": null, "doc_hash": "56e653bf76ad63ea148fddff3c13a5158079bc9b06ad9170bfee0521023dd61f", "extra_info": {"page_label": "527"}, "node_info": {"start": 0, "end": 2107}, "relationships": {"1": "52facd60-fe99-40f8-8034-c40a65c341a9"}}, "__type__": "1"}, "6311aa3d-a68f-4770-a253-c82a4ab2209d": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator504entry identifies a directory in your local filesystem that you want to share with other com-\nputers. The entry also identifies the other computers that can access the resource (or opens \nit to all computers) and includes other options that reflect permissions associated with the \ndirectory.\nRemember that when you share a directory, you are sharing all files and subdirectories \nbelow that directory as well (by default). You need to be sure that you want to share every -\nthing in that directory structure. You can still restrict access within that directory struc -\nture in many ways; those are discussed later in this chapter.\nConfiguring the /etc/exports file\nTo make a directory from your Linux system available to other systems, you need to export \nthat directory. Exporting is done on a permanent basis by adding information about an \nexported directory to the /etc/exports  file.\nHere\u2019s the format of the /etc/exports  file:\nDirectory   Host(Options...)  Host(Options...)  # Comments\nIn this example, Directory  is the name of the directory that you want to share, and \nHost indicates the client computer to which the sharing of this directory is restricted. \nOptions  can include a variety of options to define the security measures attached to the \nshared directory for the host. (You can repeat Host  and Option  pairs.) Comments  are any \noptional comments that you want to add (following the # sign).\nThe exports  man page ( man exports ) contains details about the syntax of the  \n/etc/exports  file. In particular, you can see the options that you can use to limit  \naccess and secure each shared directory.\nAs root user, you can use any text editor to configure /etc/exports  to modify shared \ndirectory entries or add new ones. Here\u2019s an example of an /etc/exports  file:\n/cal    *.linuxtoys.net(rw)              # Company events\n/pub    *(ro,insecure,all_squash)        # Public dir\n/home   maple(rw,root_squash) spruce(rw,root_squash)\nThe /cal  entry represents a directory that contains information about events related to \nthe company. Any computer in the company\u2019s domain ( *.linuxtoys.net ) can mount that \nNFS share. Users can write files to the directory as well as read them (indicated by the rw  \noption). The comment ( # Company events ) simply serves to remind you of what the \ndirectory contains.\nThe /pub  entry represents a public directory. It allows any computer and user to read \nfiles from the directory (indicated by the ro  option) but not to write files. The insecure  \noption enables any computer, even one that doesn\u2019t use a secure NFS port, to access the \ndirectory. The all _ squash  option causes all users (UIDs) and groups (GIDs) to be mapped \nto the nobody  user (UID 65534 ), giving them minimal permission to files and directories.", "doc_id": "6311aa3d-a68f-4770-a253-c82a4ab2209d", "embedding": null, "doc_hash": "09314c729b6f5d4b8570601797db38061e5deebb32770f4a408b88ab7db34741", "extra_info": {"page_label": "528"}, "node_info": {"start": 0, "end": 2830}, "relationships": {"1": "fb5dd54f-abad-406f-8d9f-153771956b6b"}}, "__type__": "1"}, "931660bc-80c1-4d58-ad5c-8aea7742f154": {"__data__": {"text": "Chapter 20: Configuring an NFS File Server\n505\n20The /home  entry enables a set of users to have the same /home  directory on different \ncomputers. Suppose, for example, that you are sharing /home  from a computer named oak . \nThe computers named maple  and spruce  could each mount that directory on their own  \n/home  directories. If you gave all users the same username/UID on all machines, you could \nhave the same /home/ user  directory available for each user, regardless of which computer \nthey are logged into. The root _ squash  is used to exclude the root user from another \ncomputer from having root privilege to the shared directory.\nThese are just examples; you can share any directories that you choose, including the \nentire filesystem ( /). Of course, there are security implications of sharing the whole  \nfilesystem or sensitive parts of it (such as /etc ). Security options that you can add to your \n/etc/exports  file are described throughout the sections that follow.\nHostnames in /etc/exports\nYou can indicate in the /etc/exports  file which host computers can have access to your \nshared directory. If you want to associate multiple hostnames or IP addresses with a par -\nticular shared directory, be sure to leave a space before each hostname. However, add no \nspaces between a hostname and its options. Here\u2019s an example:\n/usr/local maple(rw) spruce(ro,root_squash)\nNotice that there is a space after (rw)  but none after maple . You can identify hosts in \nseveral ways:\nIndividual host  Enter one or more TCP/IP hostnames or IP addresses. If the host is \nin your local domain, you can simply indicate the hostname. Otherwise, use the full \nhost.domain  format. These are valid ways to indicate individual host computers:\n        maple\n        maple.handsonhistory.com\n        10.0.0.11\nIP network  Allow access to all hosts from a particular network address by indicating \na network number and its netmask, separated by a slash ( /). Here are valid ways to \ndesignate network numbers:\n        10.0.0.0/255.0.0.0 172.16.0.0/255.255.0.0\n        192.168.18.0/255.255.255.0\n        192.168.18.0/24\nTCP/IP domain  Using wildcards, you can include all or some host computers from a \nparticular domain level. Here are some valid uses of the asterisk and question mark \nwildcards:\n        *.handsonhistory.com\n        *craft.handsonhistory.com\n        ???.handsonhistory.com", "doc_id": "931660bc-80c1-4d58-ad5c-8aea7742f154", "embedding": null, "doc_hash": "ef7711bd2c538bebe5dcc43b3eebd86d3e02ce45aa213cdff9cb1d3232132ee3", "extra_info": {"page_label": "529"}, "node_info": {"start": 0, "end": 2392}, "relationships": {"1": "65f524b4-e9de-448c-b4a4-a3be98145e66"}}, "__type__": "1"}, "d2f2ea19-763f-4f16-9864-ca01c7b5a980": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator506The first example matches all hosts in the handsonhistory.com  domain. The sec -\nond example matches woodcraft , basketcraft , or any other hostnames ending \nin craft  in the handsonhistory.com  domain. The final example matches any \nthree-letter hostnames in the domain.\nNIS groups  You can allow access to hosts contained in an NIS group. To indicate an \nNIS group, precede the group name with an at ( @) sign (for example, @group ).\nAccess options in /etc/exports\nYou don\u2019t have to just give away your files and directories when you export a directory with \nNFS. In the options part of each entry in /etc/exports , you can add options that allow or \nlimit access by setting read/write permission. These options, which are passed to NFS, are \nas follows:\nro: Client can mount this exported filesystem read-only. The default is to mount the \nfilesystem read/write.\nrw: Explicitly asks that a shared directory be shared with read/write permissions. (If \nthe client chooses, it can still mount the directory as read-only.)\nUser mapping options in /etc/exports\nIn addition to options that define how permissions are handled generally, you can use \noptions to set the permissions that specific users have to NFS shared filesystems.\nOne method that simplifies this process is to have each user with multiple user accounts \nhave the same username and UID on each machine. This makes it easier to map users so \nthey have the same permissions on a mounted filesystem as they do on files stored on their \nlocal hard disks. If that method is not convenient, user IDs can be mapped in many other \nways. Here are some methods of setting user permissions and the /etc/exports  option \nthat you use for each method:\nroot  user  The client\u2019s root user is mapped by default into the nobody  username \n(UID 65534). This prevents a client computer\u2019s root user from being able to change \nall files and directories in the shared filesystem. If you want the client\u2019s root user to \nhave root permission on the server, use the no_root_squash option.\ntip\nKeep in mind that even though root is squashed, the root user from the client can still become any other user account \nand access files for those user accounts on the server. So, be sure that you trust root with all of your user data before \nyou share it read/write with a client.\nnfsnobody  or nobody  user/group  By using the 65534  user ID and group ID, you \nessentially create a user/group with permissions that do not allow access to files \nthat belong to any real users on the server, unless those users open permission to \neveryone. However, files created by the 65534  user or group are available to anyone ", "doc_id": "d2f2ea19-763f-4f16-9864-ca01c7b5a980", "embedding": null, "doc_hash": "4a9c6a8a7d9f378da67cce8dca94f6dc305e0ac539ce95a9ec42baad0cb3ef16", "extra_info": {"page_label": "530"}, "node_info": {"start": 0, "end": 2696}, "relationships": {"1": "977106f8-727c-4748-892c-213923909f57"}}, "__type__": "1"}, "dce78927-d728-43ae-8aa4-45eda30502cf": {"__data__": {"text": "Chapter 20: Configuring an NFS File Server\n507\n20assigned as the 65534  user or group. To set all remote users to the 65534  user/\ngroup, use the all _ squash  option.\nThe 65534  UIDs and GIDs are used to prevent the ID from running into a valid  \nuser or group ID. Using anonuid  or anongid  options, you can change the 65534  \nuser or group, respectively. For example, anonuid=175  sets all anonymous  users \nto UID 175, and anongid=300  sets the GID to 300. (Only the number is displayed \nwhen you list file permission unless you add entries with names to /etc/passwd  \nand /etc/group  for the new UIDs and GIDs.)\nUser mapping  If a user has login accounts for a set of computers (and has the \nsame ID), NFS, by default, maps that ID. This means that if the user named mike  \n(UID 110) on maple  has an account on pine  (mike, UID 110), he can use his own \nremotely mounted files on either computer from either computer.\nIf a client user who is not set up on the server creates a file on the mounted NFS \ndirectory, the file is assigned to the remote client\u2019s UID and GID. (An ls -l  on the \nserver shows the UID of the owner.)\nExporting the shared filesystems\nAfter you have added entries to your /etc/exports  file, run the exportfs  command \nto have those directories exported (made available to other computers on the network). \nReboot your computer or restart the NFS service, and the exportfs  command runs \nautomatically to export your directories. If you want to export them immediately, run \nexportfs  from the command line (as root).\ntip\nRunning the exportfs  command after you change the exports file is a good idea. If any errors are in the file, \nexportfs  identifies them for you.\nHere\u2019s an example of the exportfs  command:\n# /usr/sbin/exportfs -a -r -v\nexporting maple:/pub\nexporting spruce:/pub\nexporting maple:/home\nexporting spruce:/home\nexporting *:/mnt/win\nThe -a  option indicates that all directories listed in /etc/exports  should be exported. \nThe -r  resyncs all exports with the current /etc/exports  file (disabling those exports no \nlonger listed in the file). The -v  option says to print verbose output. In this example, the  \n/pub  and /home  directories from the local server are immediately available for mounting \nby those client computers that are named ( maple  and spruce ). The /mnt/win  directory \nis available to all client computers.", "doc_id": "dce78927-d728-43ae-8aa4-45eda30502cf", "embedding": null, "doc_hash": "5907b11ff9da2db1763c06db2351f1a2c98d52ec0852c452b73692b2df25196f", "extra_info": {"page_label": "531"}, "node_info": {"start": 0, "end": 2378}, "relationships": {"1": "da311f91-b9bb-4133-94e7-39b6e3511b10"}}, "__type__": "1"}, "c02bdba5-bc15-4bad-aa9a-0405b98f10c8": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator508Securing Your NFS Server\nThe NFS facility was created at a time when encryption and other security measures were \nnot routinely built into network services (such as remote login, file sharing, and remote \nexecution). Therefore, NFS (even up through version 3) suffers from some rather glaring \nsecurity issues.\nNFS security issues made it an inappropriate facility to use over public networks and even \nmade it difficult to use securely within an organization. These are some of the issues:\nRemote  root  users  Even with the default root_squash (which prevents root users \nfrom having root access to remote shares), the root user on any machine to which \nyou share NFS directories can gain access to any other user account. Therefore, if \nyou are doing something like sharing home directories with read/write permission, \nthe root user on any box to which you are sharing has complete access to the con -\ntents of those home directories.\nUnencrypted communications Because NFS traffic is unencrypted, anyone sniffing \nyour network can see the data that is being transferred.\nUser mapping  Default permissions to NFS shares are mapped by user ID. So, for \nexample, a user with UID 1000 on an NFS client has access to files owned by UID \n1000 on the NFS server. This is regardless of the usernames used.\nFilesystem structure exposed Up to NFSv3, if you shared a directory over NFS, you \nexposed the location of that directory on the server\u2019s filesystem. (In other words, if \nyou shared the /var/stuff  directory, clients would know that /var/stuff  was \nits exact location on your server).\nThat\u2019s the bad news. The good news is that most of these issues are addressed in NFSv4 but \nrequire some extra configuration. By integrating Kerberos support, NFSv4 lets you configure \nuser access based on each user obtaining a Kerberos ticket. For you, the extra work is con -\nfiguring a Kerberos server. As for exposing NFS share locations, with NFSv4 you can bind \nshared directories to an /exports  directory, so when they are shared, the exact location \nof those directories is not exposed.\nVisit https://help.ubuntu.com/community/NFSv4Howto  for details on NFSv4 fea -\ntures in Ubuntu.\nAs for standard Linux security features associated with NFS, iptables  firewalls, TCP wrap -\npers, and SELinux can all play a role in securing and providing access to your NFS server \nfrom remote clients. In particular, getting firewall features working with NFS can be par -\nticularly challenging. These security features are described in the sections that follow.\nOpening up your firewall for NFS\nThe NFS service relies on several different service daemons for normal operation, with most \nof these daemons listening on different ports for access. For the default NFSv4 used in \nFedora, TCP and UDP ports 2049 ( nfs) and 111 ( rpcbind ) must be open for an NFS server ", "doc_id": "c02bdba5-bc15-4bad-aa9a-0405b98f10c8", "embedding": null, "doc_hash": "2542feaec99a1aab981a213357bb7c910db9579f25a2d0d503adadc6abe77752", "extra_info": {"page_label": "532"}, "node_info": {"start": 0, "end": 2900}, "relationships": {"1": "93ea7b12-d2a6-47d0-b1d5-5b4d97d3cca8"}}, "__type__": "1"}, "0e9ba824-9a02-4233-8eb6-defa156ebd6e": {"__data__": {"text": "Chapter 20: Configuring an NFS File Server\n509\n20to perform properly. The server must also open TCP and UDP ports 20048 for the show -\nmount  command to be able to query available NFS shared directories from rpc.mountd  on \nthe server.\nFor RHEL 8, Fedora 30, and other systems that use the firewalld  service, you can use the \nFirewall Configuration window ( yum install firewall-config ) to open the firewall \nfor your NFS service. Type firewall-config , then make sure that mountd, nfs, and rpc-\nbind are checked in the window to open the appropriate ports to allow access to your NFS \nservice. Figure\u00a020.3 shows an example of this window:\nFor RHEL 6 and other systems that use iptables  service directly (prior to firewalld  \nbeing added), to open ports on the NFS server\u2019s firewall, make sure iptables  is enabled \nand started with firewall rules similar to the following added to the /etc/sysconfig/\niptables  file:\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 111 -j ACCEPT\n-A INPUT -m state --state NEW -m udp -p udp --dport 111 -j ACCEPT\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 2049 -j ACCEPT\nFIGURE 20.3\nUse the Firewall Configuration window to open your firewall to allow access to the \nNFS service.", "doc_id": "0e9ba824-9a02-4233-8eb6-defa156ebd6e", "embedding": null, "doc_hash": "2a79e3fc89eba102a8c4d630cf12f2238f2d6ee70db05ed2d4fd6be883361b39", "extra_info": {"page_label": "533"}, "node_info": {"start": 0, "end": 1228}, "relationships": {"1": "5cc88e99-7b3d-4d03-84c2-88c198def688"}}, "__type__": "1"}, "b92104ef-e713-4d00-840a-52ee3303a62e": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator510-A INPUT -m state --state NEW -m udp -p udp --dport 2049 -j ACCEPT\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 20048 -j ACCEPT\n-A INPUT -m state --state NEW -m udp -p udp --dport 20048 -j ACCEPT\nIn Red Hat Enterprise Linux 6. x and earlier, the firewall issue is a bit more complex. The \nproblem, as it relates to firewalls, is that several different services are associated with NFS \nthat listen on different ports, and those ports are assigned randomly. To get around that \nproblem, you need to lock down the port numbers those services use and open the firewall \nso that those ports are accessible.\nTo make the process of locking down NFS server ports easier, entries in the /etc/syscon -\nfig/nfs  file can be added to assign specific port numbers to services. The following are \nexamples of options in the /etc/sysconfig/nfs  file with static port numbers set:\nRQUOTAD_PORT=49001\nLOCKD_TCPPORT=49002\nLOCKD_UDPPORT=49003\nMOUNTD_PORT=49004\nSTATD_PORT=49005\nSTATD_OUTGOING_PORT=49006\nRDMA_PORT=49007\nWith those ports set, I restarted the nfs  service (service nfs restart ). Using the \nnetstat  command, you can see the resulting processes that are listening on those \nassigned ports:\ntcp  0  0 0.0.0.0:49001   0.0.0.0:*    LISTEN    4682/rpc.rquotad\ntcp  0  0 0.0.0.0:49002   0.0.0.0:*    LISTEN    -\ntcp  0  0 0.0.0.0:49004   0.0.0.0:*    LISTEN    4698/rpc.mountd\ntcp  0  0 :::49002        :::*         LISTEN    -\ntcp  0  0 :::49004        :::*         LISTEN    4698/rpc.mountd\nudp  0  0 0.0.0.0:49001   0.0.0.0:*              4682/rpc.rquotad\nudp  0  0 0.0.0.0:49003   0.0.0.0:*              -\nudp  0  0 0.0.0.0:49004   0.0.0.0:*              4698/rpc.mountd\nudp  0  0 :::49003        :::*                   -\nudp  0  0 :::49004        :::*                   4698/rpc.mountd\nWith those port numbers set and being used by the various services, you can now add ipt -\nables  rules, as you did with ports 2049 and 111 for the basic NFS service.\nAllowing NFS access in TCP wrappers\nFor services such as vsftpd  and sshd , TCP wrappers in Linux enable you to add informa -\ntion to /etc/hosts.allow  and /etc/hosts.deny  files to indicate which hosts can or \ncannot access the service. Although the nfsd  server daemon itself is not enabled for TCP \nwrappers, the rpcbind  service is.\nFor NFSv3 and earlier versions, simply adding a line such as the following to the  \n/etc/hosts.deny  file would deny access to the rpcbind  service, but it would also deny \naccess to your", "doc_id": "b92104ef-e713-4d00-840a-52ee3303a62e", "embedding": null, "doc_hash": "133219e1bfe55ffb8427c2b6223e5f96644066829edb9ef31079ed4a2b8e87a6", "extra_info": {"page_label": "534"}, "node_info": {"start": 0, "end": 2529}, "relationships": {"1": "f17ab070-3c88-417c-a6ba-6e604aff0ce2", "3": "bfecf4c9-0a1f-4a65-85a5-d96e8b520f7e"}}, "__type__": "1"}, "bfecf4c9-0a1f-4a65-85a5-d96e8b520f7e": {"__data__": {"text": "numbers set and being used by the various services, you can now add ipt -\nables  rules, as you did with ports 2049 and 111 for the basic NFS service.\nAllowing NFS access in TCP wrappers\nFor services such as vsftpd  and sshd , TCP wrappers in Linux enable you to add informa -\ntion to /etc/hosts.allow  and /etc/hosts.deny  files to indicate which hosts can or \ncannot access the service. Although the nfsd  server daemon itself is not enabled for TCP \nwrappers, the rpcbind  service is.\nFor NFSv3 and earlier versions, simply adding a line such as the following to the  \n/etc/hosts.deny  file would deny access to the rpcbind  service, but it would also deny \naccess to your NFS service:\nrpcbind: ALL", "doc_id": "bfecf4c9-0a1f-4a65-85a5-d96e8b520f7e", "embedding": null, "doc_hash": "aee46c7eb72c3494501338290ceaade8c8a3b79c4299c27460fa1eae2cbe6a7b", "extra_info": {"page_label": "534"}, "node_info": {"start": 1855, "end": 2555}, "relationships": {"1": "f17ab070-3c88-417c-a6ba-6e604aff0ce2", "2": "b92104ef-e713-4d00-840a-52ee3303a62e"}}, "__type__": "1"}, "e5f8e08f-6da0-4faf-beda-07a6a09b3b7c": {"__data__": {"text": "Chapter 20: Configuring an NFS File Server\n511\n20For servers running NFSv4 by default, however, the rpcbind: ALL  line just shown pre -\nvents outside hosts from getting information about RPC services (such as NFS) using com-\nmands like showmount . However, it does not prevent you from mounting an NFS shared \ndirectory.\nConfiguring SELinux for your NFS server\nWith SELinux set to permissive or disabled, it does not block access to the NFS service. In \nenforcing mode, however, you should understand a few SELinux Booleans. To check the \nstate of SELinux on your system, enter the following:\n# getenforce\nEnforcing\n# grep ^SELINUX= /etc/sysconfig/selinux\nSELINUX=enforcing\nIf your system is in enforcing mode, as it is here, check the nfs _ selinux  man page \nfor information about SELinux settings that can impact the operation of your vsftpd  \nservice. Here are a few SELinux file contexts associated with NFS that you might need to \nknow about:\nnfs_export_all_ro : With this Boolean set to on, SELinux allows you to share files \nwith read-only permission using NFS. NFS read-only file sharing is allowed with this \non regardless of the SELinux file context set on the shared files and directories.\nnfs_export_all_rw : With this Boolean set to on, SELinux allows you to share files \nwith read/write permission using NFS. As with the previous Boolean, this works \nregardless of the file context set on the shared files and directories.\nuse_nfs_home_dirs: To allow the NFS server to share your home directories via \nNFS, set this Boolean to on.\nOf the Booleans just described, the first two are on by default. The use_nfs_home_dirs \nBoolean is off. To turn on the use_nfs_home_dirs directory, you could type the \nfollowing:\n# setsebool -P use_nfs_home_dirs on\nYou can ignore all of the Booleans related to NFS file sharing, however, by changing the file \ncontexts on the files and directories you want to share via NFS. The public_content_t \nand public_content_rw_t file contexts can be set on any directory that you want to \nshare via NFS (or other file share protocols, such as HTTP, FTP, and others, for that matter). \nFor example, to set the rule to allow the /whatever  directory and its subdirectories to be \nshared read/write via NFS, and then to apply that rule, enter the following:\n# semanage fcontext -a -t public_content_rw_t \"/whatever(/.*)?\"\n# restorecon -F -R -v /whatever", "doc_id": "e5f8e08f-6da0-4faf-beda-07a6a09b3b7c", "embedding": null, "doc_hash": "e178277dcd78391563440649cb306a1a107c906089ee32690570ba0cada1ae0a", "extra_info": {"page_label": "535"}, "node_info": {"start": 0, "end": 2388}, "relationships": {"1": "42de9950-141b-4acb-ac12-187aa82acf1a"}}, "__type__": "1"}, "2ca21c5e-68ff-43f3-8ad1-d2fd664a4410": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator512If you wanted to allow users just to be able to read files from a directory, but not write to \nit, you could assign the public_content_t file context to the directory instead.\nUsing NFS Filesystems\nAfter a server exports a directory over the network using NFS, a client computer connects \nthat directory to its own filesystem using the mount  command. That\u2019s the same command \nused to mount filesystems from local hard disks, DVDs, and USB drives, but with slightly \ndifferent options.\nThe mount  command enables a client to mount NFS directories added to the /etc/fstab  \nfile automatically, just as it does with local disks. NFS directories can also be added to the /\netc/fstab  file in such a way that they are not automatically mounted (so you can mount \nthem manually when you choose). With a noauto  option, an NFS directory listed in /etc/\nfstab  is inactive until the mount  command is used, after the system is up and running, \nto mount the filesystem.\nIn addition to the /etc/fstab  file, you can set mount options using the /etc/nfs -\nmount.conf  file. Within that file, you can set mount options that apply to any NFS  \ndirectory you mount or only those associated with specific mount points or NFS servers.\nBefore you set about mounting NFS shared directories, however, you probably want to check \nout what shared directories are available via NFS using the showmount  command.\nViewing NFS shares\nFrom a client Linux system, you can use the showmount  command to see what shared \ndirectories are available from a selected computer, such as in this example:\n$ showmount -e server.example.com\n/export/myshare client.example.com\n/mnt/public     *\nThe showmount  output shows that the shared directory named /export/myshare  is \navailable only to the host client.example.com . The /mnt/public  shared directory, \nhowever, is available to anyone.\nManually mounting an NFS filesystem\nAfter you know that the directory from a computer on your network has been exported \n(that is, made available for mounting), you can mount that directory manually using the \nmount  command. This is a good way to make sure that it is available and working before \nyou set it up to mount permanently. The following is an example of mounting the /stuff  \ndirectory from a computer named maple  on your local computer:\n# mkdir /mnt/maple\n# mount maple:/stuff /mnt/maple", "doc_id": "2ca21c5e-68ff-43f3-8ad1-d2fd664a4410", "embedding": null, "doc_hash": "b2c6038923f3f80469f17ef73717cde32a45dc8df5aa4c6fb7859a330115f986", "extra_info": {"page_label": "536"}, "node_info": {"start": 0, "end": 2405}, "relationships": {"1": "2855f849-2e4d-41a9-8cf9-ce4b25f5e58a"}}, "__type__": "1"}, "6fd60630-ec63-429a-ae1d-c56b07f140b8": {"__data__": {"text": "Chapter 20: Configuring an NFS File Server\n513\n20The first command ( mkdir ) creates the mount point directory. ( /mnt  is a common place to \nput temporarily mounted disks and NFS filesystems.) The mount  command identifies the \nremote computer and shared filesystem, separated by a colon ( maple:/stuff ), and the \nlocal mount point directory ( /mnt/maple ) follows.\nNote\nIf the mount fails, make sure that the NFS service is running on the server and that the server\u2019s firewall rules don\u2019t \ndeny access to the service. From the server, type ps ax | grep nfsd to see a list of nfsd  server processes. \nIf you don\u2019t see the list, try to start your NFS daemons as described earlier in this chapter. To view your firewall rules, \ntype iptables -vnL . By default, the nfsd  daemon listens for NFS requests on port number 2049. Your firewall \nmust accept udp  requests on ports 2049 ( nfs) and 111 (rpc). In Red Hat Enterprise Linux 6 and earlier versions \nof Fedora, you may need to set static ports for related services and then open ports for those services in the firewall. \nRefer to the section \u201cSecuring Your NFS Server\u201d earlier in this chapter to review how to overcome these security \nissues.\nTo ensure that the NFS mount occurred, type mount -t nfs4 . This command lists all \nmounted NFS filesystems. Here is an example of the mount  command and its output (with \nfilesystems not pertinent to this discussion edited out):\n# mount -t nfs4\n192.168.122.240:/mnt on /mnt/fed type nfs4  \n(rw,relatime,vers=4.2,rsize=262144,wsize=262144,namlen=255,hard,\nproto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=192.168.122.63,\nlocal_lock=none,addr=192.168.122.240)\nThe output from the mount -t nfs4 command shows only those filesystems mounted \nfrom NFS file servers. The NFS filesystem is the /mnt  directory from 192.168.122.240 \n(192.168.122.240 :/mnt ). It is mounted on /mnt/fed , and its mount type is nfs4 . The file -\nsystem was mounted read/write ( rw), and the IP address of maple  is 192.168.122.240  \n(addr=192.168.122.240 ). Many other settings related to the mount are shown as well, \nsuch as the read and write sizes of packets and the NFS version number.\nThe mount operation just shown temporarily mounts an NFS filesystem on the local system. \nThe next section describes how to make the mount more permanent (using the /etc/\nfstab  file) and how to select various options for NFS mounts.\nMounting an NFS filesystem at boot time\nTo set up an NFS filesystem to mount automatically on a specified mount point each time \nyou start your Linux system, you need to add an entry for that NFS filesystem to the /etc/\nfstab  file. That file contains information about all different kinds of mounted (and avail -\nable to be mounted) filesystems for your system.\nHere\u2019s the format for adding an NFS filesystem to your local system:\nhost:directory    mountpoint    nfs    options    0    0", "doc_id": "6fd60630-ec63-429a-ae1d-c56b07f140b8", "embedding": null, "doc_hash": "9095b41d92ce3b228c8b487d66b905024fd3b6d5aac0e4b35b4bf31283e49fed", "extra_info": {"page_label": "537"}, "node_info": {"start": 0, "end": 2884}, "relationships": {"1": "9ac47593-6fef-44e6-ad2b-997207af7b11"}}, "__type__": "1"}, "9d00581f-57bf-46d5-ae23-64b494eaed50": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator514The first item ( host:directory ) identifies the NFS server computer and shared direc -\ntory. mountpoint  is the local mount point on which the NFS directory is mounted. It is \nfollowed by the filesystem type ( nfs). Any options related to the mount appear next in a \ncomma-separated list. (The last two zeros configure the system not to dump the contents of \nthe filesystem and not to run fsck  on the filesystem.)\nThe following are examples of NFS entries in /etc/fstab :\nmaple:/stuff   /mnt/maple nfs   bg,rsize=8192,wsize=8192  0 0\noak:/apps      /oak/apps  nfs   noauto,ro                 0 0\nIn the first example, the remote directory /stuff  from the computer named maple  \n(maple:/stuff ) is mounted on the local directory /mnt/maple  (the local directory must \nalready exist). If the mount fails because the share is unavailable, the bg  causes the mount \nattempt to go into the background and retry again later.\nThe filesystem type is nfs , and read ( rsize ) and write ( wsize ) buffer sizes (discussed \nin the section \u201cUsing mount options,\u201d later in this chapter) are set at 8192  to speed data \ntransfer associated with this connection. In the second example, the remote directory is \n/apps  on the computer named oak . It is set up as an NFS filesystem ( nfs) that can be \nmounted on the /oak/apps  directory locally. This filesystem is not mounted automati-\ncally (noauto ), however, and it can be mounted only as read-only ( ro) using the mount  \ncommand after the system is already running.\ntip\nThe default is to mount an NFS filesystem as read/write. However, the default for exporting a filesystem is read-only. \nIf you are unable to write to an NFS filesystem, check that it was exported as read/write from the server.\nMounting noauto filesystems\nYour /etc/fstab  file may also contain devices for other filesystems that are not mounted \nautomatically. For example, you might have multiple disk partitions on your hard disk or an \nNFS shared filesystem that you want to mount only occasionally. A noauto  filesystem can \nbe mounted manually. The advantage is that when you type the mount  command, you can \ntype less information and have the rest filled in by the contents of the /etc/fstab  file. \nSo, for example, you could type\n# mount /oak/apps\nWith this command, mount  knows to check the /etc/fstab  file to get the filesystem to \nmount (oak:/apps ), the filesystem type ( nfs), and the options to use with the mount (in \nthis case ro , for read-only). Instead of typing the local mount point ( /oak/apps ), you \ncould have typed the remote filesystem name ( oak:/apps ) and had other information \nfilled in.", "doc_id": "9d00581f-57bf-46d5-ae23-64b494eaed50", "embedding": null, "doc_hash": "35969a70435ef95c30c4ea9497e0ec0e98fb821d8b848a541fa8d9a7d65d38cd", "extra_info": {"page_label": "538"}, "node_info": {"start": 0, "end": 2683}, "relationships": {"1": "5379b944-75b7-4cee-a16a-a3a7768ddf78"}}, "__type__": "1"}, "e585e45f-ea96-4cc7-8e67-6c519728c3b2": {"__data__": {"text": "Chapter 20: Configuring an NFS File Server\n515\n20Using mount options\nYou can add several mount  options to the /etc/fstab  file (or to a mount  command line \nitself) to influence how the filesystem is mounted. When you add options to /etc/fstab , \nthey must be separated by commas. For example, here the noauto , ro, and hard  options \nare used when oak:/apps  is mounted:\noak:/apps    /oak/apps  nfs   noauto,ro,hard    0 0\nThe following are some options that are valuable for mounting NFS filesystems. You can \nread about these and other NFS mount options you can put in the /etc/fstab  file from \nthe nfs  man page ( man 5 nfs ):\nhard  If this option is used and the NFS server disconnects or goes down while a pro -\ncess is waiting to access it, the process hangs until the server comes back up. This \nis helpful if it is critical that the data with which you are working stay in sync with \nthe programs that are accessing it. (This is the default behavior.)\nsoft  If the NFS server disconnects or goes down, a process trying to access data from \nthe server times out after a set period when this option is on. An input/output error \nis delivered to the process trying to access the NFS server.\nrsize  This is the size of the blocks of data (in bytes) that the NFS client will request \nbe used when it is reading data from an NFS server. The default is 1024. Using a \nlarger number (such as 8192) gets you better performance on a network that is fast \n(such as a LAN) and is relatively error-free (that is, one that doesn\u2019t have lots of \nnoise or collisions).\nwsize  This is the size of the blocks of data (in bytes) that the NFS client will request \nto be used when it is writing data to an NFS server. The default is 1024. Performance \nissues are the same as with the rsize  option.\ntimeo=#  This sets the time after an RPC time-out occurs that a second transmission \nis made, where # represents a number in tenths of a second. The default value is \nseven-tenths of a second. Each successive time-out causes the time-out value to be \ndoubled (up to 60 seconds maximum). Increase this value if you believe that time-\nouts are occurring because of slow response from the server or a slow network.\nretrans=#  This sets the number of minor time-outs and retransmissions that need \nto happen before a major time-out occurs.tip\nWhen naming mount points, including the name of the remote NFS server in that name can help you remember where \nthe files are actually being stored. This may not be possible if you are sharing home directories ( /home ) or mail \ndirectories ( /var/spool/mail ). For example, you might mount a filesystem from a machine called duck  on the \ndirectory /mnt/duck .", "doc_id": "e585e45f-ea96-4cc7-8e67-6c519728c3b2", "embedding": null, "doc_hash": "4c92e980b9f1da6978fa80e2cdd2b51477bd43e5344aab7dbeb167713b5165f2", "extra_info": {"page_label": "539"}, "node_info": {"start": 0, "end": 2689}, "relationships": {"1": "8150a85f-cdbb-4127-bde8-73809ad09d55"}}, "__type__": "1"}, "8ebd7d56-3f00-4afa-9e47-85dcb2417b5d": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator516retry=#  This sets how many minutes to continue to retry failed mount requests, \nwhere # is replaced by the number of minutes to retry. The default is 10,000 minutes \n(which is about one week).\nbg If the first mount attempt times out, try all subsequent mounts in the \nbackground. This option is very valuable if you are mounting a slow or sporadically \navailable NFS filesystem. When you place mount requests in the background, your \nsystem can continue to mount other filesystems instead of waiting for the current \none to complete.\nNote\nIf a nested mount point is missing, a time-out to allow for the needed mount point to be added occurs. For example, \nif you mount /usr/trip  and /usr/trip/extra  as NFS filesystems and /usr/trip  is not yet mounted when \n/usr/trip/extra  tries to mount, /usr/trip/extra  times out. If you\u2019re lucky, /usr/trip  comes up and /\nusr/trip/extra  mounts on the next retry.\nfg If the first mount attempt times out, try subsequent mounts in the foreground. \nThis is the default behavior. Use this option if it is imperative that the mount be \nsuccessful before continuing (for example, if you were mounting /usr ).\nNot all NFS mount options need to go into the /etc/fstab  file. On the client side, the /\netc/nfsmount.conf  file can be configured for Mount, Server, and Global sections. In the \nMount section, you can indicate which mount options are used when an NFS filesystem is \nmounted to a particular mount point. The Server section lets you add options to any NFS \nfilesystem mounted from a particular NFS server. Global options apply to all NFS mounts \nfrom this client.\nThe following entry in the /etc/nfsmount.conf  file sets a 32KB read and write block \nsize for any NFS directories mounted from the system named thunder.example.com :\n[ Server \"thunder.example.com\" ]\n  rsize=32k\n  wsize=32k\nTo set default options for all NFS mounts for your systems, you can uncomment the NFS -\nMount _ Global _ Options  block. In that block, you can set such things as protocols \nand NFS versions as well as transmission rates and retry settings. Here is an example of an \nNFSMount _ Global_ Options  block:\n[ NFSMount_Global_Options ]\n# This sets the default version to NFS 4\nDefaultvers=4\n# Sets the number of times a request will be retried before\n# generating a timeout\nRetrans=2\n# Sets the number of minutes before retrying a failed\n# mount to 2 minutes\nRetry=2", "doc_id": "8ebd7d56-3f00-4afa-9e47-85dcb2417b5d", "embedding": null, "doc_hash": "ef514857c1d238d92fbfdc0a7a88076cc2807e0bb63cae3c17f3c74105f70552", "extra_info": {"page_label": "540"}, "node_info": {"start": 0, "end": 2444}, "relationships": {"1": "546a9877-3fca-4fce-a5d1-14e50833f3d8"}}, "__type__": "1"}, "fb6a1471-e28d-42de-bf7a-f97522aa4179": {"__data__": {"text": "Chapter 20: Configuring an NFS File Server\n517\n20In the example just shown, the default NFS version is 4. Data is retransmitted twice ( 2) \nbefore generating a time-out. The wait time is 2 minutes before retrying a failed transmis -\nsion. You can override any of these default values by adding mount options to the /etc/\nfstab  or to the mount command line when the NFS directory is mounted.\nUsing autofs to mount NFS filesystems on demand\nImprovements to autodetecting and mounting removable devices have meant that you can \nsimply insert or plug in those devices to have them detected, mounted, and displayed. \nHowever, to make the process of detecting and mounting remote NFS filesystems more \nautomatic, you still need to use a facility such as autofs  (short for automatically mounted \nfilesystems ).\nThe autofs  facility mounts network filesystems on demand when someone tries to use the \nfilesystems. With the autofs  facility configured and turned on, you can cause any avail -\nable NFS shared directories to mount on demand. To use the autofs  facility, you need to \nhave the autofs  package installed. (For Fedora and RHEL, you can type yum install \nautofs  or for Ubuntu or Debian apt-get install autofs to install the package from \nthe network.)\nAutomounting to the /net directory\nWith autofs  enabled, if you know the hostname and directory being shared by another \nhost computer, simply change ( cd) to the autofs  mount directory ( /net  or /var/autofs  \nby default). This causes the shared resource to be automatically mounted and made acces -\nsible to you.\nThe following steps explain how to turn on the autofs  facility in Fedora or RHEL:\n1. In Fedora or RHEL, as root user from a Terminal window, open the  \n/etc/auto.master  file and look for the following line :\n        /net   -hosts\nThis causes the /net  directory to act as the mount point for the NFS shared direc -\ntories that you want to access on the network. (If there is a comment character at \nthe beginning of that line, remove it.)\n2. To start the autofs  service in a Fedora 30, RHEL 7, or later system, type the \nfollowing as root user :\n        # systemctl start autofs.service\n3. On a Fedora 30, RHEL 7, or later system, set up the autofs  service to restart \nevery time you boot your system :\n        # systemctl enable autofs\nBelieve it or not, that\u2019s all you have to do. If you have a network connection to the NFS \nservers from which you want to share directories, try to access a shared NFS directory. For ", "doc_id": "fb6a1471-e28d-42de-bf7a-f97522aa4179", "embedding": null, "doc_hash": "e91c420c25ec585f6a769faea945f876abc8275cbdae39c28c9615c77d202ddc", "extra_info": {"page_label": "541"}, "node_info": {"start": 0, "end": 2498}, "relationships": {"1": "8035cfab-d7cc-46ca-8c4a-4ca03e504cf0"}}, "__type__": "1"}, "7689f001-6397-464e-835b-b052a0682eb5": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator518example, if you know that the /usr/local/share  directory is being shared from the \ncomputer on your network named shuttle , you can do the following:\n$ cd /net/shuttle/\nIf that computer has any shared directories that are available to you, you can successfully \nchange to that directory.\nYou also can type the following:\n$ ls\nusr\nYou should be able to see that the usr  directory is part of the path to a shared directory. If \nthere were shared directories from other top-level directories (such as /var  or /tmp ), you \nwould see those. Of course, seeing any of those directories depends on how security is set \nup on the server.\nTry going straight to the shared directory, as shown in this example:\n$ cd /net/shuttle/usr/local/share\n$ ls\ninfo man music television\nAt this point, the ls  should reveal the contents of the /usr/local/share  directory on \nthe computer named shuttle . What you can do with that content depends on how it was \nconfigured for sharing by the server.\nThis can be a bit disconcerting because you don\u2019t see any files or directories until you  \nactually try to use them, such as changing to a network-mounted directory. The ls  \ncommand, for example, doesn\u2019t show anything under a network-mounted directory until \nthe directory is mounted, which may lead to a sometimes-it\u2019s-there-and-sometimes-it\u2019s-not \nimpression. Just change to a network-mounted directory, or access a file on such a direc -\ntory, and autofs  takes care of the rest.\nIn the example shown, the hostname shuttle  is used. However, you can use any name \nor IP address that identifies the location of the NFS server computer. For example, instead \nof shuttle , you might have used shuttle.example.com  or an IP address such as \n192.168.0.122 .\nAutomounting home directories\nInstead of just mounting an NFS filesystem under the /net  directory, you might want to \nconfigure autofs  to mount a specific NFS directory in a specific location. For example, \nyou could configure a user\u2019s home directory from a centralized server that could be auto -\nmounted from a different machine when a user logs in. Likewise, you could use a central \nauthentication mechanism, such as LDAP (as described in Chapter\u00a011, \u201cManaging User \nAccounts\u201d), to offer centralized user accounts.", "doc_id": "7689f001-6397-464e-835b-b052a0682eb5", "embedding": null, "doc_hash": "2fbe175eddf9be6c13ed435ec4da0a9c4b3211e66d4c1316ac3600d6b833aac4", "extra_info": {"page_label": "542"}, "node_info": {"start": 0, "end": 2306}, "relationships": {"1": "58bd6b46-9b48-4c1b-acd2-6472658690e2"}}, "__type__": "1"}, "2d63168d-6b7c-444a-8591-79839a9973c7": {"__data__": {"text": "Chapter 20: Configuring an NFS File Server\n519\n20The following procedure illustrates how to set up a user account on an NFS server and share \nthe home directory of a user named joe  from that server so that it can be automounted \nwhen joe  logs into a different computer. In this example, instead of using a central \nauthentication server, matching accounts are created on each system.\n1. On the NFS server ( mynfs.example.com ) that provides a centralized user home \ndirectory for the user named joe , create a user account for joe  with a home direc -\ntory of /home/shared/joe  as its name. Also find joe \u2019s user ID number from the \n/etc/passwd  file (third field) so that you can match it when you set up a user \naccount for joe  on another system.\n        # mkdir /home/shared\n        # useradd -c \"Joe Smith\" -d /home/shared/joe joe\n        # grep joe /etc/passwd\n        joe:x:1000:1000:Joe Smith:/home/shared/joe:/bin/bash\n2. On the NFS server, export the /home/shared/  directory to any system on your \nlocal network (I use 192.168.0.* here), so that you can share the home directory for \njoe and any other users you create by adding this line to the /etc/exports  file:\n        # /etc/exports file to share directories under /home/shared\n        # only to other systems on the 192.168.0.0/24 network:\n        /home/shared 192.168.0.*(rw,insecure)\nNote\nIn the exports file example above, the insecure  option allows clients to use ports above port 1024 to make mount \nrequests. Some NFS clients require this because they do not have access to NFS-reserved ports.\n3. On the NFS server, restart the nfs-server  service, or if it is already running, you \ncan simply export the shared directory as follows:\n        # exportfs -a -r -v\n4. On the NFS server, make sure that the appropriate ports are open on the firewall. \nSee the section \u201cSecuring Your NFS Server\u201d earlier in this chapter for details.\n5. On the NFS client system, add an entry to the /etc/auto.master  file that iden -\ntifies the mount point where you want the remote NFS directory to be mounted \nand a file (of your choosing) where you will identify the location of the remote NFS \ndirectory. I added this entry to the auto.master  file:\n        /home/remote /etc/auto.joe\n6. On the NFS client system, add an entry to the file you just noted ( /etc/auto.joe  \nis what I used) that contains an entry like the following:\n        joe      -rw     mynfs.example.com:/home/shared/joe\n7. On the NFS client system, restart the autofs  service:\n        # systemctl restart autofs.service", "doc_id": "2d63168d-6b7c-444a-8591-79839a9973c7", "embedding": null, "doc_hash": "f13ea9d3b5fc36da9a04f7684a6ccfcb26d95f4a2c8e9b570474c43775777919", "extra_info": {"page_label": "543"}, "node_info": {"start": 0, "end": 2550}, "relationships": {"1": "5d5ce0d9-e984-441c-8167-8282e95d5e2f"}}, "__type__": "1"}, "182074ce-2b1d-4565-8074-df6c51091fe0": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator5208. On the NFS client system, create a user named joe  using the useradd  command. \nFor that command line, you need to get the UID for joe  on the server (507 in this \nexample) so that joe  on the client system owns the files from joe \u2019s NFS home \ndirectory. When you run the following command, the joe  user account is created, \nbut you will see an error message stating that the home directory already exists \n(which is correct):\n        # useradd -u 507 -c \"Joe Smith\" -d /home/remote/joe joe\n        # passwd joe\n        Changing password for user joe.\n        New password: ********\n        Retype new password: ********\n9. On the NFS client system, log in as joe . If everything is working properly, when \njoe logs in and tries to access his home directory ( /home/remote/joe), the \ndirectory /home/share/joe  should be mounted from the mynfs.example.com  \nserver. The NFS directory was both shared and mounted as read/write with owner -\nship to UID 507 ( joe on both systems), so the user joe  on the local system should \nbe able to add, delete, change, and view files in that directory.\nAfter joe  logs off (actually, when he stops accessing the directory) for a time-out period \n(10 minutes, by default), the directory is unmounted.\nUnmounting NFS filesystems\nAfter an NFS filesystem is mounted, unmounting it is simple. You use the umount  \ncommand with either the local mount point or the remote filesystem name. For example, \nhere are two ways that you could unmount maple:/stuff  from the local directory /\nmnt/maple :\n# umount maple:/stuff\n# umount /mnt/maple\nEither form works. If maple:/stuff  is mounted automatically (from a listing in /etc/\nfstab ), the directory is remounted the next time you boot Linux. If it was a temporary \nmount (or listed as noauto  in /etc/fstab ), it isn\u2019t remounted at boot time.\ntip\nThe command is umount , not unmount. This is easy to get wrong.\nIf you get the message device is busy  when you try to unmount a filesystem, it means \nthat the unmount failed because the filesystem is being accessed. Most likely, one of the \ndirectories in the NFS filesystem is the current directory for your shell (or the shell of \nsomeone else on your system). The other possibility is that a command is holding a file ", "doc_id": "182074ce-2b1d-4565-8074-df6c51091fe0", "embedding": null, "doc_hash": "ef32387e2453b96a89388ab1ea13638f7dc5943cd717c81c27ee7136a5f9ba43", "extra_info": {"page_label": "544"}, "node_info": {"start": 0, "end": 2301}, "relationships": {"1": "73027aea-92a0-48dc-8a43-a7f43f4cdee0"}}, "__type__": "1"}, "782c106b-e93f-45da-ae1c-97cbbd2d352e": {"__data__": {"text": "Chapter 20: Configuring an NFS File Server\n521\n20open in the NFS filesystem (such as a text editor). Check your Terminal windows and other \nshells, and then cd  out of the directory if you are in it, or just close the Terminal windows.\nIf an NFS filesystem doesn\u2019t unmount, you can force it ( umount -f /mnt/maple ) or \nunmount and clean up later ( umount -l /mnt/maple ). The -l  option is usually the \nbetter choice because a forced unmount can disrupt a file modification that is in progress. \nAnother alternative is to run fuser -v  mountpoint  to see what users are holding your \nmounted NFS share open and then fuser -k  mountpoint  to kill all of those processes.\nSummary\nNetwork File System (NFS) is one of the oldest computer file sharing products in exis -\ntence today. It is still the most popular for sharing directories of files between UNIX and \nLinux systems. NFS allows servers to designate specific directories to make available to \ndesignated hosts and then allows client systems to connect to those directories by mount -\ning them locally.\nNFS can be secured using firewall ( iptables ) rules, TCP wrappers (to allow and deny \nhost access), and SELinux (to confine how file sharing protocols can share NFS resources). \nAlthough NFS was inherently insecure when it was created (data is shared unencrypted and \nuser access is fairly open), features in NFS version 4 have helped improve the overall secu -\nrity of NFS.\nThis NFS chapter is the last of the book\u2019s server chapters. Chapter\u00a021, \u201cTroubleshooting \nLinux,\u201d covers a wide range of desktop and server topics as it helps you understand tech -\nniques for troubleshooting your Linux system.\nExercises\nExercises in this section take you through tasks related to configuring and using an NFS \nserver in Linux. If possible, have two Linux systems available that are connected on a local \nnetwork. One of those Linux systems will act as an NFS server while the other will be an \nNFS client.\nTo get the most from these exercises, I recommend that you don\u2019t use a Linux server that \nhas NFS already up and running. You can\u2019t do all of the exercises here without disrupting \nan NFS service that is already running and sharing resources.\nSee Appendix B for suggested solutions.\n1. On the Linux system you want to use as an NFS server, install the packages needed \nto configure an NFS service.\n2. On the NFS server, list the documentation files that come in the package that pro -\nvides the NFS server software.", "doc_id": "782c106b-e93f-45da-ae1c-97cbbd2d352e", "embedding": null, "doc_hash": "00e6372d9aefd70cac07ab0d643331f438d8a75786340785a5b819c6c4b7c505", "extra_info": {"page_label": "545"}, "node_info": {"start": 0, "end": 2473}, "relationships": {"1": "28b9ae88-7301-4b5f-b8b6-5858df9741bc"}}, "__type__": "1"}, "70f2979e-0af1-444e-86e7-9b92f90833ef": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator5223. On the NFS server, determine the name of the NFS service and start it.\n4. On the NFS server, check the status of the NFS service you just started.\n5. On the NFS server, create the /var/mystuff  directory and share it from your NFS \nserver with the following attributes: available to everyone, read-only, and the root \nuser on the client has root access to the share.\n6. On the NFS server, make sure that the share you created is accessible to all hosts by \nopening TCP wrappers, iptables , and SELinux.\n7. On a second Linux system (NFS client), view the shares available from the NFS \nserver. (If you don\u2019t have a second system, you can do this from the same system.) \nIf you do not see the shared NFS directory, go back to the previous question and \ntry again.\n8. On the NFS client, create a directory called /var/remote  and temporarily mount \nthe /var/mystuff  directory from the NFS server on that mount point.\n9. On the NFS client, unmount /var/remote , add an entry so that the same mount \nis done automatically when you reboot (with a bg  mount option), and test that the \nentry you created is working properly.\n10. From the NFS server, copy some files to the /var/mystuff  directory. From the NFS \nclient, make sure that you can see the files just added to that directory and make \nsure that you can\u2019t write files to that directory from the client.", "doc_id": "70f2979e-0af1-444e-86e7-9b92f90833ef", "embedding": null, "doc_hash": "3847ddf0f6aeb9ae91a3e3cabddadc7df3236c43de4f4babe662d2be68a53970", "extra_info": {"page_label": "546"}, "node_info": {"start": 0, "end": 1408}, "relationships": {"1": "6a2e8f49-772b-4996-8d0d-74f5d4be0e6c"}}, "__type__": "1"}, "685da344-9e72-4fed-86ee-198573f34a27": {"__data__": {"text": "523\nCHAPTER21\nTroubleshooting Linux\nIN THIS CHAPTER\nTroubleshooting boot loaders\nTroubleshooting system initialization\nFixing software packaging problems\nChecking network interface issues\nDealing with memory problems\nUsing rescue mode\nIn any complex operating system, lots of things can go wrong. You can fail to save a file because \nyou are out of disk space. An application can crash because the system is out of memory. The \nsystem can fail to boot up properly for, well, lots of different reasons.\nIn Linux, the dedication to openness, and the focus on making the software run with maximum \nefficiency, has led to an amazing number of tools that you can use to troubleshoot every imaginable \nproblem. In fact, if the operating system isn\u2019t working as you would like, you even have the ultimate \nopportunity to rewrite the code yourself (although I don\u2019t cover how to do that here).\nThis chapter takes on some of the most common problems that you can run into on a Linux system, \nand it describes the tools and procedures that you can use to overcome those problems. Topics are \nbroken down by areas of troubleshooting, such as the boot process, software packages, networking, \nmemory issues, and rescue mode.\nBoot-Up Troubleshooting\nBefore you can begin troubleshooting a running Linux system itself, that system needs to boot up. \nFor a Linux system to boot up, a series of things has to happen. A Linux system installed directly \non a PC architecture computer goes through the following steps to boot up:\n\u25a0\u25a0Turning on the power\n\u25a0\u25a0Starting the hardware (from BIOS or UEFI firmware)\n\u25a0\u25a0Finding the location of the boot loader and starting it\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "685da344-9e72-4fed-86ee-198573f34a27", "embedding": null, "doc_hash": "536aa957c7d5aeeec24f4f9e69d8283715b46556a5a3e647d3bc79ea0e473e17", "extra_info": {"page_label": "547"}, "node_info": {"start": 0, "end": 1767}, "relationships": {"1": "2ca09b75-8377-44b2-9372-eea5c90acb9d"}}, "__type__": "1"}, "74811923-5cf7-4369-bbe1-2354fa68a064": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator524\u25a0\u25a0Choosing an operating system from the boot loader\n\u25a0\u25a0Starting the kernel and initial RAM disk for the selected operating system\n\u25a0\u25a0Starting the initialization process ( init  or systemd )\n\u25a0\u25a0Starting all of the services associated with the selected level of activity (runlevel \nor default target)\nThe exact activities that occur at each of these points have undergone a transformation in \nrecent years. Boot loaders are changing to accommodate new kinds of hardware. The ini-\ntialization process is changing so that services can start more efficiently, based on depen -\ndencies and in reaction to the state of the system (such as what hardware is plugged in or \nwhat files exist) rather than a static boot order.\nTroubleshooting the Linux boot process begins when you turn on your computer, and it \nends when all of the services are up and running. At that point, typically a graphical or \ntext-based login prompt is available from the console, ready for you to log in.\nAfter reading the short descriptions of startup methods, go to the section \u201cStarting from \nthe firmware (BIOS or UEFI)\u201d in order to understand what happens at each stage of the boot \nprocess and where you might need to troubleshoot. Because the general structure of the \nLinux boot process is the same for the three Linux systems featured here (Fedora, RHEL, \nand Ubuntu), I will go through the boot process only once, but I will describe the differ -\nences among them as I go.\nUnderstanding Startup Methods\nIt\u2019s up to the individual Linux distribution how the services associated with the running \nLinux system are started. After the boot loader starts the kernel, how the rest of the activ -\nities (mounting filesystems, setting kernel options, running services, and so on) are done is \nall managed by the initialization process.\nAs I describe the boot process, I focus on two different types of initialization: System V \ninit  and systemd .\nStarting with System V init scripts\nThe System V init  facility consists of the init  process (the first process to run after the \nkernel itself), an /etc/inittab  file that directs all startup activities, and a set of shell \nscripts that starts each of the individual services. The first Fedora releases, and up to RHEL \n5, used the System V init  process. RHEL 6 contains a sort of hybrid of System V init , \nwith the init  process itself replaced by the Upstart init  process.\nSystem V init  was developed for UNIX System V at AT&T in the mid-1980s when UNIX \nsystems first incorporated the startup of network interfaces and the services connected to \nthem. It has been supplanted only over the past decade by Upstart and systemd  to better \nsuit the demands of modern operating systems.\nIn System V init , sets of services are assigned to what is referred to as runlevels . For \nexample, the multi-user runlevel can start basic system services, network interfaces, ", "doc_id": "74811923-5cf7-4369-bbe1-2354fa68a064", "embedding": null, "doc_hash": "f79a4677eb3ec247d215cdea4b9b6d9ff2788916abc24bc9da44367d4f748c3e", "extra_info": {"page_label": "548"}, "node_info": {"start": 0, "end": 2931}, "relationships": {"1": "35ef44bc-dc35-4418-9829-fa3f6a5fc549"}}, "__type__": "1"}, "badc67df-81c3-4aff-a5fe-e101ecb89e68": {"__data__": {"text": "Chapter 21: Troubleshooting Linux\n525\n21and network services. Single-user mode just starts enough of the basic Linux system so \nthat someone can log in from the system console without starting network interfaces \nor services.\nAfter a System V init  system is up and running, you can use commands such as reboot , \nshutdown , and init  to change runlevels. You can use commands such as service  and \nchkconfig  to start/stop individual services or enable/disable services, respectively.\nThe System V init  scripts are set to run in a specific order, with each script having to \ncomplete before the next can start. If a service fails, there is no provision for that service \nto restart automatically. In contrast, systemd  was designed to address these and other \nSystem V init  shortcomings.\nStarting with systemd\nThe systemd  facility is quickly becoming the present and future of the initialization \nprocess for many Linux systems. It was adopted in Fedora 15 and in RHEL 7 and replaced \nUpstart in Debian and Ubuntu 15.04. Although systemd  is more complex than System V \ninit , it also offers many more features, such as these:\nTargets  Instead of runlevels, systemd  focuses on targets. A target  can start a set \nof services as well as create or start other types of units (such as directory mounts, \nsockets, swap areas, and timers).\nSystem V compatibility There are targets that align with System V runlevels, if you \nare used to dealing with runlevels. For example, graphical.target  aligns with \nrunlevel 5 while multi-user.target  is essentially runlevel 3. However, there \nare many more targets than runlevels, giving you the opportunity to manage sets \nof units more finely. Likewise, systemd  supports System V init  scripts and com-\nmands, such as chkconfig  and service  for manipulating those services if System \nV init  services happen to be installed.\nDependency-based startup  When the system starts up, any service in the default \ntarget (graphical.target  for desktops and multi-user.target  for most \nservers) that has had its dependencies met can start. This feature can speed up the \nboot process by ensuring that a single stalled service doesn\u2019t stall other services \nfrom starting if they don\u2019t need the stalled service.\nResource usage   With systemd , you can use cgroups  to limit how much of your \nsystem\u2019s resources are consumed by a service. For example, you can limit the \namount of memory, CPU, or other resources an entire service can consume, so a run -\naway process or a service that spins off an unreasonable number of child processes \ncannot consume more than the entire service is allowed.\nWhen a systemd -enabled Linux system starts up, the first running process (PID 1) is \nthe systemd  daemon (instead of the init  daemon). Later, the primary command for \nmanaging systemd  services is the systemctl  command. Managing systemd  journal \n(log) messages is done with the journalctl  command. You also have the ability to use \nold-style System V init  commands such as init , poweroff , reboot , runlevel , and \nshutdown  to manage services.", "doc_id": "badc67df-81c3-4aff-a5fe-e101ecb89e68", "embedding": null, "doc_hash": "f0dcccfc2b6a027cfa6f9ced7cd934ed87e8e23d8da569dbcc338f0bb437bc3f", "extra_info": {"page_label": "549"}, "node_info": {"start": 0, "end": 3080}, "relationships": {"1": "bff1a03a-19ad-4fae-afaf-2a1b11dcbf49"}}, "__type__": "1"}, "5fc42715-0af8-4b7a-9a61-e3327402d5c7": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator526Starting from the firmware (BIOS or UEFI)\nWhen you physically turn on a computer, firmware is loaded to initialize the hardware and \nfind an operating system to boot. On PC architectures, that firmware has traditionally been \nreferred to as BIOS (Basic Input Output System) . In recent years, a new type of firmware \ncalled UEFI (Unified Extensible Firmware Interface) has become available to replace BIOS on \nsome computers. The two are mutually exclusive.\nUEFI was designed to allow a secure boot feature, which can be used to ensure that only \noperating systems whose components have been signed can be used during the boot pro -\ncess. UEFI can still be used with non-signed operating systems by disabling the secure \nboot feature.\nFor Ubuntu, secure boot was first supported in 12.04.2. RHEL 7 and later versions also offi-\ncially support secure boot. The main job of BIOS and UEFI firmware is to initialize the hard -\nware and then hand off control of the boot process to a boot loader. The boot loader then \nfinds and starts the operating system. After an operating system is installed, you should \ntypically just let the firmware do its work and not interrupt it.\nThere are, however, occasions when you want to interrupt the firmware. For this discus -\nsion, we focus on how BIOS generally works. Right after you turn on the power, you should \nsee a BIOS screen that usually includes a few words noting how to go into Setup mode and \nchange the boot order. If you press the function key noted (often F1, F2, or F12) to choose \none of those two items, here\u2019s what you can do:\nSetup utility  The setup utility lets you change settings in the BIOS. These settings \ncan be used to enable or disable certain hardware components or turn on or off \nselected hardware features.\nBoot order  Computers are capable of starting an operating system, or more spe -\ncifically, a boot loader that can start an operating system, from several different \ndevices attached to the computer. Those devices can include a CD drive, DVD drive, \nhard disk, USB driver, or network interface card. The boot order defines the order in \nwhich those devices are checked. By modifying the boot order, you can tell the com-\nputer to ignore the default boot order temporarily and try to boot from the device \nthat you select.\nFor my Dell workstation, after I see the BIOS screen, I immediately press the F2 function \nkey to go into Setup or F12 to change the boot order temporarily. The next sections explore \nwhat you can troubleshoot from the Setup and Boot Order screens.\nTroubleshooting BIOS setup\nAs I already noted, you can usually let the BIOS start without interruption and have the \nsystem boot up to the default boot device (probably the hard drive). However, here are some \ninstances when you may want to go into Setup mode and change something in the BIOS:\nTo see an overview of your hardware If your troubleshooting problem is hardware \nrelated, the BIOS setup is a great place to start examining your system. The Setup ", "doc_id": "5fc42715-0af8-4b7a-9a61-e3327402d5c7", "embedding": null, "doc_hash": "1c9179f69a923e83ec96d726bb075f3b886041084a5b826c15dd5646140df700", "extra_info": {"page_label": "550"}, "node_info": {"start": 0, "end": 3055}, "relationships": {"1": "323fc648-9ebe-47bc-b648-8f3df328c56b"}}, "__type__": "1"}, "fb79c043-e399-4c8a-890e-2805cb99283f": {"__data__": {"text": "Chapter 21: Troubleshooting Linux\n527\n21screen tells you the type of system, its BIOS version, its processors, its memory slots \nand types, whether it is 32-bit or 64-bit, which devices are in each slot, and many \ndetails about the types of devices attached to the system.\nIf you can\u2019t get an operating system booted at all, the BIOS Setup screen may be \nthe only way to determine the system model, processor type, and other information \nyou\u2019ll need to search for help or call for support.\nTo disable/enable a device Most devices connected to your computer are enabled and \nmade available for use by the operating system. To troubleshoot a problem, you may \nneed to disable a device.\nFor example, let\u2019s say that your computer has two network interface cards (NICs). \nYou want to use the second NIC to install Linux over a network, but the installer \nkeeps trying to use the first NIC to connect to the network. You can disable the first \nNIC so that the installer doesn\u2019t even see it when it tries to connect to the network. \nOr, you can keep the NIC visible to the computer but simply disable the NIC\u2019s ability \nto PXE boot.\nMaybe you have an audio card, and you want to disable the integrated audio on the \nmotherboard. That can be done in the BIOS as well. Conversely, sometimes you want \nto enable a device that has been disabled. Perhaps you were given a computer that \nhad a device disabled in the BIOS. From the operating system, for example, it may \nlook like you don\u2019t have front USB ports or a CD drive. Looking at the BIOS tells you \nwhether those devices are not available simply because they have been disabled in \nthe BIOS.\nTo change a device setting Sometimes, the default settings that come in your BIOS \ndon\u2019t work for your situation. You might want to change the following settings \nin the BIOS:\nNIC PXE boot settings Most modern NICs are capable of booting from servers \nfound on the network. If you need to do that, and you find that the NIC doesn\u2019t \ncome up as a bootable device on your Boot Order screen, you may have to enable \nthat feature in the BIOS.\nVirtualization settings  If you want to run a Linux system as a virtual host, the \ncomputer\u2019s CPU must include Intel Virtual Technology or AMD Secure Virtual \nMachine (SVM) support. It is possible, however, that even if your CPU comes \nwith this support, it may not be enabled in the BIOS. To enable it, go to the BIOS \nSetup screen and look for a Virtualization selection (possibly under the Perfor -\nmance category). Make sure that it is set to On.\nTroubleshooting boot order\nDepending on the hardware attached to your computer, a typical boot order might boot a \nCD/DVD drive first, then the hard drive, then a USB device, and finally the network inter -\nface card. The BIOS would go to each device, looking for a boot loader in the device\u2019s master \nboot record. If the BIOS finds a boot loader, it starts it. If no boot loader is located, the BIOS \nmoves on to the next device until all are tried. If no boot loader is found, the computer \nfails to boot.", "doc_id": "fb79c043-e399-4c8a-890e-2805cb99283f", "embedding": null, "doc_hash": "20dd929aa4f1be3eddc0e62da5731e9f843396daf133a92ebfd95b3036f2aaaa", "extra_info": {"page_label": "551"}, "node_info": {"start": 0, "end": 3035}, "relationships": {"1": "2493c2df-f507-4f46-b70a-54c5d755c6fa"}}, "__type__": "1"}, "6c47e8d0-e22e-4ca7-aa77-33d53d85a4ab": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator528One problem that could occur with the boot order is that the device you want to boot may \nnot appear in the boot order at all. In that case, going to the Setup screen, as described in \nthe previous section, either to enable the device or change a setting to make it bootable, \nmay be the thing to do.\nIf the device from which you want to boot does appear in the boot order, typically you just \nhave to move the arrow key to highlight the device you want and press Enter. The following \nare reasons for selecting your own device to boot:\nRescue mode  If Linux does not boot from the hard disk, selecting the CD drive or a \nUSB drive allows you to boot to a rescue mode (described later in this chapter) that \ncan help you repair the hard disk on an unbootable system. See the section \u201cTrou -\nbleshooting in Rescue Mode\u201d later in this chapter for further information.\nFresh install Sometimes, the boot order has the hard disk listed first. If you decide \nthat you need to do a fresh install of the operating system, you need to select the \nboot device that is holding your installation medium (CD, DVD, USB drive, or NIC).\nAssuming that you get past any problems you have with the BIOS, the next step is for the \nBIOS to start the boot loader.\nTroubleshooting the GRUB boot loader\nTypically, the BIOS finds the master boot record on the first hard disk and begins loading \nthat boot loader in stages. Chapter\u00a09, \u201cInstalling Linux,\u201d describes the GRUB boot loader \nthat is used with most modern Linux systems, including RHEL, Fedora, and Ubuntu. The \nGRUB boot loader in RHEL 6, described here, is an earlier version than the GRUB 2 boot \nloader included with RHEL 7 and later, Fedora and Ubuntu. (Later in this chapter, I intro -\nduce you to the GRUB 2 boot loader as well.)\nIn this discussion, I am interested in the boot loader from the perspective of what to do  \nif the boot loader fails or what ways you might want to interrupt the boot loader to change \nthe behavior of the boot process.\nThe GRUB Legacy boot loader\nHere are a few ways in which the boot loader might fail in RHEL 6 and some ways that you \ncan overcome those failures:\nCould not locate active partition When a boot loader is installed on a storage \nmedium, the partition is usually marked as bootable. If you see this message, it \nmeans that no bootable partition was found. If you feel sure that the boot loader is \non the disk, try using the fdisk  command (probably from rescue media) to make \nthe partition bootable and try again. See the section \u201cPartitioning Hard Disks\u201d \nof Chapter\u00a012, \u201cManaging Disks and Filesystems,\u201d for more information on the \nfdisk  command.\nSelected boot device not available You might see a message like this when the \nmaster boot record has been deleted from the hard drive, or it may just be that ", "doc_id": "6c47e8d0-e22e-4ca7-aa77-33d53d85a4ab", "embedding": null, "doc_hash": "f8e63bf519f95052be8df78c62d7a2541f27f9dff7a5f2aab801453c0f0a5941", "extra_info": {"page_label": "552"}, "node_info": {"start": 0, "end": 2850}, "relationships": {"1": "854f53d1-c4ac-41b9-941f-180ae8043834"}}, "__type__": "1"}, "42780557-7e7a-4ee3-bd26-8fd7b118bcae": {"__data__": {"text": "Chapter 21: Troubleshooting Linux\n529\n21the contents of the hard disk expect to be loaded from another boot loader, such \nas a boot CD. First, try seeing if the system will boot from other media. If it turns \nout that the master boot record was erased, you can try booting rescue media to \nattempt to recover the contents of the disk. However, if the master boot record \nis lost, it is possible that other data on the disk either is also erased or would \nrequire disk forensics to find it. If the master boot record was simply overwritten \n(which could happen if you installed another operating system on a different \ndisk partition), it may be possible to reinstall the master boot record from res -\ncue mode (described in the section \u201cTroubleshooting in Rescue Mode\u201d later in \nthis chapter).\nText-based GRUB prompt appears It is possible for the BIOS to start GRUB and go \nstraight to a GRUB prompt with no operating system selections available. This prob-\nably means that the master boot record portion of GRUB was found, but when GRUB \nlooked on the hard drive to find the next stage of the boot process and a menu of \noperating systems to load, it could not find them. Sometimes this happens when the \nBIOS detects the disks in the wrong order and looks for the grub.conf file on the \nwrong partition.\nOne workaround to this problem, assuming that grub.conf  is on the first partition \nof the first disk, is to list the contents of this file and enter the root , kernel , and \ninitrd  lines manually. To list the file, enter cat (hd0,0)/grub/grub.conf . \nIf that doesn\u2019t work, try hd0,1  to access the next partition on that disk (and so \non) or hd1,0  to try the first partition of the next disk (and so on). When you find \nthe lines representing the grub.conf  file, manually type the root , kernel , and \ninitrd  lines for the entry that you want (replacing the location of the hard drive \nyou found on the root line), and then type boot . The system should start up,  \nand you can manually fix your boot loader files. See Chapter\u00a09 for more information \non the GRUB boot loader.\nIf the BIOS finds the boot loader in the master boot record of the disk and that boot loader \nfinds the GRUB configuration files on the disk, the boot loader starts a countdown of a few \nseconds, as determined by the timeout  value in /boot/grub/grub.conf  (it\u2019s 5 seconds \nin RHEL 6). During that countdown, you can interrupt the boot loader (before it boots the \ndefault operating system) by pressing any key.\nWhen you interrupt the boot loader, you should see a menu of available entries to boot. \nThose entries can represent different available kernels to boot. However, they may also rep -\nresent totally different operating systems (such as Windows, BSD, or Ubuntu).\nHere are some reasons to interrupt the boot process from the boot menu to trouble -\nshoot Linux:\nTo start in a different runlevel RHEL 6 systems typically start in runlevel 3 (boot \nto text prompt) or 5 (boot to graphical interface). You can override the default \nrunlevel by highlighting the kernel line from the boot menu and putting a different \nrunlevel number at the end. To do this, highlight the operating system entry you want, ", "doc_id": "42780557-7e7a-4ee3-bd26-8fd7b118bcae", "embedding": null, "doc_hash": "c2861b98853c38e42204317955d12b2dcbe089dfecfa8d400822b5ed5a104c25", "extra_info": {"page_label": "553"}, "node_info": {"start": 0, "end": 3197}, "relationships": {"1": "fcd17d77-40cb-4645-9d43-4918cb849541"}}, "__type__": "1"}, "01a8024a-8e6d-45c7-a7c4-d25dda5fe63c": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator530type e, highlight the kernel, type e , and add the new runlevel to the end of the line  \n(for example, add a space and the number 1  to go into single-user mode). Then \npress Enter, and type b  to boot the new entry.\nWhy would you boot to different runlevels for troubleshooting? Runlevel 1 bypasses \nauthentication, so you boot directly to a root prompt. This is good if you have \nforgotten the root password and need to change it (type passwd  to do that). Run -\nlevel 3 bypasses the start of your desktop interface. Go to runlevel 3 if you are hav -\ning problems with your video driver and want to try to debug it without it trying to \nstart up the graphical interface automatically.\nTo select a different kernel When RHEL installs a new kernel, it always keeps at \nleast one older kernel around. If the new kernel fails, you can always boot the \nprevious, presumably working, older kernel. To boot a different kernel from the \nGRUB menu, just use the arrow key to highlight the one you want, and press Enter \nto boot it.\nTo select a different operating system If you happen to have another operating \nsystem installed on your hard drive, you can select to boot that one instead of \nRHEL. For example, if you have Fedora and RHEL on the same computer, and RHEL \nisn\u2019t working, you can boot to Fedora, mount the RHEL filesystems that you need, \nand try to fix the problem.\nTo change boot options On the kernel line, notice that there are lots of options \nbeing passed to the kernel. At the very least, those options must contain the name \nof the kernel (such as vmlinuz-2.6.32.el6.x86_64 ) and the partition containing \nthe root filesystem (such as /dev/mapper/abc-root ). If you want, you can add \nother options to the kernel line.\nYou may want to add kernel options to add features to the kernel or temporarily \ndisable hardware support for a particular component. For example, adding init=/\nbin/bash  causes the system to bypass the init  process and go straight to a shell \n(similar to running init 1 ). In RHEL 7, adding 1 as a kernel option is not sup -\nported, so init=/bin/bash  is the best way to get into a sort of single-user mode. \nAdding nousb  would temporarily disable the USB ports (presumably to make sure \nthat anything connected to those ports would be disabled as well).\nAssuming that you have selected the kernel you want, the boot loader tries to run the \nkernel, including the content of the initial RAM disk (which contains drivers and other \nsoftware needed to boot your particular hardware).\nGRUB 2 Boot loader\nTechniques for troubleshooting Linux from the GRUB 2 boot prompt are similar to those \nin the legacy GRUB boot prompt. Follow these instructions for interrupting the GRUB boot \nprompt for the most recent Fedora, RHEL, and Ubuntu systems:\n1. After you turn on your computer and just after you see the BIOS screen, press any \nkey (such as the up arrow). You should see several menu items representing differ -\nent kernels to boot.", "doc_id": "01a8024a-8e6d-45c7-a7c4-d25dda5fe63c", "embedding": null, "doc_hash": "75ced02d2e8818030b52b39c20451fb014aad8515faa36e621c3d5c4c3adb410", "extra_info": {"page_label": "554"}, "node_info": {"start": 0, "end": 3016}, "relationships": {"1": "84c577c0-2e54-4a12-85de-209d926e6f95"}}, "__type__": "1"}, "80957618-a76d-4a4b-b7e3-d9eef427a02a": {"__data__": {"text": "Chapter 21: Troubleshooting Linux\n531\n212. From the available entries, the default is to boot the latest available kernel, which \nshould be highlighted and ready to boot. However, you can choose a different entry \nif any of the following applies:\n\u25a0\u25a0The current kernel is broken, and you want to choose an older kernel that you \nknow is working.\n\u25a0\u25a0You want to run an entry that represents a totally different operating system \nthat is installed on your disk.\n\u25a0\u25a0You want to run a rescue kernel.\n3. Assuming you want to run a Linux kernel, highlight the kernel you want (using \nup and down arrows) and type e . You will see commands that are run to start the \nsystem, as shown in Figure\u00a021.1.\n4. To add arguments to the kernel, move your cursor to the end of the line beginning \nwith \"linux\" and type the arguments you want. See https://www.kernel.org/\ndoc/Documentation/admin-guide/kernel-parameters.txt  for a list of \nkernel parameters. Here are two examples:\n\u25a0\u25a0selinux : If there is a problem with SELinux that makes your system unusable, \nyou can disable it as follows:\nselinux=0\n\u25a0\u25a0smt: Simultaneous Multithreading (smt) allows a single CPU core to execute mul -\ntiple threads. To fix some microprocessor flaws, you need to turn off that fea -\nture. You can do that at boot time by passing the smt=1  or nosmt  argument on \nthe kernel command line.\n5. Once you are done adding arguments, press Ctrl-x to boot the system with the \nkernel arguments you added.\nFIGURE 21.1\nInterrupt the GRUB bootloader to modify the boot process.", "doc_id": "80957618-a76d-4a4b-b7e3-d9eef427a02a", "embedding": null, "doc_hash": "6f94401cff2cf173cb1e73e884b3c2b5d94e16f64b4afa9b136ef402f685fa97", "extra_info": {"page_label": "555"}, "node_info": {"start": 0, "end": 1529}, "relationships": {"1": "de347875-96f0-4c32-b409-fffccc8030be"}}, "__type__": "1"}, "880d7c98-e9d4-494f-a5b9-3c83478a397f": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator532Starting the kernel\nAfter the kernel starts, there isn\u2019t much to do except to watch out for potential problems. \nFor RHEL, you see a Red Hat Enterprise Linux screen with a slow-spinning icon. If you want \nto watch messages detailing the boot process scroll by, press the Esc key.\nAt this point, the kernel tries to load the drivers and modules needed to use the hard -\nware on the computer. The main things to look for at this point (although they may scroll \nby quickly) are hardware failures that may prevent some feature from working properly. \nAlthough much rarer than it used to be, there may be no driver available for a piece of \nhardware, or the wrong driver may get loaded and cause errors.\nIn addition to scrolling past on the screen, messages produced when the kernel boots are \ncopied to the kernel ring buffer . As its name implies, the kernel ring buffer stores kernel \nmessages in a buffer, throwing out older messages after that buffer is full. After the com-\nputer boots up completely, you can log into the system and enter the following command to \ncapture these kernel messages in a file (then view them with the less  command):\n# dmesg > /tmp/kernel_msg.txt\n# less /tmp/kernel_msg.txt\nI like to direct the kernel messages into a file (choose any name you like) so that the mes -\nsages can be examined later or sent to someone who can help debug any problems. The mes -\nsages appear as components are detected, such as your CPU, memory, network cards, hard \ndrives, and so on.\nIn Linux systems that support systemd , kernel messages are stored in the systemd  \njournal. So, besides the dmesg  command, you can also run journalctl  to see kernel \nmessages from boot time to the present. For example, here are kernel messages output from \na RHEL 7 system:\n# journalctl -k\n-- Logs begin at Sat 2019-11-23 10:36:31 EST,\n      end at Sun 2019-12-08 08:09:42 EST. --\nNov 23 10:36:31 rhel81 kernel: Linux version 4.18.0-147.0.3.el8_1.x86_64\n    (mockbuild@x86-vm-09.build.eng.bos.redhat.com)\n       (gcc version 8.3.1 20190507 (Red Hat 8.3.1-4)\n          (GCC)) #1 SMP Mon Nov 11 12:58:36 UTC 2019\nNov 23 10:36:31 rhel81 kernel: Command line:\n  BOOT_IMAGE=(hd0,msdos1)/vmlinuz-4.18.0-147.0.3.el8_1.x86_64\n    root=/dev/mapper/rhel-root ro resume=/dev/mapper/rhel-swap\n       rd.lvm.lv=rhel/root rd.lvm.lv=rhel/swap rhgb quiet\n...\nNov 23 10:36:31 rhel81 kernel: Hypervisor detected: KVM\nNov 23 10:36:31 rhel81 kernel: kvm-clock: Using msrs 4b564d01 ...\nWhat you want to look for are drivers that fail to load or messages that show certain features \nof the hardware failing to be enabled. For example, I once had a TV tuner card (for watch -\ning television on my computer screen) that set the wrong tuner type for the card that was \ndetected. Using information about the TV card\u2019s model number and the type of failure, I found ", "doc_id": "880d7c98-e9d4-494f-a5b9-3c83478a397f", "embedding": null, "doc_hash": "c75e54195c5a37a1fc66e2507abe13b21fa00cd77a0b00dbdcf9e31f4d06c7c6", "extra_info": {"page_label": "556"}, "node_info": {"start": 0, "end": 2886}, "relationships": {"1": "3c13166c-38bb-498c-b53a-f1c8810f8af0"}}, "__type__": "1"}, "bc967d8d-72a9-424d-ac46-97a7bf856925": {"__data__": {"text": "Chapter 21: Troubleshooting Linux\n533\n21that passing an option to the card\u2019s driver allowed me to try different settings until I found \nthe one that matched my tuner card.\nIn describing how to view kernel startup messages, I have gotten ahead of myself a bit. \nBefore you can log in and see the kernel messages, the kernel needs to finish bringing up \nthe system. As soon as the kernel is done initially detecting hardware and loading drivers, \nit passes off control of everything else that needs to be done to boot the system to the ini-\ntialization system.\nTroubleshooting the initialization system\nThe first process to run on a system where the kernel has just started depends on the ini-\ntialization facility that system is using. For System V init , the first process to run is the \ninit  process. For systemd , the first process is systemd . Depending on which you see \nrunning on your system (type ps -ef | head to check), follow either the System V or \nsystemd  descriptions below. RHEL 6, which contains a hybrid of Upstart and System V \ninit , is used in the example of System V initialization.\nTroubleshooting System V initialization\nUp to a few years ago, most Linux systems used System V init  to initialize the services on \nthe Linux system. In RHEL 6, when the kernel hands off control of the boot process to the \ninit  process, the init  process checks the /etc/inittab  file for directions on how to \nboot the system.\nThe inittab  file tells the init  process what the default runlevel is and then points to \nfiles in the /etc/init  directory to do things such as remap some keystrokes (such as \nCtrl+Alt+Delete to reboot the system), start virtual consoles, and identify the location of \nthe script for initializing basic services on the system: /etc/rc.sysinit .\nWhen you\u2019re troubleshooting Linux problems that occur after the init  process takes over, \ntwo likely culprits are the processing by the rc.sysinit  file and the runlevel scripts.\nTroubleshooting rc.sysinit\nAs the name implies, the /etc/rc.sysinit  script initializes many basic features on the \nsystem. When that file is run by init , rc.sysinit  sets the system\u2019s hostname, sets up \nthe /proc  and /sys  filesystems, sets up SELinux, sets kernel parameters, and performs \ndozens of other actions.\nOne of the most critical functions of rc.sysinit  is to get the storage set up on the \nsystem. In fact, if the boot process fails during processing of rc.sysinit , in all likelihood \nthe script was unable to find, mount, or decrypt the local or remote storage devices needed \nfor the system to run.\nThe following is a list of some common failures that can occur from tasks run from the rc.\nsysinit  file and ways of dealing with those failures.", "doc_id": "bc967d8d-72a9-424d-ac46-97a7bf856925", "embedding": null, "doc_hash": "6476203209ebe273d73ab97968cbe61cb5ebd4f1b6a69e0417a1210711a2b1ef", "extra_info": {"page_label": "557"}, "node_info": {"start": 0, "end": 2725}, "relationships": {"1": "2482d4f9-8ad6-472d-a213-8d68a89f885d"}}, "__type__": "1"}, "fd038975-d881-47b5-952e-f18bfa904934": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator534Local mounts fail : If an entry in the /etc/fstab  fails to mount, the boot process \nends before runlevel services start. This typically happens when you add an entry \nto the /etc/fstab  that has a mistake in it but you neglected to test it before \nyou rebooted. When the fstab  file fails, you are dropped to a shell for the root \nuser with the root filesystem mounted read-only. To fix the problem, you need to \nremount the root filesystem, correct the fstab  file, mount the filesystem entry to \nmake sure that it now works, and reboot. Here\u2019s what that sequence of commands \nlooks like:\n        # mount -o remount,rw /\n        # vim /etc/fstab\n        # mount -a\n        # reboot\nHostname not set If your hostname is not set properly, you can check through the \nprocessing of rc.sysinit  to see what might have gone wrong. To set the system\u2019s \nhostname, rc.sysinit  uses the value of the HOSTNAME=  in the /etc/syscon -\nfig/network  file. If that is not set, the name localhost  is used instead. The \nhostname value can also be acquired from the DHCP server.\nCannot decrypt filesystem  The rc.sysinit  script looks in the /etc/crypttab  file \nfor information needed to decrypt encrypted filesystems. If that file becomes cor -\nrupted, you may need to find a backup of the file to be able to decrypt your filesystem. \nIf you are prompted for a password and you don\u2019t know what that is, you might be \nout of luck.\nOther features are set up by the rc.sysinit  file as well. The rc.sysinit  script sets the \nSELinux mode and loads hardware modules. The script constructs software RAID arrays and \nsets up Logical Volume Management volume groups and volumes. Troubles occurring in any \nof these areas are reflected in error messages that appear on the screen after the kernel \nboots and before runlevel processes start up.\nTroubleshooting runlevel processes\nIn Red Hat Enterprise Linux 6. x and earlier, when the system first comes up, services are \nstarted based on the default runlevel. There are seven different runlevels, from 0 to 6. The \ndefault runlevel is typically 3 (for a server) or 5 (for a desktop). Here are descriptions of the \nrunlevels in Linux systems up to RHEL 6:\n0: Shutdown runlevel . All processes are stopped, and the computer is powered down.\n1: Single-user runlevel . Only those processes that are needed to boot the computer \n(including mounting all filesystems) and have the system available from the console Note\nThe vim  command is used particularly when editing the /etc/fstab  file because it knows the format of that \nfile. When you use vim , the columns are in color and some error checking is done. For example, entries in the \nMount Options field turn green when they are valid and black when they are not.", "doc_id": "fd038975-d881-47b5-952e-f18bfa904934", "embedding": null, "doc_hash": "75e103a545ec637fb2fd80518b896a9d0449d9d8e0cfc4371b1a6f28cd4d2838", "extra_info": {"page_label": "558"}, "node_info": {"start": 0, "end": 2790}, "relationships": {"1": "89eb3d87-ac56-431b-b75f-9aeca027d6ae"}}, "__type__": "1"}, "f3433c19-3cfa-4568-aac5-2d33dd962551": {"__data__": {"text": "Chapter 21: Troubleshooting Linux\n535\n21are run. Networking and network services are not started. This runlevel bypasses \nnormal authentication and boots up to a root user prompt (called sulogin ). If you \nboot up to this mode, you can use it to become root user immediately in order to \nchange a forgotten root password. (You could also use the word single  instead of \n1 to get to single-user runlevel. The difference between single  and 1 is that sin -\ngle does not start scripts in the /etc/rc1.d  directory.)\n2: Multiuser runlevel . This runlevel is rarely used today. The original meaning of this \nrunlevel has been lost. Early UNIX systems used this runlevel to start tty  processes \nfor systems where there were multiple dumb terminals connected to the system for \npeople to use. This allowed many people to access a system simultaneously from \ncharacter-based terminals (lots of people working from a shell with no graphical \ninterface). Network interfaces were not started, usually because always-up network \ninterfaces were not common. These days, runlevel 2 usually starts network inter -\nfaces, although not all network services are started.\n3: Multiuser plus networking runlevel . This runlevel is typically used on Linux \nservers that do not boot up to a graphical interface but rather just a plain text \nprompt at the console. The network is started, as are all network services. A \ngraphical desktop environment may or may not be installed (typically not) on \nmachines that boot to runlevel 3, but the graphical environments must be started \nafter boot time to be used.\n4: Undefined . This runlevel tends to start the same services as runlevel 3. It can be \nused if you want to have different services available from runlevel 3 and runlevel \n4. This runlevel is typically not used. Instead, runlevel 3 or runlevel 5 is used to \nboot to, with an administrator simply turning services on or off as required for the \nrunning system.\n5: Multiuser, networking, plus graphical interface runlevel . This is the runlevel \ngenerally used with desktop Linux systems. It generally starts networking and all \nnetworked services; plus, it launches a graphical login prompt at the console. When \nthe users log in, they see a graphical desktop environment.\n6: Reboot runlevel . This is like runlevel 0 in that it brings down all services and stops \nall processes. However, runlevel 6 then starts the system back up again.\nRunlevels are meant to set the level of activity on a Linux system. A default runlevel is set \nin the /etc/inittab  file, but you can change the runlevel anytime you like using the \ninit  command. For example, as root, you might type init 0  to shut down, init 3  if \nyou want to kill the graphical interface (from runlevel 5) but leave all other services up, or \ninit 6  to reboot.\nNormal default runlevels (in other words, the runlevel to which you boot) are 3 (for a \nserver) and 5 (for a desktop). Often, servers don\u2019t have desktops installed, so they boot to \nrunlevel 3 so that they don\u2019t incur the processing overhead or the added security risks for \nhaving a desktop running on their web servers or file servers.\nYou can go either up or down with runlevels. For example, an administrator doing main -\ntenance on a system may boot to runlevel 1 and then type init 3  to boot up to the full ", "doc_id": "f3433c19-3cfa-4568-aac5-2d33dd962551", "embedding": null, "doc_hash": "86d8ae920da2701a69849759e452172ae296c7432bdefd1f4227a7f08aee35d2", "extra_info": {"page_label": "559"}, "node_info": {"start": 0, "end": 3321}, "relationships": {"1": "637b611b-b03f-4f80-9391-ec00994a37b8"}}, "__type__": "1"}, "2c6583ac-fad2-446a-9a01-d970ab7b35f3": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator536services needed on a server. Someone debugging a desktop may boot to runlevel 5 and then \ngo down to runlevel 3 to try to fix the desktop (such as installing a new driver or changing \nthe screen resolution) before typing init 5  to return to the desktop.\nThe level of services at each runlevel is determined by the runlevel scripts that are  \nset to start. There are rc  directories for each runlevel: /etc/rc0.d/ , /etc/rc1.d/ ,  \n/etc/rc2.d/ , /etc/rc3.d/ , and so on. When an application has a startup script associ-\nated with it, that script is placed in the /etc/init.d/  directory and then symbolically \nlinked to a file in each /etc/rc?.d/  directory.\nScripts linked to each /etc/rc?.d  directory begin with either the letter K or S , followed \nby two numbers and the service name. A script beginning with K indicates that the service \nshould be stopped, while one beginning with an S indicates that it should be started. The \ntwo numbers that follow indicate the order in which the service is started. Here are a few \nfiles that you might find in the /etc/rc3.d/  directory, which are set to start up (with a \ndescription of each to the right):\nS01sysstat : Start gathering system statistics.\nS08iptables : Start iptables  firewall.\nS10network : Start network interfaces.\nS12rsyslog : Start system logging.\nS28autofs : Start automounter.\nS50bluetooth : Start Bluetooth service.\nS55sshd : Start the secure shell service.\nS58ntpd : Start NTP time synchronization service.\nS85httpd : Start the Apache web service.\nS90crond : Start the crond  service.\nS91smb : Start the Samba service.\nS97rhnsd : Start the Red Hat Network service.\nS99local : Start user-defined local commands.\nThis example of a few services started from the /etc/rc3.d  directory should give you a \nsense of the order in which processes boot up when you enter runlevel 3. Notice that the \nsysstat  service (which gathers system statistics) and the iptables  service (which cre -\nates the system\u2019s firewall) are both started before the networking interfaces are started. \nThose are followed by rsyslog  (system logging service) and then the various net -\nworked services.\nBy the time the runlevel scripts start, you should already have a system that is basically \nup and running. Unlike some other Linux systems that start all of the scripts for runlevel \n1, then 2, then 3, and so on, RHEL goes right to the directory that represents the runlevel, \nfirst stopping all services that begin with K and starting all those that begin with S in that \ndirectory.", "doc_id": "2c6583ac-fad2-446a-9a01-d970ab7b35f3", "embedding": null, "doc_hash": "f3b58af822369cc442142cf27b91aeede9181d9959054b92dddd87539e3863b3", "extra_info": {"page_label": "560"}, "node_info": {"start": 0, "end": 2576}, "relationships": {"1": "1d455d44-1b34-4212-ac12-58a445925308"}}, "__type__": "1"}, "9aaf6dec-7310-4665-aaa4-6f03c204dedf": {"__data__": {"text": "Chapter 21: Troubleshooting Linux\n537\n21As each S script runs, you should see a message saying whether the service started. Here \nare some things that might go wrong during this phase of system startup:\nA service can fail. A service may require access to network interfaces to start prop -\nerly or access to a disk partition that is not mounted. Most services time out, fail, \nand allow the next script to run. After you are able to log in, you can debug the \nservice. Some techniques for debugging services include adding a debug option to \nthe daemon process so that it spews more data into a log file or running the daemon \nprocess manually so that error messages come straight to your screen. See Chap -\nter\u00a015, \u201cStarting and Stopping Services,\u201d for further information on starting ser -\nvices manually.\nA service can hang. Some services that don\u2019t get what they need to start can hang \nindefinitely, keeping you from logging in to debug the problem. Some processes take \nlonger to come up the first time after a fresh install, so you might want to wait for a \nfew minutes to see if the script is still working and not just spinning forever.\nIf you cannot get past a hanging service, you can reboot into an interactive startup mode , \nwhere you are prompted before starting each service. To enter interactive startup mode \nin RHEL, reboot and interrupt the boot loader (press any key when you see the 5 second \ncountdown). Highlight the entry you want to boot, and type e . Highlight the kernel line, \nand type e . Then add the word confirm  to the end of the kernel line, press Enter, and \ntype b to boot the new kernel.\nFigure\u00a021.2 shows an example of the messages that appear when RHEL boots up in interac -\ntive startup mode.\nnetwork-pre.target\nNetworkManager .service (859ms)\nnetwork.target \ncups.ser vice (1.493s)\nrhsmcertd.ser vice (1.092s)\nsshd.ser vice (946ms)\niscsi-shutdown.ser vice\nremote-fs-pre.target\nremote-fs.target\nhttpd.ser vice (4.456s)\ntuned.ser vice (20.089s)\nNetworkManager -wait-online.ser vice (20.539s)\ngdm.ser vice (1.155s)\natd.ser vice systemd-user -sessions.ser vice (1.239s) \nplymouth-quit-wait.ser vice (1min 4.217s) \ncrond.ser vice \nlibvirtd.ser vice (4.219s) FIGURE 21.2\nConfirm each service in RHEL interactive startup mode.", "doc_id": "9aaf6dec-7310-4665-aaa4-6f03c204dedf", "embedding": null, "doc_hash": "33e0cc46d116dfe00bd41da779286cba2ed14ddcb69014e2737eb4bfea937074", "extra_info": {"page_label": "561"}, "node_info": {"start": 0, "end": 2261}, "relationships": {"1": "dd07c690-c09e-49f5-ad46-edd2e4cd2943"}}, "__type__": "1"}, "f9e3a8a5-305d-42ac-aac7-30356e286636": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator538Most messages shown in Figure\u00a021.2 are generated from rc.sysinit .\nAfter the Welcome message, udev  starts (to watch for new hardware that is attached to \nthe system and load drivers as needed). The hostname is set, Logical Volume Management \n(LVM) volumes are activated, all filesystems are checked (with the added LVM volumes), any \nfilesystems not yet mounted are mounted, the root filesystem is remounted read-write, and \nany LVM swaps are enabled. Refer to Chapter\u00a012, \u201cManaging Disks and Filesystems,\u201d for fur -\nther information on LVM and other partition and filesystem types.\nThe last \u201cEntering interactive startup\u201d message tells you that rc.sysinit  is finished and \nthe services for the selected runlevel are ready to start. Because the system is in interac -\ntive mode, a message appears asking if you want to start the first service ( sysstat ). Type \nY to start that service and go to the next one. After you see the broken service requesting \nto start, type N to keep that service from starting. If at some point you feel that the rest \nof the services are safe to start, type C to continue starting the rest of the services. After \nyour system comes up with the broken services not started, you can go back and try to \ndebug those individual services.\nOne last comment about startup scripts: The /etc/rc.local  file is one of the last ser -\nvices to run at each runlevel. In runlevel 5, it is linked to /etc/rc5.d/S99local . Any \ncommand that you want to run every time your system starts up can be put in the  \nrc.local  file.\nYou might use rc.local  to send an email message or run a quick iptables firewall rule \nwhen the system starts. In general, it\u2019s better to use an existing startup script or create a \nnew one yourself (so you can manage the command or commands as a service). Know that \nthe rc.local  file is a quick and easy way to get some commands to run each time the \nsystem boots.\nTroubleshooting systemd initialization\nThe latest versions of Fedora, RHEL, and Ubuntu use systemd  instead of System V init as \ntheir initialization system. Although systemd  is more complex than System V init, sys -\ntemd  also offers more ways to analyze what is happening during initialization.\nUnderstanding the systemd boot process\nWhen the systemd  daemon (/usr/lib/systemd/systemd ) is started after the kernel \nstarts up, it sets in motion all of the other services that are set to start up. In particular, \nit keys off of the contents of the /etc/systemd/system/default.target  file, as in \nthis example:\n# cat /etc/systemd/system/default.target\n...\n[Unit]\nDescription=Graphical Interface\nDocumentation=man:systemd.special(7)\nRequires=multi-user.target\nWants=display-manager.service", "doc_id": "f9e3a8a5-305d-42ac-aac7-30356e286636", "embedding": null, "doc_hash": "a809613e01b8fad3ccf785ba8938fa1347d0801ca1bb85ab1502fe11458dbe3a", "extra_info": {"page_label": "562"}, "node_info": {"start": 0, "end": 2752}, "relationships": {"1": "0911ce70-34eb-407c-aa4f-b186e41d3f5b"}}, "__type__": "1"}, "3d4a3e8b-4492-469a-990d-261b7651690b": {"__data__": {"text": "Chapter 21: Troubleshooting Linux\n539\n21Conflicts=rescue.service rescue.target\nAfter=multi-user.target rescue.service rescue.target display-manager.service\nAllowIsolate=yes\nThe default.target  file is actually a symbolic link to a file in the /lib/systemd/\nsystem  directory. For a server, it may be linked to the multi-user.target  file; for a \ndesktop, it is linked to the graphical.target  file (as is shown here).\nUnlike with the System V init  facility, which just runs service scripts in alphanumeric \norder, the systemd  service needs to work backward from the default.target  to deter -\nmine which services and other targets are run. In this example, default.target  is a \nsymbolic link to the graphical.target  file. When you list the contents of that file, you \ncan see the following:\n\u25a0\u25a0The multi-user.target  is required to start first.\n\u25a0\u25a0The display-manager.service  is started after that.\nBy continuing to discover what those two units require, you can find what else is required. \nFor example, multi-user.target  requires the basic.target  (which starts a variety of \nbasic services) and display-manager.service  (which starts up the display manager, \ngdm) to launch a graphical login screen.\nTo see services the multi-user.target  starts, list contents of the /etc/systemd/\nsystem/multi-user.target.wants  directory, as in this example:\n# ls /etc/systemd/system/multi-user.target.wants/\natd.service           ksm.service             rhsmcertd.service\nauditd.service        ksmtuned.service        rpcbind.service\navahi-daemon.service  libstoragemgmt.service  rsyslog.service\nchronyd.service       libvirtd.service        smartd.service\ncrond.service         mcelog.service          sshd.service\ncups.path             mdmonitor.service       sssd.service\ndnf-makecache.timer   ModemManager.service    tuned.service\nfirewalld.service     NetworkManager.service  vdo.service\nirqbalance.service    nfs-client.target       vmtoolsd.service\nkdump.service         remote-fs.target\nThese files are symbolic links to files that define what starts for each of those services. On \nyour system, these may include remote shell ( sshd ), printing ( cups ), auditing ( auditd ), \nnetworking ( NetworkManager ), and others. Those links were added to that directory \neither when the package for a service was installed or when the service was enabled from a \nsystemctl enable  command.\nKeep in mind that, unlike System V init , systemd  can start, stop, and otherwise manage \nunit files that represent more than just services. It can manage devices, automounts, paths, \nsockets, and other things. After systemd  has started everything, you can log into the \nsystem to investigate and troubleshoot any potential problems.", "doc_id": "3d4a3e8b-4492-469a-990d-261b7651690b", "embedding": null, "doc_hash": "48d30fdf568a60f5f829991a67f893f52bc20a465398d817f17523ccc79cbd61", "extra_info": {"page_label": "563"}, "node_info": {"start": 0, "end": 2718}, "relationships": {"1": "e027dbc5-ed3b-470f-aefe-f6a918faf2b4"}}, "__type__": "1"}, "eb77ae05-3d59-40f7-9040-722e6d740909": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator540After you log in, running the systemctl  command lets you see every unit file that sys -\ntemd  tried to start up. Here is an example:\n# systemctl\nUNIT                                         LOAD   ACTIVE SUB\n      DESCRIPTION\nproc-sys-fs-binfmt_misc.automount            loaded active waiting\n      Arbitrary Executable File Formats File System\nsys-devices-pc...:00:1b.0-sound-card0.device loaded active plugged\n      631xESB/632xESB High Definition Audio Control\nsys-devices-pc...:00:1d.2-usb4-4\\x2d2.device loaded active plugged\n      DeskJet 5550\n...\n \n-.mount                                      loaded active mounted   Root Mount\nboot.mount                                   loaded active mounted   /boot\n...\nautofs.service                               loaded active running\n      Automounts filesystems on demand\ncups.service                                 loaded active running\n      CUPS Scheduler\nhttpd.service                                loaded failed failed\n      The Apache HTTP Server\nFrom the systemctl  output, you can see whether any unit file failed. In this case, you can \nsee that the httpd.service  (your web server) failed to start. To investigate further, you \ncan run journalctl -u  for that service to see whether any error messages were reported:\n# journalctl -u httpd.service\n...\nDec 08 09:30:36 rhel81-bible systemd[1]: Starting The Apache HTTP \nServer...\nDec 08 09:30:36 rhel81-bible httpd[16208]: httpd: Syntax error\n   on line 105 of /etc/httpd/conf/httpd.conf:\n   /etc/httpd/conf/httpd.conf:105: <Directory> was not closed.\nDec 08 09:30:36 rhel81-bible systemd[1]: httpd.service: Main process exited,\n   code=exited, status=1/FAILURE\nDec 08 09:30:36 rhel81-bible systemd[1]: httpd.service:\n   Failed with result 'exit-code'.\nDec 08 09:30:36 rhel81-bible systemd[1]:\n   Failed to start The Apache HTTP Server.\nFrom the output, you can see that there was a mismatch of the directives in the httpd.\nconf  file (I failed to close a Directory section). After that was corrected, I could start the \nservice (systemctl start httpd ). If more unit files appear as failed, you can run the \njournalctl -u  command again, using those unit filenames as arguments.\nAnalyzing the systemd boot process\nTo see exactly what happened during the boot process for a system using the systemd  \nservice, systemd  provides the systemd-analyze  tool. If you want to see if there ", "doc_id": "eb77ae05-3d59-40f7-9040-722e6d740909", "embedding": null, "doc_hash": "4dc5b0874aa8033ea4d8849cdfc1957f4ec96daef5efe18d41a701e1d390f1ce", "extra_info": {"page_label": "564"}, "node_info": {"start": 0, "end": 2442}, "relationships": {"1": "2160186c-61ff-4912-9b65-251463254afc"}}, "__type__": "1"}, "3c7344ee-13aa-4b65-a9d0-cbcaabb120b5": {"__data__": {"text": "Chapter 21: Troubleshooting Linux\n541\n21are services that are stalling, or you want to look for a place to put in your own sys -\ntemcd  service, you can use this command to analyze the entire startup process. Here are \nsome examples:\n# systemd-analyze time\nStartup finished in 1.775s (kernel) + 21.860s (initrd)\n    + 1min 42.414s (userspace) = 2min 6.051s\ngraphical.target reached after 1min 42.121s in userspace\nThe time  option lets you see how long each phase of the startup process took, from the \nstart of the kernel to the end of the default target. You can use plot  to create an SVG \ngraphic of each component of the startup process (I show eog  here to display the output):\n# systemd-analyze plot > /tmp/systemd-plot.svg\n# eog /tmp/systemd-plot.svg\nFigure\u00a021.3 shows a small snippet of output from the much larger graphic.\nFrom this snippet, you can see services that start after the NetworkManager.service  \nstarts up. Parts in dark red show the time in which the service or target takes to start. If \nthe service continues to run, that is shown in light red. In this example, the httpd.ser -\nvice  failed after trying to start for 4.456 seconds. You can tell this because the bar to the \nright is white, showing that the service is not running. At this point, you could use the \njournalctl  command, as described earlier, to debug the problem.\nThe next section describes how to troubleshoot issues that can arise with your soft -\nware packages.\nFIGURE 21.3\nSnippet from systemd-analyze  startup plot", "doc_id": "3c7344ee-13aa-4b65-a9d0-cbcaabb120b5", "embedding": null, "doc_hash": "6fd097118ea721087224407147e678640f2660b5d906111c9aef296f9d0fe43b", "extra_info": {"page_label": "565"}, "node_info": {"start": 0, "end": 1511}, "relationships": {"1": "8aa6590c-6151-4c7b-907a-8e0373f1f4be"}}, "__type__": "1"}, "c6f43c0f-71bc-4e43-8553-64a56b2ffc74": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator542Troubleshooting Software Packages\nSoftware packaging facilities (such as yum  for RPM and apt-get  for DEB packages) are \ndesigned to make it easier for you to manage your system software. (See Chapter\u00a010, \u201cGet -\nting and Managing Software,\u201d for the basics on how to manage software packages.) Despite \nefforts to make it all work, however, sometimes software packaging can break.\nThe following sections describe some common problems that you can encounter with RPM \npackages on a RHEL or Fedora system and how you can overcome those problems.\nSometimes, when you try to install or upgrade a package using the yum  command, \nerror messages tell you that the dependent packages that you need to do the instal -\nlation you want are not available. This can happen on a small scale (when you try to \ninstall one package) or on a grand scale (where you are trying to update or upgrade your \nentire system).\nBecause of the short release cycles and larger repositories of Fedora and Ubuntu, incon -\nsistencies in package dependencies are more likely to occur than they do in more stable, \nselective repositories (such as those offered by Red Hat Enterprise Linux). To avoid depen -\ndency failures, here are a few good practices that you can follow:\nUse recent, well-tested repositories. There are thousands of software packages in \nFedora. If you use the main Fedora repositories to install software from the current \nrelease, it is rare to have dependency problems.\nWhen packages are added to the repository, as long as the repository maintainers \nrun the right commands to set up the repository (and you don\u2019t use outside repos -\nitories), everything you need to install a selected package should be available. \nHowever, when you start using third-party repositories, those repositories may have \ndependencies on repositories that they can\u2019t control. For example, if a repository \ncreates a new version of its own software that requires later versions of basic soft -\nware (such as libraries), the versions that they need might not be available from the \nFedora repository.\nConsistently update your system.  Running dnf update  every night (or yum \nupdate  on older systems) makes it less likely that you will encounter major depen -\ndency problems than if you update your system only every few months. In systems \nwith a GNOME desktop, the Software window lets you check for and apply updates \nto installed software packages. On Fedora 22 and RHEL 8 (and later) systems, you \ncan add AutoUpdates ( https://fedoraproject.org/wiki/AutoUpdates ). Aut -\noUpdates automatically downloads updated packages when they are available and, Note\nThe dnf  facility has replaced yum  in recent Fedora and RHEL systems. This section often uses the yum  command \nsince it will work on both older and newer Fedora and RHEL systems in most cases, because yum  is aliased to dnf . \nThe dnf  command is shown when it is explicitly required.", "doc_id": "c6f43c0f-71bc-4e43-8553-64a56b2ffc74", "embedding": null, "doc_hash": "3f79eb1128237ff2a4552658e777eac58be5697d26da639db3d0c6146b47f1ef", "extra_info": {"page_label": "566"}, "node_info": {"start": 0, "end": 2965}, "relationships": {"1": "41cc0792-64bf-490d-a157-954263cc541b"}}, "__type__": "1"}, "10907192-7b46-438e-9a2e-cc1a540d78f4": {"__data__": {"text": "Chapter 21: Troubleshooting Linux\n543\n21if configured, can install them as well. Another approach is to build a cron  job to \ncheck for or run nightly updates. See the sidebar \u201cUsing cron  for Software Updates\u201d \nfor details on how to do that.\nOccasionally upgrade your system. Fedora and Ubuntu have new releases every 6 \nmonths. Fedora stops supplying updated packages for each version, 13 months after \nit is released. So, although you don\u2019t have to upgrade to the new release every 6 \nmonths, you should upgrade once a year or face possible dependency and security \nproblems when Fedora stops supplying updates.\nTo get a whole new version of those distributions (such as Fedora 30 to Fedora 31), \ndo the following:\n1. Upgrade to the latest software for your current release:\n        # dnf upgrade --refresh -y\n2. Install the dnf-plugin-system-upgrade plug-in:\n        # dnf install dnf-plugin-system-upgrade -y\n3. Start upgrading to the new release:\n        # dnf system-upgrade download --releasever=31\n4. Reboot to the upgrade process:\n        # dnf system-upgrade reboot\nIf you are looking for a stable system, Red Hat Enterprise Linux is a better bet \nbecause it provides updates for each major release for seven years or more.\nNote\nIf you use the apt-get  command in Ubuntu to update your packages, keep in mind that there are different mean -\nings to the update  and upgrade  options in Ubuntu with apt-get  than with the dnf  or yum  command (Fedora \nand RHEL).\nIn Ubuntu, apt-get update  causes the latest packaging metadata (package names, version numbers, and \nso on) to be downloaded to the local system. Running apt-get upgrade  causes the system to upgrade any \ninstalled packages that have new versions available, based on the latest downloaded metadata.\nIn contrast, every time that you run a dnf  or yum  command in Fedora or RHEL, the latest metadata about new \npackages for the current release is downloaded. When you then run yum update , you get the latest packages \navailable for the current release of Fedora or RHEL. To go to the next release, you must run dnf system-\nupgrade , as described earlier.", "doc_id": "10907192-7b46-438e-9a2e-cc1a540d78f4", "embedding": null, "doc_hash": "699790b126de71c8e5e84cc50d93f616ce8a871a279079567cbccce5eb9ee46f", "extra_info": {"page_label": "567"}, "node_info": {"start": 0, "end": 2126}, "relationships": {"1": "db978b68-622e-4395-9885-0a866cfef8e2"}}, "__type__": "1"}, "7388b28f-2e70-4a83-a4f2-75fe5a5a769d": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator544If you encounter a dependency problem, here are a few things that you can do to try to \nresolve the problem:\nUse stable repositories . For recent releases of well-known distributions (RHEL, Fedora, \nor Ubuntu, for example), dependency problems are rare and often fixed quickly. However, \nif you are relying on repositories for older releases or development-oriented repositories \n(such as Fedora\u2019s Rawhide repository), expect to find more dependency problems. Rein -\nstalling or upgrading can often fix dependency problems.\nOnly use third-party apps and repositories when necessary. The further you are from \nthe core of a Linux distribution, the more likely you are to have dependency problems \nsomeday. Always look in the main repositories for your distribution before you look else -\nwhere for a package or try to build one yourself.\nEven if it works when you first install it, a package someone just handed to you might not \nhave a way to be upgraded. A package from a third-party repository may break if the crea -\ntors don\u2019t provide a new version when dependent packages change.\nSolve kernel-related dependencies.  If you get third-party RPM packages for such \nthings as video cards or wireless network cards that contain kernel drivers and you install \na later kernel, those drivers no longer work. The result might be that the graphical login \nscreen doesn\u2019t start when the system boots or your network card fails to load, so you have \nno wireless networking.\nBecause most Linux systems keep the two most recent kernels, you can reboot, interrupt \nGRUB, and select the previous (still working) kernel from which you can boot. That gets \nyour system up and running, with the old kernel and working drivers, while you look for a \nmore permanent fix.\nThe longer-term solution is to get a new driver that has been rebuilt for your current \nkernel. Sites such as rpmfusion.org  build third-party, non-open-source driver packages \nand upgrade those drivers when a new kernel is available. With the rpmfusion.org  reposi -\ntory enabled, your system should pick up the new drivers when the new kernel is added.\nAs an alternative to sites such as rpmfusion.org , you can go straight to the website for \nthe manufacturer and try to download its Linux drivers (Nvidia offers Linux drivers for its \nvideo cards), or if source code is available for the driver, you can try to build it yourself.\nExclude some packages from update. If you are updating lots of packages at once, you \ncan exclude the packages that fail to get the others to work as you pursue the problem \nwith the broken ones. Here\u2019s how to update all packages needing an upgrade, except for \na package named somepackage  (replace somepackage  with the name of the package \nthat you want to exclude):\n       # yum -y --exclude=somepackage update", "doc_id": "7388b28f-2e70-4a83-a4f2-75fe5a5a769d", "embedding": null, "doc_hash": "63da0fc323947ee62342905821c65b611291cfc21496e1931b845e56e15e3d0c", "extra_info": {"page_label": "568"}, "node_info": {"start": 0, "end": 2853}, "relationships": {"1": "453755f7-26aa-499c-8cca-6f61a56b2f92"}}, "__type__": "1"}, "4a3d1087-cf83-42c2-be7b-99f4be07949d": {"__data__": {"text": "Chapter 21: Troubleshooting Linux\n545\n21Fixing RPM databases and cache\nInformation about all of the RPM packages on your system is stored in your local RPM \ndatabase. Although it happens much less often than it did with earlier releases of Fedora \nand RHEL, it is possible for the RPM database to become corrupted. This stops you from \ninstalling, removing, or listing RPM packages.\nIf you find that your rpm  and yum  commands are hanging or failing and returning an \nrpmdb open fails message, you can try rebuilding the RPM database. To verify that \nthere is a problem in your RPM database, you can run the yum check  command. Here is \nan example of what the output of that command looks like with a corrupted database:\n# yum check\nerror: db4 error(11) from dbenv->open: Resource temporarily \nunavailable\nerror: cannot open Packages index using db4 - Resource temporarily\n     unavailable (11)Using cron  for Software Updates\nThe cron  facility provides a means of running commands at predetermined times and intervals. You \ncan set the exact minute, hour, day, or month that a command runs. You can configure a command to \nrun every five minutes, every third hour, or at a particular time on Friday afternoon.\nIf you want to use cron  to set up nightly software updates, you can do that as the root user by running \nthe crontab -e  command. That opens a file using your default editor ( vi command by default) that you \ncan configure as a crontab  file. Here\u2019s an example of what the crontab  file you create might look like:\n    #  min  hour  day/month  month  day/week  command\n       59   23    *          *      *         dnf -y update | mail root@localhost\nA crontab  file consists of five fields, designating day and time, and a sixth field, containing the command \nline to run. I added the comment line to indicate the fields. Here, the dnf -y update command is \nrun, with its output mailed to the user root@localhost . The command is run at 59 minutes after hour \n23 (11:59 p.m.). The asterisks ( *) are required as placeholders, instructing cron  to run the command on \nevery day of the month, month, and day of the week.\nWhen you create a cron  entry, make sure that you either direct the output to a file or pipe the output \nto a command that can deal with the output. If you don\u2019t, any output is sent to the user that ran the \ncrontab -e  command (in this case, root).\nIn a crontab  file, you can have a range of numbers or a list of numbers, or you can skip numbers. For \nexample, 1, 5, or 17  in the first field causes the command to be run 1, 5, and 17 minutes after the hour. \nAn */3 in the second field causes the command to run every three hours (midnight, 3 a.m., 6 a.m., and \nso on). A 1-3  in the fourth field tells cron  to run the command in January, February, and March. Days \nof the week and months can be entered as numbers or words.\nFor more information on the format of a crontab  file, type man 5 crontab . To read about the \ncrontab  command, type man 1 crontab .", "doc_id": "4a3d1087-cf83-42c2-be7b-99f4be07949d", "embedding": null, "doc_hash": "2e0a2d450c200b461f799e4c01902993fdeaf9237e13b3f1c04e55b5d9893467", "extra_info": {"page_label": "569"}, "node_info": {"start": 0, "end": 2996}, "relationships": {"1": "6990dd6f-b33b-41a3-b119-a4b8ca5fd2e4"}}, "__type__": "1"}, "48701dc8-35ca-463f-bdfa-cdcaeaf98dc4": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator546error cannot open Packages database in /var/lib/rpm\nCRITICAL:yum.main:\nError: rpmdb open fails\nThe RPM database and other information about your installed RPM packages are stored in \nthe /var/lib/rpm  directory. You can remove the database files that begin with __db*  \nand rebuild them from the metadata stored in other files in that directory.\nBefore you start, it\u2019s a good idea to back up the /var/lib/rpm  directory. Then you need \nto remove the old __db*  files and rebuild them. Type the following commands to do that:\n# cp -r /var/lib/rpm /tmp\n# cd /var/lib/rpm\n# rm __db*\n# rpm --initdb\nNew __db*  files should appear after a few seconds in that directory. Try a simple rpm  or \nyum command to make sure that the databases are now in order.\nJust as RPM has databases of locally installed packages, the Yum facility stored informa -\ntion associated with Yum repositories in the local /var/cache/yum  directory. With the \nintroduction of dnf , the cache directory is now /var/cache/dnf . Cached data includes \nmetadata, headers, packages, and yum  plug-in data.\nIf there is ever a problem with the data cached by yum , you can clean it out. The next time \nthat you run a yum  command, necessary data is downloaded again. Here are a couple of \nreasons for cleaning out your yum  cache:\nMetadata is obsolete. The first time that you connect to a Yum  repository (by down -\nloading a package or querying the repository), metadata is downloaded to your \nsystem. The metadata consists of information on all of the available packages from \nthe repository.\nAs packages are added and removed from the repository, the metadata has to be \nupdated or your system will be working from old packaging information. By default, \nif you run a dnf  command, dnf  checks for new metadata if the old metadata is \nmore than 48 hours old (or by however many minutes metadata_expire=  is set to \nin the /etc/dnf/dnf.conf  file).\nIf you suspect that the metadata is obsolete but the expire time has not been reached, \nyou can run dnf clean metadata  to remove all metadata, forcing new metadata to be \nuploaded with the next upload. Alternatively, you could run dnf makecache  to get meta -\ndata from all repositories up to date.\nYou are running out of disk space. Normally, yum might cache as much as a few \nhundred megabytes of data in /var/cache/dnf  directories. However, depending \non the settings in your /etc/dnf/dnf.conf  file (such as keepcache=1 , which \nkeeps all downloaded RPMs even after they are installed), the cache directories can \ncontain multiple gigabytes of data.\nTo clean out all packages, metadata, headers, and other data stored in the /var/\ncache/dnf  directory, type the following:\n        # yum clean all", "doc_id": "48701dc8-35ca-463f-bdfa-cdcaeaf98dc4", "embedding": null, "doc_hash": "9e2ed8be8949318de03a802f38eede83afd31cdead6561408758db6f8aecf377", "extra_info": {"page_label": "570"}, "node_info": {"start": 0, "end": 2763}, "relationships": {"1": "c7583283-f082-4d4c-bd6a-bfe98cfb8a73"}}, "__type__": "1"}, "a87c9eca-a29f-4d18-a6fe-e47981d0bc57": {"__data__": {"text": "Chapter 21: Troubleshooting Linux\n547\n21At this point, your system gets up-to-date information from repositories the next time a \nyum command is run.\nThe next section covers information about network troubleshooting.\nTroubleshooting Networking\nWith more and more of the information, images, video, and other content that we use every \nday now available outside of our local computers, a working network connection is required \non almost every computer system. So, if you drop your network connection or can\u2019t reach \nthe systems with which you wish to communicate, it\u2019s good to know that there are many \ntools in Linux for looking at the problem.\nFor client computers (laptops, desktops, and handheld devices), you want to connect to the \nnetwork to reach other computer systems. On a server, you want your clients to be able to \nreach you. The following sections describe different tools for troubleshooting network con -\nnectivity for Linux client and server systems.\nTroubleshooting outgoing connections\nLet\u2019s say that you open your web browser but are unable to get to any website. You suspect \nthat you are not connected to the network. Maybe the problem is with name resolution, but \nit may be with the connection outside of your local network.\nTo check whether your outgoing network connections are working, you can use many of \nthe commands described in Chapter\u00a014, \u201cAdministering Networking.\u201d You can test connec -\ntivity using a simple ping  command. To see if name-to-address resolution is working, use \nhost  and dig .\nThe following sections cover problems that you can encounter with network connectivity \nfor outgoing connections and what tools to use to uncover the problems.\nView network interfaces\nTo see the status of your network interfaces, use the ip  command. The following output \nshows that the loopback interface ( lo) is up (so you can run network commands on your \nlocal system), but eth0  (your first wired network card) is down ( state DOWN ). If the \ninterface had been up, an inet  line would show the IP address of the interface. Here, only \nthe loopback interface has an inet  address (127.0.0.1).\n# ip addr show\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 16436 qdisc noqueue state UNKNOWN\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n    inet6 ::1/128 scope host\n       valid_lft forever preferred_lft forever\n2: eth0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 state DOWN qlen \n1000\n    link/ether f0:de:f1:28:46:d9 brd ff:ff:ff:ff:ff:ff", "doc_id": "a87c9eca-a29f-4d18-a6fe-e47981d0bc57", "embedding": null, "doc_hash": "f79893bcc7ed7497373d85a25efadb8df4c376b6abc42a460f92ca9ab7ad3c28", "extra_info": {"page_label": "571"}, "node_info": {"start": 0, "end": 2512}, "relationships": {"1": "f275161f-bc83-403f-8390-e22680af1b28"}}, "__type__": "1"}, "4c4a03f2-c630-4290-82f1-e24428ddaa6e": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator548By default in RHEL 8 and Fedora, network interfaces are now named based on how they \nare connected to the physical hardware. For example, in RHEL 8, you might see a net -\nwork interface of enp11s0. That would indicate that the NIC is a wired Ethernet card (en) \non PCI board 11 (p11) and slot 0 (s0). A wireless card would start with wl instead of en. \nThe intention is to make the NIC names more predictable, because when the system is \nrebooted, it is not guaranteed which interfaces would be named eth0, eth1, and so on by \nthe operating system.\nCheck physical connections\nFor a wired connection, make sure that your computer is plugged into the port on your net -\nwork switch. If you have multiple NICs, make sure that the cable is plugged into the correct \none. If you know the name of a network interface (eth0 , p4p1 , or other), to find which \nNIC is associated with the interface, enter ethtool -p eth0  at the command line and \nlook behind your computer to see which NIC is blinking (Ctrl+C stops the blinking). Plug \nthe cable into the correct port.\nIf instead of seeing an interface that is down, the ip  command shows no interface at all, \ncheck that the hardware isn\u2019t disabled. For a wired NIC, the card may not be fully seated in \nits slot or the NIC may have been disabled in the BIOS.\nOn a wireless connection, you may click the NetworkManager icon and not see an available \nwireless interface. Again, it could be disabled in the BIOS. However, on a laptop, check to \nsee if there is a tiny switch that disables the NIC. I\u2019ve seen several people shred their net -\nworking configurations only to find out that this tiny switch on the front or side of their \nlaptops had been switched to the off position.\nCheck routes\nIf your network interface is up but you still can\u2019t reach the host you want to reach, try \nchecking the route to that host. Start by checking your default route. Then try to reach \nthe local network\u2019s gateway device to the next network. Finally, try to ping a system some -\nwhere on the Internet:\n# ip route show\ndefault via 192.168.122.1 dev ens3 proto dhcp metric 100 \n192.168.122.0/24 dev ens3 proto kernel scope link src 192.168.122.194 \nmetric 100\nThe default line shows that the default gateway is at address 192.168.122.1 and that the \naddress can be reached over the ens3  card. Because there is only the ens3  interface here \nand only a route to the 192.168.122.0 network is shown, all communication not addressed to \na host on the 192.168.122.0/24 network is sent through the default gateway (192.168.122.1). \nThe default gateway is more properly referred to as a router.\nTo make sure that you can reach your router, try to ping it, as in this example:\n# ping -c 2 192.168.122.1\nPING 192.168.122.1 (192.168.122.1) 56(84) bytes of data.\n64 bytes from 192.168.122.1: icmp_seq=1 ttl=64 time=0.757 ms\n64 bytes from 192.168.122.1: icmp_seq=2 ttl=64 time=0.538 ms\n ", "doc_id": "4c4a03f2-c630-4290-82f1-e24428ddaa6e", "embedding": null, "doc_hash": "28a14c8622fe58d16db32fdc7f862fe203506893dc559db2d831e31e398beda4", "extra_info": {"page_label": "572"}, "node_info": {"start": 0, "end": 2953}, "relationships": {"1": "4aa12a2d-cef0-460d-8953-41eba24148e0"}}, "__type__": "1"}, "27a26eac-3b1e-4805-b232-e7e18c8e87e8": {"__data__": {"text": "Chapter 21: Troubleshooting Linux\n549\n21--- 192.168.122.1 ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 65ms\nrtt min/avg/max/mdev = 0.538/0.647/0.757/0.112 ms\nA \u201cDestination Host Unreachable\u201d message tells you that the router is either turned off or \nnot physically connected to you (maybe the router isn\u2019t connected to the switch you share). \nIf the ping succeeds and you can reach the router, the next step is to try an address beyond \nyour router.\nTry to ping a widely accessible IP address. For example, the IP address for the Google public \nDNS server is 8.8.8.8. Try to ping that ( ping -c2 8.8.8.8 ). If that ping succeeds, your \nnetwork is probably fine, and it is most likely your hostname-to-address resolution that is \nnot working properly.\nIf you can reach a remote system but the connection is very slow, you can use the tra -\nceroute  command to follow the route to the remote host. For example, this command \nshows each hop taken en route to http://www.google.com :\n# traceroute www.google.com\nThe output shows the time taken to make each hop along the way to the Google site. \nInstead of traceroute , you can use the mtr  command ( yum install mtr ) to watch \nthe route taken to a host. With mtr , the route is queried continuously, so you can watch \nthe performance of each leg of the journey over time.\nCheck hostname resolution\nIf you cannot reach remote hosts by name, but you can reach them by pinging IP addresses, \nyour system is having a problem with hostname resolution. Systems connected to the \nInternet do name-to-address resolution by communicating to a domain name system (DNS) \nserver that can provide them with the IP addresses of the requested hosts.\nThe DNS server your system uses can be entered manually or picked up automatically from \na DHCP server when you start your network interfaces. In either case, the names and IP \naddresses of one or more DNS servers end up in your /etc/resolv.conf  file. Here is an \nexample of that file:\nsearch example.com\nnameserver 192.168.0.254\nnameserver 192.168.0.253\nWhen you ask to connect to a hostname in Fedora or Red Hat Enterprise Linux, the /etc/\nhosts  file is searched; then the name server entries in resolv.conf  are queried in the \norder that they appear. Here are some ways of debugging name-to-address resolution:\nCheck if DNS server can be reached. Knowing the name server addresses, you can \ntry to ping each name server\u2019s IP address to see if it is accessible. For example: ping \n-c 2 192.168.0.254 . If the IP address can be reached, it could be that you were \neither assigned the wrong address for the DNS server or it is currently down.\nCheck if DNS server is working. You specifically try to use each DNS server with the \nhost  or dig  command. For example, either of these two commands can be used to \nsee if the DNS server at 192.168.0.254  can resolve the hostname www.google.", "doc_id": "27a26eac-3b1e-4805-b232-e7e18c8e87e8", "embedding": null, "doc_hash": "1fef9136011718048f9cc6113930fbcaea1660bcc0c77b91fb7dd35e3094e7a8", "extra_info": {"page_label": "573"}, "node_info": {"start": 0, "end": 2903}, "relationships": {"1": "4e27d59b-30b1-4b00-9c22-4151a49597d9"}}, "__type__": "1"}, "7383412b-59aa-4959-b006-f30133170303": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator550com into an IP address. Repeat this for each name server\u2019s IP address until you find \nwhich ones work:\n        # host www.google.com 192.168.0.254\n        Using domain server:\n        Name: 192.168.0.254\n        Address: 192.168.0.254#53\n        Aliases:\n        www.google.com has address 172.217.13.228\n        www.google.com has IPv6 address 2607:f8b0:4004:809::2004\n        # dig @192.168.0.254 www.google.com\n        ...\n        ;; QUESTION SECTION:\n        ;www.google.com.              IN  A\n \n        ;; ANSWER SECTION:\n        www.google.com.       67  IN  A   172.217.13.228\n        ...\nCorrect your DNS servers. If you determine that you have the wrong IP addresses set \nfor your DNS servers, changing them can be a bit tricky. Search /var/log/mes -\nsages  or the output of journalctl  for your DNS servers\u2019 IP addresses. If Network -\nManager is used to start your networking and connect to a DHCP server, you should \nsee name server lines with the IP addresses being assigned. If the addresses are \nwrong, you can override them.\nWith NetworkManager enabled, you can\u2019t just add name server entries to the /etc/\nresolv.conf  file because NetworkManager overwrites that file with its own name \nserver entries. Instead, add a PEERDNS=no  line to the ifcfg  file for the network \ninterface (for example, ifcfg-eth0  in the /etc/sysconfig/network-scripts  \ndirectory). Then set DNS1=192.168.0.254  (or whatever is your DNS server\u2019s IP \naddress). The new address is used the next time you restart your networking.\nIf you are using the network service, instead of NetworkManager, you can still use \nPEERDNS=no  to prevent the DHCP server from overwriting your DNS addresses. \nHowever, in that case, you can edit the resolv.conf  file directly to set your DNS \nserver addresses.\nThe procedures just described for checking your outgoing network connectivity apply to \nany type of system, whether it is a laptop, desktop, or server. For the most part, incoming \nconnections are not an issue with laptops or desktops because most requests are simply \ndenied. However, for servers, the next section describes ways of making your server acces -\nsible if clients are having trouble reaching the services you provide from that server.\nTroubleshooting incoming connections\nIf you are troubleshooting network interfaces on a server, there are different consider -\nations than on a desktop system. Because most Linux systems are configured as servers, \nyou should know how to troubleshoot problems encountered by those who are trying to \nreach your Linux servers.", "doc_id": "7383412b-59aa-4959-b006-f30133170303", "embedding": null, "doc_hash": "032a894b0a2019c34b62d6b7b5dd79030a9bc20db1066e235f499f6378b4d603", "extra_info": {"page_label": "574"}, "node_info": {"start": 0, "end": 2605}, "relationships": {"1": "953d01b9-5f72-4431-a5f1-f10536815276"}}, "__type__": "1"}, "c4ade4d3-3f2b-4e8d-ab7f-c2904dbdee35": {"__data__": {"text": "Chapter 21: Troubleshooting Linux\n551\n21I\u2019ll start with the idea of having an Apache web server ( httpd ) running on your Linux \nsystem, but no web clients can reach it. The following sections describe things that you can \ntry to locate the problem.\nCheck if the client can reach your system at all\nTo be a public server, your system\u2019s hostname should be resolvable so that any client on \nthe Internet can reach it. That means locking down your system to a particular, public IP \naddress and registering that address with a public DNS server. You can use a domain regis -\ntrar (such as http://www.networksolutions.com ) to do that.\nWhen clients cannot reach your website by name from their web browsers, if the client \nis a Linux system, you can go through ping , host , traceroute , and other commands \ndescribed in the previous section to track down the connectivity problem. Windows sys -\ntems have their own version of ping  that you can use from those systems.\nIf the name-to-address resolution is working to reach your system and you can ping  your \nserver from the outside, the next thing to try is the availability of the service.\nCheck if the service is available to the client\nFrom a Linux client, you can check if the service you are looking for (in this case httpd ) is \navailable from the server. One way to do that is using the nmap  command.\nThe nmap  command is a favorite tool for system administrators checking for various kinds \nof information on networks. However, it is a favorite cracker tool as well because it can \nscan servers, looking for potential vulnerabilities. So, it is fine to use nmap  to scan your \nown systems to check for problems, but know that using nmap  on another system is like \nchecking the doors and windows on someone\u2019s house to see if you can get in. You look like \nan intruder.\nChecking your own system to see what ports to your server are open to the outside world \n(essentially, checking what services are running) is perfectly legitimate and easy to do. \nAfter nmap  is installed ( yum install nmap ), use your system hostname or IP address to \nuse nmap  to scan your system to see what is running on common ports:\n# nmap 192.168.0.119\nStarting Nmap 6.40 ( http://nmap.org ) at 2019-12-08 13:28 EST\nNmap scan report for spike (192.168.0.119)\nHost is up (0.0037s latency).\nNot shown: 995 filtered ports\nPORT    STATE  SERVICE\n21/tcp  open   ftp\n22/tcp  open   ssh\n80/tcp  open   http\n443/tcp open   https\n631/tcp open   ipp\nMAC Address: 00:1B:21:0A:E8:5E (Intel Corporate)\nNmap done: 1 IP address (1 host up) scanned in 4.77 seconds", "doc_id": "c4ade4d3-3f2b-4e8d-ab7f-c2904dbdee35", "embedding": null, "doc_hash": "045a6520f6acb25205ca8fac9584175ce75f4f56ac0ff5ff50c3a1c1814bedec", "extra_info": {"page_label": "575"}, "node_info": {"start": 0, "end": 2582}, "relationships": {"1": "f2e88415-33e1-4f02-8b99-36513b3f5ac7"}}, "__type__": "1"}, "bbe04038-cae5-41a7-916c-f286f666d0b3": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator552The preceding output shows that TCP ports are open to the regular ( http ) and secure \n(https ) web services. When you see that the state is open , it indicates that a service is \nlistening on the port as well. If you get to this point, it means that your network connec -\ntion is fine, and you should direct your troubleshooting efforts to how the service itself is \nconfigured (for example, you might look in /etc/httpd/conf/httpd.conf  to see if spe -\ncific hosts are allowed or denied access).\nIf TCP ports 80 and/or 443 are not shown, it means that they are being filtered. You need \nto check whether your firewall is blocking (not accepting packets to) those ports. If the \nport is not filtered but the state is closed, it means that the httpd  service either isn\u2019t \nrunning or isn\u2019t listening on those ports. The next step is to log in to the server and check \nthose issues.\nCheck the firewall on the server\nFrom your server, you can use the iptables  command to list the filter table rules that are \nin place. Here is an example:\n# iptables -vnL\nChain INPUT (policy ACCEPT 0 packets, 0 bytes)\npkts bytes target prot opt in out source    destination\n...\n   0     0 ACCEPT tcp  --  *  *   0.0.0.0/0 0.0.0.0/0   state NEW tcp \ndpt:80\n   0     0 ACCEPT tcp  --  *  *   0.0.0.0/0 0.0.0.0/0   state NEW tcp \ndpt:443\n...\nFor the RHEL 8 and Fedora 30 systems where the firewalld  service is enabled, you can \nuse the Firewall configuration window to open the ports needed. With the public Zone \nand Services tab selected, click the check boxes for http  and https  to open those ports \nimmediately for all incoming traffic. If your system is using the basic iptables  service, \nthere should be firewall rules like the two shown in the preceding code among your other \nrules. If there aren\u2019t any, add those rules to the /etc/sysconfig/iptables  file. Here are \nexamples of what those rules might look like:\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT\n-A INPUT -m state --state NEW -m tcp -p tcp --dport 443 -j ACCEPT\nWith the rules added to the file, clear out all of your firewall rules ( systemctl stop \niptables.service  or service iptables stop ) and then start them again ( system-\nctl start iptables.service  or service iptables start ).\nIf the firewall is still blocking client access to the web server ports, here are a few things to \ncheck in your firewall:\nCheck rules order. Look at rules in /etc/sysconfig/iptables  and see if a \nDROP  or REJECT  rule comes before the rules opening ports 80 and/or 443. Moving \nthe rules to open those ports before any final DROP  or REJECT  lines can solve \nthe problem.", "doc_id": "bbe04038-cae5-41a7-916c-f286f666d0b3", "embedding": null, "doc_hash": "9ba6b03874b57d27fa408de27933a2841a15a102ebb0d73011cd6acecdea2b8c", "extra_info": {"page_label": "576"}, "node_info": {"start": 0, "end": 2686}, "relationships": {"1": "97373fee-517c-4ec0-b8fd-50b4316d1c57"}}, "__type__": "1"}, "4689ffd2-ce0e-466f-86da-22b8284b6130": {"__data__": {"text": "Chapter 21: Troubleshooting Linux\n553\n21Look for denied hosts. Check whether any rules drop or reject packets from particu -\nlar hosts or networks. Look for rules that include -s  or --source  followed by an \nIP address or address range and then a -j DROP  or ACCEPT . Modify the rule or add \na rule prior to your rules to make an exception for the host you want to allow to \naccess your service.\nIf the port is now open but the service itself is closed, check that the service itself is \nrunning and listening on the appropriate interfaces.\nCheck the service on the server\nIf there seems to be nothing blocking client access to your server through the actual \nports providing the service that you want to share, it is time to check the service itself. \nAssuming that the service is running (depending on your system, type service httpd \nstatus  or systemctl status httpd.service  to check), the next thing to check is \nthat it is listening on the proper ports and network interfaces.\nThe netstat  command is a great general-purpose tool for checking network services. The \nfollowing command lists the names and process IDs ( p) for all processes that are listen -\ning (l) for TCP (t) and UDP ( u) services, along with the port number ( n) on which they \nare listening. The command line filters out all lines except those associated with the \nhttpd  process:\n# netstat -tupln | grep httpd\ntcp    0  0 :::80        :::*         LISTEN      2567/httpd\ntcp    0  0 :::443       :::*         LISTEN      2567/httpd\nThe previous example shows that the httpd  process is listening on port 80 and 443 for all \ninterfaces. It is possible that the httpd  process might be listening on selected interfaces. \nFor example, if the httpd  process were only listening on the local interface (127.0.0.1) for \nHTTP requests (port 80), the entry would appear as follows:\ntcp    0  0 127.0.0.1:80 :::*         LISTEN      2567/httpd\nFor httpd , as well as for other network services that listen for requests on network inter -\nfaces, you can edit the service\u2019s main configuration file (in this case, /etc/httpd/conf/\nhttpd.conf ) to tell it to listen on port 80 for all addresses ( Listen 80 ) or a specific \naddress (Listen 192.168.0.100:80 ).\nTroubleshooting Memory\nTroubleshooting performance problems on your computer is one of the most important, \nalthough often elusive, tasks you need to complete. Maybe you have a system that was \nworking fine, but it begins to slow down to a point where it is practically unusable. Maybe \napplications just begin to crash for no apparent reason. Finding and fixing the problem may \ntake some detective work.", "doc_id": "4689ffd2-ce0e-466f-86da-22b8284b6130", "embedding": null, "doc_hash": "de727a1d6de64a90480c96f710e29300a91a04790656ac163323b08ceb82a163", "extra_info": {"page_label": "577"}, "node_info": {"start": 0, "end": 2631}, "relationships": {"1": "9913c17d-8de0-4118-a98b-b1ffe920f72b"}}, "__type__": "1"}, "9fd5a20e-b11c-4c4e-b4f8-cf1f48668498": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator554Linux comes with many tools for watching activities on your system and figuring out what \nis happening. Using a variety of Linux utilities, you can do things such as finding out \nwhich processes are consuming large amounts of memory or placing high demands on your \nprocessors, disks, or network bandwidth. Solutions can include the following:\nAdding capacity  Your computer may be trying to do what you ask of it, but failures \nmight occur because you don\u2019t have enough memory, processing power, disk space, \nor network capacity to get reasonable performance. Even nearing the boundaries \nof resource exhaustion can cause performance problems. Improving your computer \nhardware capacity is often the easiest way of solving performance problems.\nTuning the system Linux comes with default settings that define how it internally \nsaves data, moves data around, and protects data. System tunable parameters can \nbe changed if the default settings don\u2019t work well for the types of applications you \nhave on your system.\nUncovering problem applications or users  Sometimes, a system performs poorly \nbecause a user or an application is doing something wrong. Misconfigured or broken \napplications can hang or gobble up all of the resources they can find. An inexpe -\nrienced user might mistakenly start multiple instances of a program that drain \nsystem resources. As a system administrator, you want to know how to find and fix \nthese problems.\nTo troubleshoot performance problems in Linux, you use some of the basic tools for watch -\ning and manipulating processes running on your system. Refer to Chapter\u00a06, \u201cManaging \nRunning Processes,\u201d if you need details on commands such as ps , top, kill , and  \nkillall . In the following sections, I add commands such as memstat  to dig a little \ndeeper into what processes are doing and where things are going wrong.\nThe most complex area of troubleshooting in Linux relates to managing virtual memory. \nThe next sections describe how to view and manage virtual memory.\nUncovering memory issues\nComputers have ways of storing data permanently (hard disks) and temporarily ( random \naccess memory, or RAM, and swap space ). Think of yourself as a CPU, working at a desk try -\ning to get your work finished. You would put data that you want to keep permanently in \na filing cabinet across the room (that\u2019s like hard disk storage). You would put information \nthat you are currently using on your desk (that\u2019s like RAM memory on a computer).\nSwap space is a way of extending RAM. It is really just a place to put temporary data \nthat doesn\u2019t fit in RAM but is expected to be needed by the CPU at some point. Although \nswap space is on the hard disk, it is not a regular Linux filesystem in which data is stored \npermanently.", "doc_id": "9fd5a20e-b11c-4c4e-b4f8-cf1f48668498", "embedding": null, "doc_hash": "266c29cb6acc239059d35ee9ed79ab546feeb4fd3e3398ebdae1265077e48203", "extra_info": {"page_label": "578"}, "node_info": {"start": 0, "end": 2811}, "relationships": {"1": "20cd6ccd-576c-44fd-89ee-226d415c79ec"}}, "__type__": "1"}, "e77e9a4f-a121-425f-99b8-a8b3990348ac": {"__data__": {"text": "Chapter 21: Troubleshooting Linux\n555\n21Compared to disk storage, random access memory has the following attributes:\nNearer the processor Like the desk being near to you as you work, memory is phys -\nically near the CPU on the computer\u2019s motherboard. So, any data the CPU needs, it \ncan just grab immediately if the data is in RAM.\nFaster  Its proximity to the CPU and the way that it is accessed (solid state versus \nmechanical hard disks) makes it much faster for the CPU to get information from \nRAM than it can from a hard disk. It\u2019s quicker to look at a piece of paper on your \ndesk (a small, close space) than to walk to a row of file cabinets and to start search -\ning for what you want.\nLess capacity  A new computer might have a 1TB or larger hard drive but 8GB or \n16GB of RAM. Although it would make the computer run faster to put every file and \nevery piece of data that the processor may need into RAM, in most cases there just \nwouldn\u2019t be enough room. Also, both the physical memory slots on the computer \nand the computer system itself (64-bit computers can address more RAM than 32-bit \ncomputers) can limit how much RAM a computer is capable of having.\nMore expensive Although RAM is tremendously more affordable than it was a decade \nor two ago, it is still much more expensive (per GB) than hard disks.\nTemporary  RAM holds data and metadata that the CPU is using now for the work it is \ndoing (plus some content the Linux kernel is keeping around because it suspects a \nprocess will need it before long). When you turn off the computer, however, every -\nthing in RAM is lost. When the CPU is done with data, that data is discarded if it is \nno longer needed, left in RAM for possible later use, or marked to be written to disk \nfor permanent storage if it needs to be saved.\nIt is important to understand the difference between temporary (RAM) and permanent \n(hard disk) storage, but that doesn\u2019t tell the whole story. If the demand for memory exceeds \nthe supply of RAM, the kernel can temporarily move data out of RAM to an area called \nswap space.\nIf we revisit the desk analogy, this would be like saying, \u201cThere is no room left on my desk, \nyet I have to add more papers to it for the projects I\u2019m currently working on. Instead of \nstoring papers I\u2019ll need soon in a permanent file cabinet, I\u2019ll have one special file cabinet \n(like a desk drawer) to hold those papers that I\u2019m still working with but that I\u2019m not ready \nto store permanently or throw away.\u201d\nRefer to Chapter\u00a012, \u201cManaging Disks and Filesystems,\u201d for more information on swap files \nand partitions and how to create them. For the moment, however, there are a few things \nthat you should know about these kinds of swap areas and when they are used:\n\u25a0\u25a0When data is swapped from RAM to a swap area (swapped out), you get a perfor -\nmance hit. Remember, writing to disk is much slower than writing to RAM.\n\u25a0\u25a0When data is returned from swap to RAM because it is needed again (swapped in), \nyou get another performance hit.", "doc_id": "e77e9a4f-a121-425f-99b8-a8b3990348ac", "embedding": null, "doc_hash": "27f3d0ab45d788598ca67a970908aa145b77495cac2b332e2285cf8c79a5d5d9", "extra_info": {"page_label": "579"}, "node_info": {"start": 0, "end": 3009}, "relationships": {"1": "9ddc1033-a2a4-4283-80f6-c7e44e8731f4"}}, "__type__": "1"}, "321137d0-12b1-4f5b-9a6b-5374ca7eb51a": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator556\u25a0\u25a0When Linux runs out of space in RAM, swapping is like losing a high gear on a \ncar. The car might have to run in a lower gear, but it would not stop altogether. In \nother words, all your processes stay active, and they don\u2019t lose any data or fail com-\npletely, but the system performance can significantly slow down.\n\u25a0\u25a0If both RAM and swap are full and no data can be discarded or written to disk, your \nsystem can reach an out-of-memory  (OOM) condition. When that happens, the kernel \nOOM killer kicks in and begins killing off processes, one by one, to regain as much \nmemory as the kernel needs to begin functioning properly again.\nThe general rule has always been that swapping is bad and should be avoided. However, \nsome would argue that, in certain cases, more aggressive swapping can actually improve \nperformance.\nThink of the case where you open a document in a text editor and then minimize it on your \ndesktop for several days as you work on different tasks. If data from that document were \nswapped out to disk, more RAM would be available for more active applications that could \nput that space to better use. The performance hit would come the next time you needed to \naccess the data from the edited document and the data was swapped in from disk to RAM. \nThe settings that relate to how aggressively a system swaps are referred to as swappiness .\nAs much as possible, Linux wants to make everything that an open application needs \nimmediately available. So, using the desk analogy, if I am working on nine active projects \nand there is space on the desk to hold the information I need for all nine projects, why not \nleave them all within reach on the desk? Following that same way of thinking, the kernel \nsometimes keeps libraries and other content in RAM that it thinks you might eventually \nneed\u2014even if a process is not looking for it immediately.\nThe fact that the kernel is inclined to store information in RAM that it expects may be \nneeded soon (even if it is not needed now) can cause an inexperienced system admin -\nistrator to think that the system is almost out of RAM and that processes are about to \nstart failing. That is why it is important to know the different kinds of information being \nheld in memory\u2014so that you can tell when real out-of-memory situations can occur. The \nproblem is not just running out of RAM; it is running out of RAM when only non-swappable \ndata is left.\nKeep this general overview of virtual memory  (RAM and swap) in mind, as the next section \ndescribes ways to go about troubleshooting issues related to virtual memory.\nChecking for memory problems\nLet\u2019s say that you are logged in to a Linux desktop, with lots of applications running, and \neverything begins to slow down. To find out if the performance problems have occurred \nbecause you have run out of memory, you can try commands such as top  and ps  to begin \nlooking for memory consumption on your system.", "doc_id": "321137d0-12b1-4f5b-9a6b-5374ca7eb51a", "embedding": null, "doc_hash": "cbc2b61f033c4950a85c40a8c18c2cf367863ff013b4f528bac9cd0648095e83", "extra_info": {"page_label": "580"}, "node_info": {"start": 0, "end": 2979}, "relationships": {"1": "b435372f-c394-497b-9214-6f061d9317da"}}, "__type__": "1"}, "692d6fce-e751-4840-837f-deda1fb88ce8": {"__data__": {"text": "Chapter 21: Troubleshooting Linux\n557\n21To run the top  command to watch for memory consumption, type top  and then type a \ncapital M . Here is an example:\n# top\ntop - 22:48:24 up  3:59,  2 users,  load average: 1.51, 1.37, 1.15\nTasks: 281 total,   2 running, 279 sleeping,   0 stopped,   0 zombie\nCpu(s): 16.6%us,  3.0%sy,  0.0%ni, 80.3%id,  0.0%wa,  0.0%hi,  0.2%si,  0.0%st\nMem:   3716196k total,  2684924k used,  1031272k free,   146172k buffers\nSwap:  4194296k total,        0k used,  4194296k free,   784176k cached\n  PID USER     PR  NI  VIRT  RES  SHR S %CPU %MEM   TIME+  COMMAND\n 6679 cnegus     20       0        1665m 937m  32m S          7.0 25.8  1:07.95    firefox\n 6794                                                 cnegus       20                       0           743m                                         181m                                                                               30m       R  64.8                                            5.0                                                                      1:22.82         npviewer.bin\n 3327              cnegus           20           0                  1145m           116m              66m S                        0.0            3.2             0:39.25     soffice. bin\n 6939                                       cnegus   20   0                                       145m                                     71m     23m S         0.0  2.0       0:00.97        ", "doc_id": "692d6fce-e751-4840-837f-deda1fb88ce8", "embedding": null, "doc_hash": "c1e2c71dbd758916019de7323c52fb7514aa02811e0c9b1ef2687476b39a29b3", "extra_info": {"page_label": "581"}, "node_info": {"start": 0, "end": 1453}, "relationships": {"1": "332c016a-8ec4-479d-b000-5f469ad4ef3d", "3": "8a549541-6190-4c20-9c6d-60529186fd44"}}, "__type__": "1"}, "8a549541-6190-4c20-9c6d-60529186fd44": {"__data__": {"text": "  3.2             0:39.25     soffice. bin\n 6939                                       cnegus   20   0                                       145m                                     71m     23m S         0.0  2.0       0:00.97         acroread\n 2440                                        root     20   0                                        183m                                       37m  26m S             1.3                                      1.0   1:04.81          Xorg\n 2795                                       cnegus    20   0                                      1056m                                         22m  14m S         0.0  0.6      0:01.55          nautilus\nThere are two lines ( Mem and Swap ) and four columns of information ( VIRT , RES , SHR , \nand %MEM ) relating to memory in the top  output. In this example, you can see that RAM \nis not exhausted from the Mem  line (only 2684924k of 3716196k is used) and that nothing is \nbeing swapped to disk from the Swap  line (0k used).\nHowever, adding up just these first six lines of output in the VIRT  column, you would \nsee that 4937MB of memory has been allocated for those applications, which exceeds the \n3629MB of total RAM (3716196k) that is available. That\u2019s because the VIRT  column shows \nonly the amount of memory that has been promised to the application. The RES  line \nshows the amount of non-swappable memory that is actually being used, which totals \nonly 1364MB.\nNotice that, when you ask to sort by memory usage by typing a capital M , top  knows to \nsort on that RES  column. The SHR  column shows memory that could potentially be shared \nby other applications (such as libraries), and %MEM  shows the percentage of total memory \nconsumed by each application.\nIf you think that the system is reaching an out-of-memory state, here are a few things \nto look for:\n\u25a0\u25a0The free space shown on the Mem  line would be at or near zero.\n\u25a0\u25a0The used space shown on the Swap  line would be non-zero and would continue to \ngrow. That should be accompanied with a slowdown of system performance.\n\u25a0\u25a0As the top  screen redraws every few seconds, if there is a process with a memory \nleak (continuously asking for and using more memory, but not giving any memory \nback), the amount of VIRT  memory grows, but more", "doc_id": "8a549541-6190-4c20-9c6d-60529186fd44", "embedding": null, "doc_hash": "c06a524c8a10e3e8d0849841a927d37fe7aeb9fd2a695e3cb7a9dbd7f671e10a", "extra_info": {"page_label": "581"}, "node_info": {"start": 1395, "end": 3683}, "relationships": {"1": "332c016a-8ec4-479d-b000-5f469ad4ef3d", "2": "692d6fce-e751-4840-837f-deda1fb88ce8", "3": "570c332f-974a-4a9f-b83c-076f0903802b"}}, "__type__": "1"}, "570c332f-974a-4a9f-b83c-076f0903802b": {"__data__": {"text": "a capital M , top  knows to \nsort on that RES  column. The SHR  column shows memory that could potentially be shared \nby other applications (such as libraries), and %MEM  shows the percentage of total memory \nconsumed by each application.\nIf you think that the system is reaching an out-of-memory state, here are a few things \nto look for:\n\u25a0\u25a0The free space shown on the Mem  line would be at or near zero.\n\u25a0\u25a0The used space shown on the Swap  line would be non-zero and would continue to \ngrow. That should be accompanied with a slowdown of system performance.\n\u25a0\u25a0As the top  screen redraws every few seconds, if there is a process with a memory \nleak (continuously asking for and using more memory, but not giving any memory \nback), the amount of VIRT  memory grows, but more important, the RES  memory \ncontinues to grow for that process.\n\u25a0\u25a0If the Swap  space actually runs out, the kernel starts to kill off processes to deal \nwith this out-of-memory condition.", "doc_id": "570c332f-974a-4a9f-b83c-076f0903802b", "embedding": null, "doc_hash": "4f97efc9869077a1010e39e694edf17e3ddf5fd1e87278c287282511d10b1e3f", "extra_info": {"page_label": "581"}, "node_info": {"start": 2968, "end": 3930}, "relationships": {"1": "332c016a-8ec4-479d-b000-5f469ad4ef3d", "2": "8a549541-6190-4c20-9c6d-60529186fd44"}}, "__type__": "1"}, "a7ac41e1-777d-414a-b05b-473ace63fcd7": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator558If you have Cockpit installed and enabled, you can watch memory usage live from your \nWeb browser. Open Cockpit and then select System \u27aa Memory & Swap. Figure\u00a021.4 shows \na system where the memory is all being consumed by multiple video streams and has \nbegun swapping.\nDealing with memory problems\nIn the short term, you can do several things to deal with this out-of-memory condition:\nKill a process If the memory problem is due to one errant process, you can simply \nkill that process. Assuming that you are logged in as root or as the user who owns \nthe runaway process, type k from the top window, then enter the PID of the process \nthat you want to kill, and choose 15 or 9 as the signal to send.\nDrop page caches If you just want to clear up some memory right now as you otherwise \ndeal with the problem, you can tell the system to drop inactive page caches. When you \ndo this, some memory pages are written to disk; others are just discarded (because \nthey are stored permanently and can be gotten again from disk when they are needed).\nThis action is the equivalent of cleaning your desk and putting all but the most \ncritical information into the trash or into a file cabinet. You may need to retrieve \ninformation again shortly from a file cabinet, but you almost surely don\u2019t need it all \nimmediately. Keep top  running in one Terminal window to see the Mem  line change \nas you type the following (as root) into another Terminal window:\n # echo 3 > /proc/sys/vm/drop_caches\nKill an out-of-memory process Sometimes, memory exhaustion has made the system \nso unusable that you may not be able to get a response from a shell or GUI. In those \ncases, you might be able to use Alt+SysRq keystrokes to kill an out-of-memory pro -\ncess. The reason you can use Alt+SysRq keystrokes on an otherwise unresponsive \nsystem is that the kernel processes Alt+SysRq requests ahead of other requests.\nFIGURE 21.4\nMonitor RAM and Swap usage in real time with Cockpit.", "doc_id": "a7ac41e1-777d-414a-b05b-473ace63fcd7", "embedding": null, "doc_hash": "71ccd7ee0f3b10e561351287e51e367aa64c8a403cc69603a0470a9580e91be4", "extra_info": {"page_label": "582"}, "node_info": {"start": 0, "end": 2011}, "relationships": {"1": "04d8fc09-3631-43b1-b706-867639fe4120"}}, "__type__": "1"}, "f4a1ed1f-2fe5-44ae-bb92-0cda14799793": {"__data__": {"text": "Chapter 21: Troubleshooting Linux\n559\n21To enable Alt+SysRq keystrokes, the system must have already set /proc/sys/\nkernel/sysrq  to 1. An easy way to do this is to add kernel.sysrq = 1 to the \n/etc/sysctl.conf  file. Also, you must run the Alt+SysRq keystrokes from a text-\nbased interface (such as the virtual console you see when you press Ctrl+Alt+F2).\nWith kernel.sysrq  set to 1 , you can kill the process on your system with the \nhighest OOM score by pressing Alt+SysRq+f from a text-based interface. A listing of \nall processes running on your system appears on the screen with the name of the \nprocess that was killed listed at the end. You can repeat those keystrokes until you \nhave killed enough processes to be able to access the system normally from the shell \nagain.\nTroubleshooting in Rescue Mode\nIf your Linux system becomes unbootable, your best option for fixing it is probably to go \ninto rescue mode . To go into rescue mode, you bypass the Linux system installed on your \nhard disk and boot some rescue medium (such as a bootable USB key or boot CD). After the \nrescue medium boots, it tries to mount any filesystems that it can find from your Linux \nsystem so that you can repair any problems.\nFor many Linux distributions, the installation CD or DVD can serve as boot media for going \ninto rescue mode. Here\u2019s an example of how to use a RHEL installation DVD to go into rescue \nmode to fix a broken Linux system (burn the image to a USB drive if your computer doesn\u2019t \nhave a DVD drive):\n1. Get the installation CD or DVD image that you want to use and burn it to the \nappropriate medium (CD or DVD). See Appendix A, \u201cMedia,\u201d for information on \nburning CDs and DVDs. (For my example, I used a Red Hat Enterprise Linux 8 instal -\nlation DVD.)\n2. Insert the CD or DVD into the drive on the computer that has the broken Linux \nsystem installed and reboot.\n3. The moment you see the BIOS screen, press the function key noted on that screen \nfor selecting the boot device (possibly the F12 or F2 function key).\n4. Choose the drive (CD or DVD) from the list of bootable devices, and press Enter.\n5. When the RHEL 8 boot menu appears, use the arrow keys to highlight the word \nTroubleshooting  and press Enter. In other Linux boot media, the selection could say Note\nThere are many other Alt+SysRq keystrokes that you can use to deal with an unresponsive system. For example, \nAlt+SysRq+e terminates all processes except for the init  process. Alt+SysRq+t dumps a list of all current tasks \nand information about those tasks to the console. To reboot the system, press Alt+SysRq+b. See the sysrq.\ntxt file in the /usr/share/doc/kernel-doc*/Documentation  directory for more information about \nAlt+SysRq keystrokes.", "doc_id": "f4a1ed1f-2fe5-44ae-bb92-0cda14799793", "embedding": null, "doc_hash": "66fdbdccb9fd3c98bda3c1487ec261b2937b3aa1e925f59077d029f01e633a21", "extra_info": {"page_label": "583"}, "node_info": {"start": 0, "end": 2732}, "relationships": {"1": "299e83cf-8f50-441e-8eef-0da70b8dad58"}}, "__type__": "1"}, "a6c6a51e-108a-4da7-b7da-9f1c09e20e16": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator560Rescue Mode  or something similar. On the next screen that appears, select Rescue a \nRed Hat Enterprise Linux system and press Enter.\n6. After a few moments, the Linux system on the rescue medium boots up. When \nprompted, select your language and keyboard. You are asked if you want to start \nnetwork interfaces on the system.\n7. If you think that you might need to get something from another system on your \nnetwork (such as RPM packages or debugging tools), select Yes and try to configure \nyour network interfaces. You are then asked if you want to try to mount filesys -\ntems from your installed Linux system under /mnt/sysimage .\n8. Select Continue to have your filesystems mounted (if possible) under the /mnt/\nsysimage  directory. If this is successful, a Rescue message appears, telling you \nthat your filesystems have been mounted under /mnt/sysimage .\n9. Select OK to continue. You should see a shell prompt for the root user ( #). You are \nready to begin troubleshooting from rescue mode. After you are in rescue mode, the \nportion of your filesystem that is not damaged is mounted under the /mnt/sysi -\nmage  directory. Type ls /mnt/sysimage  to check that the files and directories \nfrom the hard disk are there.\nRight now, the root of the filesystem ( /) is from the filesystem that comes on the rescue \nmedium. To troubleshoot your installed Linux system, however, you can type the follow -\ning command:\n# chroot /mnt/sysimage\nNow the /mnt/sysimage  directory becomes the root of your filesystem ( /) so that it looks \nlike the filesystem installed on your hard disk. Here are some things that you can do to \nrepair your system while you are in rescue mode:\nFix /etc/fstab.  If your filesystems couldn\u2019t mount because of an error in your /etc/\nfstab  file, you could try to correct any entries that might have problems (such as \nwrong device names or a mount point directory that doesn\u2019t exist). Type mount -a  \nto make sure that all of the filesystems mount.\nReinstall missing components. It might be that the filesystems are fine, but \nthe system failed to boot because some critical command or configuration file is \nmissing. You might be able to fix the problem by reinstalling the package with the \nmissing components. For example, if someone had deleted /bin/mount  by mistake, \nthe system would have no command to mount filesystems. Reinstalling the util-\nlinux  package would replace the missing mount  command.\nCheck the filesystems.  If your booting problems stem from corrupt filesystems, \nyou can try running the fsck  command (filesystem check) to see if there is any \ncorruption on the disk partition. If there is, fsck  attempts to correct problems it \nencounters.", "doc_id": "a6c6a51e-108a-4da7-b7da-9f1c09e20e16", "embedding": null, "doc_hash": "49a2cf516b978025962388cdfdd572672da24b0e47beca122ffafce5018c37fb", "extra_info": {"page_label": "584"}, "node_info": {"start": 0, "end": 2743}, "relationships": {"1": "509c349c-f793-463a-a46c-f368578bc3db"}}, "__type__": "1"}, "f8f2d3af-cfd0-4a3e-b985-2a2c561f9d95": {"__data__": {"text": "Chapter 21: Troubleshooting Linux\n561\n21When you are finished fixing your system, type exit  to exit the chroot  environment, \nand return to the filesystem layout that the live medium sees. If you are completely fin -\nished, type reboot  to restart your system. Be sure to pop out the medium before the \nsystem restarts.\nSummary\nTroubleshooting problems in Linux can start from the moment you turn on your computer. \nProblems can occur with your computer BIOS, boot loader, or other parts of the boot process \nthat you can correct by intercepting them at different stages of the boot process.\nAfter the system has started, you can troubleshoot problems with software packages, net -\nwork interfaces, or memory exhaustion. Linux comes with many tools for finding and cor -\nrecting any part of the Linux system that might break down and need fixing.\nThe next chapter covers the topic of Linux security. Using the tools described in that chap -\nter, you can provide access to those services that you and your users need while blocking \naccess to system resources that you want to protect from harm.\nExercises\nThe exercises in this section enable you to try out useful troubleshooting techniques in \nLinux. Because some of the techniques described here can potentially damage your system, \nI recommend that you do not use a production system that you cannot risk damaging. See \nAppendix B for suggested solutions.\nThese exercises relate to troubleshooting topics in Linux. They assume that you are booting \na PC with standard BIOS. To do these exercises, you need to be able to reboot your computer \nand interrupt any work it may be doing.\n1. Boot your computer, and as soon as you see the BIOS screen, go into Setup mode as \ninstructed on the BIOS screen.\n2. From the BIOS Setup screen, determine if your computer is 32-bit or 64-bit, if it \nincludes virtualization support, and if your network interface card is capable of \nPXE booting.\n3. Reboot, and just after the BIOS screen disappears, when you see the countdown to \nbooting the Linux system, press any key to get to the GRUB boot loader.\n4. From the GRUB boot loader, add an option to boot up to runlevel 1 so that you can \ndo some system maintenance.\n5. After the system boots up, look at the messages that were produced in the kernel \nring buffer that show the activity of the kernel as it booted up.\n6. In Fedora or RHEL, run a trial yum update  and exclude any kernel package that is \navailable.", "doc_id": "f8f2d3af-cfd0-4a3e-b985-2a2c561f9d95", "embedding": null, "doc_hash": "12dd2149f24dc8e6c30bcae64f8d843b17dbc2a9262f1134b7f7246ffd966bf9", "extra_info": {"page_label": "585"}, "node_info": {"start": 0, "end": 2453}, "relationships": {"1": "a928a780-075e-4ce1-930c-dce30ef6fe3b"}}, "__type__": "1"}, "a4760bd8-cc29-4b3d-8c0c-f002b86c24f8": {"__data__": {"text": "Part IV: Becoming a Linux Server Administrator5627. Check to see what processes are listening for incoming connections on your system.\n8. Check to see what ports are open on your external network interface.\n9. Run the top  command in a Terminal window. Open a second Terminal window, \nclear your page cache, and note on the top  screen if more RES memory is now \navailable.\n10. With Cockpit enabled on your system, access Cockpit to view details on the system\u2019s \nongoing memory and swap usage.", "doc_id": "a4760bd8-cc29-4b3d-8c0c-f002b86c24f8", "embedding": null, "doc_hash": "51e90acf1af95b3a9b7c33af4a86c284694adc8aea6d15bd36c9ee7e75fb3e2e", "extra_info": {"page_label": "586"}, "node_info": {"start": 0, "end": 493}, "relationships": {"1": "42c1e297-610c-4db4-8ce9-60104aa68a1e"}}, "__type__": "1"}, "e02b6e93-b012-4466-bece-2edfd493235f": {"__data__": {"text": "Part VIN THIS PART\nChapter\u00a022 \nUnderstanding Basic Linux Security\nChapter\u00a023 \nUnderstanding Advanced Linux Security\nChapter\u00a024 \nEnhancing Linux Security with SELinux\nChapter\u00a025 \nSecuring Linux on a NetworkLearning Linux Security \nTechniques\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "e02b6e93-b012-4466-bece-2edfd493235f", "embedding": null, "doc_hash": "45aee66e7513449b468f96f28a4ae5e7ae7b73409da3c49eea11274d415d4172", "extra_info": {"page_label": "587"}, "node_info": {"start": 0, "end": 363}, "relationships": {"1": "e4c8e3ce-b4e8-4a3a-a380-6cbc0e34eb8d"}}, "__type__": "1"}, "ec3e1332-847c-4661-b304-8758242fe868": {"__data__": {"text": "565\nCHAPTER22\nUnderstanding Basic \nLinux Security\nIN THIS CHAPTER\nImplementing basic security\nMonitoring securityAuditing and reviewing security\nAt its most basic level, securing a Linux system starts with physical security, data security, \nuser accounts protection, and software security. Over time, you need to monitor that system to make sure it remains safe.\nSome of the questions that you need to ask yourself include the following:\n\u25a0 \u25a0Who can get to the system physically?\n\u25a0 \u25a0Are backup copies of data being made in case of disaster?\n\u25a0 \u25a0How well are user accounts secured?\n\u25a0 \u25a0Does the software come from a secure Linux distribution, and are security patches up to date?\n\u25a0 \u25a0Have you been monitoring the system to make sure that it has not been cracked or corrupted?\nThis chapter starts by covering basic Linux security topics. Subsequent chapters go deeper into advanced security mechanisms.\nImplementing Physical Security\nA lock on the computer server room door is the first line of defense. Although a very simple con-cept, it is often ignored. Access to the physical server means access to all of the data that it con-tains. No security software can fully protect your systems if someone with malicious intent has physical access to the Linux server.\nBasic server room physical security includes items such as these:\n\u25a0 \u25a0A lock or security alarm on the server room door\n\u25a0 \u25a0Access controls that allow only authorized access and that identify who accessed the room \nand when the access occurred, such as a card key entry system\nLinux\u00ae Bible , Tenth Edition. Christopher Negus.\n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "ec3e1332-847c-4661-b304-8758242fe868", "embedding": null, "doc_hash": "bd6335e36e0d8d1d0b319c1b23abc0d238be66dd62bffe2d4d5a5154b4b0d46f", "extra_info": {"page_label": "588"}, "node_info": {"start": 0, "end": 1654}, "relationships": {"1": "6052adcc-6ff7-45b1-a42f-3b47355c6810"}}, "__type__": "1"}, "c9a7a47e-ef38-4c07-bc1a-f99a040ded96": {"__data__": {"text": "Part V: Learning Linux Security Techniques566\u25a0\u25a0A sign stating \u201cno unauthorized access allowed\u201d on the door\n\u25a0\u25a0Policies on who can access the room and when that access may occur for groups \nsuch as the cleaning crew, server administrators, and others\nPhysical security includes environmental controls. Appropriate fire suppression systems and \nproper ventilation for your server room must be implemented.\nImplementing disaster recovery\nDisaster recovery plans should include these things:\n\u25a0\u25a0What data is to be included in backups\n\u25a0\u25a0Where backups are to be stored\n\u25a0\u25a0How long backups are maintained\n\u25a0\u25a0How backup media is rotated through storage\nBackup data, media, and software should be included in your Access Control Matrix \nchecklist.\nCaution  \nIt is important to determine how many backup copies of each object should be maintained. While you may need only \nthree backup copies of one particular object, another object may be important enough to require maintaining more \ncopies.\nBackup utilities on a Linux system include the following:\n\u25a0\u25a0amanda  (Advanced Maryland Automatic Network Disk Archiver)\n\u25a0\u25a0cpio\n\u25a0\u25a0dump/restore\n\u25a0\u25a0tar\n\u25a0\u25a0rsync\nThe cpio , dump/restore , and tar  utilities are typically pre-installed on a Linux distri-\nbution. A simple, yet effective tool for backing up data over networks is the rsync  utility. \nWith rsync , you can set up a cron  job to keep copies of all data in selected directories or \nmirror exact copies of directories on remote machines.\nOf the tools just mentioned, only amanda  is not typically installed by default. However, \namanda  is extremely popular because it comes with a great deal of flexibility and can even \nback up a Windows system. If you need more information on the amanda  backup utility, \nsee amanda.org . Ultimately, the utility you select must meet your organization\u2019s particu -\nlar security needs for backup.\nSecuring user accounts\nUser accounts are part of the authentication process allowing users into the Linux system. \nProper user account management enhances a system\u2019s security. Setting up user accounts ", "doc_id": "c9a7a47e-ef38-4c07-bc1a-f99a040ded96", "embedding": null, "doc_hash": "c15a791467b6eea09e62a63e7ef650cdeef4a30880115eb160a6541725944464", "extra_info": {"page_label": "589"}, "node_info": {"start": 0, "end": 2069}, "relationships": {"1": "3134e8c7-1b91-433f-a477-0db9e3644e25"}}, "__type__": "1"}, "b4b7480c-472a-4674-ab75-e02c859593e7": {"__data__": {"text": "Chapter 22: Understanding Basic Linux Security\n567\n22was covered in Chapter\u00a011, \u201cManaging User Accounts.\u201d However, a few additional rules are \nnecessary to increase security through user account management:\n\u25a0\u25a0One user per user account.\n\u25a0\u25a0Limit access to the root user account.\n\u25a0\u25a0Set expiration dates on temporary accounts.\n\u25a0\u25a0Remove unused user accounts.\nOne user per user account\nAccounts should enforce accountability. Thus, multiple people should not be logging in to \none account. When multiple people share an account, there is no way to prove a particular \nindividual completed a particular action.\nLimiting access to the root user account\nIf multiple people can log in to the root account, you have another repudiation situation. \nYou cannot track individual use of the root account. To allow tracking of the root account use \nby individuals, a policy for using sudo  (see Chapter\u00a08, \u201cLearning System Administration\u201d) \ninstead of logging into root should be instituted.\nInstead of giving multiple people root permission on a Linux system, you can grant root \naccess on a per-command basis with the sudo  command. Using sudo  provides the follow -\ning security benefits:\n\u25a0\u25a0The root password does not have to be given out.\n\u25a0\u25a0You can fine-tune command access.\n\u25a0\u25a0All sudo  use (who, what, when) is recorded in /var/log/secure , including any \nfailed sudo  access attempts. Recent Linux systems store all sudo  access in the \nsystemd journal (type journalctl -f  to watch live sudo  access attempts, along \nwith other system messages).\n\u25a0\u25a0After you grant someone sudo  permission, you can try to restrict root access to \ncertain commands in the /etc/sudoers  file (with the visudo  command). How -\never, after you grant root permission to a user, even in a limited way, it is difficult \nto be sure that a determined user can\u2019t find ways to gain full root access to your \nsystem and do what they want to it.\nOne way to keep a misbehaving administrator in check is to have security messages \nintended for the /var/log/secure  file sent to a remote log server to which none of the \nlocal administrators have access. In that way, any misuse of root privilege is attached to a \nparticular user and is logged in a way that the user can\u2019t cover their tracks.\nSetting expiration dates on temporary accounts\nIf you have consultants, interns, or temporary employees who need access to your Linux \nsystems, it is important to set up their user accounts with expiration dates. The expiration \ndate is a safeguard, in case you forget to remove their accounts when they no longer need \naccess to your organization\u2019s systems.", "doc_id": "b4b7480c-472a-4674-ab75-e02c859593e7", "embedding": null, "doc_hash": "63a3c59c8ceb195e9f3ec3ffa71110bf9bd9f0c01ae4a8d7e8ed9346791746c1", "extra_info": {"page_label": "590"}, "node_info": {"start": 0, "end": 2610}, "relationships": {"1": "9202f5c4-9382-4d33-80a6-ccf5da4411cd"}}, "__type__": "1"}, "9cd169d3-0bdd-464a-b62f-421fee763c74": {"__data__": {"text": "Part V: Learning Linux Security Techniques568To set a user account with an expiration date, use the usermod  command. The format \nis usermod -e  yyyy-mm-dd user_name. In the following code, the account tim  has \nbeen set to expire on January 1, 2021.\n# usermod -e 2021-01-01 tim\nTo verify that the account has been properly set to expire, double-check yourself by using \nthe chage  command. The chage  command is primarily used to view and change a user \naccount\u2019s password aging information. However, it also can access account expiration infor -\nmation. The -l  option allows you to list various information to which chage  has access. \nTo keep it simple, pipe the output from the chage  command into grep  and search for the \nword Account . This produces only the user account\u2019s expiration date.\n# chage -l tim | grep Account\nAccount expires                                   :  Jan  01,  2021\nAs you can see, the account expiration date was successfully changed for tim  to \n January 1, 2021.\nTip\nIf you do not use the /etc/shadow  file for storing your account passwords, the chage  utility doesn\u2019t work. In \nmost cases, this is not a problem because the /etc/shadow  file is configured to store password information by \ndefault on most Linux systems.\nSet account expiration dates for all transitory employees. In addition, consider reviewing \nall user account expiration dates as part of your security monitoring activities. These activ -\nities help to eliminate any potential backdoors to your Linux system.\nRemoving unused user accounts\nKeeping old expired accounts around is asking for trouble. After a user has left an organi-\nzation, it is best to perform a series of steps to remove their account along with data:\n1. Find files on the system owned by the account, using the find / -user  \nusername  command.\n2. Expire or disable the account.\n3. Back up the files.\n4. Remove the files or reassign them to a new owner.\n5. Delete the account from the system.\nProblems occur when step 5 is forgotten and expired or disabled accounts are still on the \nsystem. A malicious user gaining access to your system could renew the account and then \nmasquerade as a legitimate user.\nTo find these accounts, search through the /etc/shadow  file. The account\u2019s expiration date is \nin the eighth field of each record. It would be convenient if a date format were used. Instead, \nthis field shows the account\u2019s expiration date as the number of days since January 1, 1970.", "doc_id": "9cd169d3-0bdd-464a-b62f-421fee763c74", "embedding": null, "doc_hash": "7ae1ac7b521e06ef6f2dedac05ef51a343eada35cbde63b987754059f6def71c", "extra_info": {"page_label": "591"}, "node_info": {"start": 0, "end": 2465}, "relationships": {"1": "0c43243d-f759-4795-92c4-3cf0246fd358"}}, "__type__": "1"}, "5fcff00f-a6ce-493b-8295-7f3714e66941": {"__data__": {"text": "Chapter 22: Understanding Basic Linux Security\n569\n22You can use a two-step process to find expired accounts in the /etc/shadow  file auto -\nmatically. First, set up a shell variable (see Chapter\u00a07, \u201cWriting Simple Shell Scripts\u201d) with \ntoday\u2019s date in \u201cdays since January 1, 1970\u201d format. Then, using the gawk  command, you \ncan obtain and format the information needed from the /etc/shadow  file.\nSetting up a shell variable with the current date converted to the number of days since \nJanuary 1, 1970 is not particularly difficult. The date  command can produce the number \nof seconds since January 1, 1970. To get what you need, divide the result from the date  \ncommand by the number of seconds in a day: 86,400. The following demonstrates how to \nset up the shell variable TODAY .\n# TODAY=$(echo $(($(date --utc --date \"$1\" +%s)/86400)))\n# echo $TODAY\n16373\nNext, the accounts and their expiration dates are pulled from the /etc/shadow  file \nusing gawk . The gawk  command is the GNU version of the awk  program used in UNIX. \nThe command\u2019s output is shown in the code that follows. As you would expect, many of \nthe accounts do not have an expiration date. However, two accounts, Consultant  and \nIntern , show an expiration date in the \u201cdays since January 1, 1970\u201d format. Note that you \ncan skip this step. It is just for demonstration purposes.\n# gawk -F: '{print $1,$8}' /etc/shadow\n...\nchrony\ntcpdump\njohndoe\nConsultant 13819\nIntern 13911\nThe $1  and $8  in the gawk  command represent the username and expiration date fields in \nthe /etc/shadow  file records. To check those accounts\u2019 expiration dates and see if they \nare expired, a more refined version of the gawk  command is needed.\n# gawk -F: '{if (($8 > 0) && ($TODAY > $8)) print $1}' /etc/shadow\nConsultant\nIntern\nOnly accounts with an expiration date are collected by the ( $8 > 0 ) portion of the gawk  \ncommand. To make sure that these expiration dates are past the current date, the TODAY  \nvariable is compared with the expiration date field, $8 . If TODAY  is greater than the \naccount\u2019s expiration date, the account is listed. As you can see in the preceding example, \ntwo expired accounts still exist on the system and need to be removed.\nThat is all you need to do. Set up your TODAY  variable and execute the gawk  command. \nAll of the expired accounts in the /etc/shadow  file are listed for you. To remove these \naccounts, use the userdel  command.\nUser accounts are only a portion of the authentication process allowing users into the \nLinux system. User account passwords also play an important role in the process.", "doc_id": "5fcff00f-a6ce-493b-8295-7f3714e66941", "embedding": null, "doc_hash": "9f3fd18d513f6aa6337a8d6d7460997d9dda2d0c162f35d73c8a0ecec1990511", "extra_info": {"page_label": "592"}, "node_info": {"start": 0, "end": 2601}, "relationships": {"1": "19200d45-8bc6-42b0-950f-fccd948360ac"}}, "__type__": "1"}, "13f4993c-4f7c-487c-82aa-f0436b0628d9": {"__data__": {"text": "Part V: Learning Linux Security Techniques570Securing passwords\nPasswords are the most basic security tool of any modern operating system and, conse -\nquently, the most commonly attacked security feature. It is natural for users to want to \nchoose a password that is easy to remember, but often this means that they choose a pass -\nword that is also easy to guess.\nBrute force methods are commonly employed to gain access to a computer system. Trying the \npopular passwords often yields results. Some of the most common passwords are as follows:\n\u25a0\u25a0123456\n\u25a0\u25a0Password\n\u25a0\u25a0princess\n\u25a0\u25a0rockyou\n\u25a0\u25a0abc123\nJust use your favorite Internet search engine and look for \u201ccommon passwords.\u201d If you can \nfind these lists, then malicious attackers can too. Obviously, choosing good passwords is \ncritical to having a secure system.\nChoosing good passwords\nIn general, a password must not be easy to guess, be common or popular, or be linked to \nyou in any way. Here are some rules to follow when choosing a password:\n\u25a0\u25a0Do not use any variation of your login name or your full name.\n\u25a0\u25a0Do not use a dictionary word.\n\u25a0\u25a0Do not use proper names of any kind.\n\u25a0\u25a0Do not use your phone number, address, family, or pet names.\n\u25a0\u25a0Do not use website names.\n\u25a0\u25a0Do not use any contiguous line of letters or numbers on the keyboard (such as \n\u201cqwerty\u201d or \u201casdfg\u201d).\n\u25a0\u25a0Do not use any of the above with added numbers or punctuation at the front or end \nor typed backward.\nSo now that you know what not to do, look at the two primary items that make a \nstrong password:\n1. A password should be at least 15 to 25 characters in length.\n2. A password should contain all of the following:\n\u25a0\u25a0Lowercase letters\n\u25a0\u25a0Uppercase letters\n\u25a0\u25a0Numbers\n\u25a0\u25a0Special characters, such as : ! $ % * ( ) - + = , < > : : \u2033 \u2019", "doc_id": "13f4993c-4f7c-487c-82aa-f0436b0628d9", "embedding": null, "doc_hash": "ccee096c172d671eb8fe1d396dd1979703509d357198240842e990c3d3939eea", "extra_info": {"page_label": "593"}, "node_info": {"start": 0, "end": 1758}, "relationships": {"1": "1a067d15-eebf-4d59-9323-55007e5c502c"}}, "__type__": "1"}, "101989c5-5d47-42c9-b8e5-bae826260e1d": {"__data__": {"text": "Chapter 22: Understanding Basic Linux Security\n571\n22Twenty-five characters is a long password. However, the longer the password, the more \nsecure it is. What your organization chooses as the minimum password length depends on \nits security needs.\ntip\nGibson Research Center has some excellent material on strong passwords, including an article called \u201cHow big is \nyour haystack.\u00a0.\u00a0.and how well hidden is your needle?\u201d at grc.com/haystack.htm .\nChoosing a good password can be difficult. It has to be hard enough not to be guessed and \neasy enough for you to remember. A good way to choose a strong password is to take the \nfirst letter from each word of an easily remembered sentence. Be sure to add numbers, spe -\ncial characters, and varied case. The sentence you choose should have meaning only to you \nand should not be publicly available. Table\u00a022.1 lists examples of strong passwords and the \ntricks used to remember them.\nThe passwords look like nonsense but are actually rather easy to remember. Of course, be \nsure not to use the passwords listed here. Now that they are public, they will be added to \nmalicious attackers\u2019 dictionaries.\nSetting and changing passwords\nYou set your own password using the passwd  command. Type the passwd  command and \nit allows you to change your password. First, it prompts you to enter your old password. To \nprotect against someone shoulder surfing and learning your password, the password is not \ndisplayed as you type.\nAssuming that you type your old password correctly, the passwd command prompts you \nfor the new password. When you type your new password, it is checked using a utility called \ncracklib to determine whether it is a good or bad password. Non-root users are required to \ntry a different password if the one they have chosen is not a good password.\nThe root user is the only user who is permitted to assign bad passwords. After the password \nhas been accepted by cracklib , the passwd  command asks you to enter the new pass -\nword a second time to make sure that there are no typos (which are hard to detect when \nyou can\u2019t see what you are typing).TABLE 22.1  Ideas for Good Passwords\nPassword How to Remember It\nMrci7yo! My rusty car is 7 years old!\n2emBp1ib 2 elephants make BAD pets, 1 is better\nItMc?Gib Is that MY coat? Give it back", "doc_id": "101989c5-5d47-42c9-b8e5-bae826260e1d", "embedding": null, "doc_hash": "9ee90b61f84c8f50fd01b760b539627008f8e2ad23e1d8a3707a9f2fc8968ca6", "extra_info": {"page_label": "594"}, "node_info": {"start": 0, "end": 2304}, "relationships": {"1": "ae3ffe52-600a-4399-86b3-02cd815d3336"}}, "__type__": "1"}, "ef073839-8e76-4cd9-9d9d-ae92b71b6487": {"__data__": {"text": "Part V: Learning Linux Security Techniques572When running as root, changing a user\u2019s password is possible by supplying that user\u2019s login \nname as a parameter of the passwd  command, as in this example:\n# passwd joe\nChanging password for user joe.\nNew UNIX password: ********\nRetype new UNIX password: ********\npasswd: all authentication tokens updated successfully.\nHere, the passwd  command prompts you twice to enter a new password for joe . It does \nnot prompt for his old password in this case.\nEnforcing best password practices\nNow you know what a good password looks like and how to change a password, but how do \nyou enforce it on your Linux system? One place to start is with the PAM facility. With PAM, \nyou can define exact requirements that passwords must meet. For example, to ensure that \npasswords must be 12 characters long, with at least 2 numbers, 3 uppercase letters, and 2 \nlowercase letters, and are different than the previous passwords, you can add the following \nline to either the /etc/pam.d/common-password  or /etc/pam.d/common-auth  file:\npassword requisite pam_cracklib.so minlen=12, dcredit=2, ucredit=3, \nlcredit=2, difok=4 \nThe next question is, How can you make people change passwords? It can become tiresome \nto come up with new, strong passwords every 30 days! That is why some enforcing tech -\nniques are often necessary.\ntip\nIf users are having a difficult time creating secure and unique passwords, consider installing the pwgen  utility on \nyour Linux system. This open source password generating utility creates passwords that are made to be pronounce -\nable and memorable. You can use these generated words as a starting point for creating account passwords.\nDefault values in the /etc/login.defs  file for new accounts were covered in Chapter\u00a011. \nWithin the login.defs  file are some settings affecting password aging and length:\nPASS_MAX_DAYS     30\nPASS_MIN_DAYS     5PASS_MIN_LEN      16PASS_WARN_AGE     7\nIn this example, the maximum number of days, PASS_MAX_DAYS , until the password must \nbe changed is 30. The number that you set here is dependent upon your particular account \nsetup. For organizations that practice one person to one account, this number can be much \nlarger than 30. If you do have shared accounts or multiple people know the root password, \nit is imperative that you change the password often. This practice effectively refreshes the \nlist of those who know the password.\nTo keep users from changing their password to a new password and then immediately \nchanging it right back, you need to set the PASS_MIN_DAYS to a number larger than 0. In \nthe preceding example, the soonest a user could change their password again is 5 days.", "doc_id": "ef073839-8e76-4cd9-9d9d-ae92b71b6487", "embedding": null, "doc_hash": "4d7f60b9ea5d7e6648df8f59911ab15f5ba27c0293d5e9299e7af1b5a917a0b9", "extra_info": {"page_label": "595"}, "node_info": {"start": 0, "end": 2700}, "relationships": {"1": "67d0adea-ff04-48c1-8cf4-76ec3b030028"}}, "__type__": "1"}, "fa8aa981-7e24-43f2-945b-934d03eca0dc": {"__data__": {"text": "Chapter 22: Understanding Basic Linux Security\n573\n22The PASS_WARN_AGE setting is the number of days a user is warned before being forced to \nchange their password. People tend to need lots of warnings and prodding, so the preceding \nexample sets the warning time to 7 days.\nEarlier in the chapter, I mentioned that a strong password is between 15 and 25 characters \nlong. With the PASS_MIN_LEN setting, you can force users to use a certain minimum \nnumber of characters in their passwords. The setting you choose should be based upon your \norganization\u2019s security life cycle plans.\nNote\nUbuntu does not have the PASS_MIN_LEN setting in its login.defs  file. Instead, this setting is handled by the \nPAM utility. PAM is covered in Chapter\u00a023, \u201cUnderstanding Advanced Linux Security.\u201d\nFor accounts that have already been created, you need to control password aging via the \nchage  command. The options needed to control password aging with chage  are listed in \nTable\u00a022.2. Notice that there is not a password length setting in the chage  utility.\nThe example that follows uses the chage  command to set password aging parameters for \nthe tim  account. All three options are used at once.\n# chage -l tim | grep days\nMinimum number of days between password change         : 0\nMaximum number of days between password change         : 99999\nNumber of days of warning before password expires      : 7\n# chage -M 30 -m 5 -W 7 tim\n# chage -l tim | grep days\nMinimum number of days between password change         : 5\nMaximum number of days between password change         : 30\nNumber of days of warning before password expires      : 7\nYou can also use the chage  command as another method of account expiration, which is \nbased upon the account\u2019s password expiring. Earlier, the usermod  utility was used for \naccount expiration. Use the chage  command with the -M  and the -I  options to lock the TABLE 22.2  chage  Options\nOption Description\n-M Sets the maximum number of days before a password needs to be changed. Equiva -\nlent to PASS_MAX_DAYS in /etc/login.defs .\n-m Sets the minimum number of days before a password can be changed again. Equiva -\nlent to PASS_MIN_DAYS in /etc/login.defs .\n-W Sets the number of days a user is warned before being forced to change the account \npassword. Equivalent to PASS_WARN_AGE in /etc/login.defs .", "doc_id": "fa8aa981-7e24-43f2-945b-934d03eca0dc", "embedding": null, "doc_hash": "f7b68f62191fa8006253b1b607311d2925eb34ff73f5d0bb2cc28fa54e218ac7", "extra_info": {"page_label": "596"}, "node_info": {"start": 0, "end": 2336}, "relationships": {"1": "bf69b4f3-91e7-44ed-8b4d-55b2023937f4"}}, "__type__": "1"}, "fa1ea493-82e1-45f7-b3a2-65fba75c8af7": {"__data__": {"text": "Part V: Learning Linux Security Techniques574account. In the code that follows, the tim  account is viewed using chage -l . Only the \ninformation for tim \u2019s password settings are extracted.\n# chage -l tim | grep Password\nPassword expires                 : never\nPassword inactive                : never\nYou can see that there are no settings for password expiration ( Password expires ) or \npassword inactivity ( Password inactive ). In the following code, the account is set to be \nlocked 5 days after tim \u2019s password expires by using only the -I  option.\n# chage -I 5 tim\n# chage -l tim | grep Password\nPassword expires                 : never\nPassword inactive                : never\nNotice that no settings changed! Without a password expiration set, the -I  option has no \neffect. Thus, using the -M  option, the maximum number of days is set before the password \nexpires and the setting for the password inactivity time should take hold.\n# chage -M 30 -I 5 tim\n# chage -l tim | grep Password\nPassword expires                 : Mar 03, 2017\nPassword inactive                : Mar 08, 2017\nNow, tim \u2019s account will be locked 5 days after his password expires. This is helpful in sit -\nuations where an employee has left the company but their user account has not yet been \nremoved. Depending upon your organization\u2019s security needs, consider setting all accounts \nto lock a certain number of days after passwords have expired.\nUnderstanding the password files and password hashes\nEarly Linux systems stored their passwords in the /etc/passwd  file. The passwords \nwere hashed. A hashed password  is created using a one-way mathematical process. After \nyou create the hash, you cannot re-create the original characters from the hash. Here\u2019s \nhow it works.\nWhen a user enters the account password, the Linux system rehashes the password and \nthen compares the hash result to the original hash in /etc/passwd . If they match, the \nuser is authenticated and allowed into the system.\nThe problem with storing these password hashes in the /etc/passwd  file has to do with \nthe filesystem security settings (see Chapter\u00a04, \u201cMoving Around the Filesystem\u201d). The file -\nsystem security settings for the /etc/passwd  file are listed here:\n# ls -l /etc/passwd\n-rw-r--r--. 1 root root 1644 Feb  2 02:30 /etc/passwd\nAs you can see, everyone can read the password file. You might think that this is not a \nproblem because the passwords are all hashed. However, individuals with malicious intent \nhave created files called rainbow tables . A rainbow table is simply a dictionary of potential ", "doc_id": "fa1ea493-82e1-45f7-b3a2-65fba75c8af7", "embedding": null, "doc_hash": "d3256b67d650cdf2f44664bde78313086a154e4a0b1e522075f986184dda0b46", "extra_info": {"page_label": "597"}, "node_info": {"start": 0, "end": 2580}, "relationships": {"1": "fcb03a3f-9786-49ee-93f4-8fbbb8c66181"}}, "__type__": "1"}, "f30dd88c-4740-455e-bf42-9d10855aeca3": {"__data__": {"text": "Chapter 22: Understanding Basic Linux Security\n575\n22passwords that have been hashed. For instance, the rainbow table would contain the hash \nfor the popular password \u201cPassword,\u201d which is as follows:\n$6$dhN5ZMUj$CNghjYIteau5xl8yX.f6PTOpendJwTOcXjlTDQUQZhhy\nV8hKzQ6Hxx6Egj8P3VsHJ8Qrkv.VSR5dxcK3QhyMc.\nBecause of the ease of access to the password hashes in the /etc/passwd  file, it is only a \nmatter of time before a hashed password is matched in a rainbow table and the plain-text \npassword is uncovered.\nnote\nSecurity experts will tell you that the passwords are not just hashed but also salted. Salting a hash means that a \nrandomly generated value is added to the original password before it is hashed. This makes it even more difficult for \nthe hashed password to be matched to its original password. However, in Linux, the hash salt is also stored with the \nhashed passwords. Thus, read access to the /etc/passwd  file means that you have the hash value and its salt.\nThus, the hashed passwords were moved to a new configuration file, /etc/shadow , many \nyears ago. This file has the following security settings:\n# ls -l /etc/shadow\n----------. 1 root root 1049 Feb  2 09:45 /etc/shadow\n \nDespite having no permissions open, root, but no other user, can view this file. Thus, \nthe hashed passwords are protected. Here is the tail end of a /etc/shadow  file. You can \nsee that there are long, nonsensical character strings in each user's record. Those are the \nhashed passwords.\n# tail -2 /etc/shadow\njohndoe:$6$jJjdRN9/qELmb8xWM1LgOYGhEIxc/:15364:0:99999:7:::\nTim:$6$z760AJ42$QXdhFyndpbVPVM5oVtNHs4B/:15372:5:30:7:16436::\n \nCaution  \nYou may inherit a Linux system that still uses the old method of keeping the hashed passwords in the /etc/\npasswd  file. It is easy to fix. Just use the pwconv  command, and the /etc/shadow  file is created and hashed \npasswords moved to it.\nThe following are also stored in the /etc/shadow  file, in addition to the account name \nand hashed password:\n\u25a0\u25a0Number of days (since January 1, 1970) since the password was changed\n\u25a0\u25a0Number of days before the password can be changed\n\u25a0\u25a0Number of days before a password must be changed\n\u25a0\u25a0Number of days to warn a user before a password must be changed\n\u25a0\u25a0Number of days after a password expires that an account is disabled\n\u25a0\u25a0Number of days (since January 1, 1970) that an account has been disabled", "doc_id": "f30dd88c-4740-455e-bf42-9d10855aeca3", "embedding": null, "doc_hash": "eb1d9f908d6b84c5961fb543f966463b9fee2b3eb822f0cb24456ffda841fdd1", "extra_info": {"page_label": "598"}, "node_info": {"start": 0, "end": 2377}, "relationships": {"1": "ae2afd6b-44b8-4dcf-9f3a-99bcb0ac56f4"}}, "__type__": "1"}, "70190edb-2116-4383-93e7-9dee271d1caa": {"__data__": {"text": "Part V: Learning Linux Security Techniques576This should sound familiar, as they are the settings for password aging covered earlier in \nthe chapter. Remember that the chage  command does not work if you do not have an  \n/etc/shadow  file set up or if the /etc/login.defs  file is not available.\nObviously, filesystem security settings are very important for keeping your Linux system \nsecure. This is especially true with all Linux systems\u2019 configuration files and others.\nSecuring the filesystem\nAnother important part of securing your Linux system is setting proper filesystem security. \nThe basics for security settings were covered in Chapter\u00a04 and Access Control Lists (ACLs) \nin Chapter\u00a011. However, there are a few additional points that need to be added to your \nknowledge base.\nManaging dangerous filesystem permissions\nIf you gave full rwxrwxrwx  (777) access to every file on the Linux system, you can imag -\nine the chaos that would follow. In many ways, similar chaos can occur by not closely \nmanaging the set UID ( SUID ) and the set GID ( SGID ) permissions (see Chapter\u00a04 and \nChapter\u00a011).\nFiles with the SUID  permission in the Owner  category and execute permission in the \nOther  category allow anyone to become the file's owner temporarily while the file is being \nexecuted in memory. The riskiest case is if the file's owner is root.\nSimilarly, files with the SGID  permission in the Group  category and execute permission in \nthe Other  category allow anyone temporarily to become a group member of the file's group \nwhile the file is being executed in memory. SGID  can also be set on directories. This sets \nthe group ID of any files created in the directory to the group ID of the directory.\nExecutable files with SUID  or SGID  are favorites of malicious users. Thus, it is best to use \nthem sparingly. However, some files do need to keep these settings. Two examples are the \npasswd  and the sudo  commands that follow. Each of these files should maintain their \nSUID  permissions.\n$ ls -l /usr/bin/passwd\n-rwsr-xr-x. 1 root root 28804 Aug 17 20:50 /usr/bin/passwd\n$ ls -l /usr/bin/sudo\n---s--x--x. 2 root root 77364 Nov 3 08:10 /usr/bin/sudo\nCommands such as passwd  and sudo  are designed to be used as SUID  programs. Even \nthough those commands run as root user, as a regular user you can only change your own \npassword with passwd  and can only escalate to root permission with sudo  if you were \ngiven permission in the /etc/sudoers  file. A more dangerous situation would be if a \nhacker created a SUID bash  command; anyone running that command could effectively \nchange everything on the system that had root access.\nUsing the find  command, you can search your system to see if there are any hidden or \notherwise inappropriate SUID  and SGID  commands on your system. Here is an example:", "doc_id": "70190edb-2116-4383-93e7-9dee271d1caa", "embedding": null, "doc_hash": "c3fdb31bc85ab75256d56ee0d38edf309888fae9fce46aa89b327a13c0190d5d", "extra_info": {"page_label": "599"}, "node_info": {"start": 0, "end": 2826}, "relationships": {"1": "19d876f7-2614-429f-8be8-84e8fcdb50c4"}}, "__type__": "1"}, "e819e555-dbf3-4ef3-b6df-d90c42860b4d": {"__data__": {"text": "Chapter 22: Understanding Basic Linux Security\n577\n22# find / -perm /6000 -ls\n4597316 52 -rwxr-sr-x 1 root games 51952 Dec 21 2013 /usr/bin/atc\n4589119 20 -rwxr-sr-x 1 root tty   19552 Nov 18 2013 /usr/bin/write\n4587931 60 -rwsr-xr-x 1 root root  57888 Aug  2 2013 /usr/bin/at\n4588045 60 -rwsr-xr-x 1 root root  57536 Sep 25 2013 /usr/bin/crontab\n4588961 32 -rwsr-xr-x 1 root root  32024 Nov 18 2013 /usr/bin/su\n...\n5767487 85 -rwsrwsr-x 1 root  root 68928 Sep 13 11:52 /var/.bin/myvi\n...\nNotice that find  uncovers SUID  and SGID  commands that regular users can run to esca -\nlate their permission for particular reasons. In this example, there is also a file that a user \ntried to hide ( myvi ). This is a copy of the vi  command that, because of permission and \nownership, can change files owned by root. This is obviously a user doing something that \nthey should not be doing.\nSecuring the password files\nThe /etc/passwd  file is the file the Linux system uses to check user account information \nand was covered earlier in the chapter. The /etc/passwd  file should have the following \npermission settings:\n\u25a0\u25a0Owner: root\n\u25a0\u25a0Group: root\n\u25a0\u25a0Permissions: (644) Owner: rw-  Group: r--  Other: r--\nThe example that follows shows that the /etc/passwd  file has the appropriate settings:\n# ls -l /etc/passwd\n-rw-r--r--. 1 root root 1644 Feb  2 02:30 /etc/passwd\nThese settings are needed so that users can log in to the system and see usernames associ-\nated with user ID and group ID numbers. However, users should not be able to modify the  \n/etc/passwd  directly. For example, a malicious user could add a new account to the file if \nwrite access were granted to Other .\nThe next file is the /etc/shadow  file. Of course, it is closely related to the /etc/passwd  \nfile because it is also used during the login authentication process. This /etc/shadow  file \nshould have the following permissions settings:\n\u25a0\u25a0Owner: root\n\u25a0\u25a0Group: root\n\u25a0\u25a0Permissions: (000) Owner: ---  Group: ---  Other: ---\nThe code that follows shows that the /etc/shadow  file has the appropriate settings.\n# ls -l /etc/shadow\n----------. 1 root root 1049 Feb  2 09:45 /etc/shadow\nThe /etc/passwd  file has read access for the owner, group, and other. Notice how  \nmuch more the /etc/shadow  file is restricted than the /etc/passwd  file. For the  ", "doc_id": "e819e555-dbf3-4ef3-b6df-d90c42860b4d", "embedding": null, "doc_hash": "83c2583c647317b1c0623705dc6ceffd6afb287a3fdf4d1cc250d2d0fa435d02", "extra_info": {"page_label": "600"}, "node_info": {"start": 0, "end": 2314}, "relationships": {"1": "099bce85-e026-4d3e-b3f3-764cdc21a390"}}, "__type__": "1"}, "94c78c48-d0fd-4c0c-b078-03462eaad417": {"__data__": {"text": "Part V: Learning Linux Security Techniques578/etc/shadow  file, there is no access permission on, although the root user can still access \nthe file. So, if only root can view this file, how can users change their passwords, which are \nstored in /etc/shadow ? The passwd  utility, /usr/bin/passwd , uses the special permis -\nsion SUID . This permission setting is shown here:\n# ls -l /usr/bin/passwd\n-rwsr-xr-x. 1 root root 28804 Aug 17 20:50 /usr/bin/passwd\nThus, the user running the passwd  command temporarily becomes root while the command \nis executing in memory and can then write to the /etc/shadow  file, but only to change \nthe user\u2019s own password-related information.\nnote\nThe root user does not have write access to the /etc/shadow  permissions, so how does root write to the /etc/\nshadow  file? The root user is all-powerful and has complete access to all files, whether the permissions are listed \nor not.\nThe /etc/group  file (see Chapter\u00a011) contains all of the groups on the Linux system. Its \nfile permissions should be set exactly as the / etc/passwd  file:\n\u25a0\u25a0Owner: root\n\u25a0\u25a0Group: root\n\u25a0\u25a0Permissions: (644) Owner: rw-  Group: r--  Other: r--\nAlso, the group password file, /etc/gshadow , needs to be properly secured. As you would \nexpect, the file permission should be set exactly as the /etc/shadow  file:\n\u25a0\u25a0Owner: root\n\u25a0\u25a0Group: root\n\u25a0\u25a0Permissions: (000) Owner: ---  Group: ---  Other: ---\nLocking down the filesystem\nThe filesystem table (see Chapter\u00a012, \u201cManaging Disks and Filesystems\u201d), /etc/fstab , \nneeds some special attention too. The /etc/fstab  file is used at boot time to mount storage \ndevices on filesystems. It is also used by the mount  command, the dump  command, and the \nfsck  command. The /etc/fstab  file should have the following permission settings:\n\u25a0\u25a0Owner: root\n\u25a0\u25a0Group: root\n\u25a0\u25a0Permissions: (644) Owner: rw-  Group: r--  Other: r--\nWithin the filesystem table, there are some important security settings that need to be \nreviewed. Besides your root, boot, and swap partitions, filesystem options are fairly secure \nby default. However, you may want to also consider the following:\n\u25a0\u25a0Typically, you put the /home  subdirectory, where user directories are located, on \nits own partition. When you add mount  options to mount that directory in /etc/", "doc_id": "94c78c48-d0fd-4c0c-b078-03462eaad417", "embedding": null, "doc_hash": "837ec16835a9c01c08455fbeb31afb92a3493a0d6da76d571ff3a2dd43c329e6", "extra_info": {"page_label": "601"}, "node_info": {"start": 0, "end": 2291}, "relationships": {"1": "490a8118-f499-4804-b36a-9bb506b3b402"}}, "__type__": "1"}, "fcabbc94-0638-4fbc-92c6-110688243cba": {"__data__": {"text": "Chapter 22: Understanding Basic Linux Security\n579\n22fstab,  you can set the nosuid  option to prevent SUID  and SGID  permission-\nenabled executable programs from running from there. Programs that need SUID  \nand SGID  permissions should not be stored in /home  and are most likely malicious. \nYou can set the nodev  option so that no device file located there will be recognized. \nDevice files should be stored in /dev  and not in /home . You can set the noexec  \noption so that no executable programs, which are stored in /home , can be run.\n\u25a0\u25a0You can put the /tmp  subdirectory, where temporary files are located, on its own \npartition and use the same options settings as for /home :\n\u25a0\u25a0nosuid\n\u25a0\u25a0nodev\n\u25a0\u25a0noexec\n\u25a0\u25a0You can put the /usr  subdirectory, where user programs and data are located, on \nits own partition and set the nodev  option so that no device file located there is \nrecognized. After software is installed, the /usr  directory often has little or no \nchange (sometimes, it is even mounted read-only for security reasons).\n\u25a0\u25a0If the system is configured as a server, you probably want to put the /var  direc -\ntory on its own partition. The /var  directory is meant to grow, as log messages \nand content for web, FTP, and other servers are added. You can use the same mount  \noptions with the /var  partition as you do for /home :\n\u25a0\u25a0nosuid\n\u25a0\u25a0nodev\n\u25a0\u25a0noexec\nPutting the preceding mount  options into your /etc/fstab  would look similar to the \nfollowing:\n/dev/sdb1    /home   ext4    defaults,nodev,noexec,nosuid   1 2\n/dev/sdc1    /tmp    ext4    defaults,nodev,noexec,nosuid   1 1\n/dev/sdb2    /usr    ext4    defaults,nodev                 1 2\n/dev/sdb3    /var    ext4    defaults,nodev,noexec,nosuid   1 2\nThese mount  options will help to lock down your filesystem further and add another layer \nof protection from those with malicious intent. Again, managing the various file permis -\nsions and fstab  options should be part of your security policy. The items you choose to \nimplement must be determined by your organization\u2019s security needs.\nManaging software and services\nOften, the administrator\u2019s focus is on making sure that the needed software and services \nare on a Linux system. From a security standpoint, you need to take the opposite viewpoint \nand make sure that the unneeded software and services are not on a Linux system.\nUpdating software packages\nIn addition to removing unnecessary services and software, keeping current software up \nto date is critical for security. The latest bug fixes and security patches are obtained via ", "doc_id": "fcabbc94-0638-4fbc-92c6-110688243cba", "embedding": null, "doc_hash": "66bce0fc5651427caa826d5a9cb61a5f6dce8548458ebb110f4d7093c0f57770", "extra_info": {"page_label": "602"}, "node_info": {"start": 0, "end": 2567}, "relationships": {"1": "fad79c2d-fb76-4eca-9ef5-81aaf6c13b04"}}, "__type__": "1"}, "dcae9e6b-0ed3-4548-8eaf-24513f19c727": {"__data__": {"text": "Part V: Learning Linux Security Techniques580software updates. Software package updates were covered in Chapter\u00a09, \u201cInstalling Linux,\u201d \nand Chapter\u00a010, \u201cGetting and Managing Software.\u201d\nSoftware updates need to be done on a regular basis. How often and when you do it, of \ncourse, depends upon your organization\u2019s security needs.\nYou can easily automate software updates, but like removing services and software, it \nwould be wise to test the updates in a test environment first. When updated software shows \nno problems, you can then update the software on your production Linux systems.\nKeeping up with security advisories\nAs security flaws are found in Linux software, the Common Vulnerabilities and Exposures \n(CVE) project tracks them and helps to quickly get fixes for those flaws worked on by the \nLinux community.\nCompanies such as Red Hat provide updated packages to fix the security flaws and deliver \nthem in what is referred to as errata . Errata may consist of a single updated package or mul -\ntiple updated packages. If you are running Red Hat Enterprise Linux, you search for, iden -\ntify, and install the RPM (RPM Package Manager) packages associated with a particular CVE \nand delivered in errata.\nAs new forms of software packaging become available, make sure that the software in those \npackages is being checked for vulnerabilities. For example, the Red Hat Container Catalog \n(https://access.redhat.com/containers ) lists Red Hat\u2013supported container images \nalong with associated errata and health indexes for each image.\nFor more information on how security updates are handled in Red Hat Enterprise Linux, \nrefer to the Security Updates page on the Red Hat customer portal ( https://access  \n.redhat.com/security/updates/ ). The site contains a wealth of knowledge related \nto security vulnerabilities and how they are being handled. Being able to get timely secu -\nrity updates is one of the primary reasons companies subscribe critical systems to Red Hat \nEnterprise Linux.\nAdvanced implementation\nYou should be aware of several other important security topics as you are planning your \ndeployments. They include cryptography, Pluggable Authentication Modules (PAM), and \nSELinux. These advanced and detailed topics have been put into separate chapters\u2014 \nChapter\u00a023 and Chapter\u00a024.\nMonitoring Your Systems\nIf you do a good job of planning and implementing your system\u2019s security, most malicious \nattacks will be stopped. However, if an attack should occur, you need to be able to recog -\nnize it. Monitoring is an activity that needs to be going on continuously.", "doc_id": "dcae9e6b-0ed3-4548-8eaf-24513f19c727", "embedding": null, "doc_hash": "3785bdef0e29eb7c826456d5e626723a39c3cf07356d37e7129ac8a3656a0783", "extra_info": {"page_label": "603"}, "node_info": {"start": 0, "end": 2587}, "relationships": {"1": "7f8344a7-4298-487b-ac2f-59ae3945ac33"}}, "__type__": "1"}, "3504329c-9f11-406c-83b7-c3ddee4e1072": {"__data__": {"text": "Chapter 22: Understanding Basic Linux Security\n581\n22Monitoring your system includes watching over log files, user accounts, and the filesys -\ntem itself. In addition, you need some tools to help you detect intrusions and other types \nof malware.\nMonitoring log files\nUnderstanding how message logging is done is critical to maintaining and troubleshooting \na Linux system. Before the systemd  facility was used to gather messages in what is \nreferred to as the systemd  journal, messages generated by the kernel and system services \nwere directed to file in the /var/log  directory. While that is still true to a great extent \nwith systemd , you can now also view log messages directly from the systemd  journal \nusing the journalctl  command.\nThe log files for your Linux system are primarily located in the /var/log  directory. \nMost of the files in the /var/log  directory are directed there from the systemd  journal \nthrough the rsyslogd  service (see Chapter\u00a013, \u201cUnderstanding Server Administration\u201d). \nTable\u00a022.3 contains a list of /var/log  files and a brief description of each.\nTABLE 22.3  Log Files in the /var/log  Directory\nSystem Log Name Filename Description\nApache \nAccess Log/var/log/httpd/\nacces s_logLogs requests for information from your Apache \nweb server.\nApache Error Log /var/log/\nhttpd/er ror_logLogs errors encountered from clients trying to access data \non your Apache web server.\nBad Logins Log btmp Logs bad login attempts.\nBoot Log boot.log Contains messages indicating which system services have \nstarted and shut down successfully and which (if any) have \nfailed to start or stop. The most recent bootup messages \nare listed near the end of the file.\nKernel Log dmesg Records messages printed by the kernel when the \nsystem boots.\nCron Log cron Contains status messages from the crond daemon.\ndpkg Log dpkg.log Contains information concerning installed \nDebian packages.\nFTP Log vsftpd.log Contains messages relating to transfers made using the \nvsftpd daemon (FTP server).\nFTP Transfer Log xferlog Contains information about files transferred using the \nFTP service.\nGNOME Display \nManager Log/var/log/\ngdm/:0.logHolds messages related to the login screen (GNOME dis -\nplay manager). Yes, there really is a colon in the filename.\nLastLog lastlog Records the last time an account logs in to the system.\n(continued)", "doc_id": "3504329c-9f11-406c-83b7-c3ddee4e1072", "embedding": null, "doc_hash": "7bbbe2291108503c995382ca9e96da05ded8a34cc74e03aad058f1cb0cfdba8b", "extra_info": {"page_label": "604"}, "node_info": {"start": 0, "end": 2349}, "relationships": {"1": "16939e12-56fc-4441-ba42-494b2cacefd7"}}, "__type__": "1"}, "b82fc84b-8857-4212-9195-0f7f05d0bdf9": {"__data__": {"text": "Part V: Learning Linux Security Techniques582System Log Name Filename Description\nLogin/out Log wtmp Contains a history of logins and logouts on the system.\nMail Log maillog Contains information about addresses to which and from \nwhich email was sent. Useful for detecting spamming.\nMySQL \nServer Logmysqld.log Includes information related to activities of the MySQL \ndatabase server (mysqld).\nNews Log spooler Provides a directory containing logs of messages from the \nUsenet News server if you are running one.\nSamba Log /var/log/\nsamba/smbd.log\n/var/log/\nsamba/nmbd.logShows messages from the Samba SMB file ser -\nvice daemon.\nSecurity Log secure Records the date, time, and duration of login attempts \nand sessions.\nSendmail Log sendmail Shows error messages recorded by the sendmail daemon.\nSquid Log /var/log/squid/\naccess.logContains messages related to the squid proxy/cach -\ning server.\nSystem Log messages Provides a general-purpose log file where many programs \nrecord messages.\nUUCP Log uucp Shows status messages from the UNIX to UNIX Copy Pro -\ntocol daemon.\nYUM Log yum.log Shows messages related to RPM software packages.\nX.Org X11 Log Xorg.0.log Includes messages output by the X.Org X server.TABLE 22.3  (Continued)\nThe log files that are in your system\u2019s /var/log  directory depend upon what services you are \nrunning. Also, some log files are distribution dependent. For example, if you use Fedora, you would \nnot have the dpkg  log file.\nMost of the log files are displayed using the commands cat , head , tail , more , or less . However, \na few of them have special commands for viewing (see Table\u00a022.4).\nTABLE 22.4  Viewing Log Files That Need Special Commands\nFilename View Command\nbtmp dump-utmp btmp\ndmesg dmesg\nlastlog lastlog\nwtmp dump-utmp wtmp", "doc_id": "b82fc84b-8857-4212-9195-0f7f05d0bdf9", "embedding": null, "doc_hash": "de4c8af3583f0c622af4b64f80f74e0fc90b7531771fb2c6ad22b9a7f1c35be8", "extra_info": {"page_label": "605"}, "node_info": {"start": 0, "end": 1773}, "relationships": {"1": "8ec4454a-e6ba-4ca0-ba68-bfab0357f10f"}}, "__type__": "1"}, "897a9dac-42be-4d8b-b48c-f1d1c80ea3d4": {"__data__": {"text": "Chapter 22: Understanding Basic Linux Security\n583\n22With the change in Fedora, RHEL, Ubuntu, and other Linux distributions to systemd  \n(which manages the boot process and services), as noted earlier, the mechanism for gath -\nering and displaying log messages associated with the kernel and system services has \nchanged as well. Those messages are directed to the systemd  journal and can be displayed \nwith the journalctl  command.\nYou can view journal messages directly from the systemd  journal instead of simply list -\ning the contents of /var/log  files. In fact, the /var/log/messages  file, to which many \nservices direct log messages by default, does not even exist in the latest Fedora release. \nInstead, you can use the journalctl  command to display log messages in various ways.\nTo page through kernel messages, type the following command:\n# journalctl -k\nLogs begin at Sun 2019-06-09 18:59:23 EDT, end at \n    Sun 2019-10-20 18:11:06 EDT.\nOct 19 11:43:04 localhost.localdomain kernel:\n   Linux version 5.0.9-301.fc30.x86_64 \n   (mockbuild@bkernel04.phx2.fedoraproject.org)\n   (gcc version 9.0.1 20190312 (Red Hat 9.0.1-0.10) (GCC)) \n        #1 SMP Tue Apr 23 23:57:35 UTC 2019\nOct 19 11:43:04 localhost.localdomain kernel: Command line:\n        BOOT_IMAGE=(hd0,msdos1)/vmlinuz-5.0.9-301.fc30.x86_64\n    root=/dev/mapper/fedora_localhost--live-root ro\n    resume=/dev/mapper/fedora_localhost--live-swap\n    rd.lvm.lv=fedora_localhost-live/root\n    rd.lvm.lv=fedora_localhost-live/swap rhgb quiet\n...\nTo view messages associated with a particular service, use the -u  option followed by the \nservice name to see log messages for any service, as in this example:\n# journalctl -u NetworkManager.service\n# journalctl -u httpd.service\n# journalctl -u avahi-daemon.service\nIf you think that a security breach is in progress, you can watch all or selected messages as \nthey come in by following messages. For example, to follow kernel messages or httpd  mes-\nsages as they come in, add the -f  option (press Ctrl+C when you are finished):\n# journalctl -k -f\n# journalctl -f -u NetworkManager.service\nTo check just boot messages, you can list the boot IDs for all system boots and then boot \nthe particular boot instance that interests you. The following examples display boot IDs \nand then shows boot messages for a selected boot ID:\n# journalctl --list-boots\n-3 6b968e820df345a781cb6935d483374c\n   Sun 2019-08-25 12:42:08 EDT\u2014Mon 2019-08-26 14:30:53 EDT\n-2 f2c5a74fbe9b4cb1ae1c06ac1c24e89b", "doc_id": "897a9dac-42be-4d8b-b48c-f1d1c80ea3d4", "embedding": null, "doc_hash": "9545f307e282d01ff6029f1993c48f0c8df241dcd052fd2d66baa09de4fcf472", "extra_info": {"page_label": "606"}, "node_info": {"start": 0, "end": 2496}, "relationships": {"1": "a193671e-2f5c-405e-a5b1-1faab6eb9a0c"}}, "__type__": "1"}, "8cd78a98-f208-486e-a6d3-48e1e3fb5f12": {"__data__": {"text": "Part V: Learning Linux Security Techniques584   Mon 2019-09-02 15:49:03 EDT\u2014Thu 2019-09-12 13:08:26 EDT\n-1 5d26bee1cfb7481a9e4da3dd7f8a80a0\n   Sun 2019-10-13 12:30:27 EDT\u2014Thu 2019-10-17 13:37:22 EDT\n 0 c848e7442932488d91a3a467e8d92fcf\n   Sat 2019-10-19 11:43:04 EDT\u2014Sun 2019-10-20 18:11:06 EDT\n# journalctl -b c848e7442932488d91a3a467e8d92fcf\n-- Logs begin at Sun 2019-06-09 18:59:23 EDT,\n   end at Sun 2019-10-20 18:21:18 EDT. --\nOct 19 11:43:04 localhost.localdomain kernel: Linux version\n5.0.9-301.fc30.x86_64 (mockbuild@bkernel04.phx2.fedoraproject.org) \n...\nOct 19 11:43:04 localhost.localdomain kernel: Command line:\n   BOOT_IMAGE=(hd0,msdos1)/vmlinuz-5.0.9-301.fc30.x86_64\n   root=/dev/mapper/fedora_local>\n...\nOct 19 11:43:04 localhost.localdomain kernel: \n   DMI: Red Hat KVM, BIOS 1.9.1-5.el7_3.3 04/01/2014\nOct 19 11:43:04 localhost.localdomain kernel: Hypervisor detected: KVM\nMonitoring user accounts\nUser accounts are often used in malicious attacks on a system by gaining unauthorized \naccess to a current account, by creating new bogus accounts, or by leaving an account \nbehind to access later. To avoid such security issues, watching over user accounts is an \nimportant activity.\nDetecting counterfeit new accounts and privileges\nAccounts created without going through the appropriate authorization should be consid -\nered counterfeit. Also, modifying an account in any way that gives it a different unau -\nthorized user identification (UID) number or adds unauthorized group memberships is a \nform of rights escalation. Keeping an eye on the /etc/passwd  and /etc/group  files will \n monitor these potential breaches.\nTo help you monitor the /etc/passwd  and /etc/group  files, you can use the audit \ndaemon. The audit daemon is an extremely powerful auditing tool that allows you to select \nsystem events to track and record them, and it provides reporting capabilities.\nTo begin auditing the /etc/passwd  and /etc/group  files, you need to use the auditctl  \ncommand. Two options at a minimum are required to start this process:\n-w filename : Place a watch on filename . The audit daemon tracks the file by its \ninode number. An inode number is a data structure that contains information con -\ncerning a file, including its location.\n-p trigger(s\u2014) : If one of these access types occurs ( r=read, w =write, x =execute, \na=attribute change) to filename , then trigger an audit record.", "doc_id": "8cd78a98-f208-486e-a6d3-48e1e3fb5f12", "embedding": null, "doc_hash": "be83870deac0e716da4d6054560155745790356a6040d4cedd2e38c554adc337", "extra_info": {"page_label": "607"}, "node_info": {"start": 0, "end": 2404}, "relationships": {"1": "c5046fbb-3a9e-4d15-9b17-2e3225ecb568"}}, "__type__": "1"}, "349b78f4-c963-4a4d-b842-aec9a42c2850": {"__data__": {"text": "Chapter 22: Understanding Basic Linux Security\n585\n22In the following example, a watch has been placed on the /etc/passwd  file using the \nauditctl  command. The audit daemon will monitor access, which consists of any reads, \nwrites, or file attribute changes:\n# auditctl -w /etc/passwd -p rwa\nAfter you have started a file audit, you may want to turn it off at some point. To turn off \nan audit, use the command\n# auditctl -W filename -p trigger(s)\nTo see a list of current audited files and their watch settings, type auditctl -l  at the \ncommand line.\nTo review the audit logs, use the audit daemon\u2019s ausearch  command. The only option \nneeded here is the -f  option, which specifies which records you want to view from the \naudit log. The following is an example of the /etc/passwd  audit information:\n# ausearch -f /etc/passwd\ntime->Fri Feb  7 04:27:01 2020\ntype=PATH msg=audit(1328261221.365:572):\nitem=0 name=\"/etc/passwd\" inode=170549\ndev=fd:01 mode=0100644 ouid=0 ogid=0\nrdev=00:00 obj=system_u:object_r:etc_t:s0\ntype=CWD msg=audit(1328261221.365:572):  cwd=\"/\"\n...\ntime->Fri Feb  7 04:27:14 2020\ntype=PATH msg=audit(1328261234.558:574):\nitem=0 name=\"/etc/passwd\" inode=170549\ndev=fd:01 mode=0100644 ouid=0 ogid=0\nrdev=00:00 obj=system_u:object_r:etc_t:s0\ntype=CWD msg=audit(1328261234.558:574):\ncwd=\"/home/johndoe\"\ntype=SYSCALL msg=audit(1328261234.558:574):\narch=40000003 syscall=5 success=yes exit=3\na0=3b22d9 a1=80000 a2=1b6 a3=0 items=1 ppid=3891\npid=21696 auid=1000 uid=1000 gid=1000 euid=1000\nsuid=1000 fsuid=1000 egid=1000 sgid=1000 fsgid=1000\ntty=pts1 ses=2 comm=\"vi\" exe=\"/bin/vi\"\n subj=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023\"\n----\nThis is a lot of information to review. A few items will help you see what audit event hap -\npened to trigger the bottom record:\ntime : The time stamp of the activity\nname : The filename, /etc/passwd , being watched\ninode: The /etc/passwd \u2019s inode number on this filesystem", "doc_id": "349b78f4-c963-4a4d-b842-aec9a42c2850", "embedding": null, "doc_hash": "5158c1ea09d2e9958f38a2631cbe614c206c4762ba4d2f0f5d729a021127523b", "extra_info": {"page_label": "608"}, "node_info": {"start": 0, "end": 1939}, "relationships": {"1": "21521fe2-da41-4839-9a82-1593543eb214"}}, "__type__": "1"}, "dac194fb-3182-4124-a288-137cea9fb16d": {"__data__": {"text": "Part V: Learning Linux Security Techniques586uid: The user ID, 1000, of the user running the program\nexe: The program, /bin/vi , used on the /etc/passwd  file\nTo determine what user account is assigned the UID of 1000, look at the /etc/passwrd  \nfile. In this case, the UID of 1000 belongs to the user johndoe . Thus, from the audit event \nrecord displayed above, you can determine that account johndoe  has attempted to use the \nvi editor on the /etc/passwd  file. It is doubtful that this was an innocent action, and it \nrequires more investigation.\nnote\nThe ausearch  command returns nothing if no watch events on a file have been triggered.\nThe audit daemon and its associated tools are extremely rich. To learn more about it, look \nat the man pages for the following audit daemon utilities and configuration files:\nauditd: The audit daemon\nauditd.conf:  The audit daemon configuration file\nautditctl : Controls the auditing system\naudit.rule : Configuration rules loaded at boot\nausearch : Searches the audit logs for specified items\naureport : Report creator for the audit logs\naudispd : Sends audit information to other programs\nThe audit daemon is one way to keep an eye on important files. You should also review your \naccount and group files on a regular basis with a \u201chuman eye\u201d to see if anything looks irregular.\nImportant files, such as /etc/passwd , do need to be monitored for unauthorized account \ncreation. However, just as bad as a new unauthorized user account is an authorized user \naccount with a bad password.\nDetecting bad account passwords\nEven with all your good efforts, bad passwords will slip in. Therefore, you do need to mon -\nitor user account passwords to ensure they that are strong enough to withstand an attack.\nOne password strength monitoring tool that you can use is the same one malicious users \nuse to crack accounts, John the Ripper. John the Ripper is a free, open source tool that you \ncan use at the Linux command line. It\u2019s not installed by default. For a Fedora distribution, \nyou need to issue the command yum install john to install it.\ntip\nTo install John the Ripper on Ubuntu, use the command sudo apt-get install john .", "doc_id": "dac194fb-3182-4124-a288-137cea9fb16d", "embedding": null, "doc_hash": "62a8e16bf946c8c50bf99ecebf7c2dbc5088ed2e62e61d9f17696709104c333e", "extra_info": {"page_label": "609"}, "node_info": {"start": 0, "end": 2171}, "relationships": {"1": "634df08c-edb8-4537-9cc1-1fb9462f0add"}}, "__type__": "1"}, "120086cd-1c64-4e43-9151-6a3ad4f79a14": {"__data__": {"text": "Chapter 22: Understanding Basic Linux Security\n587\n22In order to use John the Ripper to test user passwords, you must first extract account \nnames and passwords using the unshadow  command. This information needs to be redi-\nrected into a file for use by john , as shown here:\n# unshadow /etc/passwd /etc/shadow > password.file\nNow edit the password.file  using your favorite text editor to remove any accounts \nwithout passwords. Because it is wise to limit John the Ripper to testing a few accounts at \na time, remove any account names that you do not wish to test presently.\nCaution  \nThe john  utility is extremely CPU-intensive. It does set its nice  value to 19 in order to lower its priority. However, it \nwould be wise to run it on a non-production system or during off-peak hours and for only a few accounts at a time.\nNow use the john command to attempt password cracks. To run john against the created password \nfile, issue the command john filename. In the following code snippet, you can see the output \nfrom running john against the sample password.file. For demonstration purposes, only one \naccount was left in the sample file. Further, the account, Samantha, was given the bad password of \npassword. You can see how little time it took for John the Ripper to crack the password.\n# john password.file\nLoaded 1 password hash (generic crypt(3) [?/32])\npassword         (Samantha)\nguesses: 1  time: 0:00:00:44 100% (2)  c/s: 20.87\n trying: 12345 - missy\nUse the \"--show\" option to display all of the\n cracked passwords reliably\nTo demonstrate how strong passwords are vital, consider what happens when the Saman -\ntha account\u2019s password is changed from password  to Password1234 . Even though \nPassword1234  is still a weak password, it takes longer than 7 days of CPU time to crack \nit. In the code that follows, john  was finally aborted to end the cracking attempt.\n# passwd Samantha\nChanging password for user Samantha.\n...\n# john password.file\nLoaded 1 password hash (generic crypt(3) [?/32])\n...\ntime: 0:07:21:55 (3)  c/s: 119  trying: tth675 - tth787\nSession aborted\nAs soon as passwords cracking attempts have been completed, the password.file   \nshould be removed from the system. To learn more about John the Ripper, visit www  \n.openwall.com/john .\nMonitoring the filesystem\nMalicious programs often modify files. They also can try to cover their tracks by posing as \nordinary files and programs. However, there are ways to uncover them through the various \nmonitoring tactics covered in the following sections.", "doc_id": "120086cd-1c64-4e43-9151-6a3ad4f79a14", "embedding": null, "doc_hash": "989501a220326ff01c0628e800ca0b1de01ea3e05b835e59626ef2bd011e9b63", "extra_info": {"page_label": "610"}, "node_info": {"start": 0, "end": 2535}, "relationships": {"1": "11d4e906-d585-47d1-a947-e4975e8f6b16"}}, "__type__": "1"}, "e58aa6a7-5c07-40b1-a908-d6ce35fa482b": {"__data__": {"text": "Part V: Learning Linux Security Techniques588Verifying software packages\nTypically, if you install a software package from a standard repository or download a rep -\nutable site\u2019s package, you won\u2019t have any problems. But it is always good to double-check \nyour installed software packages to see if they have been compromised. The command to \naccomplish this is rpm -V  package_name.\nWhen you verify the software, information from the installed package files is compared \nagainst the package metadata (see Chapter\u00a010, \u201cGetting and Managing Software\u201d) in the \nrpm database. If no problems are found, the rpm -V  command returns nothing. However, \nif there are discrepancies, you get a coded listing. Table\u00a022.5 shows the codes used and a \ndescription of the discrepancy.\nIn the partial list that follows, all of the installed packages are given a verification check. \nYou can see that the codes 5 , S, and T were returned, indicating some potential problems.\n# rpm -qaV\n5S.T.....  c /etc/hba.conf\n...\n...T.....    /lib/modules/3.2.1-3.fc16.i686/modules.devname\n...T.....    /lib/modules/3.2.1-3.fc16.i686/modules.softdep\nYou do not have to verify all of your packages at once. You can verify just one package \nat a time. For example, if you want to verify your nmap  package, you simply enter \nrpm -V nmap .\nnote\nTo verify packages on Ubuntu, you need the debsums  utility. It is not installed by default. To install debsums , use \nthe command sudo apt-get install debsums . To check all installed packages, use the debsums -a  \ncommand. To check one package, type debsums  packagename .TABLE 22.5  Package Verification Discrepancies\nCode Discrepancy\nS File size\nM File permissions and type\n5 MD5 check sum\nD Device file\u2019s major and minor numbers\nL Symbolic links\nU User ownership\nG Group ownership\nT File modified times ( mtime )\nP Other installed packages this package is dependent upon (aka capabilities)", "doc_id": "e58aa6a7-5c07-40b1-a908-d6ce35fa482b", "embedding": null, "doc_hash": "5c666d8b886291471848cdc63e46220545dc3e430674ac3cfa6a893745a44c98", "extra_info": {"page_label": "611"}, "node_info": {"start": 0, "end": 1906}, "relationships": {"1": "76507da0-fca8-4e0d-b866-bc56be8d7a7e"}}, "__type__": "1"}, "53123884-ca99-41d3-81d1-00199854e400": {"__data__": {"text": "Chapter 22: Understanding Basic Linux Security\n589\n22Scanning the filesystem\nUnless you have recently updated your system, binary files should not have been modified \nfor any reason. Commands such as find  and rpm -V  can help you determine if a binary \nfile has been tampered with.\nTo check for binary file modification, find  can use the file\u2019s modify time, or mtime . The \nfile mtime  is the time when the contents of a file were last modified. Also, find  can mon -\nitor the file\u2019s create/change time, or ctime .\nIf you suspect malicious activity, you can quickly scan your filesystem to see if any \nbinaries were modified or changed today (or yesterday, depending upon when you think the \nintrusion took place). To do this scan, use the find  command.\nIn the example that follows, a scan is made of the /sbin  directory. To see if any binary \nfiles were modified less than 24 hours ago, the command find /sbin -mtime -1  \nis used. In the example, several files are displayed, showing that they were modified \nrecently. This indicates that malicious activity is taking place on the system. To investi-\ngate further, review each individual file\u2019s times, using the stat  filename  command, as \nshown here:\n# find /sbin -mtime -1\n/sbin\n/sbin/init\n/sbin/reboot\n/sbin/halt\n#\n# stat /sbin/init\n  File: '/sbin/init' -> '../bin/systemd'\n  Size: 14    Blocks: 0      IO Block: 4096   symbolic link\nDevice: fd01h/64769d    Inode: 9551        Links: 1\nAccess: (0777/lrwxrwxrwx)\nUid: (    0/    root)   Gid: (    0/    root)\nContext: system_u:object_r:bin_t:s0\nAccess: 2016-02-03 03:34:57.276589176 -0500\nModify: 2016-02-02 23:40:39.139872288 -0500\nChange: 2016-02-02 23:40:39.140872415 -0500\n Birth: -\nYou could create a database of all of the binary\u2019s original mtime s and ctime s and then \nrun a script to find current mtime s and ctime s, compare them against the database, \nand note any discrepancies. However, this type of program has already been created \nand works well. It\u2019s called an Intrusion Detection System, and it is covered later in \nthis chapter.\nYou need to perform several other filesystem scans on a regular basis. Favorite files or file set-\ntings of malicious attackers are listed in Table\u00a022.6. The table also lists the commands to per-\nform the scans and why the file or file setting is potentially problematic.", "doc_id": "53123884-ca99-41d3-81d1-00199854e400", "embedding": null, "doc_hash": "8935225be6a48e9fed5507ccce5e969db953e71e86ff4a7f3e84994f03b9b739", "extra_info": {"page_label": "612"}, "node_info": {"start": 0, "end": 2327}, "relationships": {"1": "b356994e-7652-4f58-b58d-77f9454cd1bc"}}, "__type__": "1"}, "1deb7187-cbf7-4c19-86ea-05ac5a280499": {"__data__": {"text": "Part V: Learning Linux Security Techniques590The rpm -V  package  command can tell you information about changes that have occurred \nto a file after it has been installed from an RPM package. For each file that has changed from \nthe selected package since it was installed, you can see the following information:\n       S   Size of the file differs\n       M   Permissions or file type (Mode) of the file differs\n       5   Digest differs (formerly MD5 sum)\n       D   Device major/minor number is mismatched\n       L   The readLink(2) path is mismatch\n       U   User ownership differs\n       G   Group ownership differs\n       T   mTime differs\n       P   caPabilities differ\nBy default, only changed files appear. Add -v  (verbose) to also show files that have not \nchanged. Here is an example:\n# rpm -V samba \nS.5....T.    /usr/sbin/eventlogadm\nIn this example, I echoed a few characters into the eventlogadm  binary. The S shows the \nsize of the file changes, 5 shows the digest no longer matches the original digest, and T \nsays the modification time on the file has changed.\nThese filesystem scans help monitor what is going on in your system and help detect malicious \nattacks. However, other types of attacks can occur to your files, including viruses and rootkits.\nDetecting viruses and rootkits\nTwo popular malicious attack tools are viruses and rootkits because they stay hidden while \nperforming their malicious activities. Linux systems need to be monitored for both such \nintrusions.TABLE 22.6  Additional Filesystem Scans\nFile or Setting Scan Command Problem with File or Setting\nSUID \npermissionfind / \n-perm -4000Allows anyone to become the file\u2019s owner tempo -\nrarily while the file is being executed in memory.\nSGID \npermissionfind / \n-perm -2000Allows anyone to become a group member of the \nfile\u2019s group temporarily while the file is being exe -\ncuted in memory.\nrhost files find /home \n-name .rhostsAllows a system to trust another system com -\npletely. It should not be in /home  directories.\nOwnerless files find / -nouser Indicates files that are not associated with \nany username.\nGroupless files find / -nogroup Indicates files that are not associated with any \ngroup name.", "doc_id": "1deb7187-cbf7-4c19-86ea-05ac5a280499", "embedding": null, "doc_hash": "836aed02ef6e064ea55eb892a3cdb6d7ee0cd0d87447b31fec1fc6c5e7def50e", "extra_info": {"page_label": "613"}, "node_info": {"start": 0, "end": 2200}, "relationships": {"1": "f609026a-cf8b-4940-95f6-f4fc30ced2df"}}, "__type__": "1"}, "04dac2bf-2c67-4630-9686-2fd2e22e99d9": {"__data__": {"text": "Chapter 22: Understanding Basic Linux Security\n591\n22Monitoring for viruses\nA computer virus  is malicious software that can attach itself to already installed system \nsoftware, and it has the ability to spread through media or networks. It is a misconception \nthat there are no Linux viruses. The malicious creators of viruses do often focus on the \nmore popular desktop operating systems, such as Windows. However, that does not mean \nthat viruses are not created for the Linux systems.\nEven more important, Linux systems are often used to handle services, such as mail \nservers, for Windows desktop systems. Therefore, Linux systems used for such purposes \nneed to be scanned for Windows viruses as well.\nAntivirus software scans files using virus signatures. A virus signature  is a hash created \nfrom a virus\u2019s binary code. The hash will positively identify that virus. Antivirus programs \nhave a virus signature database that is used to compare against files to see if there is a sig -\nnature match. Depending upon the number of new threats, a virus signature database can \nbe updated often to provide protection from these new threats.\nA good antivirus software choice for your Linux system, which is open source and free, is \nClamAV. To install ClamAV on a Fedora or RHEL system, type the command dnf install \nclamav . You can find out more about ClamAV at clamav.net , where there is documenta -\ntion on how to set up and run the antivirus software.\ntip\nYou can review the packages available for Ubuntu installation by entering the command apt-cache search \nclamav . A couple of different packages are available for Ubuntu, so review the ClamAV website information before \nyou choose a package.\nMonitoring for rootkits\nA rootkit is a little more insidious than a virus. A rootkit  is a malicious program that does \nthe following:\n\u25a0\u25a0Hides itself, often by replacing system commands or programs\n\u25a0\u25a0Maintains high-level access to a system\n\u25a0\u25a0Is able to circumvent software created to locate it\nThe purpose of a rootkit is to get and maintain root-level access to a system. The term was \ncreated by putting together root , which means that it has to have administrator access, and \nkit, which means it is usually several programs that operate in concert.\nA rootkit detector that can be used on a Linux system is chkrootkit . To install  \nchkrootkit  on a Fedora or RHEL system, issue the command yum install  \nchkrootkit . To install chkrookit  on an Ubuntu system, use the command sudo apt-\nget install chkrootkit .", "doc_id": "04dac2bf-2c67-4630-9686-2fd2e22e99d9", "embedding": null, "doc_hash": "ae756e336a18534a3e3cbf1d87358b6275e484a005dd86d8e6b6844d8aa2bccf", "extra_info": {"page_label": "614"}, "node_info": {"start": 0, "end": 2519}, "relationships": {"1": "2f8edf0c-c84d-4b18-ad63-93cb445bf8e2"}}, "__type__": "1"}, "e9effa83-8bc3-440c-89fd-1e5d457a1c72": {"__data__": {"text": "Part V: Learning Linux Security Techniques592tip\nIt is best to use a Live CD or flash drive to run chkrootkit  so that the results are not circumvented by a  \nrootkit. The Fedora Security Spin has chkrootkit  on its Live CD. You can get this distribution at labs \n.fedoraproject.org/en/security .\nFinding a rootkit with chkrootkit  is simple. After installing the package or booting up \nthe Live CD, type in chkrootkit  at the command line. It searches the entire file structure \ndenoting any infected files.\nThe code that follows shows a run of chkrootkit  on an infected system. The grep  \ncommand was used to search for the keyword INFECTED . Notice that many of the files \nlisted as \u201cinfected\u201d are bash shell command files. This is typical of a rootkit.\n# chkrootkit | grep INFECTED\nChecking 'du'... INFECTED\nChecking 'find'... INFECTED\nChecking 'ls'... INFECTED\nChecking 'lsof'... INFECTED\nChecking 'pstree'... INFECTED\nSearching for Suckit rootkit... Warning: /sbin/init INFECTED\nIn the last line of the preceding chkrootkit  code is an indication that the system has \nbeen infected with the Suckit rootkit. It actually is not infected with this rootkit. When \nrunning utilities, such as antivirus and rootkit-detecting software, you often get a number \nof false positives. A false positive  is an indication of a virus, rootkit, or other malicious \nactivity that does not really exist. In this particular case, this false positive is caused by a \nknown bug.\nThe chkrootkit  utility should have regularly scheduled runs and, of course, should be \nrun whenever a rootkit infection is suspected. To find more information on chkrootkit , \ngo to chkrootkit.org .\ntip\nAnother rootkit detector that might interest you is called Rootkit Hunter ( rkhunter ). Run the rkhunter  script to \ncheck your system for malware and known rootkits. Configure rkhunter  in the /etc/rkhunter.conf  file. For \na simple example, run rkhunter -c  to check the filesystem for a variety of rootkits and vulnerabilities.\nDetecting an intrusion\nIntrusion Detection System (IDS)  software\u2014a software package that monitors a system\u2019s \nactivities (or its network) for potential malicious activities and reports these activities\u2014\ncan help you monitor your system for potential intrusions. Closely related to Intrusion \nDetection System software is a software package that prevents an intrusion, called Intru -\nsion Prevention System  software. Some of these packages are bundled together to provide \nIntrusion Detection and Prevention.", "doc_id": "e9effa83-8bc3-440c-89fd-1e5d457a1c72", "embedding": null, "doc_hash": "ef2fa5e53814a459ebf3bc052a8d77e28def3131004b71c7a8b09ac377bf1bc3", "extra_info": {"page_label": "615"}, "node_info": {"start": 0, "end": 2509}, "relationships": {"1": "d60364fb-b1fd-4419-9594-ef3829c610a2"}}, "__type__": "1"}, "e115307f-96e2-43ff-97a6-da4eb80f183d": {"__data__": {"text": "Chapter 22: Understanding Basic Linux Security\n593\n22Several Intrusion Detection System software packages are available for a Linux system. A \nfew of the more popular utilities are listed in Table\u00a022.7. You should know that tripwire  \nis no longer open source. However, the original tripwire  code is still available. See the \ntripwire  website listed in Table\u00a022.7 for more details.\nThe Advanced Intrusion Detection Environment (aide) IDS uses a method of comparison \nto detect intrusions. When you were a child, you may have played the game of comparing \ntwo pictures and finding what was different between them. The aide  utility uses a similar \nmethod. A \u201cfirst picture\u201d database is created. At some time later, another database \u201csecond \npicture\u201d is created, and aide  compares the two databases and reports what is different.\nTo begin, you need to take that \u201cfirst picture.\u201d The best time to create this picture is when \nthe system has been freshly installed. The command to create the initial database is aide \n-i and it takes a long time to run. Some of its output follows. Notice that aide  tells you \nwhere it is creating its initial \u201cfirst picture\u201d database.\n# aide -i\nAIDE, version 0.16.11\n \n### AIDE database at /var/lib/aide/aide.db.new.gz initialized.\nThe next step is to move the initial \u201cfirst picture\u201d database to a new location. This protects \nthe original database from being overwritten. Plus, the comparison does not work unless \nthe database is moved. The command to move the database to its new location and give it a \nnew name is as follows:\n# cp /var/lib/aide/aide.db.new.gz /var/lib/aide/aide.db.gz\n \nWhen you are ready to check whether your files have been tampered with, you need to \ncreate a new database, \u201csecond picture,\u201d and compare it to the original database, \u201cfirst pic -\nture.\u201d The check option on the aide  command, -c , creates a new database and runs a com-\nparison against the old database. The output shown next illustrates this comparison being \ndone and the aide  command reporting on some problems.\n# aide -CTABLE 22.7  Popular Linux Intrusion Detection Systems\nIDS Name Installation Website\naide yum install aide\napt-get install aidehttp://aide.\nsourceforge.net\nSnort rpm or tarball  packages from website http://snort.org\ntripwire yum install tripwire\napt-get install tripwirehttp://tripwire.org", "doc_id": "e115307f-96e2-43ff-97a6-da4eb80f183d", "embedding": null, "doc_hash": "1c0a1d99ccf75c70c467b5701a440058efcaca26f14cd7c49fab843371dbbae0", "extra_info": {"page_label": "616"}, "node_info": {"start": 0, "end": 2341}, "relationships": {"1": "066a00d7-1f9a-46c7-ba9c-98546729adce"}}, "__type__": "1"}, "bc377baa-1bc0-497a-acd8-41f16802449b": {"__data__": {"text": "Part V: Learning Linux Security Techniques594...\n---------------------------------------------------\nDetailed information about changes:\n---------------------------------------------------\nFile: /bin/find\nSize : 189736 , 4620\nCtime : 2020-02-10 13:00:44 , 2020-02-11 03:05:52\nMD5 : <NONE> , rUJj8NtNa1v4nmV5zfoOjg==\nRMD160 : <NONE> , 0CwkiYhqNnfwPUPM12HdKuUSFUE=\nSHA256 : <NONE> , jg60Soawj4S/UZXm5h4aEGJ+xZgGwCmN\n \nFile: /bin/ls\nSize : 112704 , 6122\nCtime : 2020-02-10 13:04:57 , 2020-02-11 03:05:52\nMD5 : POeOop46MvRx9qfEoYTXOQ== , IShMBpbSOY8axhw1Kj8Wdw==\nRMD160 : N3V3Joe5Vo+cOSSnedf9PCDXYkI= ,\n e0ZneB7CrWHV42hAEgT2lwrVfP4=\nSHA256 : vuOFe6FUgoAyNgIxYghOo6+SxR/zxS1s ,\n Z6nEMMBQyYm8486yFSIbKBuMUi/+jrUi\n...\nFile: /bin/ps\nSize : 76684 , 4828\nCtime : 2020-02-10 13:05:45 , 2020-02-11 03:05:52\nMD5 : 1pCVAWbpeXINiBQWSUEJfQ== , 4ElJhyWkyMtm24vNLya6CA==\nRMD160 : xwICWNtQH242jHsH2E8rV5kgSkU= ,\n AZlI2QNlKrWH45i3/V54H+1QQZk=\nSHA256 : ffUDesbfxx3YsLDhD0bLTW0c6nykc3m0 ,\n w1qXvGWPFzFir5yxN+n6t3eOWw1TtNC/\n...\nFile: /usr/bin/du\nSize : 104224 , 4619\nCtime : 2020-02-10 13:04:58 , 2020-02-11 03:05:53\nMD5 : 5DUMKWj6LodWj4C0xfPBIw== , nzn7vrwfBawAeL8nkayICg==\nRMD160 : Zlbm0f/bUWRLgi1B5nVjhanuX9Q= ,\n 2e5S00lBWqLq4Tnac4b6QIXRCwY=\nSHA256 : P/jVAKr/SO0epBBxvGP900nLXrRY9tnw ,\n HhTqWgDyIkUDxA1X232ijmQ/OMA/kRgl\nFile: /usr/bin/pstree\nSize : 20296 , 7030\nCtime : 2020-02-10 13:02:18 , 2020-02-11 03:05:53\nMD5 : <NONE> , ry/MUZ7XvU4L2QfWJ4GXxg==\nRMD160 : <NONE> , tFZer6As9EoOi58K7/LgmeiExjU=\nSHA256 : <NONE> , iAsMkqNShagD4qe7dL/EwcgKTRzvKRSe\n...\nThe files listed by the aide  check in this example are infected. However, aide  can also \ndisplay many false positives.", "doc_id": "bc377baa-1bc0-497a-acd8-41f16802449b", "embedding": null, "doc_hash": "48ffaaf3db96602ef57fd2d30dfca8b6a46212a463fa55c4e04151cf8ca02697", "extra_info": {"page_label": "617"}, "node_info": {"start": 0, "end": 1654}, "relationships": {"1": "3b9fbd32-4764-42a4-a26c-5e01e1049f1d"}}, "__type__": "1"}, "c1451c18-209c-4870-9a17-c6f4a2d8bc98": {"__data__": {"text": "Chapter 22: Understanding Basic Linux Security\n595\n22Where aide databases are created, what comparisons are made, and several other configura-\ntion settings are handled in the /etc/aide.conf file. The following is a partial display of \nthe file. You can see the names of the database file and the log file directories set here:\n# cat /etc/aide.conf\n# Example configuration file for AIDE.\n \n@@define DBDIR /var/lib/aide\n@@define LOGDIR /var/log/aide\n \n# The location of the database to be read.\ndatabase=file:@@{DBDIR}/aide.db.gz\n \n# The location of the database to be written.\n#database_out=sql:host:port:database:login_name:passwd:table\n#database_out=file:aide.db.new\ndatabase_out=file:@@{DBDIR}/aide.db.new.gz\n...\nAn Intrusion Detection System can be a big help in monitoring the system. When poten -\ntial intrusions are detected, comparing the output to information from other commands \n(such as rpm -V ) and log files can help you better understand and correct any attacks on \nyour system.\nAuditing and Reviewing Linux\nYou must understand two important terms when you are auditing the health of your Linux \nsystem. A compliance review  is an audit of the overall computer system environment to \nensure that the policies and procedures you have set for the system are being carried out \ncorrectly. A security review  is an audit of current policies and procedures to ensure that \nthey follow accepted best security practices.\nConducting compliance reviews\nSimilar to audits in other fields, such as accounting, audits can be conducted internally or \nby external personnel. These reviews can be as simple as someone sitting down and com-\nparing implemented security to your company\u2019s stated policies. However, more popular is \nconducting audits using penetration testing.\nPenetration testing  is an evaluation method used to test a computer system\u2019s security by \nsimulating malicious attacks. It is also called pen testing and ethical hacking. No longer \ndo you have to gather tools and the local neighborhood hacker to help you conduct \nthese tests.\nKali Linux (https://www.kali.org/) is a distribution created specifically for  \npenetration testing. It can be used from a live DVD or a flash drive. Training on the use of \nKali Linux is offered by Offensive Security (https://www.offensive-security.com/\ninformation-security-training/).", "doc_id": "c1451c18-209c-4870-9a17-c6f4a2d8bc98", "embedding": null, "doc_hash": "78fbf5958b13262d95d6cbfe53852f9f0c28737490aa72de0c8521b548592fea", "extra_info": {"page_label": "618"}, "node_info": {"start": 0, "end": 2340}, "relationships": {"1": "423ba13c-29a7-4cf2-90a0-760eee24a4d6"}}, "__type__": "1"}, "d19a91c1-72e9-4496-a78d-644e1b90c0e5": {"__data__": {"text": "Part V: Learning Linux Security Techniques596While penetration testing is lots of fun, for a thorough compliance review, a little more is \nneeded. You should also use checklists from industry security sites.\nConducting security reviews\nConducting a security review requires that you know current best security practices. There \nare several ways to stay informed about best security practices. The following is a brief list \nof organizations that can help you.\n\u25a0\u25a0United States Cybersecurity and Infrastructure Security Agency (CISA)\n\u25a0\u25a0URL: www.us-cert.gov\n\u25a0\u25a0Offers the National Cyber Alert System\n\u25a0\u25a0Offers RSS feeds on the latest security threats\n\u25a0\u25a0The SANS Institute\n\u25a0\u25a0URL: www.sans.org/security-resources\n\u25a0\u25a0Offers Computer Security Research newsletters\n\u25a0\u25a0Offers RSS feeds on the latest security threats\n\u25a0\u25a0Gibson Research Corporation\n\u25a0\u25a0URL: www.grc.com\n\u25a0\u25a0Offers the Security Now!  security netcast\nInformation from these sites will assist you in creating stronger policies and procedures. \nGiven how fast the best security practices change, it would be wise to conduct security \nreviews often, depending upon your organization\u2019s security needs.\nNow you understand a lot more about basic Linux security. The hard part is actually putting \nall of these concepts into practice.\nSummary\nBasic Linux security practices, such as managing user accounts, securing passwords, and \nmanaging software and services, form the foundation for all other security on your Linux \nsystem. With that foundation in place, ongoing monitoring of your system includes watch -\ning over system log files, checking for malicious intrusions, and monitoring the filesystem.\nReviews of your security policies are also important to keep up on a regular basis. Audits \nassist in ensuring that your Linux system is secured and the proper security policies and \npractices are in place.\nYou have completed your first step of gathering basic security procedures and principles \nknowledge. It is not enough just to know the basics. You need to add advanced Linux secu -\nrity tools to your security toolbox. In the next chapter, advanced security topics of cryp -\ntography and authentication modules are covered.", "doc_id": "d19a91c1-72e9-4496-a78d-644e1b90c0e5", "embedding": null, "doc_hash": "68622f74db8df8c7ea99d87daf3c56cf0274d322731720bd8257e59f0f554fdc", "extra_info": {"page_label": "619"}, "node_info": {"start": 0, "end": 2174}, "relationships": {"1": "d1d2f24f-ef17-408b-9835-d7a4d81891d2"}}, "__type__": "1"}, "55a0e89d-7acd-476e-994b-61737a941e42": {"__data__": {"text": "Chapter 22: Understanding Basic Linux Security\n597\n22Exercises\nRefer to the material in this chapter to complete the tasks that follow. If you are stuck, \nsolutions to the tasks are shown in Appendix B (although in Linux, there are often multiple \nways to complete a task). Try each of the exercises before referring to the answers. These \ntasks assume that you are running a Fedora or Red Hat Enterprise Linux system (although \nsome tasks will work on other Linux systems as well).\n1. Check log messages from the systemd  journal for the following services:  \nNetworkManager.service , sshd.service , and auditd.service .\n2. List the permissions of the file containing your system\u2019s user passwords and deter -\nmine if they are appropriate.\n3. Determine your account\u2019s password aging and if it will expire using a sin -\ngle command.\n4. Start auditing writes to the /etc/shadow  with the auditd  daemon and then \ncheck your audit settings.\n5. Create a report from the auditd  daemon on the /etc/shadow  file, and then turn \noff auditing on that file.\n6. Install the lemon package, damage the /usr/bin/lemon  file (perhaps copy /etc/\nservices  there), verify that the file has been tampered with, and remove the \nlemon package.\n7. You suspect that you have had a malicious attack on your system today and impor -\ntant binary files have been modified. What command should you use to find these \nmodified files?\n8. Install and run chkrootkit  to see if the malicious attack from the exercise above \ninstalled a rootkit.\n9. Find files with the SUID  or SGID  permission set.\n10. Install the aide  package, run the aide  command to initialize the aide database, \ncopy the database to the correct location, and run the aide  command to check if \nany important files on your system have been modified.", "doc_id": "55a0e89d-7acd-476e-994b-61737a941e42", "embedding": null, "doc_hash": "bc4e52e732b847e2aa00e89266e5d06856d1360d2db1541b3dd59f8670405005", "extra_info": {"page_label": "620"}, "node_info": {"start": 0, "end": 1792}, "relationships": {"1": "d51515f7-f737-475d-a6d2-a0225b27bc67"}}, "__type__": "1"}, "41a919fc-eb92-474b-bc76-27329632ba03": {"__data__": {"text": "599\nCHAPTER23\nUnderstanding Advanced \nLinux Security\nIN THIS CHAPTER\nUnderstanding hashing and encryption\nChecking file integrity\nEncrypting files, directories, and filesystems\nUnderstanding pluggable authentication modules\nManaging Linux security with PAM\nDue to ever-changing and growing threats, implementing basic computer security is no longer \nenough. As malicious users gain access to and knowledge of advanced tools, so must a Linux \nsystem administrator. Understanding advanced computer security topics and tools must be \npart of your preparation.\nIn this chapter, you will learn about cryptography basics, such as ciphers and encryption. You will \nalso learn how the authentication module utility can simplify your administrative duties, even \nthough it is an advanced security topic.\nImplementing Linux Security with Cryptography\nUsing cryptography enhances the security of your Linux system and its network communications. \nCryptography  is the science of concealing information. It has a long and rich history that goes back \nfar before computers were around. Because of its heavy use of mathematical algorithms, cryptog -\nraphy has easily transitioned to computers. Linux comes with many cryptographic tools ready for \nyou to use.\nTo understand cryptographic concepts and the various Linux tools, you should know a few cryptog -\nraphy terms:\nPlain text : Text that a human or machine can read and comprehend\nCiphertext : Text that a human or machine cannot read and comprehend\nEncryption : The process of converting plain text into ciphertext using an algorithm\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "41a919fc-eb92-474b-bc76-27329632ba03", "embedding": null, "doc_hash": "e44b02b75982ce48d851cf9f32e5bc22d6dbbe581048be86b6bf7065c534fa00", "extra_info": {"page_label": "621"}, "node_info": {"start": 0, "end": 1698}, "relationships": {"1": "08d5950e-0ca0-47dc-8fb4-e28f865ca8ca"}}, "__type__": "1"}, "b6f80684-ea9c-463a-9fa1-071882eff338": {"__data__": {"text": "Part V: Learning Linux Security Techniques600Decryption : The process of converting cipher text into plain text using an algorithm\nCipher : The algorithm used to encrypt plain text into ciphertext and decrypt cipher -\ntext into plain text\nBlock cipher : A cipher that breaks data into blocks before encrypting\nStream cipher : A cipher that encrypts the data without breaking it up\nKey: A piece of data required by the cipher to encrypt or decrypt data successfully\nParents of young children often use a form of cryptography. They spell words instead of \nspeaking them. A parent may take the plain-text word \u201ccandy\u201d and turn it into ciphertext \nby saying to the other parent \u201cC-A-N-D-Y.\u201d The other parent decrypts the word by using the \nsame spelling cipher and recognizes that the word is \u201ccandy.\u201d Unfortunately, it does not \ntake children long to learn how to decrypt via the spelling cipher.\nYou may have noticed that hashing was not included in the preceding cryptography def -\ninition list. Hashing needs some special attention because it is often confused with \nencryption.\nUnderstanding hashing\nHashing is not encryption, but it is a form of cryptography. Remember from Chapter\u00a022, \n\u201cUnderstanding Basic Linux Security,\u201d that hashing  is a one-way mathematical process used \nto create ciphertext. However, unlike encryption, after you create a hash, you cannot de-\nhash it back to its original plain text.\nIn order for a hashing algorithm to be used in computer security, it needs to be collision-\nfree, which means that the hashing algorithm does not output the same hash for two \ntotally different inputs. Each input must have a unique hashed output. Thus, cryptographic \nhashing  is a one-way mathematical process that is collision-free.\nBy default, cryptography is already in use on a Linux system. For example, the  \n/etc/shadow  file contains hashed passwords. Hashing is used on Linux systems for  \nthe following:\n\u25a0\u25a0Passwords (Chapter\u00a022)\n\u25a0\u25a0Verifying files\n\u25a0\u25a0Digital signatures\n\u25a0\u25a0Virus signatures (Chapter\u00a022)\nA hash is also called a message digest , checksum , fingerprint , or signature . One Linux util -\nity that produces message digests is the sha256sum  utility. In Chapter\u00a010, \u201cGetting and \nManaging Software,\u201d you learned about getting software for your Linux system. When you \ndownload a software file, you can make sure that the file was not corrupted on download.\nFigure\u00a023.1 shows the website for downloading the Fedora distribution software (stored as \na file in the form that is referred to as an ISO image ). The web page describes how to get \nand use the sha256sum  utility to ensure that the ISO image you downloaded was not cor -\nrupted during the download.", "doc_id": "b6f80684-ea9c-463a-9fa1-071882eff338", "embedding": null, "doc_hash": "d79fbec53cd73229d54b9df3d67c29a9f7d2f193c5f98f6d8bdb55763c111d02", "extra_info": {"page_label": "622"}, "node_info": {"start": 0, "end": 2688}, "relationships": {"1": "d698099a-3bc4-4b0b-a98e-699e4be54bb2"}}, "__type__": "1"}, "8dbd0a0b-edd3-46c6-823e-30aceec79a12": {"__data__": {"text": "Chapter 23: Understanding Advanced Linux Security\n601\n23A hash is made up of a software file at its original location, using the SHA-256 hash algorithm. \nThe hash results can be posted in public, as was done in Figure\u00a023.1. To ensure the integrity \nof your downloaded software file, you create an sha256sum hash of the software file at your \nlocation. You then compare the results of your hash to the posted hash results. If they match, \nthe software file was not corrupted upon download.\nTo create your hash, run the sha256sum  command on the ISO image after you download \nthat image. The sha256sum  hash results for the downloaded software file are shown in the \ncode that follows:\n$ sha256sum Fedora-Workstation-Live-x86_64-30-1.2.iso\na4e2c49368860887f1cc1166b0613232d4d5de6b46f29c9756bc7cfd5e13f39f\n   Fedora-Workstation-Live-x86_64-30-1.2.iso\nThe resulting hash does  match the one available from the website in Figure\u00a023.1. This \nmeans that the downloaded ISO file has not been corrupted and is ready for use.\nYou can implement even more cryptography besides hashing on your Linux system. The \nLinux utilities to do so are very easy to use. However, first you need to understand a few \nmore underlying cryptography concepts.\nFIGURE 23.1\nThe Fedora ISO security page tells how to get and check with sha256sum .", "doc_id": "8dbd0a0b-edd3-46c6-823e-30aceec79a12", "embedding": null, "doc_hash": "3c6aef14356cfb56c687a87f93f32da3803911df88e14300a299d319e5026e14", "extra_info": {"page_label": "623"}, "node_info": {"start": 0, "end": 1315}, "relationships": {"1": "f76b83eb-0cfb-4514-a7db-761be15d00fc"}}, "__type__": "1"}, "63d0e4bf-059e-48f2-bbf9-c878a46d0981": {"__data__": {"text": "Part V: Learning Linux Security Techniques602Understanding encryption/decryption\nThe primary use of cryptography on a Linux system is to encode data to hide it (encryp -\ntion) from unauthorized eyes and then decode the data (decryption) for authorized eyes. \nOn a Linux system, you can encrypt the following:\n\u25a0\u25a0Individual files\n\u25a0\u25a0Partitions and volumes\n\u25a0\u25a0Web page connections\n\u25a0\u25a0Network connections\n\u25a0\u25a0Backups\n\u25a0\u25a0Zip files\nThese encryption/decryption processes use special math algorithms to accomplish their \ntask. The algorithms are called cryptographic ciphers .\nUnderstanding cryptographic ciphers\nOne of the original ciphers, called the Caesar Cipher , was created and used by Julius Cae -\nsar. It was terribly easy to crack, however. Today, many more secure ciphers are available. \nUnderstanding how each cipher works is important because the strength of the cipher you \nchoose should directly relate to the security needs of your data. Table\u00a023.1 lists a few mod -\nern ciphers.\nTABLE 23.1  Cryptography Ciphers\nMethod Description\nAES (Advanced Encryption \nStandard), also called RijndaelSymmetric cryptography .\nBlock cipher, encrypting data in 128-, 192-, 256-, 512-bit \nblocks using a 128-, 192-, 256, or 512-bit key for encrypting/\ndecrypting.\nBlowfish Symmetric cryptography .\nBlock cipher, encrypting data in 64-bit blocks using the \nsame 32-bit to 448-bit keys for encrypting/decrypting.\nCAST5 Symmetric cryptography .\nBlock cipher, encrypting data in 64-bit blocks using the \nsame up to 128-bit key for encrypting/decrypting.\nDES (Data Encryption Standard) No longer considered secure.\nSymmetric cryptography .\nBlock cipher, encrypting data in 64-bit blocks using the \nsame 56-bit key for encrypting/decrypting.\n3DES Improved DES cipher.\nSymmetric cryptography .\nData is encrypted up to 48 times with three different 56-bit \nkeys before the encryption process is completed.", "doc_id": "63d0e4bf-059e-48f2-bbf9-c878a46d0981", "embedding": null, "doc_hash": "17ac1e9ec956d7928ecb46f2056fb67c66211df61cf952fe6e7e387c67fd0766", "extra_info": {"page_label": "624"}, "node_info": {"start": 0, "end": 1884}, "relationships": {"1": "5657481b-8fd5-4bc9-be1f-ce813f9429e4"}}, "__type__": "1"}, "bef5acd1-6ec6-45e5-9c85-3234f73f9dd9": {"__data__": {"text": "Chapter 23: Understanding Advanced Linux Security\n603\n23Understanding cryptographic cipher keys\nCryptographic ciphers require a piece of data, called a key , to complete their mathematical \nprocess of encryption/decryption. The key can be either a single key or a pair of keys.\nNotice the different cipher key sizes listed in Table\u00a023.1. The key size is directly related to \nhow easily the cipher is cracked. The bigger the key size, the less the chance of cracking \nthe cipher. For example, DES is no longer considered secure because of its small 56-bit key \nsize. However, a cipher with a key size of 256 bits or 512 bits is considered secure because it \nwould take trillions of years to brute-force crack such a keyed cipher.\nSymmetric key cryptography\nSymmetric cryptography , also called secret key  or private key  cryptography, encrypts plain \ntext using a single keyed cipher. The same key is needed in order to decrypt the data. The \nadvantage of symmetric key cryptography is speed. The disadvantage is the need to share \nthe single key if the encrypted data is to be decrypted by another person.Method Description\nEl Gamal Asymmetric cryptography .\nUses two keys derived from a logarithm algorithm.\nElliptic Curve Cryptosystems Asymmetric cryptography .\nUses two keys derived from an algorithm containing two \nrandomly chosen points on an elliptic curve.\nIDEA Symmetric cryptography .\nBlock cipher, encrypting data in 64-bit blocks using the \nsame 128-bit key for encrypting/decrypting.\nRC4 also called  \nArcFour or ARC4Stream cipher, encrypting data in 64-bit blocks using a vari -\nable key size for encrypting/decrypting.\nRC5 Symmetric cryptography .\nBlock cipher, encrypting data in 32-, 64-, or 128-bit blocks \nusing the same up to 2,048-bit keys for encrypting/\ndecrypting.\nRC6 Symmetric cryptography .\nSame as RC5, but slightly faster.\nRijndael also called AES Symmetric cryptography .\nBlock cipher, encrypting data in 128-, 192-, 256-, 512-bit \nblocks using a 128-, 192-, 256-, or 512-bit key for encrypting/\ndecrypting.\nRSA Most popular asymmetric cryptography .\nUses two keys derived from an algorithm containing a mul -\ntiple of two randomly generated prime numbers.", "doc_id": "bef5acd1-6ec6-45e5-9c85-3234f73f9dd9", "embedding": null, "doc_hash": "e959c4a9793a00ef78e515a3792bae090ae4b2d4a54f3df0ce5fa7a3633fb78a", "extra_info": {"page_label": "625"}, "node_info": {"start": 0, "end": 2187}, "relationships": {"1": "2e4cb92a-4cb5-4a70-a423-8df0e76b64ca"}}, "__type__": "1"}, "a8d33be9-a4a2-476d-b1ad-ed3d700006f1": {"__data__": {"text": "Part V: Learning Linux Security Techniques604An example of symmetric key cryptography on a Linux system is accomplished using the \nOpenPGP utility, GNU Privacy Guard, gpg2 . The gnupg2 package is installed by default \nin Fedora and RHEL. For Ubuntu, you need to install the gnupg2 package to get the \ngpg2  command.\nEncrypting and decrypting a tar archive file\nThe example that follows shows the tar  command used to create a compressed tar archive \n(backup.tar.gz ) and the gpg2  utility used to encrypt the file. With the -c  option, gpg2  \nencrypts the file with a symmetric key. The original file is kept and a new encrypted file, \nbackup.tar.gz.gpg , is created.\n# tar -cvzf /tmp/backup.tar.gz /etc\n# gpg2 -c --force-mdc \\\n    -o /tmp/backup.tar.gz.gpg /tmp/backup.tar.gz\nEnter passphrase: ******\nRepeat passphrase: ******\n# cd /tmp ; file backup*\n/tmp/enc/backup.tar.gz:     gzip compressed data, last modified: Thu\n    Jan 30 02:36:48 2020, from Unix, original size modulo 2^32 \n49121280\n/tmp/enc/backup.tar.gz.gpg: GPG symmetrically encrypted data \n(CAST5 cipher)\nThe single key used to encrypt the file is protected by a passphrase. This passphrase is sim-\nply a password or phrase chosen by the user at the time of encryption.\nTo decrypt the file, use the gpg2  utility again. For example, if you were to hand the file to \nanother user, that user could run gpg2  with the -d  option and provide the passphrase for \nthe secret key.\n$ gpg2 -d --force-mdc /tmp/backup.tar.gz.gpg > /tmp/backup.tar.gz\n<A pop-up window asks for your passphrase>\ngpg: CAST5 encrypted data\ngpg: encrypted with 1 passphrase\n...\nThe result here is that the original tar file is decrypted and copied to /tmp/backup.tar.\ngz. If the gpg-agent  daemon is running on the system, that passphrase is cached so that \nfile could be decrypted again without entering the passphrase again.\nSymmetric key cryptography is rather simple and easy to understand. Asymmetric cryptog -\nraphy is much more complicated and often is a point of confusion in cryptography.\nAsymmetric key cryptography\nAsymmetric cryptography , also called private/public key cryptography, uses two keys, \ncalled a key pair . A key pair consists of a public key and a private key. The public key \nis just that\u2014public. There is no need to keep it secret. The private key needs to be \nkept secret.", "doc_id": "a8d33be9-a4a2-476d-b1ad-ed3d700006f1", "embedding": null, "doc_hash": "4ff280230d688db96715abf6b81322e07f395f417fc23d8b32e90d39b23642c8", "extra_info": {"page_label": "626"}, "node_info": {"start": 0, "end": 2337}, "relationships": {"1": "749a9622-920c-4930-ad12-993d11205de3"}}, "__type__": "1"}, "8c59078a-b43a-4309-b7e2-8d2f06e4f05d": {"__data__": {"text": "Chapter 23: Understanding Advanced Linux Security\n605\n23The general idea of asymmetric key cryptography is shown in Figure\u00a023.2. A plain-text file \nis encrypted using a public key of a key pair. The encrypted file then can be securely trans -\nmitted to another person. To decrypt the file, the private key is used. This private key must \nbe from the public/private key pair. Thus, data that has been encrypted with the public \nkey can only be decrypted with its private key. The advantage of asymmetric cryptography \nis heightened security. The disadvantage is speed and key management.\nGenerating a key pair\nYou can perform asymmetric encryption on your Linux system using gpg2 . It is a very ver -\nsatile cryptographic utility. Before you can encrypt a file, you must first create your key \npair and a \u201ckey ring.\u201d In the example that follows, the gpg2 --gen-key  command was \nused. This command creates a public/private key pair for the user johndoe , according to \nhis desired specifications. It also generates a key ring to store his keys.\n$ gpg2 --gen-key\ngpg (GnuPG) 2.2.9; Copyright (C)\n 2018 Free Software Foundation, Inc.\n...\nGnuPG needs to construct a user ID to identify your key.\nReal name: John Doe\nEmail address: jdoe@example.com\nYou selected this USER-ID:\n    \"John Doe <jdoe@gmail.com>\"\nChange (N)ame, (E)mail or (O)kay/(Q)uit? OPublic Key Private Key\nUnencr ypted\n\ufb01leUnencr ypted\n\ufb01leEncrypted\n\ufb01leEncrypted\n\ufb01leFIGURE 23.2\nBasic asymmetric key cryptography", "doc_id": "8c59078a-b43a-4309-b7e2-8d2f06e4f05d", "embedding": null, "doc_hash": "9cae8105dd300edca2eedc05c46af2eb8b092638010663a187e91ab58698c3c4", "extra_info": {"page_label": "627"}, "node_info": {"start": 0, "end": 1471}, "relationships": {"1": "cf3c703d-b532-4295-a0c7-ba98a207f835"}}, "__type__": "1"}, "11c3a327-bec8-434f-9ae5-b46e48f1606b": {"__data__": {"text": "Part V: Learning Linux Security Techniques606You need a Passphrase to protect your secret key.\n<A pop-up window prompts you for a passphrase>\nEnter passphrase: **********\nRepeat passphrase: **********\n...\ngpg: /home/jdoe/.gnupg/trustdb.gpg: trustdb created\ngpg: key 383D645D9798C173 marked as ultimately trusted\ngpg: directory '/home/jdoe/.gnupg/openpgp-revocs.d' created\ngpg: revocation certificate stored as '/home/jdoe/.gnupg/openpgp-\nrevocs.d/7469BCD3D05A4\n3130F1786E0383D645D9798C173.rev'\npublic and secret key created and signed.\npub   rsa2048 2019-10-27 [SC] [expires: 2021-10-26]\n      7469BCD3D05A43130F1786E0383D645D9798C173\nuid                      John Doe <jdoe@example.com>\nsub   rsa2048 2019-10-27 [E] [expires: 2021-10-26]\nIn the preceding example, the gpg2  utility asks for several specifications to generate the \ndesired public/private keys:\nUser ID : This identifies the public key portion of the public/private key pair.\nEmail Address : This is the email address associated with the key.\nPassphrase : This is used to identify and protect the private key portion of the public/\nprivate key pair.\nThe user johndoe  can check his key ring by using the gpg2 --list-keys  command, as \nshown in the code that follows. Notice the User ID (UID) of the public key is displayed just \nas it was created, containing johndoe \u2019s real name, comment, and email address.\n$ gpg2 --list-keys\n/home/jdoe/.gnupg/pubring.kbx\n-----------------------------\npub   rsa2048 2019-10-27 [SC] [expires: 2021-10-26]\n      7469BCD3D05A43130F1786E0383D645D9798C173\nuid           [ultimate] John Doe <jdoe@example.com>\nsub   rsa2048 2019-10-27 [E] [expires: 2021-10-26]\nAfter the key pair and key ring are generated, files can be encrypted and decrypted. First, \nthe public key must be extracted from the key ring so that it can be shared. In the example \nthat follows, the gpg2  utility is used to extract the public key from johndoe \u2019s key ring. \nThe extracted key is put into a file to be shared. The filename can be any name you wish it \nto be. In this case, the user johndoe  chose the filename JohnDoe.pub .\n$ gpg2 --export John Doe > JohnDoe.pub\n$ ls *.pub\nJohnDoe.pub\n$ file JohnDoe.pub\nJohnDoe.pub: PGP/GPG key public ring (v4) created Sun Oct 27 16:24:27 \n2019 RSA (Encrypt or Sign) 2048 bits MPI=0xc57a29a6151b3e8d...", "doc_id": "11c3a327-bec8-434f-9ae5-b46e48f1606b", "embedding": null, "doc_hash": "dc0d5c34f5dbec88addbf50054261b8d5f2aae0db41d5c82fa0f9fecdb9a4e3b", "extra_info": {"page_label": "628"}, "node_info": {"start": 0, "end": 2315}, "relationships": {"1": "15766b8a-3298-4022-9df9-9c245d98097b"}}, "__type__": "1"}, "e068f964-17db-4aa1-995d-7338b3e547c5": {"__data__": {"text": "Chapter 23: Understanding Advanced Linux Security\n607\n23Sharing a public key\nThe file containing the public key can be shared in any number of ways. It can be sent as \nan attachment via email or even posted on a web page. The public key is considered public, \nso there is no need to hide it. In the example that follows, johndoe  has given the file \ncontaining his public key to the user jill . She adds johndoe \u2019s public key to her key ring \nusing the gpg2 --import  command. The user jill  verifies that johndoe \u2019s public key is \nadded using the gpg2 --list-keys  command to view her key ring.\n$ ls *.pub\nJohnDoe.pub\n$ gpg2 --import JohnDoe.pub\ngpg: directory '/home/jill/.gnupg' created\n...\ngpg: directory '/home/jill/.gnupg' created\ngpg: keybox '/home/jill/.gnupg/pubring.kbx' created\ngpg: /home/jill/.gnupg/trustdb.gpg: trustdb created\ngpg: key 383D645D9798C173: public key \"John Doe <jdoe@example.com>\" \nimported\ngpg: Total number processed: 1\ngpg:               imported: 1\n$ gpg2 --list-keys\n/home/jill/.gnupg/pubring.gpg\n----------------------------\npub   rsa2048 2019-10-27 [SC] [expires: 2021-10-26]\n      7469BCD3D05A43130F1786E0383D645D9798C173\nuid           [ unknown] John Doe <jdoe@example.com>\nsub   rsa2048 2019-10-27 [E] [expires: 2021-10-26]\nEncrypting an email message\nAfter the key is added to the key ring, that public key can be used to encrypt data for the \npublic key\u2019s original owner. In the example code that follows, note that jill  has created a \ntext file, MessageForJohn.txt , for user johndoe .\n\u25a0\u25a0She encrypts the file using his  public key.\n\u25a0\u25a0The encrypted file, MessageForJohn , is created by the --out  option.\n\u25a0\u25a0The option --recipient  identifies johndoe \u2019s public key using only the real name \nportion of his public key\u2019s UID in quotation marks, \u2033 John Doe \u2033.\n$ gpg2 --out MessageForJohn --recipient \"John Doe\" \\\n    --encrypt MessageForJohn.txt\n...\n$ ls\nJohnDoe.pub  MessageForJohn  MessageForJohn.txt\nThe encrypted message file, MessageForJohn , created from the plain-text file, Message -\nForJohn.txt , can be securely sent to the user johndoe . In order to decrypt this mes -\nsage, johndoe  uses his  private key, identified and protected by the secret passphrase used \nto create the key originally. After johndoe  provides the proper passphrase, gpg2  decrypts ", "doc_id": "e068f964-17db-4aa1-995d-7338b3e547c5", "embedding": null, "doc_hash": "82437f789a3a2fbfb3201fa9266fd65d51ba3cfb8c8c8170252e29def677f3c3", "extra_info": {"page_label": "629"}, "node_info": {"start": 0, "end": 2304}, "relationships": {"1": "e74bec38-64f3-46f6-9792-f8c8216d37e1"}}, "__type__": "1"}, "9df54351-f55e-4e43-a8bf-8c2313051034": {"__data__": {"text": "Part V: Learning Linux Security Techniques608the message file and puts it into the file JillsMessage , designated by the --out  option. \nOnce it\u2019s decrypted, he can read the plaintext message.\n$ ls MessageForJohn\nMessageForJohn\n$ gpg2 --out JillsMessage --decrypt MessageForJohn\n<A pop-up window prompts you for a passphrase>\ngpg: encrypted with 2048-bit RSA key, ID D9EBC5F7317D3830, created \n2019-10-27\n      \"John Doe <jdoe@example.com>\"\n$ cat JillsMessage\nI know you are not the real John Doe.\nTo review, the steps needed for encryption/decryption of files using asymmetric keys \ninclude the following:\n1. Generate the key pair and the key ring.\n2. Export a copy of your public key to a file.\n3. Share the public key file.\n4. Individuals who want to send you encrypted files add your public key to \ntheir key ring.\n5. A file is encrypted using your  public key.\n6. The encrypted file is sent to you.\n7. You decrypt the file using your  private key.\nYou can see why asymmetric keys can cause confusion! Remember that in asymmetric cryp -\ntography, each public and private key is a paired set that works together.\nUnderstanding digital signatures\nA digital signature  is an electronic originator used for authentication and data verification. \nA digital signature is not a scan of your physical signature. Instead, it is a cryptographic \ntoken sent with a file, so the file\u2019s receiver can be assured that the file came from you and \nhas not been modified in any way.\nWhen you create a digital signature, the following steps occur:\n1. You create a file or message.\n2. Using the gpg2  utility, you create a hash or message-digest of the file.\n3. The gpg2  utility then encrypts the hash and the file, using an asymmetric key \ncipher. For the encryption, the private key of the public/private key pair is used. \nThis is now a digitally signed encrypted file.\n4. You send the encrypted hash (aka digital signature) and file to the receiver.\n5. The receiver re-creates the hash or message digest of the received encrypted file.", "doc_id": "9df54351-f55e-4e43-a8bf-8c2313051034", "embedding": null, "doc_hash": "63c6631948cb3f770673d7e466ad27c7b0605d79f083683d3b7386f747d757f4", "extra_info": {"page_label": "630"}, "node_info": {"start": 0, "end": 2024}, "relationships": {"1": "026df233-c40e-46d9-b93f-1720a4e6eb88"}}, "__type__": "1"}, "3e94ab66-0311-4fe3-b91e-8404af858e38": {"__data__": {"text": "Chapter 23: Understanding Advanced Linux Security\n609\n236. Using the gpg2  utility, the receiver decrypts the received digital signature using \nthe public key, to obtain the original hash or message digest.\n7. The gpg2  utility compares the original hash to the re-created hash to see if they \nmatch. If they match, the receiver is told the digital signature is good.\n8. The receiver can now read the decrypted file.\nNotice in step 3 that the private key is used first. In the description of asymmetric key \ncryptography, the public key was used first. Asymmetric key cryptography is flexible \nenough to allow you to use your private key to encrypt and the receiver to use your public \nkey to decrypt.\nNote\nDigital signatures have their own special ciphers. While several ciphers can handle both encryption and creating \nsignatures, there are a few whose only job is to create digital signatures. Previously, the most popular cryptographic \nciphers to use in creating signatures were RSA and Digital Signature Algorithm (DSA). The RSA algorithm can be \nused for both encryption and creating signatures, while DSA can be used only for creating digital signatures. Today, \nEd25519 is considered to be more secure and faster than RSA, and ECDSA provides better protection than DSA.\nAs you can see, a digital signature contains both cryptographic hashing and asymmetric \nkey cryptography. This complicated process is often handled by an application that has \nbeen configured to do so, instead of being directly handled by Linux system users. How -\never, you can manually add your own digital signatures to documents.\nSigning a file with a digital signature\nLet\u2019s say that user johndoe  is going to send a message to the user christineb , along with \nhis digital signature. He has created a file containing the plain-text message to send. He uses \nthe gpg2  utility to create the signature file and encrypt the message file. The --sign  option \ntells the gpg2  utility that MessageForChristine.txt  is the file to encrypt and use to \ncreate the digital signature. In response, the gpg2  utility does the following:\n\u25a0\u25a0Creates a message digest (aka hash) of the message file\n\u25a0\u25a0Encrypts the message digest, which creates the digital signature\n\u25a0\u25a0Encrypts the message file\n\u25a0\u25a0Places the encrypted contents into the file specified by the --output  option, \nJohnDoe.DS\nThe file JohnDoe.DS  now contains an encrypted and digitally signed message. The follow -\ning code demonstrates this process:\n$ gpg2 --output JohnDoe.DS --sign MessageForJill.txt\n \nAfter the user jill  receives the signed and encrypted file, she can use the gpg2  utility to \ncheck the digital signature and decrypt the file in one step. In the code that follows, the ", "doc_id": "3e94ab66-0311-4fe3-b91e-8404af858e38", "embedding": null, "doc_hash": "3704fb0e722bd9a4c5df30cec04308f192f2a1b9b688faf63054bd3a5495895b", "extra_info": {"page_label": "631"}, "node_info": {"start": 0, "end": 2724}, "relationships": {"1": "7ee00712-165d-4f15-8c96-e58ce2254ff1"}}, "__type__": "1"}, "88674dbf-c39c-49cb-a616-6afe413e5587": {"__data__": {"text": "Part V: Learning Linux Security Techniques610--decrypt  option is used along with the name of the digitally signed file, JohnDoe.DS . \nThe file's message is decrypted and shown. The digital signature of the file is checked and \nfound to be valid.\n$ gpg2 --decrypt JohnDoe.DS\nI am the real John Doe!\ngpg: Signature made Sun 27 Oct 2019 07:03:21 PM EDT\ngpg:                using RSA key \n7469BCD3D05A43130F1786E0383D645D9798C173\ngpg: Good signature from \"John Doe <jdoe@example.com>\" [unknown]\n...\nWithout johndoe \u2019s public key on her key ring, jill  would not be able to decrypt this \nmessage and check the digital signature.\ntip\nThe previous example of digitally signing a document allows anyone with the public key the ability to decrypt the \ndocument. In order to keep it truly private, use the public key of the recipient to encrypt with the gpg2  options: \n--sign  and --encrypt . The recipient can decrypt with their private key.\nUnderstanding a few cryptography basics will help you get started on securing your Linux \nsystem with encryption. Keep in mind that we\u2019ve covered just the basics in this chapter. \nThere are many more cryptography topics, such as digital certificates and public key infra -\nstructure, that would be worth your time to learn.\nImplementing Linux cryptography\nMany cryptography tools are available on your Linux system. Which ones you choose to use \ndepend upon your organization\u2019s security requirements. The following is a brief review of \nsome of the Linux cryptography tools available.\nEnsuring file integrity\nEarlier in this chapter, an ISO\u2019s file integrity was checked using the message digest utility \nsha256sum .\nRelated message digest utilities include the following:\n\u25a0\u25a0sha224sum\n\u25a0\u25a0sha256sum\n\u25a0\u25a0sha384sum\n\u25a0\u25a0sha512sum\nThese tools work just like the sha1sum  command, except, of course, they use the SHA-2 \ncryptographic hash standard. The only difference between the various SHA-2 tools is \nthe key length they use. The sha224sum  command uses a key length of 224 bits, the ", "doc_id": "88674dbf-c39c-49cb-a616-6afe413e5587", "embedding": null, "doc_hash": "d4bba03189e9a81d2b6f21997c7c524f9423934b7115537c416ad6b14cbe3a6f", "extra_info": {"page_label": "632"}, "node_info": {"start": 0, "end": 2011}, "relationships": {"1": "706c75e1-2e2f-40d0-b375-fe191221057a"}}, "__type__": "1"}, "76893ab9-a9e6-4af5-9e42-6eabe753aa01": {"__data__": {"text": "Chapter 23: Understanding Advanced Linux Security\n611\n23sha256sum  command uses a key length of 256 bits, and so on. Remember that the longer \nthe key length, the less the chance of cracking the cipher.\nThe SHA-2 cryptographic hash standard was created by the National Security Agency (NSA). \nSHA-3 is another cryptographic hash standard, which was released by NIST in August 2015.\nEncrypting a Linux filesystem at installation\nYou may need to encrypt an entire filesystem on your Linux server. This can be done in a \nnumber of different ways, including using a Free and Open Source Software (FOSS) third-party \ntool such as Linux Unified Key Setup (LUKS) (https://gitlab.com/cryptsetup/cryptsetup).\nOne of your options in Linux is to encrypt your root partition upon installation (see Chap -\nter\u00a09, \u201cInstalling Linux\u201d). Many Linux distributions include an encryption option during \ntheir installation process. Figure\u00a023.3 shows the encryption option during a Red Hat Enter -\nprise Linux installation.\nAfter you select this option during installation, you are asked for a password. This is \nsymmetric key cryptography with a password protecting the single key. Figure\u00a023.4 shows the \ninstallation asking for the key\u2019s password. The password must be at least eight characters long.\nFIGURE 23.3\nRed Hat Enterprise Linux installation encryption option\nFIGURE 23.4\nLinux Fedora encryption symmetric key password", "doc_id": "76893ab9-a9e6-4af5-9e42-6eabe753aa01", "embedding": null, "doc_hash": "9ca824041a8a0ee1071c7758c4029424da2a568ed9816d466b08941764a62b20", "extra_info": {"page_label": "633"}, "node_info": {"start": 0, "end": 1407}, "relationships": {"1": "8a63abcc-54f5-46b7-a54c-fc7462cc0141"}}, "__type__": "1"}, "ae5d25bd-0605-4843-98a6-ca9013b9925f": {"__data__": {"text": "Part V: Learning Linux Security Techniques612If you select this encryption option, whenever you boot the system, you are asked for the \nsymmetric key password. Figure\u00a023.5 shows what this looks like. This protects the root par -\ntition, should the disk it resides on be stolen.\nIf you inherit a system with an encrypted disk, using root privileges, you can use the lvs  \nand cryptsetup  commands and the /etc/crypttab  file to help. In the following exam-\nple, the lvs  command shows all of the logical volumes currently on the system and their \nunderlying device names. See Chapter\u00a012, \u201cManaging Disks and Filesystems,\u201d for a review of \ndifferent LVM commands.\n# lvs -o devices\n  Devices\n  /dev/mapper/luks-b099fbbe-0e56-425f-91a6-44f129db9f4b(56)\n  /dev/mapper/luks-b099fbbe-0e56-425f-91a6-44f129db9f4b(0)\nOn this system, notice that the underlying device names start with luks . This indicates \nthat the Linux Unified Key Setup (LUKS) standard for hard disk encryption has been used.\nNote\nUbuntu does not have the lvs  command installed by default. To install it, type sudo apt-get install \nlvm2  at the command line.\nThe encrypted logical volumes are mounted at boot time using the information from the /\netc/fstab  file. However, contents of the /etc/crypttab  file, which are used to trigger \nthe capture of the password at boot time, will decrypt the /etc/fstab  entries as they are \nmounted. This is shown in the following code. Notice that the luks  names are the same as \nthose listed by the lvs  command in the previous example.\n# cat /etc/crypttab\nluks-b099fbbe-0e56-425f-91a6-44f129db9f4b\n     UUID=b099fbbe-0e56-425f-91a6-44f129db9f4b none\nYou can also use the cryptsetup  command to help you uncover more information about \nyour Linux system\u2019s encrypted volumes. In the example that follows, the status  option is \nused along with the luks  device name to determine further information.\nFIGURE 23.5\nAsking for the encryption symmetric key password at boot", "doc_id": "ae5d25bd-0605-4843-98a6-ca9013b9925f", "embedding": null, "doc_hash": "ec02737a836f69fe2becb79784ffe4b13f79a82173e088cdb6f832e1c4ee4ec7", "extra_info": {"page_label": "634"}, "node_info": {"start": 0, "end": 1970}, "relationships": {"1": "764e66b4-ff42-4dce-8313-38dc8d2f41b0"}}, "__type__": "1"}, "91bedafe-a40c-4019-bc5e-9dbfcd66dd27": {"__data__": {"text": "Chapter 23: Understanding Advanced Linux Security\n613\n23# cryptsetup status luks-b099fbbe-0e56-425f-91a6-44f129db9f4b\n/dev/mapper/luks-b099fbbe-0e56-425f-91a6-44f129db9f4b\n is active and is in use.\n  type:    LUKS1\n  cipher:  aes-xts-plain64\n  keysize: 512 bits\n  device:  /dev/sda3\n  offset:  4096 sectors\n  size:    493819904 sectors\n  mode:    read/write\nEncrypting a Linux directory\nYou can also use the ecryptfs  utility to encrypt on a Linux system. The ecryptfs  util-\nity is not a filesystem type, as the name would imply. Instead, it is a POSIX-compliant util -\nity that allows you to create an encryption layer on top of any filesystem.\nThe ecryptfs  utility is not installed by default on Fedora and not available in RHEL. To \ninstall that utility in Fedora, you use the command dnf install ecryptfs-utils . \nIf it is not installed on a Debian system, use the command sudo apt-get install \necrypt-utils .\ntip\nBecause the ecryptfs  utility is used for encryption, it is a common mistake to put the letter n after the letter e in \nthe syntax ecryptfs . If you get an error while using the ecryptfs  utilities, make sure that you did not use the \nsyntax encryptfs  by mistake.\nIn the example that follows, the user johndoe  will have a subdirectory encrypted using \nthe ecryptfs  utility. First, there should be no files currently residing in the directory \nbefore it is encrypted. If there are files located there, move them to a safe place until after \nthe encryption has been completed. If you do not move them, you cannot access them \nwhile the directory is encrypted.\nNow, to encrypt the directory /home/johndoe/Secret , use the mount  command. You \nmust have root privileges to mount and unmount the encrypted directory in this method. \nLook at the mount  command used in the example that follows. It is somewhat similar to \nthe regular mount  command, except that the partition type used is ecryptfs . The item \nto mount and its mount point are the same directory! You are literally encrypting the \ndirectory and mounting it upon itself. The other unusual item about this mount  command \nis that it kicks off the ecryptfs  utility, which asks a few interactive questions.\n# mount -t ecryptfs /home/johndoe/Secret /home/johndoe/Secret\nSelect key type to use for newly created files:\n 1) tspi\n 2) passphrase\n 3) pkcs11-helper\n 4) openssl", "doc_id": "91bedafe-a40c-4019-bc5e-9dbfcd66dd27", "embedding": null, "doc_hash": "7badc9bb876d7c595093750c2b6dcc97ab9b8adadc734a62fbb31a718240a132", "extra_info": {"page_label": "635"}, "node_info": {"start": 0, "end": 2350}, "relationships": {"1": "6f0b5503-9bf5-4524-828e-6c049759dfa7"}}, "__type__": "1"}, "5e66b07d-6008-409e-930d-cc35efb3605c": {"__data__": {"text": "Part V: Learning Linux Security Techniques614Selection: 2\nPassphrase: **********\nSelect cipher:\n 1) aes: blocksize = 16;\n min keysize = 16; max keysize = 32 (loaded)\n 2) blowfish: blocksize = 16;\n min keysize = 16; max keysize = 56 (not loaded)\n 3) des3_ede: blocksize = 8;\n min keysize = 24; max keysize = 24 (not loaded)\n 4) twofish: blocksize = 16;\n min keysize = 16; max keysize = 32 (not loaded)\n 5) cast6: blocksize = 16;\n min keysize = 16; max keysize = 32 (not loaded)\n 6) cast5: blocksize = 8;\n min keysize = 5; max keysize = 16 (not loaded)\nSelection [aes]: 1\nSelect key bytes:\n 1) 16\n 2) 32\n 3) 24\nSelection [16]: 16\nEnable plaintext passthrough (y/n) [n]: n\nEnable filename encryption (y/n) [n]: n\nAttempting to mount with the following options:\n  ecryptfs_unlink_sigs\n  ecryptfs_key_bytes=16\n  ecryptfs_cipher=aes\n  ecryptfs_sig=70993b8d49610e67\nWARNING: Based on the contents of [/root/.ecryptfs/sig-cache.txt]\nit looks like you have never mounted with this key\nbefore. This could mean that you have typed your\npassphrase wrong.\n \nWould you like to proceed with the mount (yes/no)? : yes\nWould you like to append sig [70993b8d49610e67] to\n[/root/.ecryptfs/sig-cache.txt]\nin order to avoid this warning in the future (yes/no)? : yes\nSuccessfully appended new sig to user sig cache file\nMounted eCryptfs\nThe ecryptfs  utility allows you to choose the following:\n\u25a0\u25a0Key type\n\u25a0\u25a0Passphrase\n\u25a0\u25a0Cipher\n\u25a0\u25a0Key size (in bytes)\n\u25a0\u25a0To enable or disable plain text to pass through\n\u25a0\u25a0To enable or disable filename encryption", "doc_id": "5e66b07d-6008-409e-930d-cc35efb3605c", "embedding": null, "doc_hash": "f490b6b86ac15180607f84d4a961583e63458f47589e3b93009c04513cccbfed", "extra_info": {"page_label": "636"}, "node_info": {"start": 0, "end": 1521}, "relationships": {"1": "66350227-7841-460c-bf9a-3596b667258e"}}, "__type__": "1"}, "ae338825-0a2f-474b-a717-484fbead0c3a": {"__data__": {"text": "Chapter 23: Understanding Advanced Linux Security\n615\n23It also warns you when you are first mounting this encrypted directory because the key \nhas not been used before. The utility allows you to apply a digital signature to the mounted \ndirectory so that if you mount  it again, it just mounts the directory and does not require a \npassphrase.\ntip\nWrite down the selections you make when you mount an ecryptfs  folder for the first time. You need the exact \nselections you chose the next time you remount the folder.\nTo verify that the encrypted directory is now mounted, you can use the mount  command \nagain. In the example that follows, the mount  command is used and then piped into grep  \nto search for the /home/johndoe/Secret  directory. As you can see, the directory is \nmounted with an ecryptfs  type.\n# mount | grep /home/johndoe/Secret\n \n/home/johndoe/Secret on /home/johndoe/Secret type ecryptfs\n(rw,relatime,ecryptfs_sig=70993b8d49610e67,ecryptfs_cipher=aes,\necryptfs_key_bytes=16,ecryptfs_unlink_sigs)\nSo far, you have not seen the effects of this mounted and encrypted directory. In the text \nthat follows, the file my_secret_file  is copied to the encrypted directory. User john -\ndoe can still use the cat  command to display the file in plain text. The file is automati-\ncally decrypted by the ecryptfs  layer.\n$ cp my_secret_file Secret\n$ cat /home/johndoe/Secret/my_secret_file\nShh... It's a secret.\nThe root user also can use the cat  command to display the file in plain text.\n# cat /home/johndoe/Secret/my_secret_file\nShh... It's a secret.\nHowever, after the encrypted directory is unmounted using the umount  command, the \nfiles are no longer automatically decrypted. The file my_secret_file  is now gibberish \nand cannot be read, even by the root user.\n# umount /home/johndoe/Secret\nThus, the ecryptfs  utility allows you to create a location on the filesystem to encrypt \nand decrypt files quickly. However, after that directory is no longer mounted as an \necryptfs  type, the files are secure and cannot be decrypted.\ntip\nAs a non-root user, you could use the ecryptfs-setup-private  and ecryptfs-mount-private  com-\nmands to configure a private cryptographic mountpoint as a non-root user.", "doc_id": "ae338825-0a2f-474b-a717-484fbead0c3a", "embedding": null, "doc_hash": "5dd08047312a7a05942ea9eb9b67119169a7cec747bae182ddb6062c4334fb2e", "extra_info": {"page_label": "637"}, "node_info": {"start": 0, "end": 2218}, "relationships": {"1": "bb83d2c0-00bd-468b-bd96-e3a731a50e41"}}, "__type__": "1"}, "6561232f-7876-48d7-8209-493dd45ae370": {"__data__": {"text": "Part V: Learning Linux Security Techniques616Encrypting a Linux file\nThe most popular tool for file encryption on a Linux system is the OpenPGP utility GNU \nPrivacy Guard, gpg . Its flexibility and variety of options, along with the fact that it is \ninstalled by default on most Linux distributions, add to its appeal.\nCautio N\nIf your organization uses a third-party cloud storage company, you need to know that some of these companies, such \nas Dropbox, do not encrypt the files until they are received. This means that the company has the keys required to \ndecrypt your files and can leave your organization\u2019s data vulnerable. Encrypting files on your Linux system before they \nare sent to the cloud adds the extra layer of protection needed.\nHowever, you can use several other cryptography tools on a Linux system to encrypt files. \nJust like gpg , many of these tools allow you to do much more than merely file encryp -\ntion. The following are some of the popular Linux cryptography tools that you can use to \nencrypt files:\naescrypt : It uses the symmetric key cipher Rijndael, also called AES. This third-party \nFOSS tool is available for download from\u00a0www.aescriypt.com.\nbcrypt : This tool uses the symmetric key cipher blowfish . It is not installed by \ndefault. After bcrypt  is installed, man pages are available.\n\u25a0\u25a0For Fedora (not available in RHEL) : yum install bcrypt\n\u25a0\u25a0For Ubuntu : sudo apt-get install bcrypt\nccrypt : This tool uses the symmetric key cipher Rijndael, also called AES. It was cre -\nated to replace the standard Unix crypt  utility and is not installed by default. \nAfter ccrypt  is installed, man pages are available.\n\u25a0\u25a0For Fedora (not available in RHEL) : yum install ccrypt\n\u25a0\u25a0For Ubuntu : sudo apt-get install ccrypt\ngpg: This utility can use either asymmetric key pairs or a symmetric key. It is \ninstalled by default, and it is the cryptography tool of choice for Linux servers. The \ndefault cipher to use is set in the gpg.conf  file. There are man pages available as \nwell as info gnupg .\nKeep in mind that this list covers only the more popular tools. Also, remember that many \nof these tools can be used for more than just file cryptography.\nEncrypting Linux with miscellaneous tools\nYou can apply cryptography , defined as the act of writing or generating codes meant to keep \nsecrets, to just about everything in Linux. Besides filesystems, directories, and files, you \ncan also encrypt backups, Zip files, network connections, and more.", "doc_id": "6561232f-7876-48d7-8209-493dd45ae370", "embedding": null, "doc_hash": "055eaa2a75bc4cb704dbfe172af6c1c507a7ed4db0331f31d3eefbc1634f439f", "extra_info": {"page_label": "638"}, "node_info": {"start": 0, "end": 2480}, "relationships": {"1": "3aed12bb-9fd8-4276-8a02-4db208c5bd94"}}, "__type__": "1"}, "632fd1f9-cf7d-4a93-acd8-9d0ea1a17fda": {"__data__": {"text": "Chapter 23: Understanding Advanced Linux Security\n617\n23Table\u00a023.2 lists some of the miscellaneous Linux cryptography tools and what they do. If \nyou want to see a full list of installed cryptography tools on your current Linux distribu -\ntion, type man -k crypt at the command line.\nLike many other items on a Linux system, the available cryptography tools are rich and \nplentiful. This gives you the flexibility and variety that you need in order to implement the \ncryptography standards your particular organization requires.\nUsing Encryption from the Desktop\nThe Passwords and Keys window provides a means of viewing and managing keys and pass -\nwords from the GNOME desktop. This window can be launched by selecting the Passwords \nand Keys icon from the Activities screen or by running the seahorse  command. With the \nwindow that appears, you can work with the following:\nPasswords : When you access a website, from a Chromium or Chrome web browser, and \nenter a username and password (and you select to save that password), it is stored \non your system for the next time that you visit that site. Select the Login entry \nunder the Passwords heading to see each of these saved usernames and passwords.\nCertificates : You can view certificates associated with the Gnome2 Key Storage, User \nKey Storage, System Trust, and Default Trust.\nPGP keys : You can view the GPG keys that you create by selecting the GnuPG \nkeys entry.\nSecure Shell : You can create public and private OpenSSH keys that let you log in to \nremote systems using those keys instead of passwords for authentication with ssh , \nscp, rsync , sftp , and related commands. Select OpenSSH keys to view any keys \nthat you have created for this purpose. (See the section \u201cUsing key-based password -\nless authentication\u201d in Chapter\u00a013 for information on creating these types of keys.)TABLE 23.2  Linux Miscellaneous Cryptography Tools\nTool Description\nDuplic -\nityEncrypts backups. To install on Fedora, type yum install duplicity . To install \non Ubuntu, type sudo apt-get install duplicity at the command line.\ngpg-zip Uses GNU Privacy Guard to encrypt or sign files into an archive. Installed \nby default.\nOpenssl A toolkit that implements Secure Sockets Layer (SSL) and Transport Layer Security \n(TLS) protocols. These protocols require encryption. Installed by default.\nSea-\nhorseA GNU Privacy Guard encryption key manager. Installed by default on Ubuntu. To \ninstall on Fedora and RHEL, type yum install seahorse  at the command line.\nSsh Encrypts remote access across a network. Installed by default.\nZipcloak Encrypts entries in a Zip file. Installed by default.", "doc_id": "632fd1f9-cf7d-4a93-acd8-9d0ea1a17fda", "embedding": null, "doc_hash": "296360405dd57669df770ff360da6df2ea6935b5c4be10dc03d2d23cd5da3cb8", "extra_info": {"page_label": "639"}, "node_info": {"start": 0, "end": 2635}, "relationships": {"1": "112ba11c-f7b2-4a40-8206-7e8463b28dc1"}}, "__type__": "1"}, "15a579e7-91be-4656-b233-8ac3fc6e7c5e": {"__data__": {"text": "Part V: Learning Linux Security Techniques618Another extremely powerful security tool available on Linux is PAM. The next sections in \nthis chapter cover basic PAM concepts and how you can use this tool to enhance even fur -\nther your Linux system\u2019s security.\nImplementing Linux Security with PAM\nPluggable Authentication Modules (PAM)  was invented by Sun Microsystems and originally \nimplemented in the Solaris operating system. The Linux-PAM project began in 1997. Today, \nmost Linux distributions use PAM.\nPAM simplifies the authentication management process. Remember that authentication \n(see Chapter\u00a022, \u201cUnderstanding Basic Linux Security\u201d) is the process of determining that \na subject (aka user or process) is who they say they are. This process is sometimes called \n\u201cidentification and authentication.\u201d PAM is a centralized method of providing authentica -\ntion for the Linux system and applications.\nApplications can be written to use PAM; such applications are called \u201cPAM-aware.\u201d A PAM-\naware application does not have to be rewritten and recompiled to have its authentication \nsettings changed. Any required changes are made within a PAM configuration file for the \nPAM-aware applications. Thus, authentication management for these applications is cen -\ntralized and simplified.\nYou can see whether a particular Linux application or utility is PAM-aware. Check whether \nit is compiled with the PAM library, libpam.so . In the example that follows, the crontab  \napplication is being checked for PAM awareness. The ldd  command checks a file\u2019s shared \nlibrary dependencies. To keep it simple, grep  is used to search for the PAM library. As you \ncan see, crontab  on this particular Linux system is PAM-aware.\n# ldd /usr/bin/crontab | grep pam\nlibpam.so.0 => /lib64/libpam.so.0 (0x00007fbee19ce000)\nThe benefits of using PAM on your Linux system include the following:\n\u25a0\u25a0Simplified and centralized authentication management from the administra -\ntor viewpoint\n\u25a0\u25a0Simplified application development, because developers can write applications \nusing the documented PAM library instead of writing their own authentica -\ntion routines\n\u25a0\u25a0Flexibility in authentication:\n\u25a0\u25a0Allow or deny access to resources based on traditional criteria, such as \nidentification\n\u25a0\u25a0Allow or deny access based on additional criteria, such as time-of-day \nrestrictions\n\u25a0\u25a0Set subject limitations, such as resource usage\nAlthough the benefits of PAM simplify authentication management, the way that PAM actu -\nally works is not so simple.", "doc_id": "15a579e7-91be-4656-b233-8ac3fc6e7c5e", "embedding": null, "doc_hash": "3b9006856808bc17a95e41444df2e74d40a023f4a5faf3d7bed4f4621ad892ed", "extra_info": {"page_label": "640"}, "node_info": {"start": 0, "end": 2522}, "relationships": {"1": "faa52826-1c42-41f2-9d7d-faa4e0c19b71"}}, "__type__": "1"}, "d2373422-89c2-4817-a41f-9588f51255d0": {"__data__": {"text": "Chapter 23: Understanding Advanced Linux Security\n619\n23Understanding the PAM authentication process\nWhen a subject (user or process) requests access to a PAM-aware application or utility, two \nprimary components are used to complete the subject authentication process:\n\u25a0\u25a0The PAM-aware application\u2019s configuration file\n\u25a0\u25a0The PAM modules the configuration file uses\nEach PAM-aware application configuration file is at the center of the process. The PAM con -\nfiguration files call upon particular PAM modules to perform the needed authentication. \nPAM modules authenticate subjects from system authorization data, such as a centralized \nuser account using LDAP (see Chapter\u00a011, \u201cManaging User Accounts\u201d).\nLinux comes with many applications that are PAM-aware, with their needed configu -\nration files and PAM modules already installed. If you have any special authentication \nneeds, you can most likely find a PAM module that has already been written for that \nneed. However, before you start tweaking PAM, you need to understand more about how \nPAM operates.\nA series of steps is taken by PAM using the modules and configuration files in order to \nensure that proper application authentication occurs:\n1. A subject (user or process) requests access to an application.\n2. The application\u2019s PAM configuration file, which contains an access policy, is \nopen and read.\nThe access policy is set via a list of all the PAM modules to be used in the authenti-\ncation process. This PAM module(s) list is called a stack .\n3. The PAM modules in the stack are invoked in the order in which they are listed.\n4. Each PAM module returns either a success or failure status.\n5. The stack continues to be read in order, and it is not necessarily stopped by a single \nreturned failure status.\n6. The status results of all of the PAM modules are combined into a single overall \nresult of authentication success or failure.\nTypically, if a single PAM module returns a failure status, access to the application is \ndenied. However, this is dependent upon the configuration file settings. Most PAM configu -\nration files are located in /etc/pam.d . The general format of a PAM configuration file is\ncontext   control flag   PAM module [module options]\nUnderstanding PAM contexts\nPAM modules have standard functions that provide different authentication services. These \nstandard functions within a PAM module can be divided into function types called contexts . \nContexts can also be called module interfaces  or types . In Table\u00a023.3, the different PAM con -\ntexts are listed along with what type of authentication service they provide.", "doc_id": "d2373422-89c2-4817-a41f-9588f51255d0", "embedding": null, "doc_hash": "2e3237c05c4a432fe6588a63c72e46d94c0b4ae9155aed4cf190bfdc54e64a68", "extra_info": {"page_label": "641"}, "node_info": {"start": 0, "end": 2614}, "relationships": {"1": "1693c946-6be2-4716-b335-1c9a5cb80e4f"}}, "__type__": "1"}, "02d8df6d-89ed-4208-907d-3f0a0b7185e0": {"__data__": {"text": "Part V: Learning Linux Security Techniques620Understanding PAM control flags\nIn a PAM configuration file, control flags are used to determine the overall status, which \nare returned to the application. A control flag is either of the following:\nSimple keyword: The only concern here is if the corresponding PAM module returns \na response of either \u201cfailed\u201d or \u201csuccess.\u201d See Table\u00a023.4 for how these statuses \nare handled.TABLE 23.3  PAM Contexts\nContext Service Description\nauth Provides authentication management services, such as verifying \naccount passwords\naccount Provides account validation services, such as time-of-day access restrictions\npassword Manages account passwords, such as password length restrictions\nTABLE 23.4  PAM Configuration Control Flags and Response Handling\nrequired If failed, returns a failure status to the application, after the rest of the contexts \nhave been run in the stack.\nFor example, a requisite control might cause a login to fail if someone types in \nan invalid user. But the user might not be told of the failure until after entering a \npassword, hiding the fact that it was the bad username that caused the failure.\nrequisite If failed, returns a failure status to the application immediately without running \nthe rest of the stack. (Be careful where you place this control in the stack.)\nFor example, a requisite control might require key-based authentication and \nfail immediately when a valid key is not provided. In that case, it could fail \nbefore even prompting for a username/password.\nsufficient If failed, the module status is ignored. If successful, then a success status is \nimmediately returned to the application without running the rest of the stack. \n(Be careful where you place this control in the stack.)\noptional This control flag is important only for the final overall return status of success \nor failure. Think of it as a tiebreaker. When the other modules in the config -\nuration file stack return statuses that are neither clear-cut failure nor success \nstatuses, this optional module\u2019s status is used to determine the final status or \nbreak the tie. In cases where the other modules in the stack are returning a \nclear-cut path of failure or success, this status is ignored.\ninclude Get all the return statuses from this particular PAM configuration file\u2019s stack \nto include in this stack\u2019s overall return status. It\u2019s as if the entire stack from the \nnamed configuration file is now in this configuration file.\nsubstack Similar to the include control flag, except for how certain errors and evalua -\ntions affect the main stack. This forces the included configuration file stack to \nact as a substack to the main stack. Thus, certain errors and evaluations affect \nonly the substack and not the main stack.", "doc_id": "02d8df6d-89ed-4208-907d-3f0a0b7185e0", "embedding": null, "doc_hash": "00719f142646a8f4da78e8770464db548dfb606560ec95b784a81045056d7dc7", "extra_info": {"page_label": "642"}, "node_info": {"start": 0, "end": 2777}, "relationships": {"1": "635b2631-1876-4fe9-a823-cc5ce0b096e6"}}, "__type__": "1"}, "43e47fcc-df6a-4160-b759-f62d56b4d5ae": {"__data__": {"text": "Chapter 23: Understanding Advanced Linux Security\n621\n23Series of actions : The returned module status is handled through the series of actions \nlisted in the file.\nTable\u00a023.4 shows the various keyword control flags and their responses to the returned \nmodule status. Notice that a few of the control flags need to be carefully placed within \nthe configuration file\u2019s stack. Some control flags cause the authentication process to stop \nimmediately, and the rest of the PAM modules are not called. The control flags simply con -\ntrol how the PAM module status results are combined into a single overall result. Table\u00a023.4 \ndemonstrates how the status results are combined.\nYou should know that the PAM modules return many more status result codes than \n just \u201csuccess\u201d or \u201cfailure.\u201d For example, a module may return the status code of PAM_  \nACCT_EXPIRED , which means that the user account has expired. This would be deemed a \n\u201cfailure.\u201d\nUnderstanding PAM modules\nA PAM module is actually a suite of shared library modules (DLL files) stored in /usr/\nlib64/security  (64-bit). You can see a list of the various installed PAM modules on your \nsystem by entering ls /usr/lib64/security/pam*.so  at the command line.\nNote\nOn Ubuntu, to find your PAM modules, type the command sudo find / -name pam*.so at the command \nline.\nYour Linux system comes with many of the PAM modules needed already installed. If you do \nneed a module not already installed, most likely someone else has already written it. Check \nout sources such as these:\n\u25a0\u25a0http://www.openwall.com/pam/\n\u25a0\u25a0http://puszcza.gnu.org.ua/software/pam-modules/download.html\n\u25a0\u25a0Understanding PAM system event configuration files\nSo far, the focus has been on PAM-aware applications and their configuration files. How -\never, other system events, such as logging into the Linux system, also use PAM. Thus, these \nevents also have configuration files.\nThe following is a partial directory listing of the PAM configuration file directory. Notice \nthat there are PAM-aware application configuration files, such as crond , and system event \nconfiguration files, such as postlogin-ac .\n# ls -l /etc/pam.d\ntotal 204\n-rw-r--r--. 1 root root  272 Nov 15 10:06 atd\n...\n-rw-r--r--. 1 root root  232 Jan 31 12:35 config-util\n-rw-r--r--. 1 root root  293 Oct 26 23:10 crond", "doc_id": "43e47fcc-df6a-4160-b759-f62d56b4d5ae", "embedding": null, "doc_hash": "21706b8d82bccc61dc41b3584c6ddcdf67d4d0bf4e57dbbf98dab10ea75a568b", "extra_info": {"page_label": "643"}, "node_info": {"start": 0, "end": 2309}, "relationships": {"1": "35d4ad19-15f9-4c69-9551-c01eeb37fdbb"}}, "__type__": "1"}, "244d31db-68e1-4c87-a2e6-1810caecc69e": {"__data__": {"text": "Part V: Learning Linux Security Techniques622...\n-rw-r--r--. 1 root root  109 Feb 28 01:33 postlogin\n \n...\n-rw-r--r--. 1 root root  981 Feb 28 01:33 system-auth\n...\nYou can modify these system event configuration files to implement your organization\u2019s \nspecific security needs. For example, the system-auth  file can be modified to force cer -\ntain password restrictions.\nCautio N\nModifying or deleting PAM system event configuration files incorrectly can lock you out of your own system. Make \nsure that you test any changes in a virtual or test environment before modifying your production Linux servers.\nThese PAM system event configuration files operate in exactly the same way as the PAM-\naware application configuration files. They have the same format, use the same syntax, and \ncall upon PAM modules. However, many of these files are symbolically linked (see Chapter\u00a04, \n\u201cMoving Around the Filesystem\u201d). Therefore, these configuration files require a few extra \nsteps when changes are made to them. The \u201chow-tos\u201d are covered later in this chapter.\ntip\nMany of the PAM configuration files have a man page associated with them. For example, to find out more informa -\ntion on the pam _ unix  module, type man pam _ unix at the command line of your Fedora and RHEL distribu -\ntion. There are also module documentation files in the /usr/share/doc/pam-*/txts/  directory.\nEven though Linux comes with many PAM-aware applications, various configuration files, \nand PAM modules already installed, you cannot just hope that PAM will take care of itself. \nCertain administrative steps are needed to manage PAM.\nAdministering PAM on your Linux system\nThe task of administering PAM on your Linux system is rather minimal. You need to verify \nthat PAM is properly implemented and make adjustments to meet your particular organiza -\ntion\u2019s security needs.\nAlso, PAM does a little more than just the application authentication steps described previ-\nously. PAM can also limit resources, restrict access times, enforce good password selection, \nand so on.\nManaging PAM-aware application configuration files\nYou should review PAM configuration files for your PAM-aware applications and utilities \nin order to ensure that their authentication process matches your organization\u2019s desired \nauthentication process. Your Access Control Matrix (see Chapter\u00a022, \u201cUnderstanding Basic ", "doc_id": "244d31db-68e1-4c87-a2e6-1810caecc69e", "embedding": null, "doc_hash": "7cbf416b2b463d5870e3f1bc087d9c8a44ca0cb527c9928038bc7e89692a1335", "extra_info": {"page_label": "644"}, "node_info": {"start": 0, "end": 2368}, "relationships": {"1": "5a0f14f6-f792-4435-a78d-15a5e85ac1b7"}}, "__type__": "1"}, "ffb509fd-7854-40d4-88f1-6b41a92fd959": {"__data__": {"text": "Chapter 23: Understanding Advanced Linux Security\n623\n23Linux Security\u201d) and the information on understanding PAM provided in this chapter \nshould help you conduct an audit of the PAM configuration files.\nEach PAM-aware application should have its very own PAM configuration file. Each config -\nuration file defines what particular PAM modules are used for that application. If no con -\nfiguration file exists, a security hole may be created for that application. This hole could \nbe used for malicious intent. As a safety precaution, PAM comes with the \u201cother\u201d configu -\nration file. If a PAM-aware application does not have a PAM configuration file, it defaults to \nusing the \u201cother\u201d PAM configuration file.\nYou can verify whether your Linux system has the /etc/pam.d/other  configuration file \nby using the ls  command. The example that follows shows that the /etc/pam.d/other  \nPAM configuration file does exist on this system.\n$ ls /etc/pam.d/other\n/etc/pam.d/other\nThe PAM /etc/pam.d/other  configuration file should deny all access, which in terms of \nsecurity is referred to as Implicit Deny. In computer security access control, Implicit Deny  \nmeans that if certain criteria are not clearly met, access must be denied. In this case, if no \nconfiguration file exists for a PAM-aware application, all access to it is denied. The follow -\ning shows an /etc/pam.d/other  file\u2019s contents:\n$ cat /etc/pam.d/other\n#%PAM-1.0\nauth     required       pam_deny.so\naccount  required       pam_deny.so\npassword required       pam_deny.so\nsession  required       pam_deny.so\nNotice that all four PAM contexts\u2014 auth , account , password , and session \u2014are listed. \nEach context uses the required  control flag and the pam_deny.so  module. The pam_\ndeny.so  PAM module is used to deny access.\nEven with the \u201cother\u201d configuration file in place, if a PAM configuration file for a PAM-\naware application is not there, it must be created. Add this item to your PAM audit check -\nlist. You should also review your PAM \u201cother\u201d configuration file on your Linux system to \nensure that it enforces Implicit Deny.\nManaging PAM system event configuration files\nSimilar to PAM-aware application and utility configuration files, your PAM system event \nconfiguration files need to be audited with your organization\u2019s Access Control Matrix. How -\never, for any needed modifications to these files, there are extra steps that must be taken.\nIn the material that follows, you will learn how to set up special security requirements via \nPAM on your Linux system, such as account login time restrictions. Many of the special \nrequirements require you to make a change to PAM system event configuration files, such \nas /etc/pam.d/system-auth .", "doc_id": "ffb509fd-7854-40d4-88f1-6b41a92fd959", "embedding": null, "doc_hash": "753d8242410a5a91d84f96d7440cb6335cadeb8b79985093c3fd6e9e3868e7df", "extra_info": {"page_label": "645"}, "node_info": {"start": 0, "end": 2717}, "relationships": {"1": "b4f73cb7-7466-44a9-8ca1-ffbe416926eb"}}, "__type__": "1"}, "eb1d1413-1c83-474d-994b-6614897c79dc": {"__data__": {"text": "Part V: Learning Linux Security Techniques624The problem with making changes to some of these PAM system event configuration files is \nthat the utility authselect  can rewrite these files and remove any locally made changes. \nFortunately, each PAM configuration file that runs this risk has it documented in a com-\nment line within. Using grep , you can quickly find which PAM configuration files have this \npotential problem.\n# grep \"authselect\" /etc/pam.d/*\nfingerprint-auth:# Generated by authselect on Mon Oct 21 19:24:36 \n2019\npassword-auth:# Generated by authselect on Mon Oct 21 19:24:36 2019\npostlogin:# Generated by authselect on Mon Oct 21 19:24:36 2019\nsmartcard-auth:# Generated by authselect on Mon Oct 21 19:24:36 2019\nsystem-auth:# Generated by authselect on Mon Oct 21 19:24:36 2019\nThese PAM system event configuration files use symbolic links (see Chapter\u00a04, \u201cMoving \nAround the Filesystem\u201d). For example, in Fedora you can see that the file system-auth  is \nactually a symbolic link pointing to the file /etc/authselect/system-auth . The first \ncharacter in the file\u2019s security is an l . This indicates that the file is linked. The ->  symbol \nshows that the file is symbolically linked.\n# ls -l system-auth\nlrwxrwxrwx. 1 root root 27 Oct 1 15:24 system-auth -> /etc/\nauthselect/system-auth\nNote\nOn some Linux distributions, the utility pam-auth-config  is similar to the authselect  utility in its ability to \noverwrite configuration files. This can happen if the command pam-auth-config --force is entered at the \ncommand line. Read the man pam-auth-config man page to learn more about this utility if it is installed on \nyour system.\n \nImplementing resources limits with PAM\nManaging resources is not just a system administrative task. It is also a security admin -\nistrative task. Setting resource limitations helps you avoid many adverse problems on \nyour Linux system. Problems such as fork bombs can be averted by limiting the number \nof processes a single user can create. A fork bomb  occurs when a process spawns one \nprocess after another in a recursive manner until system resources are consumed. Fork \nbombs can be malicious or just accidental; that is, created simply by poor program code \ndevelopment.\nThe PAM module pam-limits  uses a special configuration file to set these resources limits: \n/etc/security/limits.conf . By default, this file has no resource limits set within it. \nTherefore, you need to review the file and set resources limits to match your organization\u2019s \nsecurity needs.", "doc_id": "eb1d1413-1c83-474d-994b-6614897c79dc", "embedding": null, "doc_hash": "b6544f0c4cbeb469a4aff689699b25699cb731c1fab99edea3d8a799ff38baab", "extra_info": {"page_label": "646"}, "node_info": {"start": 0, "end": 2527}, "relationships": {"1": "e7bf8485-5b53-46bb-9b5f-fc09587c3b8b"}}, "__type__": "1"}, "9d93aa42-ffad-4c4e-b041-16c167e14473": {"__data__": {"text": "Chapter 23: Understanding Advanced Linux Security\n625\n23Note\nPAM configuration files are in the /etc/pam.d  directory and the /etc/security  directory.\nThe following snippet shows the /etc/security/limits.conf  file. The file is well docu-\nmented. You should read through the contents of that file for a thorough format description \nand examples of limits that can be set.\n$ cat /etc/security/limits.conf\n# /etc/security/limits.conf\n#\n#This file sets the resource limits for the users logged in via PAM.\n#It does not affect resource limits of the system services.\n#\n#Also note that configuration files in /etc/security/limits.d \ndirectory,\n#which are read in alphabetical order, override the settings in this\n#file in case the domain is the same or more specific.\n...\n#Each line describes a limit for a user in the form:\n#\n#<domain>        <type>  <item>  <value>\n...\n#*               soft    core            0\n#*               hard    rss             10000\n#@student        hard    nproc           20\n#@faculty        soft    nproc           20\n#@faculty        hard    nproc           50\n#ftp             hard    nproc           0\n#@student        -       maxlogins       4\n# End of file\nThe format items domain  and type  need some further explanation than what is documented \nin the configuration file:\ndomain : The limit applies to the listed user or group. If the domain is * , it applies to \nall users.\ntype : A hard  limit cannot be exceeded. A soft  limit can be exceeded, but only \ntemporarily.\nLook at the limits.conf  file setting example that follows. The group faculty  is listed, \nbut what you should notice is nproc. The nproc  limit sets the maximum number of \nprocesses a user can start. This setting is what prevents a fork bomb. Notice that the type  \nselected is hard ; thus, the limit of 50 processes cannot be exceeded. Of course, this limit is \nnot enforced because the line is commented out with a # symbol.\n#@faculty        hard    nproc           50", "doc_id": "9d93aa42-ffad-4c4e-b041-16c167e14473", "embedding": null, "doc_hash": "79536085dc11dd87ec941215e7d5864f70a72413f05ab5131624856c8105b3bb", "extra_info": {"page_label": "647"}, "node_info": {"start": 0, "end": 1976}, "relationships": {"1": "b89fe7ae-a5c1-4bc4-91cc-132ba9dcb317"}}, "__type__": "1"}, "8df0183b-93e9-4c8f-925e-5f73d9b977e0": {"__data__": {"text": "Part V: Learning Linux Security Techniques626Limit settings are set per login and only last for the duration of the login session. A mali-\ncious user could log in several times to create a fork bomb. Thus, setting the maximum \nnumber of logins for these user accounts is a good idea too.\nLimiting the maximum number of logins may have to be done on a per-user basis. For \nexample, johndoe  needs to log in to the Linux system only once. To prevent others from \nusing johndoe \u2019s account, set his account\u2019s maxlogins  to 1.\njohndoe        hard    maxlogins           1\nTo override any settings in the limits.conf  file, add files named *.conf  to the /etc/\nsecurity/limits.d  directory. This is a convenient way to have an RPM file or other \nmethod to add and remove limits without needing to edit the limits.conf  file directly.\nThe final step in limiting this resource is to ensure that the PAM module using limits.\nconf  is included in one of the PAM system event configuration files. The PAM module using \nlimits.conf  is pam_limits . In the partial listing that follows, grep  is used to verify \nthat the PAM module is used within the system event configuration files.\n# grep \"pam_limits\" /etc/pam.d/*\n/etc/pam.d/fingerprint-auth:session required    pam_limits.so\n/etc/pam.d/password-auth:session    required    pam_limits.so\n/etc/pam.d/runuser:session          required    pam_limits.so\n/etc/pam.d/system-auth:session      required    pam_limits.so\nTime limits for access to services and accounts are not handled by the PAM /etc/secu -\nrity/limits.conf  configuration file. Instead, it is handled by the time.conf  file.\nImplementing time restrictions with PAM\nPAM can make your entire Linux system operate on \u201cPAM time.\u201d Time restrictions such as \naccess to particular applications during certain times of the day, or allowing logins only \nduring specified days of the week, are all handled by PAM.\nThe PAM configuration file that handles these restrictions is located in the /etc/secu -\nrity  directory. The following code shows the well-documented /etc/security/time.\nconf  PAM configuration file.\n$ cat /etc/security/time.conf\n# this is an example configuration file for the pam_time module. Its \nsyntax\n# was initially based heavily on that of the shadow package \n(shadow-960129).\n \n#\n# the syntax of the lines is as follows:\n#\n#       services;ttys;users;times\n...", "doc_id": "8df0183b-93e9-4c8f-925e-5f73d9b977e0", "embedding": null, "doc_hash": "7f05ec9f4fd31a4b9fb5e7b03c53496c67c5a177c8cff03430f61a75db7925f4", "extra_info": {"page_label": "648"}, "node_info": {"start": 0, "end": 2374}, "relationships": {"1": "fe1e7fac-e836-4fb2-9506-d5079828cc47"}}, "__type__": "1"}, "f98b5ac4-b242-4fa3-a2c4-e2bc91b7da2a": {"__data__": {"text": "Chapter 23: Understanding Advanced Linux Security\n627\n23I recommend that you read through the contents of the time.conf  file. Note that the \nformat for each valid entry follows this syntax: services ;ttys ;users ;times . Fields are \nseparated by semicolons. The valid field values are documented in the time.conf  configu-\nration file.\nWhile time.conf  is well-documented, an example is always helpful. For instance, you \nhave decided that regular users should be allowed to log in on terminals on weekdays only \n(Monday through Friday). They can log in from 7 a.m. to 7 p.m. on these weekdays. The fol -\nlowing list describes what elements need to be set:\nservices : Login\nttys\u2014* : Indicates that all terminals are to be included\nusers : Everyone but root ( !root )\ntimes : Allowed on weekdays (Wd ) from 7 a.m. ( 0700) to 7 p.m. ( 1900)\nThe entry in time.conf  would look like the following:\nlogin; * ; !root ; Wd0700-1900\nThe final step in implementing this example time restriction is to ensure that the PAM \nmodule using time.conf  is included in one of the PAM system event configuration files. \nThe PAM module using time.conf  is pam_time . In the partial listing that follows, grep  \nshows the PAM module; pam_time  is not used within any of the system event configura -\ntion files.\n# grep \"pam_time\" /etc/pam.d/*\nconfig-util:auth              sufficient   pam_timestamp.so\nconfig-util:session           optional     pam_timestamp.so\nBecause pam_time  is not listed, you must modify the /etc/pam.d/system-auth  file in \norder for PAM to enforce the time restrictions. The PAM configuration file system-auth  \nis used by PAM at system login and during password modifications. This configuration file \nchecks many items, such as time restrictions.\nAdd the following near the top of the \u201caccount\u201d section of the configuration file. Now the \npam_time  module checks the login restrictions you set within the /etc/security/\ntime.conf  file.\naccount    required   pam_time.so\nNote\nOn Ubuntu, you need to modify the /etc/pam.d/common-auth  file instead of the system-auth configura -\ntion file.\nRemember that system-auth  is a symbolically linked file. If you modify this file, you \nmust take extra steps to preserve the modifications from the authselect  utility. You can \nemploy additional PAM modules and configuration files to set even more restrictions on \nsubjects. One important security module is pam_cracklib .", "doc_id": "f98b5ac4-b242-4fa3-a2c4-e2bc91b7da2a", "embedding": null, "doc_hash": "5f19e2aa8d5fb495a126a28f1893214cfb6859436f7817b2c5a884c953140b44", "extra_info": {"page_label": "649"}, "node_info": {"start": 0, "end": 2421}, "relationships": {"1": "951930e0-3b29-4168-88e2-f3c100f4e5f4"}}, "__type__": "1"}, "56775cb9-9a91-4485-a765-cfdae11ea738": {"__data__": {"text": "Part V: Learning Linux Security Techniques628Enforcing good passwords with PAM\nWhen a password is modified, the PAM module pam_cracklib  is involved in the process. \nThe module prompts the user for a password and checks its strength against a system dic -\ntionary and a set of rules for identifying poor choices.\nNote\nThe pam_cracklib  module is installed by default on Fedora and RHEL. For Ubuntu Linux systems, it is not \ninstalled by default. Therefore, to get access to the pam_cracklib  module on Ubuntu, issue the command  \nsudo apt-get install libpam-cracklib .\nUsing pam_cracklib , you can check a newly chosen password for the following:\n\u25a0\u25a0Is it a dictionary word?\n\u25a0\u25a0Is it a palindrome?\n\u25a0\u25a0Is it the old password with the case changed?\n\u25a0\u25a0Is it too much like the old password?\n\u25a0\u25a0Is it too short?\n\u25a0\u25a0Is it a rotated version of the old password?\n\u25a0\u25a0Does it use the same consecutive characters?\n\u25a0\u25a0Does it contain the username in some form?\nYou can change the rules pam_cracklib  uses for checking new passwords by making \nmodifications to the /etc/pam.d/system-auth  file. You may think that the changes \nshould be made in the PAM-aware passwd  configuration file. However, /etc/pam.d/\npasswd  includes the system-auth  file in its stack.\n# cat /etc/pam.d/passwd\n#%PAM-1.0\n# This tool only uses the password stack.\npassword   substack   system-auth\n-password   optional        pam_gnome_keyring.so use_authtok\npassword   substack   postlogin\nNote\nOn Ubuntu, you need to modify the /etc/pam.d/common-password  file instead of the system-auth con -\nfiguration file.\nThe current settings of the system-auth  file are shown here. Currently, one entry calls \nthe pam_cracklib  PAM module.\n# cat /etc/pam.d/system-auth\n#%PAM-1.0\n# Generated by authselect on Mon Oct 21 19:24:36 2019", "doc_id": "56775cb9-9a91-4485-a765-cfdae11ea738", "embedding": null, "doc_hash": "45610f9cac532db23252009063409442be45884de1e614e93e17105085c1250e", "extra_info": {"page_label": "650"}, "node_info": {"start": 0, "end": 1778}, "relationships": {"1": "f5600451-6172-43dd-8206-9243ff7f2e65"}}, "__type__": "1"}, "32165c7a-5ec6-4de9-8f6f-b4cdcb23b94f": {"__data__": {"text": "Chapter 23: Understanding Advanced Linux Security\n629\n23# Do not modify this file manually.\nauth        required      pam_env.so\nauth        required      pam_faildelay.so delay=2000000\nauth        sufficient    pam_fprintd.so\n...\nauth        sufficient    pam_unix.so nullok try_first_pass\nauth        requisite     pam_succeed_if.so uid >= 1000 quiet_success\nauth        required      pam_deny.so\nauth        sufficient    pam_sss.so forward_pass\nauth        required      pam_deny.so\naccount     required      pam_unix.so\naccount     sufficient    pam_localuser.so\naccount     sufficient    pam_succeed_if.so uid < 1000 quiet\naccount     [default=bad success=ok user_unknown=ignore] pam_sss.so\naccount     required      pam_permit.so\npassword    requisite     pam_cracklib.so try_first_pass retry=3\n...\nThe pam_cracklib entry in the preceding listing uses the keyword retry . The following \nkeywords are available for cracklib :\ndebug\nCauses module to write information to syslog.\nauthtok_type=XXX\n\u25a0\u25a0Defaults to using New UNIX password:  and Retype UNIX password: to \nrequest passwords.\n\u25a0\u25a0Replace XXX  with a word to use instead of UNIX.\nretry=N\n\u25a0\u25a0Default = 1\n\u25a0\u25a0Prompt user at most N times before returning with an error.\ndifok=N\n\u25a0\u25a0Default = 5\n\u25a0\u25a0The number of characters in the new password that must not be present in the \nold password.\n\u25a0\u25a0Exception 1 : If half of the characters in the new password are different, then the \nnew password is accepted.\n\u25a0\u25a0Exception 2 : See difignore .\ndifignore= N\n\u25a0\u25a0Default = 23\n\u25a0\u25a0The number of characters that the password has before the difok  setting \nis ignored.", "doc_id": "32165c7a-5ec6-4de9-8f6f-b4cdcb23b94f", "embedding": null, "doc_hash": "b2280eb588bb4e4549713917be3c5d69399a229c8c3bedf23af6eb8f942c2b99", "extra_info": {"page_label": "651"}, "node_info": {"start": 0, "end": 1601}, "relationships": {"1": "c6fc990a-1c9b-4839-8d1b-27e02a547763"}}, "__type__": "1"}, "8cc65232-5d32-4a63-97e4-dd64fc2cbba8": {"__data__": {"text": "Part V: Learning Linux Security Techniques630minlen=N\n\u25a0\u25a0Default = 9\n\u25a0\u25a0The minimum acceptable size for the new password.\n\u25a0\u25a0See dcredit , ucredit , lcredit , and ocredit for how their settings \naffect minlen .\ndcredit= N\n\u25a0\u25a0Default =1\n\u25a0\u25a0If (N >= 0): The maximum credit for having digits in the new password. If you \nhave fewer than or N digits, each digit counts +1 toward meeting the current \nminlen  value.\n\u25a0\u25a0If (N < 0): The minimum number of digits that must be met for a new password.\nucredit= N\n\u25a0\u25a0Default = 1\n\u25a0\u25a0If (N >= 0): The maximum credit for having uppercase letters in the new password. \nIf you have fewer than or N uppercase letters, each letter counts +1 toward meeting \nthe current minlen  value.\n\u25a0\u25a0If (N < 0): The minimum number of uppercase letters that must be met for a \nnew password.\nlcredit= N\n\u25a0\u25a0Default = 1\n\u25a0\u25a0If (N >= 0): The maximum credit for having lowercase letters in the new password. \nIf you have fewer than or N lowercase letters, each letter counts +1 toward meeting \nthe current minlen  value.\n\u25a0\u25a0If (N < 0): The minimum number of lowercase letters that must be met for a \nnew password.\nocredit= N\n\u25a0\u25a0Default = 1\n\u25a0\u25a0If (N >= 0): The maximum credit for having other characters in the new password. If \nyou have fewer than or N other characters, each character counts +1 toward meet -\ning the current minlen  value.\n\u25a0\u25a0If (N < 0): The minimum number of other characters that must be met for a \nnew password.\nminclass= N\n\u25a0\u25a0Default = 0\n\u25a0\u25a0N out of four character classes is required for the new password. The four classes \nare digits, uppercase letters, lowercase letters, and other characters.\nmaxrepeat= N\n\u25a0\u25a0Default = 0\n\u25a0\u25a0Reject passwords that contain more than N same consecutive characters.", "doc_id": "8cc65232-5d32-4a63-97e4-dd64fc2cbba8", "embedding": null, "doc_hash": "b1059f935ad1ce5e0a5586922954b0c0b3226748a0a3c457646bc9424705a18c", "extra_info": {"page_label": "652"}, "node_info": {"start": 0, "end": 1713}, "relationships": {"1": "fbb399c0-cc79-4ee9-94a5-cb70a850ad3d"}}, "__type__": "1"}, "45596f74-d86c-4a46-9994-0a0e527075f5": {"__data__": {"text": "Chapter 23: Understanding Advanced Linux Security\n631\n23reject_username\nCheck whether the name of the user in straight or reversed form is contained in the \nnew password. If it is found, the new password is rejected.\ntry_first_pass\nTry to get the password from a previous PAM module. If that does not work, prompt \nthe user for the password.\nuse_authtok\nThis argument is used to force  the module not to prompt the user for a new pass -\nword. Instead, the new password is provided by the previously stacked password  \nmodule.\ndictpath =/path\nPath to the cracklib  dictionaries.\nmaxsequence =N\n\u25a0\u25a0Default = 0 (meaning this check is disabled)\n\u25a0\u25a0N set to any number other than 0 causes passwords with monotonic characters \nlonger than that number to be rejected.\nmaxclassrepeat =N\n\u25a0\u25a0Default = 0 (meaning this check is disabled)\n\u25a0\u25a0N set to any number other than 0 causes passwords with consecutive characters in \nthe same class that are longer than that number to be rejected.\ngecoscheck =N\nCauses passwords with more than three straight characters from the user\u2019s GECOS field, \ntypically containing the user\u2019s real name, to be rejected.\nenforce_for_root =N\n\u25a0\u25a0Default = 0 (meaning this check is disabled)\n\u25a0\u25a0N set to any number other than 0 causes passwords with consecutive characters in \nthe same class that are longer than that number to be rejected.\nenforce_for_root\nEnforce failed password checks for the root user. This option is off by default.\nFor example, if your organization requires passwords to be 10 characters long and they \nmust contain two digits, you would add a line similar to the following to the /etc/pam.d/\nsystem-auth  file:\npassword required pam_cracklib.so minlen=10 dcredit=-2", "doc_id": "45596f74-d86c-4a46-9994-0a0e527075f5", "embedding": null, "doc_hash": "a517bcbcd667557382a49b5d29c5aa6ea3b61d31ecddea0f01d8bab77c2a2d0b", "extra_info": {"page_label": "653"}, "node_info": {"start": 0, "end": 1697}, "relationships": {"1": "675421be-3819-4745-ab9a-78351f6128b0"}}, "__type__": "1"}, "70456fce-874a-49c3-8261-7d869bc00ee5": {"__data__": {"text": "Part V: Learning Linux Security Techniques632The keywords used in this example with pam_cracklib  are as follows:\n\u25a0\u25a0minlen=10 : The new password must be at least 10 characters.\n\u25a0\u25a0dcredit=-2 : The new password must contain two numbers.\nNote\nThe pam_cracklib restrictions do not apply to the root user unless you apply the enforce_for_root \noption.\nEncouraging sudo use with PAM\nTo allow tracking of root-account use by individuals and avoid a repudiation situation (see \nChapter\u00a022, \u201cUnderstanding Basic Linux Security\u201d), you should restrict the use of the su  \ncommand and encourage the use of sudo . If your organization has such a policy, you can \naccomplish this with PAM in just a few steps.\nThe su  command is PAM-aware, which greatly simplifies things. It uses the PAM module \npam_wheel  to check for users in the wheel  group. The /etc/pam.d/su  configuration file \nis shown here:\n# cat /etc/pam.d/su\n#%PAM-1.0\nauth        required      pam_rootok.so\nauth        sufficient    pam_rootok.so\n# Uncomment the following line to implicitly trust users\n# in the \"wheel\" group.\n#auth        sufficient  pam_wheel.so trust use_uid\n# Uncomment the following line to require a user to be\n# in the \"wheel\" group.\n#auth       required      pam_wheel.so use_uid\nauth        substack      system-auth\nauth        include       postlogin\naccount     sufficient    pam_succeed_if.so uid = 0 use_uid quiet\naccount     include       system-auth\npassword    include       system-auth\nsession     include       system-auth\nsession     include       postlogin\nsession     optional      pam_xauth.so\nFirst, to restrict the use of su , if you are using the wheel  group as your administrative \ngroup, you need to reassign your administrative group to a new group (see Chapter\u00a011, \n\u201cManaging User Accounts\u201d). If you are not using the wheel  group, just be sure not to \nassign anyone in the future to this group.\nNext, you need to edit the /etc/pam.d/su  configuration file. Remove the comment mark, \n#, from the following line:\n#auth        required    pam_wheel.so use_uid", "doc_id": "70456fce-874a-49c3-8261-7d869bc00ee5", "embedding": null, "doc_hash": "d656f20116cd5fe6bda839f3246c68e115efe9a9739498141913422b4bd5386f", "extra_info": {"page_label": "654"}, "node_info": {"start": 0, "end": 2057}, "relationships": {"1": "22a1b7ca-e5c0-4a86-bdfb-c4b7b374cd7f"}}, "__type__": "1"}, "7cfe2105-6b8d-4829-b1d5-475a53b165b9": {"__data__": {"text": "Chapter 23: Understanding Advanced Linux Security\n633\n23With these modifications, PAM disables the use of the su  command. Administrative users \nnow must use sudo , which the system tracks and provides a desired non-repudiation envi-\nronment (see Chapter\u00a022).\nObtaining more information on PAM\nPAM is another rich and versatile security tool available to you on your Linux system. In \nyour own Linux system\u2019s man pages, you can read about managing the PAM configuration \nfiles and about the modules in your /usr/lib64/security  (64-bit) directory.\n\u25a0\u25a0To get more information on PAM configuration files, use the command \nman pam.conf .\n\u25a0\u25a0You can see all of the PAM modules available on your system by entering ls /usr/\nlib64/security/pam*.so  at the command line. To get more information on each \nPAM module, enter man pam_ module _name . Be sure to leave off the file exten -\nsion of so  for the pam _module _name . For example, enter man pam_lastlog  \nto learn more about the pam_lastlog.so  module. Several websites can provide \nadditional information on PAM:\n\u25a0\u25a0The Official Linux-PAM website : http://linux-pam.org\n\u25a0\u25a0The Linux-PAM System Administrator\u2019s Guide : http://linux-pam.org/\nLinux-PAM-html/Linux-PAM_SAG.html\n\u25a0\u25a0PAM Module reference : http://linux-pam.org/Linux-PAM-html/sag-\nmodule-reference.html\nSummary\nCryptography tools offer ways of protecting and verifying the validity of the data you use \non your Linux system. The PAM facility provides a means of creating policies to secure the \ntools that are used to authenticate users on your system.\nBoth the cryptography tools and PAM should be handled with care as you learn about \nLinux. Be sure to test any modifications that you make on a test Linux system or a virtual -\nized Linux system before you implement them on a production machine.\nThe next chapter covers SELinux. While cryptography and PAM are tools that you can use \non your Linux system, SELinux is an entire security enhancement layer.\nExercises\nUse these exercises to test your knowledge of using cryptography tools and PAM. These \ntasks assume that you are running a Fedora or Red Hat Enterprise Linux system (although \nsome tasks work on other Linux systems as well). If you are stuck, solutions to the tasks are \nshown in Appendix B (although in Linux, there are often multiple ways to complete a task).\n1. Encrypt a file using the gpg2  utility and a symmetric key.\n2. Generate a public key ring using the gpg2  utility.", "doc_id": "7cfe2105-6b8d-4829-b1d5-475a53b165b9", "embedding": null, "doc_hash": "5c6fffd2491f755491218b1c68f41979f6cf910803ab32db8f0b12d04c683d71", "extra_info": {"page_label": "655"}, "node_info": {"start": 0, "end": 2452}, "relationships": {"1": "d4e06117-e29f-467b-a081-de34e576e7db"}}, "__type__": "1"}, "cb207bec-2c1d-4bac-a875-dbdb79f90efc": {"__data__": {"text": "Part V: Learning Linux Security Techniques6343. List out the key ring you generated.\n4. Encrypt a file and add your digital signature using the gpg2  utility.\n5. Go to the Fedora download page: https://getfedora.org . Select one of \nthe Fedora distributions to download. When the download is complete, verify \nyour image.\n6. Using the command which su , determine the su  command\u2019s full filename. Next, \ndetermine whether the su  command on your Linux system is PAM-aware.\n7. Does the su  command have a PAM configuration file? If so, display the configura -\ntion file on the screen and list what PAM contexts it uses.\n8. List out the various PAM modules on your system to your screen.\n9. Find the PAM \u201cother\u201d configuration file on your system. Does it exist? Does it \nenforce Implicit Deny?\n10. Find the PAM limits configuration file. Does it have a setting to keep a fork bomb \nfrom occurring on your system?", "doc_id": "cb207bec-2c1d-4bac-a875-dbdb79f90efc", "embedding": null, "doc_hash": "863d46f9fba25b8f456e277f2bb3d167b0b60309340a22df6f7dc2a3edd33e4c", "extra_info": {"page_label": "656"}, "node_info": {"start": 0, "end": 910}, "relationships": {"1": "12a2905f-959c-4839-8d4b-82391a6e3750"}}, "__type__": "1"}, "571dc5f3-f6b8-404e-9c99-0fccb55763c1": {"__data__": {"text": "635\nCHAPTER24\nEnhancing Linux Security \nwith SELinux\nIN THIS CHAPTER\nLearning about SELinux benefits\nLearning how SELinux works\nSetting up SELinux\nFixing problems with SELinux\nGetting additional information on SELinux\nSecurity Enhanced Linux  (SELinux)  was developed by the National Security Agency (NSA) along \nwith other security research organizations, such as the Secure Computing Corporation (SCC). \nSELinux was released to the open source community in 2000, and it became popular when \nRed Hat included SELinux in its Linux distributions. Now, SELinux is used by many organizations \nand is widely available.\nUnderstanding SELinux Benefits\nSELinux is a security enhancement module deployed on top of Linux. It provides additional security \nmeasures, is included by default, and is set to be in enforcing mode in Red Hat Enterprise Linux \n(RHEL) and Fedora.\nSELinux provides improved security on the Linux system via role based access controls (RBACs) on \nsubjects and objects (aka processes and resources). \u201cTraditional\u201d Linux security uses Discretionary \nAccess Controls (DACs).\nWith DAC, a process can access any file, directory, device, or other resource that leaves itself open \nto access. With RBAC, a process only has access to resources that it is explicitly allowed to access, \nbased on the assigned role. The way that SELinux implements RBAC is to assign an SELinux policy \nto a process. That policy restricts access as follows:\n\u25a0\u25a0Only letting the process access resources that carry explicit labels\n\u25a0\u25a0Making potentially insecure features, such as write access to a directory, available as Bool -\neans, which can be turned on or off\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "571dc5f3-f6b8-404e-9c99-0fccb55763c1", "embedding": null, "doc_hash": "f08967429f7c50efea1543ebacc8143121e186f5466241c62a498ebb5dd9b7a7", "extra_info": {"page_label": "657"}, "node_info": {"start": 0, "end": 1770}, "relationships": {"1": "47408614-d40b-439c-bf8d-d615016e2772"}}, "__type__": "1"}, "99125867-af15-4e4b-9ab2-49c26c29ce32": {"__data__": {"text": "Part V: Learning Linux Security Techniques636A service, such as a web server, that includes an SELinux policy will often get installed \nwith SELinux labels set on specific directories and files. This can make it so that the \nrunning server process can only read and write files from specific directories. If you want \nto change that, you need to add the correct SELinux labels on the files and directories that \nyou want the process to access.\nSELinux is not a replacement for DAC. Instead, it is an additional security layer.\n\u25a0\u25a0DAC rules are still used when using SELinux.\n\u25a0\u25a0DAC rules are checked first, and if access is allowed, then SELinux policies \nare checked.\n\u25a0\u25a0If DAC rules deny access, SELinux policies are not reviewed.\nIf a user tries to execute a file for which they do not have execute access to ( rw-), the  \n\u201ctraditional\u201d Linux DAC controls deny access. Thus, the SELinux policies are not even checked.\nNote\nSELinux is the default security enhancement of Red Hat distributions, whereas AppArmor is the default secu -\nrity enhancement for Ubuntu. You can still install SELinux on Ubuntu by using the command sudo apt-get \ninstall selinux  and then reboot. However, as of this writing, the Ubuntu Wiki page for SELinux suggests that \nyou do not use Ubuntu\u2019s SELinux package ( https://wiki.ubuntu.com/SELinux ). If you want to learn \nmore about AppArmor, go to https://help.ubuntu.com/community/AppArmor .\nEven though \u201ctraditional\u201d Linux security controls still work, there are several benefits to \nusing SELinux. Following are a few of SELinux\u2019s benefits:\nIt implements the RBAC access control model. This is considered the strongest \naccess control model.\nIt uses least privilege access for subjects (for example, users and processes). The \nterm least privilege  means that every subject is given a limited set of privileges that \nare only enough to allow the subject to be functional in its tasks. With least priv -\nilege implemented, a user or process is limited on the accidental (or on-purpose) \ndamage to objects it can cause.\nIt allows process sandboxing. The term process sandboxing  means that each pro -\ncess runs in its own area (sandbox). It cannot access other processes or their files \nunless special permissions are granted. These areas where processes run are called \n\u201cdomains.\u201d\nIt allows a test of its functionality before implementation. SELinux has a permis -\nsive mode, which allows you to see the effect of enforcing SELinux on your system. \nIn permissive mode, SELinux still logs what it considers security breaches (called \nAVC denials), but it doesn\u2019t prevent them.\nAnother way to look at SELinux benefits is to examine what can happen if SELinux is \nnot running on your Linux system. For example, getting back to the web server example, ", "doc_id": "99125867-af15-4e4b-9ab2-49c26c29ce32", "embedding": null, "doc_hash": "4e4e7b31667f5bc0685e4e79fedaf9d78f5395f0364db82bbbceaa3870e50aee", "extra_info": {"page_label": "658"}, "node_info": {"start": 0, "end": 2775}, "relationships": {"1": "1c624b9d-0446-4a7f-bc28-da411251f932"}}, "__type__": "1"}, "e3f64ee8-7afd-4355-99be-68defb5c86b6": {"__data__": {"text": "Chapter 24: Enhancing Linux Security with SELinux\n637\n24your web server daemon ( httpd ) is listening on a port for something to happen. A simple \nrequest from a web browser comes in to view a home page. Going through its normal rou -\ntine, the httpd  daemon hears the request and only \u201ctraditional\u201d Linux security is applied. \nBeing unconstrained by SELinux, httpd  can do these things:\n\u25a0\u25a0Access any  file or directory, based on read/write/execute permissions for the asso -\nciated owner and group.\n\u25a0\u25a0Perform potentially insecure activities, such as allowing a file upload or changing \nsystem limits.\n\u25a0\u25a0Listen on any port it likes for incoming requests.\nOn a system constrained by SELinux, the httpd  daemon is much more tightly con -\ntrolled. Using the preceding example, httpd  can only listen on the port on which \nSELinux allows it to listen. SELinux prevents httpd  from accessing any file that \ndoesn\u2019t have the proper security context set and denies potentially insecure activities \nthat are not explicitly enabled with Booleans in SELinux. In essence, SELinux severely \nlimits what malicious code might gain access to and generally limits activity on your \nLinux system.\nUnderstanding How SELinux Works\nSELinux can be compared to a guard at a door: In this comparison, the subject (the user) \nwants to access the object (the file) inside the room. To gain access to this object:\n1. The subject must present an ID badge to the guard.\n2. The guard reviews the ID badge and access rules kept in a large manual.\na. If the access rules allow this particular ID badge inside the door, the subject \nmay enter the room to access the object.\nb. If the access rules do not allow this particular ID badge access to the object, \nthen the guard refuses entry.\nSELinux provides a combination of role based access control (RBAC) and either type enforce -\nment (TE)  or Multi-Level Security (MLS) . In role based access control, access to an object is \nbased on a subject\u2019s assigned role in the organization. Therefore, it is not based on the sub -\nject\u2019s username or process ID. Each role is granted access rights.\nUnderstanding Type Enforcement\nType enforcement (TE) is necessary to implement the RBAC model. Type enforcement \nsecures a system through these methods:\n\u25a0\u25a0Labeling objects as certain security types\n\u25a0\u25a0Assigning subjects to particular domains and roles\n\u25a0\u25a0Providing rules allowing certain domains and roles to access certain object types", "doc_id": "e3f64ee8-7afd-4355-99be-68defb5c86b6", "embedding": null, "doc_hash": "6e24ee07b9365e73779362bdc63e1a549b60849abe964db67af8e65d148b4fcb", "extra_info": {"page_label": "659"}, "node_info": {"start": 0, "end": 2443}, "relationships": {"1": "b11a3125-28a6-4c48-a28a-a6b4722df724"}}, "__type__": "1"}, "20c6c5c7-c1b3-4898-9b01-1b59855d8073": {"__data__": {"text": "Part V: Learning Linux Security Techniques638The example that follows uses the ls -l  command to show the DAC controls on the file \nmy_stuff . The output shows the file\u2019s owner (johndoe) and group (johndoe) as well as its \nassignments for permissions.\nIf you need a review of file permissions, see Chapter\u00a04, \u201cMoving Around the Filesystem.\u201d\n$ ls -l my_stuff\n-rw-rw-r--. 1 johndoe johndoe 0 Feb 12 06:57 my_stuff\nThe example that follows includes ls -lZ  and the same file, my _ stuff , but instead of \njust the DAC controls, the -Z  option displays the SELinux security RBAC controls too.\n$ ls -lZ my_stuff\n-rw-rw-r--. johndoe johndoe unconfined_u:object_r:user_home_t:s0 \n... my_stuff\nThe ls -Z  example displays four items associated with the file that are specific \nto SELinux:\nuser (unconfined_u)\nrole (object_r)\ntype (user_home_t)\nlevel (s0)\nThese four RBAC items (user, role, type, and level) are used in the SELinux access control to \ndetermine appropriate access levels. Together, the items are called the SELinux security con -\ntext. A security context (ID badge) is sometimes called a security label.\nThese security context assignments are given to subjects (processes and users). Each secu -\nrity context has a specific name. The name given depends upon what object or subject it \nhas been assigned: Files have a file context, users have a user context, and processes have a \nprocess context, also called a domain.\nThe rules allowing access are called allow rules or policy rules. A policy rule is the process \nSELinux follows to grant or deny access to a particular system security type. Returning \nto the comparison of SELinux with the guard, SELinux serves as the guard who must see \nthe subject\u2019s security context (ID badge) and review the policy rules (access rules manual) \nbefore allowing or denying access to an object. Thus, type enforcement ensures that only \ncertain \u201ctypes\u201d of subjects can access certain \u201ctypes\u201d of objects.\nUnderstanding Multi-Level Security\nWith SELinux, the default policy type is called a targeted policy , which primarily controls \nhow network services (such as web servers and file servers) can be accessed on a Linux \nsystem. The targeted policy places fewer restrictions on what valid user accounts can do \non the system. For a more restricted policy, you can choose Multi-Level Security (MLS) . MLS \nuses type enforcement along with the additional feature of security clearances. It also \noffers Multi-Category Security, which gives classification levels to objects.", "doc_id": "20c6c5c7-c1b3-4898-9b01-1b59855d8073", "embedding": null, "doc_hash": "fd44134e2711d248d4b3ee11b211af80197d1064ba87870c9b7b58b90d2dbb18", "extra_info": {"page_label": "660"}, "node_info": {"start": 0, "end": 2515}, "relationships": {"1": "37b6de1e-f780-418a-b19e-dddfdcd52e7f"}}, "__type__": "1"}, "fde6e150-9d5a-4042-9433-2425a22f6612": {"__data__": {"text": "Chapter 24: Enhancing Linux Security with SELinux\n639\n24tip\nThe Multi-Level Security (MLS) names can cause confusion. Multi-Category Security (MCS) is sometimes called \nMulti-Clearance Security. Because MLS offers MCS, it is sometimes called MLS/MCS.\nMulti-Level Security enforces the Bell-LaPadula Mandatory Access security model. The \nBell-LaPadula model was developed by the US government to impose information confiden -\ntiality. Enforcing this model is accomplished by granting object access based on a role\u2019s \nsecurity clearance and an object\u2019s classification level.\nSecurity clearance  is an attribute granted to roles allowing access to classified objects. Clas -\nsification level  is an attribute granted to an object, providing protection from subjects who \nhave a security clearance attribute that is too low. You most likely have heard of the clas -\nsification level top secret. The fictional book and movie character James Bond had a top-\nsecret security clearance, which granted him access to top-secret classified information. \nThis is a classic example of the Bell-LaPadula model.\nThe combination of RBAC along with either type enforcement (TE) or Multi-Level Security \n(MLS) enables SELinux to provide such a strong security enhancement. SELinux also offers \ndifferent operational modes for its use.\nImplementing SELinux security models\nThe role-based access control model, type enforcement, Multi-Level Security, and Bell-\nLaPadula models are all interesting topics. SELinux implements these models through a \ncombination of four primary SELinux pieces:\n\u25a0\u25a0Operational modes\n\u25a0\u25a0Security contexts\n\u25a0\u25a0Policy types\n\u25a0\u25a0Policy rule packages\nAlthough we\u2019ve touched upon some of these design elements, the following will give you an \nin-depth understanding of them. This understanding is needed before you can begin modi-\nfying the SELinux configuration on your system.\nUnderstanding SELinux operational modes\nSELinux comes with three operational modes: disabled, permissive, and enforcing. Each of \nthese modes offers different benefits for Linux system security.\nUsing the disabled mode\nIn the disabled mode , SELinux is turned off. The default method of access control, Discre -\ntionary Access Control (DAC), is used instead. This mode is useful for circumstances in \nwhich enhanced security is not required.\nIf at all possible, Red Hat recommends setting SELinux to permissive mode rather than dis -\nabling it. However, there are occasions where disabling SELinux is appropriate.", "doc_id": "fde6e150-9d5a-4042-9433-2425a22f6612", "embedding": null, "doc_hash": "fb6d883eca5124ffd4033a48df952755a2029f6e30ee695261e7b92e15d47625", "extra_info": {"page_label": "661"}, "node_info": {"start": 0, "end": 2490}, "relationships": {"1": "0af9cfe6-f629-496b-bdb0-d7c140d1c85c"}}, "__type__": "1"}, "4325e93f-f4ee-4f59-986a-5de587fbb32d": {"__data__": {"text": "Part V: Learning Linux Security Techniques640If you are running applications that are working properly (from your perspective) but are \ngenerating massive amounts of SELinux AVC denial messages (even in permissive mode), \nyou may end up filling up log files to the point of making your systems unusable. The \nbetter approach is to set the proper security context on the files your applications need to \naccess. Nevertheless, disabling SELinux is the quicker fix.\nBefore you disable SELinux, however, think about whether you may ever want to enable \nit on that system again. If you decide to set it to enforcing or permissive at a later date, \nthe next time you reboot your system, it will go through an automatic SELinux file relabel \nbefore it comes up.\ntip\nIf all you care about is turning SELinux off, you have found the answer. Just edit the configuration file /etc/\nselinux/config  and change the text SELINUX=  to SELINUX=disabled . SELinux will be disabled after a \nsystem reboot. You can now skip the rest of this chapter.\nUsing the permissive mode\nIn permissive mode , SELinux is turned on, but the security policy rules are not enforced. \nWhen a security policy rule should deny admission, access is still allowed. However, a mes -\nsage is sent to a log file denoting that access should have been denied.\nSELinux permissive mode is used for the following:\n\u25a0\u25a0Auditing the current SELinux policy rules\n\u25a0\u25a0Testing new applications to see what effect SELinux policy rules will have on them\n\u25a0\u25a0Testing new SELinux policy rules to see what effect the new rules will have on \ncurrent services and applications\n\u25a0\u25a0Troubleshooting why a particular service or application is no longer working prop -\nerly under SELinux\nIn some cases, you can use the audit2allow  command to read the SELinux audit logs and \ngenerate new SELinux rules to allow the denied actions selectively. This can be a quick way \nto get your applications working on your Linux system without disabling SELinux.\nUsing the Enforcing mode\nThe name says it all. In enforcing mode , SELinux is turned on and all of the security policy \nrules are enforced.\nUnderstanding SELinux security contexts\nAs mentioned earlier, an SELinux security context is the method used to classify objects \n(such as files) and subjects (such as users and programs). The defined security context \nallows SELinux to enforce policy rules for subjects accessing objects. A security context \nconsists of four attributes: user , role , type , and level .", "doc_id": "4325e93f-f4ee-4f59-986a-5de587fbb32d", "embedding": null, "doc_hash": "0bb9027791a55bf22381270752dc92c7a9d4305884759cbf431b46a7c13c14cd", "extra_info": {"page_label": "662"}, "node_info": {"start": 0, "end": 2489}, "relationships": {"1": "6717935b-83b1-4324-a332-766ee976b1d7"}}, "__type__": "1"}, "70b2b2af-1712-4347-a379-cb0484a82525": {"__data__": {"text": "Chapter 24: Enhancing Linux Security with SELinux\n641\n24User  The user  attribute is a mapping of a Linux username to an SELinux name. \nThis is not the same as a user\u2019s login name, and it is referred to specifically as the \nSELinux user. The SELinux username ends with a u , making it easier to identify in \nthe output. Regular unconfined users have an unconfined _ u  user attribute in \nthe default targeted policy.\nRole  A designated role in the company is mapped to an SELinux role name. The \nrole  attribute is then assigned to various subjects and objects. Each role is granted \naccess to other subjects and objects based on the role\u2019s security clearance and the \nobject\u2019s classification level. More specifically, for SELinux, users are assigned a \nrole and roles are authorized for particular types or domains. Using roles can force \naccounts, such as root, into a less privileged position. The SELinux role name has an \nr at the end. On a targeted SELinux system, processes run by the root user have a \nsystem_r role, while regular users run under the unconfined_r role.\nType  This type  attribute defines a domain type for processes, a user type for users, \nand a file type for files. This attribute is also called security type. Most policy rules \nare concerned with the security type of a process and what files, ports, devices, and \nother elements of the system that process has access to (based on their security \ntypes). The SELinux type name ends with a t .\nLevel  The level  is an attribute of Multi-Level Security (MLS), and it enforces the \nBell-LaPadula model. It is optional in TE but is required if you are using MLS.\nThe MLS level is a combination of the sensitivity and category values that together \nform the security level. A level is written as sensitivity : category.\nsensitivity\n\u25a0\u25a0Represents the security or sensitivity level of an object, such as confidential or \ntop secret.\n\u25a0\u25a0Is hierarchical, with s0  (unclassified) typically being the lowest.\n\u25a0\u25a0Is listed as a pair of sensitivity levels ( lowlevel-highlevel ) if the levels differ.\n\u25a0\u25a0Is listed as a single sensitivity level (s0) if there are no low and high levels. In \nsome cases, however, even if there are no low and high levels, the range is still \nshown (s0-s0).\ncategory\n\u25a0\u25a0Represents the category of an object, such as No Clearance, Top Clearance, \nand so on.\n\u25a0\u25a0Traditionally, the values are between c0  and c255 .\n\u25a0\u25a0Is listed as a pair of category levels ( lowlevel.highlevel ) if the levels differ.\n\u25a0\u25a0Is listed as a single category (level) if there are no low and high levels.\nUsers have security contexts\nTo see your SELinux user context, enter the id  command at the shell prompt. The following \nis an example of the security context for user johndoe :", "doc_id": "70b2b2af-1712-4347-a379-cb0484a82525", "embedding": null, "doc_hash": "0e7fcdce549ea200a231adb9ef22064b4689a720e25a9e8efe5eaed4b0e97788", "extra_info": {"page_label": "663"}, "node_info": {"start": 0, "end": 2744}, "relationships": {"1": "552c7007-8afa-4540-8ec4-d5aa60eb0047"}}, "__type__": "1"}, "95a21f24-d67c-49e5-93f2-7b2258b2a07a": {"__data__": {"text": "Part V: Learning Linux Security Techniques642$ id\nuid=1000(johndoe) gid=1000(johndoe) groups=1000(johndoe)\n context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023\nThe user\u2019s security context list shows the following:\nuser : The Linux user, johndoe , is mapped to the SELinux unconfined_u user.\nrole : The SELinux user, unconfined_u, is mapped to the role of the \nunconfined_r.\ntype : The user has been given the type of unconfined_t.\nlevel :\nsensitivity : The user has only one sensitivity level, and it is the lowest \nlevel of s0 .\ncategories : The user has access to c0.c1023 , which is all categories ( c0 through \nto c1023 ).\nFiles have security contexts\nA file also has a security context. To see an individual file\u2019s context, use the -Z  option on \nthe ls  command. The following is a security context for the file my_stuff :\n$ ls -Z my_stuff\n-rw-rw-r--. johndoe johndoe\n unconfined_u:object_r:user_home_t:s0 my_stuff\nThe file context list shows the following:\nuser : The file is mapped to the SELinux unconfined_u user.\nrole : The file is mapped to the role of object_r.\ntype : The file is considered to be part of the user_home_t domain.\nlevel :\nsensitivity : The user has only one sensitivity level, and it is the lowest \nlevel of s0 .\ncategories : MCS is not set for this file.\nProcesses have security contexts\nA process\u2019s security context has the same four attributes as a user\u2019s and a file\u2019s context. To \nsee process information on a Linux system, you typically use a variant of the ps  command. \nIn the following code, the ps -el  command was used.\n# ps -el | grep bash\n0 S  1000  1589  1583  0  80   0 -  1653 n_tty_ pts/0    00:00:00 \nbash\n0 S  1000  5289  1583  0  80   0 -  1653 wait   pts/1    00:00:00 \nbash\n4 S     0  5350  5342  0  80   0 -  1684 wait   pts/1    \n00:00:00 bash", "doc_id": "95a21f24-d67c-49e5-93f2-7b2258b2a07a", "embedding": null, "doc_hash": "8ef71e8e7debc2317cb5d05db2ca13f9e9e406f88c3f6c0ecb36dfe252796e31", "extra_info": {"page_label": "664"}, "node_info": {"start": 0, "end": 1805}, "relationships": {"1": "425e6bdd-1295-4efc-9693-ec034da485d5"}}, "__type__": "1"}, "c3054673-a6b7-4b1a-b5ef-5ac306bdc39d": {"__data__": {"text": "Chapter 24: Enhancing Linux Security with SELinux\n643\n24To see a process\u2019s security context, you need to use the -Z  option on the ps  command. In \nthe example that follows, the ps -eZ  command was used and then piped into grep  to \nsearch only for processes running the bash shell.\n# ps -eZ | grep bash\nunconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 1589 pts/0 \n00:00:00 bash\nunconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 5289 pts/1 \n00:00:00 bash\nunconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 5350 pts/1 \n00:00:00 bash\nThe process context list shows the following:\nuser : Process is mapped to the SELinux unconfined_u user.\nrole : Process is running as the unconfined_r role.\ntype : Process is running in the unconfined_t domain.\nlevel :\nsensitivity : Process has only level s0 .\ncategories : Process has access to c0.c1023 , which is all categories ( c0 through \nto c1023 ).\nThese security contexts can all be changed to meet your organization\u2019s particular security \nneeds. However, before you learn how to change the settings of these security contexts, \nyou need to understand another piece of the SELinux puzzle, SELinux policy types.\nUnderstanding SELinux Policy types\nThe policy type chosen directly determines what sets of policy rules are used to dictate \nwhat an object can access. The policy type also determines what specific security context \nattributes are needed. This is where you start to see the fine level of access control that \ncan be implemented via SELinux.\nNote\nThe policy types available on your distribution may not match the ones listed here. For instance, on older Linux \ndistributions, the strict policy is still available. On newer distributions, the strict policy has been merged into the Tar -\ngeted policy, with Targeted used by default.\nSELinux has different policies among which you can choose:\n\u25a0\u25a0Targeted\n\u25a0\u25a0MLS\n\u25a0\u25a0Minimum", "doc_id": "c3054673-a6b7-4b1a-b5ef-5ac306bdc39d", "embedding": null, "doc_hash": "09a9ab00c694067796cbe6cbf69667b086bd10e554d9d8dee9cc5bbdb5c1b5ff", "extra_info": {"page_label": "665"}, "node_info": {"start": 0, "end": 1880}, "relationships": {"1": "f1384f71-be0c-4adf-b32d-5a7346a8915c"}}, "__type__": "1"}, "a4c0c55d-26ca-4382-bbdb-310d709e2a24": {"__data__": {"text": "Part V: Learning Linux Security Techniques644Each policy implements different access controls to match your organization\u2019s needs. It is \ncritical to understand these policy types in order to select the correct one for your particu -\nlar security requirements.\nTargeted policy\nThe Targeted policy \u2019s primary purpose is to restrict \u201ctargeted\u201d daemons. However, it can also \nrestrict other processes and users. Targeted daemons are sandboxed. A sandbox  is an envi-\nronment where programs can run but their access to other objects is tightly controlled.\nA process running in such an environment is said to be \u201csandboxed.\u201d Thus, a targeted \ndaemon is restricted so that no malicious attacks launched through them can affect other \nservices or the Linux system as a whole. Targeted daemons make it safer for you to share \nyour print server, file server, web server, or other services while limiting the risks that \naccess to those services pose to other assets on your system.\nAll subjects and objects not targeted are run in the unconfined_t domain. The \nunconfined_t domain has no SELinux policy restrictions and thus only uses the \u201ctradi-\ntional\u201d Linux security.\nSELinux comes with the Targeted policy set as the default. Thus, by default, SELinux tar -\ngets only a few daemons.\nMLS (Multi-Level Security) policy\nThe MLS policy \u2019s primary purpose is to enforce the Bell-LaPadula model. It grants access to \nother subjects and objects based upon a role\u2019s security clearance  and the object\u2019s classifica -\ntion level .\nIn the MLS policy, a security context\u2019s MLS attribute is critical. Otherwise, the policy rules \nwill not know how to enforce access restrictions.\nMinimum policy\nThis policy is just as it sounds\u2014minimal. It was originally created for low-memory \nmachines or devices such as smartphones.\nThe Minimum policy  is essentially the same as the Targeted policy, but only the base \npolicy rule package is used. This \u201cbare-bones\u201d policy can be used to test out the effects \nof SELinux on a single designated daemon. For low-memory devices, the Minimum policy \nallows SELinux to run without consuming a great deal of resources.\nUnderstanding SELinux policy rule packages\nPolicy rules , also called allow rules , are the rules used by SELinux to determine if a subject \nhas access to an object. Policy rules are installed with SELinux and are grouped into pack -\nages, also called modules .\nOn your Linux system, there is user documentation on these various policy modules in \nthe form of HTML files. To view this documentation on Fedora or RHEL, open your sys -\ntem\u2019s browser and type in the following URL: file:///usr/share/doc/selinux-\npolicy/html/index.html. For Ubuntu, the URL is file:///usr/share/doc/", "doc_id": "a4c0c55d-26ca-4382-bbdb-310d709e2a24", "embedding": null, "doc_hash": "df75a72e36385e0aa1bd09f6726d0b6097d34f032c8ac116b5d5ab903ae335b7", "extra_info": {"page_label": "666"}, "node_info": {"start": 0, "end": 2711}, "relationships": {"1": "4a2a5849-9d5b-4ed2-ae8b-5eec3d1a802c"}}, "__type__": "1"}, "046cabda-68d2-4356-8a2b-6f75027a8c35": {"__data__": {"text": "Chapter 24: Enhancing Linux Security with SELinux\n645\n24selinux-policy-doc/html/index.html . If you do not have the policy documentation \non your system, you can install it on a Fedora or RHEL system by typing yum install \nselinux-policy-doc  at the command line. On Ubuntu, type sudo apt-get install \nselinux-policy-doc  at the command line.\nYou can review this policy documentation to see how policy rules are created and packaged.\nThe policy rule packages, along with the SELinux operational modes, policy type, and var -\nious security contexts, work together to secure your Linux system via SELinux. The follow -\ning sections cover how to begin configuring SELinux to meet your particular organization\u2019s \nsecurity needs.\nConfiguring SELinux\nSELinux comes preconfigured. You can use the SELinux features without any configuration \nwork. However, rarely do the preconfigured settings meet all of your Linux system\u2019s secu -\nrity needs.\nSELinux configurations can only be set and modified by the root user. Configuration and \npolicy files are located in the /etc/selinux  directory. The primary configuration file is \nthe /etc/selinux/config  file, and it appears as follows:\n# cat /etc/selinux/config\n# This file controls the state of SELinux on the system.\n# SELINUX= can take one of these three values:\n#      enforcing - SELinux security policy is enforced.\n#      permissive - SELinux prints warnings instead of enforcing.\n#      disabled - SELinux is fully disabled.\nSELINUX=enforcing\n# SELINUXTYPE= can take one of these three values:\n#     targeted - Targeted processes are protected,\n#     minimum - Modification of targeted policy.\n#               Only selected processes are protected. \n#     mls - Multi Level Security protection.\nSELINUXTYPE=targeted\nThis main SELinux configuration file allows you to set the mode and the policy type.\nSetting the SELinux mode\nTo see SELinux\u2019s current mode on your system, use the getenforce  command. To see both \nthe current mode and the mode set in the configuration file, use the sestatus  command. \nBoth commands are shown in the code that follows:\n# getenforce\nEnforcing\n# sestatus\nSELinux status:                 enabled\nSELinuxfs mount:                /sys/fs/selinux", "doc_id": "046cabda-68d2-4356-8a2b-6f75027a8c35", "embedding": null, "doc_hash": "2a6286985386bdb586103367e1f055341350b73d85341ca1d04ecfa9e6c39a3a", "extra_info": {"page_label": "667"}, "node_info": {"start": 0, "end": 2222}, "relationships": {"1": "d9a8b7f7-5217-4452-a853-62c282430388"}}, "__type__": "1"}, "2e38bf80-4328-465e-930b-0dffc8ad0efe": {"__data__": {"text": "Part V: Learning Linux Security Techniques646SELinux root directory:         /etc/selinux\nLoaded policy name:             targeted\nCurrent mode:                   enforcing\nMode from config file:          enforcing\nPolicy MLS status:              enabled\nPolicy deny_unknown status:     allowed\nMemory protection checking:     actual (secure)\nMax kernel policy version:      31\nTo change the mode setting, you can use the setenforce  newsetting , where  \nnewsetting  is either\n\u25a0\u25a0enforcing or 1\n\u25a0\u25a0permissive or 0\nNotice that you cannot use the setenforce  command to change SELinux to dis -\nabled mode.\nThe example that follows shows the SELinux mode being changed immediately to permis -\nsive mode via the setenforce  command. The sestatus  command shows the current \noperational mode and the mode in the configuration file, which has not been modified. \nWhen the system is rebooted, it determines the SELinux operational mode from the con -\nfiguration file. Thus, the permissive mode set in the example that follows is temporary \nbecause the enforcing mode is set via the configuration file when the system is rebooted.\n# setenforce 0\n# getenforce\nPermissive\n# sestatus\nSELinux status:                 enabled\nSELinuxfs mount:                /sys/fs/selinux\nSELinux root directory:         /etc/selinux\nLoaded policy name:             targeted\nCurrent mode:                   permissive\nMode from config file:          enforcing\n...\nCautio N \nIt is best to switch from the disabled to the enforcing mode by modifying the configuration file and rebooting. Switch -\ning from disabled to enforcing via the setenforce  command may hang your system as a result of incorrect file \nlabels. Keep in mind that, when rebooting after changing from disabled  mode, there could be a long wait for your \nfilesystem to be relabeled after the system comes back up in permissive or enforcing mode.\nTo disable SELinux, you must edit the SELinux configuration file. Rebooting the system \nalways changes the mode back to what is set in that configuration file. The preferred \nmethod of changing the SELinux mode is to modify the configuration file and then reboot \nthe system.", "doc_id": "2e38bf80-4328-465e-930b-0dffc8ad0efe", "embedding": null, "doc_hash": "955969b3b77b82270456759117d537f2cfcc5ff41a95ad8be36d2f46ce59975a", "extra_info": {"page_label": "668"}, "node_info": {"start": 0, "end": 2157}, "relationships": {"1": "d5d8803b-a0cb-4d11-9a97-2df8fdce2573"}}, "__type__": "1"}, "df937357-6cf1-4c23-ab7d-1e20fc5bb765": {"__data__": {"text": "Chapter 24: Enhancing Linux Security with SELinux\n647\n24When switching from disabled to either enforcing or permissive mode, SELinux automat -\nically relabels the filesystem after a reboot. This means that SELinux checks and changes \nthe security contexts of any files with incorrect security contexts (for example, mislabeled \nfiles) that can cause problems in the new mode. Also, any files not labeled are labeled \nwith contexts. This relabeling process can take a long time because each file\u2019s context is \nchecked. Following is the message that you\u2019ll receive when a system is going through a \nrelabeling process after a reboot:\n*** Warning -- SELinux targeted policy relabel is required.\n*** Relabeling could take a very long time, depending on file\n*** system size and speed of hard drives.\nTo modify the mode in the /etc/selinux/config  file, change the line SELINUX=  to one \nof the following:\n\u25a0\u25a0SELINUX=disabled\n\u25a0\u25a0SELINUX=enforcing\n\u25a0\u25a0SELINUX=permissive\nThe SELinux configuration file example that follows shows that the mode has been set to \npermissive. Now, when a system reboot occurs, the mode is changed.\n# cat /etc/selinux/config\n# This file controls the state of SELinux on the system.\n# SELINUX= can take one of these three values:\n#     targeted - Targeted processes are protected,\n#     minimum - Modification of targeted policy.\n#               Only selected processes are protected. \n#     mls - Multi Level Security protection\nSELINUX=permissive\n...\nThe primary SELinux configuration file does not just contain the mode setting. It also spec -\nifies the policy type, which will be enforced.\nSetting the SELinux policy type\nThe policy type you choose determines whether SELinux enforces TE, MLS, or a base \npackage. This type setting directly determines the sets of policy rules used to dictate what \nan object can access.\nBy default, the policy type is set to targeted . To change the default policy type, \nedit the /etc/selinux/config  file. Change the line SELINUXTYPE=  to one of the \nfollowing:\n\u25a0\u25a0SELINUX=targeted\n\u25a0\u25a0SELINUX=mls\n\u25a0\u25a0SELINUX=minimum", "doc_id": "df937357-6cf1-4c23-ab7d-1e20fc5bb765", "embedding": null, "doc_hash": "cf0f6bb33298a1589db016ea45bd18be826222e1dba937e9198108a663c377d2", "extra_info": {"page_label": "669"}, "node_info": {"start": 0, "end": 2069}, "relationships": {"1": "58d8100f-b2df-439e-ab75-a30af24329a7"}}, "__type__": "1"}, "61f898a3-3505-47f7-aefe-722bd418354c": {"__data__": {"text": "Part V: Learning Linux Security Techniques648If you set the SELinux type to mls or minimum, you need to make sure that you have their \npolicy package installed first. Check by typing the following command:\nyum list selinux-policy-mls or yum list selinux-policy-minimum\nNote\nTo check the SELinux policy packages on Ubuntu, use the command sudo apt-cache policy package_\nname.\nThe example of the SELinux configuration file that follows shows that the type has been set \nto mls . Now when a system reboot occurs, the policy type is changed.\n# cat /etc/selinux/config\n# This file controls the state of SELinux on the system.\n...\n# SELINUXTYPE= type of policy in use. Possible values are:\n \n#     targeted - Targeted processes are protected,\n#     minimum - Modification of targeted policy.\n#               Only selected processes are protected. \n#     mls - Multi Level Security protection.\nSELINUXTYPE=mls\nManaging SELinux security contexts\nSELinux security contexts allow SELinux to enforce policy rules for subjects accessing \nobjects. Your Linux system comes with security contexts already assigned.\nTo view current SELinux file and process security contexts, use the secon  command. \nTable\u00a024.1 lists available options on the secon  command.\nTABLE 24.1  secon  Command Options\nOption Description\n-u Use this option to show the user of the security context.\n-r Use this option to show the role of the security context.\n-t Use this option to show the type of the security context.\n-s Use this option to show the sensitivity level of the security context.\n-c Use this option to show the clearance level of the security context.\n-m Use this option to show the sensitivity and clearance level of the security context as an \nMLS range.", "doc_id": "61f898a3-3505-47f7-aefe-722bd418354c", "embedding": null, "doc_hash": "179994e2c25725388ba1e7499e60fed7538218727efba2eaef62b186b12165e0", "extra_info": {"page_label": "670"}, "node_info": {"start": 0, "end": 1730}, "relationships": {"1": "2bc7c8b3-82d1-4b74-b9f8-81bcddbe8c40"}}, "__type__": "1"}, "04c8f721-86f3-4074-9d1d-4aa5674924ac": {"__data__": {"text": "Chapter 24: Enhancing Linux Security with SELinux\n649\n24If you use the secon  command with no designation, it shows you the current process\u2019s \nsecurity context. To see another process\u2019s security context, use the -p  option. The example \nthat follows shows you how to use secon  to view the current and the systemd  process\u2019s \nsecurity context.\n# secon -urt\nuser: unconfined_u\nrole: unconfined_r\ntype: unconfined_t\n# secon -urt -p 1\nuser: system_u\nrole: system_r\ntype: init_t\nTo view a file\u2019s security context, you use the -f  option, as shown here:\n# secon -urt -f /etc/passwd\nuser: system_u\nrole: object_r\ntype: passwd_file_t\nThe secon  command doesn\u2019t show your security context. To see your security context, use \nthe id  command.\nManaging the user security context\nRemember that every system user login ID is mapped to a particular SELinux user ID. To see \na mapping list on your system, enter the semanage login -l command. The semanage  \ncommand and its output are shown in the code that follows. If a user login ID is not listed, \nthen it uses the \u201cdefault\u201d login mapping, which is the Login Name  of _default_. Notice \nthat the associated MLS/MCS settings for each SELinux user are shown as well.\n# semanage login -l\nLogin Name           SELinux User         MLS/MCS Range     Service\n__default__          unconfined_u         s0-s0:c0.c1023    *\nroot                 unconfined_u         s0-s0:c0.c1023    *\nTo see a current display of the SELinux users and their associated roles, use the command \nsemanage user -l . The partial display that follows shows roles mapped to SELinux \nusernames:\n# semanage user -l\n \n             Labeling MLS/      MLS/\nSELinux User Prefix   MCS Level MCS Range       SELinux Roles\nguest_u      user     s0        s0              guest_r\n...\nuser_u       user     s0        s0              user_r\nxguest_u     user     s0        s0              xguest_r", "doc_id": "04c8f721-86f3-4074-9d1d-4aa5674924ac", "embedding": null, "doc_hash": "ddbc398cc00054efd7fcf271d05c6700d858aa60a4a8e4a53cebe1300c4152a0", "extra_info": {"page_label": "671"}, "node_info": {"start": 0, "end": 1893}, "relationships": {"1": "b55945bb-264b-4bd4-8198-6fd2eba8b3e8"}}, "__type__": "1"}, "8b1f4c30-d72c-4900-b65c-0273b0279177": {"__data__": {"text": "Part V: Learning Linux Security Techniques650If you need to add a new SELinux username, the semanage  utility is used again. This \ntime, the command is semanage user -a  selinux_username. To map a login ID to \nthe newly-added SELinux username, the command is semanage login -a -s selinux_\nusername loginID . The semanage  utility is a powerful tool in managing your SELinux \nconfiguration. For more information on the semanage  utility, see the man pages.\nManaging the file security context\nLabeling files is critical to maintaining proper access control to each file\u2019s data. SELinux \ndoes set file security labels upon installation and upon system reboot when the SELinux \nmode is switched from disabled . To see a file\u2019s current label (aka security context), use \nthe ls -Z  command, as shown here:\n# ls -Z /etc/passwd\n-rw-r--r--. root root system_u:object_r:etc_t:s0 /etc/passwd\nYou can use several commands to manage file security context labels, as shown in \nTable\u00a024.2.\nThe chcat  and chcon  commands, shown in Table\u00a024.2, allow you to change a file\u2019s security \ncontext. In the following example, the chcon  command is used to change the SELinux user \nassociated with file.txt  from undefined _ u  to system _ u .\n# ls -Z file.txt\n-rw-rw-r--. johndoe johndoe\n unconfined_u:object_r:user_home_t:s0 file.txt\n# chcon -u system_u file.txt\n# ls -Z file.txt\n-rw-rw-r--. johndoe johndoe\n system_u:object_r:user_home_t:s0 file.txtTABLE 24.2  File Security Context Label Management Commands\nUtility Description\nchcat Use this to change a file\u2019s security context label\u2019s category.\nchcon Use this to change a file\u2019s security context label.\nfixfiles This calls the restorecon/setfiles  utility.\nrestorecon This does the exact same thing as setfiles  utility, but it has a different inter -\nface than setfiles .\nsetfiles Use this to verify and/or correct security context labels. It can be run for file \nlabel verification and/or relabeling files when adding a new policy module to \nthe system. Does exactly the same thing as the restorecon  utility but has a \ndifferent interface than restorecon .", "doc_id": "8b1f4c30-d72c-4900-b65c-0273b0279177", "embedding": null, "doc_hash": "683f9992e6cd0d7990af74007e5e60075f7fa1105653d1977988f816866e674f", "extra_info": {"page_label": "672"}, "node_info": {"start": 0, "end": 2091}, "relationships": {"1": "2a197dae-5788-409a-85f9-c26d2d3aafbb"}}, "__type__": "1"}, "066dd50f-da66-4adf-b597-7858c3232b2c": {"__data__": {"text": "Chapter 24: Enhancing Linux Security with SELinux\n651\n24Notice in Table\u00a024.2 that fixfiles , restorecon , and setfiles  are essentially the same \nutility. However, restorecon  is the popular choice to use when fixing files\u2019 labels. The \ncommand restorecon  filename  changes a file back to its default security context.\nManaging the process security context\nThe definition of a process is a running program. When you run programs or start ser -\nvices on a Linux system, each one is given a process ID (see Chapter\u00a06, \u201cManaging Running \nProcesses\u201d). On a system with SELinux, a process is also given a security context.\nHow a process gets its security context depends upon which process started it. Remember \nthat systemd  (previously init ) is the \u201cmother\u201d of all processes (see Chapter\u00a015, \u201cStarting \nand Stopping Services\u201d). Thus, many daemons and processes are started by systemd . The \nprocesses systemd  starts are given new security contexts. For instance, when the apache  \ndaemon is started by systemd , it is assigned the type (aka domain) httpd_t. The context \nassigned is handled by the SELinux policy written specifically for that daemon. If no policy \nexists for a process, then it is assigned a default type, unconfined_t.\nFor a program or application run by a user (parent process), the new process (child process) \ninherits the user\u2019s security context. Of course, this occurs only if the user is allowed to run \nthe program. A process can also run a program. The child process in this case also inherits \nits parent process\u2019s security context. Thus, the child process runs in the same domain.\nSo, a process\u2019s security context is set before the program is run and depends upon who \nstarted it. You can use a couple of commands to change the security contexts under which \na program is run:\nruncon : Run the program using options to determine the user, role, and type \n(aka domain).\nsandbox : Run the program within a tightly controlled domain (aka sandbox).\nYou can cause several problems by using runcon , so use it with caution. However, \nsandbox  offers a great deal of protection. It allows flexibility in testing out new programs \non your Linux system.\nManaging SELinux policy rule packages\nPolicy rules are the rules used by SELinux to determine whether a subject has access to \nan object. They are grouped into packages, also called modules, and are installed with \nSELinux. An easy way to view the modules on your system is to use the semodule -l  \ncommand. It lists all of the policy modules along with their current version number. An \nexample of the semodule -l  command is shown here:\n# semodule -l\nabrt\naccountsd\nacct\n...", "doc_id": "066dd50f-da66-4adf-b597-7858c3232b2c", "embedding": null, "doc_hash": "6d06eb0bc2e1d4c8c18e382f1d4c135df99634712b7f2e8e6d93b498ff975286", "extra_info": {"page_label": "673"}, "node_info": {"start": 0, "end": 2649}, "relationships": {"1": "23361655-cf42-4f62-866b-660a347e8711"}}, "__type__": "1"}, "3b0fcdde-5394-490f-aefa-6c7fb24d1bc2": {"__data__": {"text": "Part V: Learning Linux Security Techniques652xserver\nzabbix\nzarafa\nzebra\nzoneminder\nzosremote\nSeveral tools can help you manage and even create your own policy modules. Table\u00a024.3 \nshows the various policy rule package tools available on a Fedora system.\nThe following is an example policy typically used as a framework to create local policy \nrules. The example policy is rather long, so only a portion of it is shown.\n# cat /usr/share/doc/selinux-policy/example.te\n \npolicy_module(myapp,1.0.0)\n \n########################################\n#\n# Declarations\n#\n \ntype myapp_t;\ntype myapp_exec_t;\ndomain_type(myapp_t)\ndomain_entry_file(myapp_t, myapp_exec_t)\n \ntype myapp_log_t;\nlogging_log_file(myapp_log_t)\n TABLE 24.3  SELinux Policy Package Tools\nPolicy Tool Description\naudit2allow Generates policy allow /dontaudit  rules from logs of denied \noperations\naudit2why Generates a description of why the access was denied from logs of \ndenied operations\ncheckmodule Compiles policy modules\ncheckpolicy Compiles SELinux policies\nload_policy Loads new policies into the kernel\nsemodule_expand Expands a policy module package\nsemodule_link Links policy module packages together\nsemodule _ package Creates a policy module package", "doc_id": "3b0fcdde-5394-490f-aefa-6c7fb24d1bc2", "embedding": null, "doc_hash": "a1b2f001d686a719bb111fa939cfbf096a3e91a170efc4325f6032fa9e2d3bee", "extra_info": {"page_label": "674"}, "node_info": {"start": 0, "end": 1222}, "relationships": {"1": "94ea69bc-9fb4-4780-90bf-4d79aafe64e0"}}, "__type__": "1"}, "331cf6f8-f379-41b8-8309-2ab814ae8ac8": {"__data__": {"text": "Chapter 24: Enhancing Linux Security with SELinux\n653\n24type myapp_tmp_t;\nfiles_tmp_file(myapp_tmp_t)\n...\nallow myapp_t myapp_tmp_t:file manage_file_perms;\nfiles_tmp_filetrans(myapp_t,myapp_tmp_t,file)\n#\nYou can see from the preceding example code that a special syntax is used in policy code. \nTo create and modify policy rules, you need to learn this policy rule language syntax, learn \nhow to use the SELinux policy compilers, and learn how to link policy rule files together to \nform modules; you probably need to take a couple of day-long classes to accomplish this. \nYou may be tempted to give up on SELinux at this point. However, it is much easier to use \nBooleans to modify policies.\nManaging SELinux via Booleans\nSELinux policy rule writing and module creation is a rather complicated and time-con -\nsuming activity. Creating incorrect policy rules could potentially compromise your Linux \nsystem\u2019s security. Thankfully, SELinux provides Booleans.\nA Boolean is a toggle switch that toggles a setting on or off. A Boolean switch allows you to \nchange parts of SELinux policy rules without any knowledge of policy writing. These policy \nchanges can be done without a system reboot too!\nTo see a list of all of the current Booleans used in SELinux, use the getsebool -a  \ncommand. The following is an example of the SELinux policy rules with Booleans on a \nFedora Linux system:\n# getsebool -a\nabrt_anon_write --> off\nabrt_handle_event --> off\n...\nxserver_object_manager --> off\nzabbix_can_network --> off\nTo see a specific policy that can be modified by a Boolean, the getsebool  command is \nused again. This time, the policy name is passed to it, as shown in the following example:\n# getsebool httpd_can_connect_ftp\nhttpd_can_connect_ftp --> off\nTo toggle a policy, you can use the setsebool  command. This command changes the \npolicy rule temporarily. When the system is rebooted, the Boolean returns to its origi-\nnal setting. If you need this setting to be permanent, you can use setsebool  with the \n-P option.\nThe setsebool  command has six settings: three for turning a policy on ( on, 1, or true ), \nand three for turning a policy off ( off, 0, or false ).\nOne example where you might want to use setsebool  relates to restricting the use of exe -\ncutable files. In some situations, it is not good security to allow users to execute programs ", "doc_id": "331cf6f8-f379-41b8-8309-2ab814ae8ac8", "embedding": null, "doc_hash": "c0c4a762315f4a12c4da3076de0222f96ea8cf84e8b949c9c0f5459836afe47b", "extra_info": {"page_label": "675"}, "node_info": {"start": 0, "end": 2357}, "relationships": {"1": "49dddca3-5a05-42f6-8b7c-298e84574cd1"}}, "__type__": "1"}, "180e7636-d28b-4af9-bcbe-a1d13992400a": {"__data__": {"text": "Part V: Learning Linux Security Techniques654from their /home  directory. To prevent this from happening, the allow_user_exec_\ncontent policy rule needs to be turned off. The example that follows shows the setse -\nbool  command being used to do just that. Notice that the -P  option is used to make this \nsetting permanent.\n# setsebool -P allow_user_exec_content off\nThe getsebool  command verifies that the Boolean setting has been correctly made:\n# getsebool allow_user_exec_content\nallow_user_exec_content --> off\nBooleans make modifying current SELinux policy rules much easier. Overall, the SELinux \ncommand line configuration utilities, such as getsebool, are easy to use. However, if \nyou want a GUI configuration tool, SELinux has one. It is installed via the command yum \ninstall policycoreutils-gui. On Ubuntu, use the command sudo apt-get \ninstall policycoreutils. To use this configuration tool, simply type in the command \nsystem-config-selinux and a GUI interface appears.\nMonitoring and Troubleshooting SELinux\nSELinux is another tool for monitoring your system. It logs all access denials, which can \nhelp you determine whether an attack is being attempted. These same SELinux log files are \nalso useful in troubleshooting SELinux problems.\nUnderstanding SELinux logging\nSELinux uses a cache called the Access Vector Cache (AVC) when reviewing policy rules for \nparticular security contexts. When access is denied, called an AVC denial, a denial message \nis put into a log file.\nThese logged denial messages can help you diagnose and address routine SELinux policy \nviolations. Where these denial messages are logged depends upon the status of the auditd  \nand rsyslogd  daemons:\n\u25a0\u25a0If the auditd  daemon is running, the denial messages are logged to /var/log/\naudit/audit.log .\n\u25a0\u25a0If auditd  is not running, but the rsyslogd  daemon is running, the denial mes -\nsages are logged to /var/log/messages .\nNote\nIf both auditd  and rsyslogd  are running, and you have the setroubleshootd  daemon on your system, \ndenial messages are sent to both the audit.log  and messages  log files. However, denial information in the \nmessages  log file is put into a more understandable format by the setroubleshootd  daemon.", "doc_id": "180e7636-d28b-4af9-bcbe-a1d13992400a", "embedding": null, "doc_hash": "9af8e8fb413f34271cd7fc514d0f44492123029a8316cc4d960679137cb9bb18", "extra_info": {"page_label": "676"}, "node_info": {"start": 0, "end": 2223}, "relationships": {"1": "938c7cad-1c17-4615-b516-37113c379bcb"}}, "__type__": "1"}, "e61c1878-d98b-4ebd-9772-c0529ce2dd8a": {"__data__": {"text": "Chapter 24: Enhancing Linux Security with SELinux\n655\n24Reviewing SELinux messages in the audit log\nIf you have the auditd  daemon running, you can quickly see if any AVC denials have \nbeen logged by using the aureport  command. The example that follows shows the use of \naureport  and grep  to search for AVC denials. At least one denial has been logged to /\nvar/log/audit/audit.log :\n# aureport | grep AVC\nNumber of AVC's: 1\nAfter you discover that an AVC denial has been logged in audit.log , you can use aus -\nearch  to review the denial message(s). The example that follows shows the ausearch  \ncommand being used to review the logged AVC denial message:\n# ausearch -m avc\ntype=AVC msg=audit(1580397837.344:274): avc: denied { getattr } for \npid=1067\n   comm=\"httpd\" path=\"/var/myserver/services\" dev=\"dm-0\" ino=655836\n   scontext=system_u:system_r:httpd_t:s0\n   tcontext=unconfined_u:object_r:var_t:s0 tclass=file permissive=0\nThe display provides information on who was attempting access, along with their security \ncontext when attempting it. Look for these key words in an AVC denial message:\n\u25a0\u25a0type=AVC\n\u25a0\u25a0avc: denied\n\u25a0\u25a0com=\"httpd\"\n\u25a0\u25a0path=\"/var/myserver/services\"\nThis can give you enough data either to begin fixing a problem or to track down malicious \nactivity. Here, the /var/myserver/services  directory has the wrong SELinux file con -\ntext to be read by the httpd  service.\nReviewing SELinux messages in the messages log\nIf you have the auditd  service running, you can find AVC denial messages by search -\ning through the /var/log/audit/audit.log  file using grep . For the latest RHEL and \nFedora systems, or any Linux system using systemd , you can run the journalctl  \ncommand to check for AVC denial log messages as well. Within each log message is an AVC \nmessage that you can view to get information about that AVC denial, as in the follow -\ning example:\n# journalctl | grep AVC\ntype=AVC msg=audit(1580397837.346:275): avc: denied { getattr }for \npid=1067 \n   comm=\"httpd\" path=\"/var/myserver/services\" dev=\"dm-0\" ino=655836 \n   scontext=system_u:system_r:httpd_t:s0\n   tcontext=unconfined_u:object_r:var_t:s0 tclass=file permissive=0", "doc_id": "e61c1878-d98b-4ebd-9772-c0529ce2dd8a", "embedding": null, "doc_hash": "f1bad15710ee522ad5900d70cf5d06d448658d97a8697c3da63fc771493a6942", "extra_info": {"page_label": "677"}, "node_info": {"start": 0, "end": 2157}, "relationships": {"1": "65f887ed-e7d7-44cd-99c2-fcda28e11f29"}}, "__type__": "1"}, "be6940e2-ba9d-4119-aace-40c2cfd19240": {"__data__": {"text": "Part V: Learning Linux Security Techniques656Since you know that there are AVC denials, you can pass the entire /var/log/audit/\naudit.log  file to sealert  to step through the issues:\n# sealert -a /var/log/audit/audit.log\nSELinux is preventing httpd from getattr access on the file\n/var/myserver/services.\n \n*****  Plugin catchall (100. confidence) suggests   *************\n \nIf you believe that httpd should be allowed getattr access on the\nservices file by default.\nThen you should report this as a bug.\nYou can generate a local policy module to allow this access.\nDo\nallow this access for now by executing:\n# ausearch -c 'httpd' --raw | audit2allow -M my-httpd\n# semodule -X 300 -i my-httpd.pp\n \nAdditional Information:\nSource Context                system_u:system_r:httpd_t:s0\nTarget Context                unconfined_u:object_r:var_t:s0\nTarget Objects                /var/myserver/services [ file ]\n...\nRaw Audit Messages\ntype=AVC msg=audit(1580397837.346:275): avc:  denied  { getattr }\nfor  pid=1067 comm=\"httpd\" path=\"/var/myserver/services\" dev=\"dm-0\"\nino=655836 scontext=system_u:system_r:httpd_t:s0 \ntcontext=unconfined_u:object_r:var_t:s0 tclass=file permissive=0\nHash: httpd,httpd_t,var_t,file,getattr\nIn this case, if you want to allow access by the httpd  service to the content in the direc -\ntory being denied, you can run the ausearch  and semodule  commands shown in the \noutput. This creates and applies a new SELinux policy to allow access to the content. Pro -\nvided there are no other permission problems, httpd  should be able to access that content.\nTroubleshooting SELinux logging\nObviously, the log files are extremely important for diagnosing and addressing SELinux \npolicy violations. The log files, or directly querying the systemd  journal (journalctl  \ncommand), are your first steps in troubleshooting SELinux. Thus, it is important to make \nsure that your Linux system is logging messages in the first place.\nA quick way to determine if the logging is taking place is to check if the proper dae -\nmons are running: auditd , rsyslogd , and/or setroubleshootd . Use an appropriate \ncommand, such as systemctl status auditd.service . Of course, the command you \nuse depends on your Linux distribution and its version. See Chapter\u00a015 for more details. If \nthe daemon is not running, start it so that logging may begin to occur.", "doc_id": "be6940e2-ba9d-4119-aace-40c2cfd19240", "embedding": null, "doc_hash": "33066dee997f84da4a2ba38a57438c44c2d1da370cd2b1d92b8f7f1442e39e0e", "extra_info": {"page_label": "678"}, "node_info": {"start": 0, "end": 2358}, "relationships": {"1": "7cf91735-c48d-4107-8803-4add5255b869"}}, "__type__": "1"}, "05ae72b0-ed40-4e0a-94ba-d6cb9b4e84ba": {"__data__": {"text": "Chapter 24: Enhancing Linux Security with SELinux\n657\n24Cautio N \nSometimes AVC denials are not logged because of dontaudit  policy rules. Although the dontaudit  rules help \nreduce false positives in the logs, they can cause problems when troubleshooting. To fix this, temporarily disable all \ndontaudit  policy rules using the command semodule -DB .\nTroubleshooting common SELinux problems\nWhen you begin working with SELinux, it is easy to overlook the obvious. Whenever access \nis denied, you should first check the \u201ctraditional\u201d Linux DAC permissions. For example, \nuse the ls -l  command and double-check that a file\u2019s owner; group; and read, write, and \nexecute assignments are correct.\nWith SELinux, several regular items can cause problems:\n\u25a0\u25a0Using a nonstandard directory for a service\n\u25a0\u25a0Using a nonstandard port for a service\n\u25a0\u25a0Moving files that result in losing their security context labels\n\u25a0\u25a0Having Booleans set incorrectly\nEach one of these problems can be solved fairly quickly.\nUsing a nonstandard directory for a service\nFor various reasons, you may decide to store a service\u2019s files in a nonstandard directory. \nWhen you do this, SELinux needs to know that this nonstandard behavior has occurred. \nOtherwise, it denies access to legitimate service access requests.\nFor example, you decided to keep your HTML files in a different location from the standard \n/var/www/html . You put the files in /abc/www/html . You must let SELinux know that \nyou want the http  service to be able to access the files within /abc/www/html . The com-\nmands to accomplish this are semanage  and restorecon . In the following code snippet, \nthe commands are used to add the proper security context type on the /abc/www/html  \ndirectory and all it contains:\n# semanage fcontext -a -t httpd_sys_content_t  \"/abc/www/html(/.*)?\"\nTo actually set the new security context type to the files within the directory, you need to \nuse the restorecon -R  command. This is accomplished in the following code:\n# restorecon -R -v /abc/www/html\n# ls -Z /abc/www/html\nunconfined_u:object_r:httpd_sys_content_t:s0 abc\nNow the httpd  daemon has permission to access your HTML files in their non-standard \ndirectory location.", "doc_id": "05ae72b0-ed40-4e0a-94ba-d6cb9b4e84ba", "embedding": null, "doc_hash": "9bb5333a5063d2c7c29ac9b64d83b78f7691529d4e78aed27773de7e39543604", "extra_info": {"page_label": "679"}, "node_info": {"start": 0, "end": 2203}, "relationships": {"1": "a0aa7e02-5291-4ded-bacc-0bb0c0420ffb"}}, "__type__": "1"}, "a3fe2f9d-23bc-4b6a-98ad-4e4bc85aafee": {"__data__": {"text": "Part V: Learning Linux Security Techniques658Using a nonstandard port for a service\nSimilar to the problem just described, you may decide to have a service listening on a non -\nstandard port. When you make this port change, the service often fails to start.\nFor example, you decide for security purposes to move sshd  from port 22 to a nonstandard \nport, 47347. SELinux does not know about this port, and the service fails to start. To fix \nthis problem, you must first find the security context type for sshd . This is accomplished \nusing the code that follows by issuing the semanage port -l command and piping the \nresults into grep  to search for ssh .\n# semanage port -l | grep ssh\nssh_port_t                tcp             22\nIn the preceding example, you can see that the context type needed is ssh_port_t. Now, \nusing the semanage  command again, you add that type to port 47347, as shown here:\n# semanage port -a -t ssh_port_t -p tcp 47347\n# semanage port -l | grep ssh\nssh_port_t                tcp             47347, 22\nAt this point, edit the /etc/ssh/sshd _ config  file to add a Port 47347  line to \nthe file. Then restart the sshd  service so that the service listens on the nonstandard \nport 47347.\nMoving files and losing security context labels\nYou used the cp  command to move a file from /etc  temporarily to the /tmp  directory. \nThen you used the mv  command to put it back. Now the file has the security context of the \ntemporary directory instead of its original security context, and your system is getting AVC \ndenial messages when the service using that file tries to start up.\nThere is an easy fix, thanks to the restorecon -R  command. Simply type in  \nrestorecon  file , and the file has its permanent security context restored.\nBooleans set incorrectly\nAnother common problem is simply setting a Boolean incorrectly. This can give you several \nAVC denials.\nFor example, if your system\u2019s scripts are no longer able to connect out to the network and \nyou are getting AVC denials in your logs, you need to check the httpd  Booleans. Use the \ngetsebool -a  command, and pipe it into grep  to search for any Booleans that affect \nhttpd . The example here shows these commands being used:\n# getsebool -a | grep http\n...\nhttpd_can_network_connect --> off\n...\nThe getsebool  command shows the Boolean httpd_can_network_connect \nis set to off. To change this Boolean, use the following command: setsebool -P ", "doc_id": "a3fe2f9d-23bc-4b6a-98ad-4e4bc85aafee", "embedding": null, "doc_hash": "6c0c06edfaef9b2ac0cf363f32502429c1858df0600597fb31e7c187a610a7d3", "extra_info": {"page_label": "680"}, "node_info": {"start": 0, "end": 2430}, "relationships": {"1": "e817642e-0a8c-4cb5-9c1d-ea6f53d3e864"}}, "__type__": "1"}, "ac5a12b6-e7e4-4751-bd4a-42adf9cdd960": {"__data__": {"text": "Chapter 24: Enhancing Linux Security with SELinux\n659\n24httpd_can_network_connect on. Notice the -P  option was used to make the setting \npermanent. Now your scripts should be able to connect out to the network.\nPutting It All Together\nObviously, SELinux is a rather complicated and rich tool. You now have a good, solid foun -\ndation on the SELinux basics. Here are some recommendations as you get started imple -\nmenting SELinux on your system.\nThe default targeted  SELinux mode can be used to secure most basic network services \n(httpd , vsftpd , Samba, and so on) without you needing to assign special user roles or \notherwise lock down your system. In this case, the main things you need to do are to put \nfiles in standard locations (or run commands to assign the proper file contexts to nonstan -\ndard locations), make sure that Booleans are turned on for less secure features that you \nwant on anyway, and watch AVC denials for problems.\n\u25a0\u25a0Start with the permissive operational mode. This allows requests to succeed that \nSELinux sees as insecure.\n\u25a0\u25a0Run your current system for a significant amount of time in permissive mode. \nReview the logs and see what problems may occur with the default SELinux set -\ntings. You can then change Booleans or file contexts so that features improperly \ndenied can be allowed. After the problems are worked out, turn on enforcing mode.\n\u25a0\u25a0Overall, implement SELinux configuration changes one at a time in a test envi-\nronment or using permissive mode. See what kind of effect each configuration \nchange has before moving on to the next one. You can then use the audit2al -\nlow command to allow actions that were stopped by AVC denials to be selectively \nallowed in the policy for a service.\nObtaining More Information on SELinux\nSeveral additional sources of information can help you with SELinux on your Linux system:\nYour System\u2019s man Pages Issue the command man -k selinux to find all \nof the various man pages that you can review for the SELinux utilities currently \ninstalled on your system. If you are debugging SELinux problems for a well-known \nservice (such as httpd , vsftpd , Samba, and so on), there is probably a man page \nassociated with how specifically to fix SELinux problems with that service.\nThe Red Hat Enterprise Linux Manuals Located at http://docs.redhat \n.com , this site contains an entire manual on SELinux.\nThe Fedora Project SELinux Guide Located at http://docs.fedorapro -\nject.org , this site has a Security-Enhanced Linux Guide. However, the guide is \nnot updated for every Fedora version, so you may need to look in older versions to \nfind it. Also, the SELinux Guide is not located within the Security manual, but the \nSecurity manual is a good manual to review as well.\nSELinux Project Wiki This is the official SELinux project page. Several resources \nare available at this site, which is located at http://selinuxproject.org .", "doc_id": "ac5a12b6-e7e4-4751-bd4a-42adf9cdd960", "embedding": null, "doc_hash": "c3084c11778ad9a8d388ce58b3683d22a2f31bd8c82484559f3bfadd5bd74b5c", "extra_info": {"page_label": "681"}, "node_info": {"start": 0, "end": 2906}, "relationships": {"1": "d02e7dbb-a300-4530-9e2d-da62fd570631"}}, "__type__": "1"}, "ba86eb15-39e8-46de-a52c-a5f61605c75b": {"__data__": {"text": "Part V: Learning Linux Security Techniques660Summary\nSELinux provides a security enhancement to Linux, and it is installed by default on many \nLinux distributions. In this chapter, you learned the benefits of SELinux, how it works, how \nto set it up, how to fix various problems with SELinux, and how to get more information \nabout this important security enhancement.\nAt first glance, SELinux appears rather complicated. However, after it\u2019s broken down into its \nvarious components\u2014operational modes, security contexts, policy types, and policy pack -\nages\u2014you can see how the various pieces work together. Each component plays an impor -\ntant role for enforcing and testing the chosen security requirements for your organization.\nYou learned about the various steps available to configure SELinux. Even though SELinux \ncomes preconfigured, you may need to make some modifications to meet your organization\u2019s \nsecurity needs. Each component has its own configuration steps and settings to choose. \nThough policy rule creation was not covered, you did learn how to modify the supplied pol -\nicies via Booleans.\nSELinux provides another tool for monitoring your Linux system\u2019s security. Because \nSELinux logs all access denials, it can help you determine if an attack has been or is being \nattempted. Even the best-laid plans can go badly. Therefore, in this chapter, you learned \nhow to fix common SELinux configuration problems.\nIn the next chapter, you\u2019ll learn how to protect your Linux system on a network. You\u2019ll \nlearn about controlling access, managing firewalls, and securing remote access.\nExercises\nUse these exercises to test your knowledge of using SELinux. These tasks assume that you \nare running a Fedora or Red Hat Enterprise Linux system (although some tasks work on \nother Linux systems as well). If you are stuck, solutions to the tasks are shown in Appendix \nB (although in Linux, there are often multiple ways to complete a task).\n1. Making no changes to the SELinux primary configuration file, write down the \ncommand to set your system into the permissive operating mode for SELinux.\n2. Making no changes to the SELinux primary configuration file, write down the \ncommand to set your system into the enforcing mode for SELinux.\n3. What current and permanent SELinux policy types are set on your system and how \ndid you find them?\n4. List the security context for the /etc/hosts  file and identify its different secu -\nrity context attributes.\n5. Create a file called test.html  in your home directory, and assign its type to \nhttpd_sys_content_t . (This is something that you might do to make content \navailable to be shared by your web server outside of the common /var/www/html  \ndirectory.)", "doc_id": "ba86eb15-39e8-46de-a52c-a5f61605c75b", "embedding": null, "doc_hash": "b8a923e05449cbc80fdca55771bc11ccaa4637537c0595f46ef5fec763119e8f", "extra_info": {"page_label": "682"}, "node_info": {"start": 0, "end": 2716}, "relationships": {"1": "1db597a3-1654-4147-92e3-7a4867f13e89"}}, "__type__": "1"}, "fe0f92f3-61fc-4dc1-866c-a4103b4bd1de": {"__data__": {"text": "Chapter 24: Enhancing Linux Security with SELinux\n661\n246. List the security context for the running crond  process and identify its security \ncontext attributes.\n7. Create a file called /etc/test.txt , change its file context to user_tmp_t, \nrestore it to its proper content (the default context for the /etc  directory), and \nremove the file. Use the ls -Z /etc/test.txt command to check the file at each \npoint in the process.\n8. You have a tftp server on your private network, and you want to allow anonymous \nwrites and access to the tftp service\u2019s home directory (while SELinux is in enforc -\ning mode). Determine what Booleans allow anonymous writes and access to the tftp \nservice\u2019s home directory and turn those Booleans on.\n9. What command would list out all of the SELinux policy modules on your system \nalong with their version number?\n10. Tell SELinux to allow access to the sshd service through TCP Port 54903.", "doc_id": "fe0f92f3-61fc-4dc1-866c-a4103b4bd1de", "embedding": null, "doc_hash": "30adb22c3010a7dfebba9880e62972584e05617c65cf3cebe66f0229faa17df6", "extra_info": {"page_label": "683"}, "node_info": {"start": 0, "end": 924}, "relationships": {"1": "3eab9b70-fe02-4933-ab0a-8be2b8d34bfd"}}, "__type__": "1"}, "08e834fe-8e94-47e1-b8d7-0f657fe2e0b6": {"__data__": {"text": "663\nCHAPTER25\nSecuring Linux on a Network\nIN THIS CHAPTER\nManaging network services\nControlling access to network services\nImplementing firewalls\nSetting up your Linux system on a network, especially a public network, creates a whole new \nset of challenges when it comes to security. The best way to secure your Linux system is to \nkeep it off all networks. However, that is rarely a feasible option.\nEntire books have been filled with information on how to secure a computer system on a network. \nMany organizations hire full-time computer security administrators to watch over their network-\nattached Linux systems. Therefore, think of this chapter as a brief introduction to securing Linux on \na network.\nAuditing Network Services\nMost Linux systems used for large enterprises are configured as servers that, as the name implies, \noffer services to remote clients over a network. A network service  is any task that the computer per -\nforms requiring it to send and receive information over the network using some predefined set of \nrules. Routing email is a network service, as is serving web pages.\nA Linux server has the potential to provide thousands of services. Many of them are listed in the /\netc/services  file. Consider the following sections from the /etc/services  file:\n$ cat /etc/services\n# /etc/services:\n# $Id: services,v 1.55 2013/04/14 ovasik Exp $\n#\n# Network services, Internet style\n# IANA services version: last updated 2013-04-10\n#\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "08e834fe-8e94-47e1-b8d7-0f657fe2e0b6", "embedding": null, "doc_hash": "f8cbb53c7c4b97a5adb50060f9f14b274a10a41dbe97f3d746f9897a386b7e55", "extra_info": {"page_label": "684"}, "node_info": {"start": 0, "end": 1580}, "relationships": {"1": "ac611dfb-3cad-4a7c-9390-3774f3f0bc7e"}}, "__type__": "1"}, "2f5fb929-b1c2-46ef-bad1-d8f73f4ea6ae": {"__data__": {"text": "Part V: Learning Linux Security Techniques664# Note that it is presently the policy of IANA to assign ...\n# Each line describes one service, and is of the form:\n#\n# service-name  port/protocol  [aliases ...]   [# comment]\n...\necho            7/tcp\necho            7/udp\ndiscard         9/tcp           sink null\ndiscard         9/udp           sink null\nsystat          11/tcp          users\nsystat          11/udp          users\ndaytime         13/tcp\ndaytime         13/udp\nqotd            17/tcp          quote\nqotd            17/udp          quote\n...\nchargen         19/tcp          ttytst source\nchargen         19/udp          ttytst source\nftp-data        20/tcp\nftp-data        20/udp\n# 21 is registered to ftp, but also used by fsp\nftp             21/tcp\n...\nhttp            80/tcp      www www-http    # WorldWideWeb HTTP\nhttp            80/udp      www www-http    # HyperText Transfer \nProtocol\nhttp            80/sctp                     # HyperText Transfer \nProtocol\nkerberos        88/tcp      kerberos5 krb5  # Kerberos v5\nkerberos        88/udp      kerberos5 krb5  # Kerberos v5\n...\nblp5            48129/udp           # Bloomberg locator\ncom-bardac-dw   48556/tcp           # com-bardac-dw\ncom-bardac-dw   48556/udp           # com-bardac-dw\niqobject        48619/tcp               # iqobject\niqobject        48619/udp               # iqobject\nAfter the comment lines, notice three columns of information. The left column contains \nthe name of each service. The middle column defines the port number and protocol type \nused for that service. The right column contains an optional alias or list of aliases for \nthe service.\nMany Linux distributions come with unneeded network services running. An unnecessary \nservice exposes your Linux system to malicious attacks. For example, if your Linux server \nis a print server, then it should only be offering printing services. It should not also offer \nApache Web Services. This would unnecessarily expose your print server to any malicious \nattacks that take advantage of web service vulnerabilities.", "doc_id": "2f5fb929-b1c2-46ef-bad1-d8f73f4ea6ae", "embedding": null, "doc_hash": "3881457964f6b56059a0d440600b6d97be09d9484bf59148ffea011bb18b5b7c", "extra_info": {"page_label": "685"}, "node_info": {"start": 0, "end": 2065}, "relationships": {"1": "5f5a2809-2f98-473a-8e50-280e0c31cd98"}}, "__type__": "1"}, "7ed51720-b57c-4450-be27-f9e6d02a3159": {"__data__": {"text": "Chapter 25: Securing Linux on a Network\n665\n25Originally, restricting services on Linux systems meant setting up individual physical Linux \nservers with only a few services running on each. Later, running multiple Linux virtual \nmachines on a physical host let you lock down small sets of services on virtual machines. \nMore recently, containerized applications can allow many more separate and secured ser -\nvices to run on each physical host.\nEvaluating access to network services with nmap\nA wonderful tool to help you review your network services from a network standpoint is \nthe nmap  security scanner. The nmap  utility is available in most Linux distribution reposi-\ntories and has a web page full of information at http://nmap.org .\nTo install nmap  on a Fedora or RHEL distribution, use the yum  or dnf  command (using root \nprivileges), as shown in the example that follows.\n# yum install nmap -y\nUpdating Subscription Management repositories.\nLast metadata expiration check: 0:03:41 ago on Sat 12 Oct 2019 \n11:24:07 PM EDT.\nDependencies resolved.\n=====================================================================\n Package      Arch    Version       Repository                   Size\n=====================================================================\nInstalling:\n nmap         x86_64  2:7.70-4.el8  rhel-8-for-x86_64-appstream-rpms  \n5.8 M\n \nTransaction Summary\n=====================================================================\nInstall  1 Package\n \nTotal download size: 5.8 M\nInstalled size: 24 M\n...\nInstalled:\n  nmap-2:7.70-4.el8.x86_64\n \nComplete!\nTo install the nmap  utility on an Ubuntu distribution, type sudo apt-get install \nnmap at the command line.\nThe nmap  utility\u2019s full name is Network Mapper. It has a variety of uses for security audits \nand network exploration. Using nmap  to do various port scans allows you to see what ser -\nvices are running on all of the servers on your local network and whether they are advertis -\ning their availability.", "doc_id": "7ed51720-b57c-4450-be27-f9e6d02a3159", "embedding": null, "doc_hash": "3750fb292727e223f06d6f4b9711b97e3e1c2af6aee8200abc0a3335c53e6627", "extra_info": {"page_label": "686"}, "node_info": {"start": 0, "end": 1985}, "relationships": {"1": "3f0241d2-4bcd-4957-9a72-37304efc89d7"}}, "__type__": "1"}, "779cd096-cb94-4c2e-b77b-55a48dfbb162": {"__data__": {"text": "Part V: Learning Linux Security Techniques666To audit your server\u2019s ports, the nmap  utility offers several useful scan types. The nmap  \nsite has an entire manual on all of the port scanning techniques that you can use at \nhttp://nmap.org/book/man-port-scanning-techniques.html . Here are two basic \nport scans to get you started on your service auditing:\nTCP Connect port scan For this scan, nmap  attempts to connect to ports using the \nTransmission Control Protocol (TCP) on the server. If a port is listening, the connec -\ntion attempt succeeds.\nTCP is a network protocol used in the TCP/IP network protocol suite. TCP is a connec -\ntion-oriented protocol. Its primary purpose is to negotiate and initiate a connection \nusing what is called a \u201cthree-way handshake.\u201d TCP sends a synchronize packet (SYN) \nto a remote server specifying a specific port number in the packet. The remote \nserver receives the SYN and replies with an acknowledgment packet (SYN-ACK)  \nto the originating computer. The original server then acknowledges (ACK) the \nresponse, and a TCP connection is officially established. This three-way handshake \nis often called a SYN-SYN-ACK or SYN, SYN-ACK, ACK.\nIf you select a TCP Connect port scan, the nmap  utility uses this three-way hand -\nshake to do a little investigative activity on a remote server. Any services that use \nthe TCP protocol will respond to the scan.\nUDP port scan For this scan, nmap  sends a UDP packet to every port on the system \nbeing scanned. UDP  is another popular protocol in the TCP/IP network protocol \nsuite. Unlike TCP, however, UDP is a connectionless protocol . If the port is listening \nand has a service that uses the UDP protocol, it responds to the scan.\nTip\nKeep in mind that Free and Open Source Software (FOSS) utilities are also available to those with malicious intent. \nWhile you are doing these nmap  scans, realize that the remote scan results that you see for your Linux server are \nthe same scan results that others will see. This will help you evaluate your system\u2019s security settings in terms of how \nmuch information is being given out to port scans. Keep in mind that you should use tools like nmap  only on your \nown systems, because scanning ports on other people\u2019s computers can give the impression that you are trying to \nbreak in.NoTe\nWhat is a port? Ports, or more correctly network ports , are numeric values used by the TCP and UDP network pro -\ntocols as access points to services on a system. Standard port numbers are assigned to services so that a service \nknows to listen on a particular port number and a client knows to request the service on that port number.\nFor example, port 80 is the standard network port for unencrypted (HTTP) traffic to the Apache web service. So, if \nyou ask for www.example.com  from your web browser, the browser assumes that you mean to use TCP port 80 \non the server that offers that web content. Think of a network port as a door to your Linux server. Each door is num -\nbered. And behind every door is a particular service waiting to help whoever knocks on that door.", "doc_id": "779cd096-cb94-4c2e-b77b-55a48dfbb162", "embedding": null, "doc_hash": "4fa46a31a1ecf888d1efd6d9412fafaa5703f58b9bd6454d1000a130af9ee564", "extra_info": {"page_label": "687"}, "node_info": {"start": 0, "end": 3091}, "relationships": {"1": "849eef0b-c2b7-4c25-8c77-7cbad09ea253"}}, "__type__": "1"}, "94018cd7-33e0-42da-8feb-395b1cb83aae": {"__data__": {"text": "Chapter 25: Securing Linux on a Network\n667\n25When you run the nmap  utility, it provides a handy little report with information on the \nsystem you are scanning and the ports it sees. The ports are given a \u201cstate\u201d status. nmap  \nreports six possible port states:\nopen : This is the most dangerous state an nmap  scan can report for a port. An open  \nport indicates that a server has a service handling requests on this port. Think of \nit as a sign on the door, \u201cCome on in! We are here to help you.\u201d Of course, if you are \noffering a public service, you want the port to be open.\nclosed : A closed  port is accessible, but there is no service waiting on the other side \nof this door. However, the scan status still indicates that there is a Linux server at \nthis particular IP address.\nfiltered : This is the best state to secure a port that you don\u2019t want anyone to \naccess. It cannot be determined if a Linux server is actually at the scanned IP \naddress. It is possible that a service could be listening on a particular port, but the \nfirewall is blocking access to that port, effectively preventing any access to the ser -\nvice through the particular network interface.\nunfiltered : The nmap  scan sees the port but cannot determine if the port is open  \nor closed .\nopen|filtered : The nmap  scan sees the port but cannot determine if the port is \nopen  or filtered .\nclosed|filtered : The nmap  scan sees the port but cannot determine if the port is \nclosed  or filtered .\nTo help you better understand how to use the nmap  utility, review the following example. \nFor the purposes of building a network services list, the example nmap  scans are conducted \non a Fedora system. The first scan is a TCP Connect scan from the command line using the \nloopback address 127.0.0.1.\n# nmap -sT 127.0.0.1\nStarting Nmap 7.70 ( https://nmap.org ) at 2020-1-10 11:47 EDT\nNmap scan report for localhost (127.0.0.1)\n \nHost is up (0.016s latency).\nNot shown: 998 closed ports\n \nPORT    STATE SERVICE\n25/tcp  open  smtp\n631/tcp open  ipp\n \nNmap done: 1 IP address (1 host up) scanned in 1.34 seconds", "doc_id": "94018cd7-33e0-42da-8feb-395b1cb83aae", "embedding": null, "doc_hash": "8a6d72ef5fc15f4e8b0e20561195f3711c6e2b846c93dc45c087832da402826e", "extra_info": {"page_label": "688"}, "node_info": {"start": 0, "end": 2089}, "relationships": {"1": "45cdc8fb-233b-4fca-9bf5-cf6dada9ca99"}}, "__type__": "1"}, "58a56288-3abe-4112-b787-c20bf2e77407": {"__data__": {"text": "Part V: Learning Linux Security Techniques668The TCP Connect nmap  scan reports that two TCP ports are open and have services listening \non the localhost ( 127.0.0.1 ) for requests to these ports:\n\u25a0\u25a0Simple Mail Transfer Protocol (SMTP) is listening at TCP port 25.\n\u25a0\u25a0Internet Printing Protocol (IPP) is listening at TCP port 631.\nThe next nmap  scan is a UDP scan on the Fedora system\u2019s loopback address.\n# nmap -sU 127.0.0.1\n \nStarting Nmap 7.70 ( https://nmap.org ) at 2020-1-10 11:48 EDT\nNmap scan report for localhost (127.0.0.1)\nHost is up (0.00048s latency).\nNot shown: 997 closed ports\n \nPORT     STATE         SERVICE\n68/udp   open|filtered dhcpc\n631/udp  open|filtered ipp\n \nNmap done: 1 IP address (1 host up) scanned in 2.24 seconds\nThe UDP nmap  scan reports that two UDP ports are open and have services listening on \nthose ports:\n\u25a0\u25a0Dynamic Host Control Protocol client ( dhcpc ) is listening at port 68.\n\u25a0\u25a0Internet Printing Protocol ( ipp) is listening at port 631.\nNotice that port 631\u2019s IPP is listed under both nmap \u2019s TCP Connect scan and the UDP scan \nbecause the IPP service can communicate over both the TCP and the UDP protocol and thus \nis listed in both scans.\nUsing these two simple nmap  scans, TCP Connect and UDP on your loopback address, you \ncan build a list of the network services offered by your Linux server. Keep in mind that \nport numbers are associated with a particular protocol (TCP or UDP) and a particular net -\nwork interface. For example, if you have one network interface card (NIC) on a computer \nthat faces the Internet and another that faces a private network, you may want to offer a \nprivate service (like the CUPS service for printing) to the NIC on your private network. But \nyou may want to filter that port (631) on the NIC that faces the Internet.\nUsing nmap to audit your network services advertisements\nYou probably want lots of people to visit your website ( httpd  service). You probably don\u2019t \nwant everyone on the Internet to be capable of accessing your SMB file shares ( smb ser -\nvice). To make sure that you are properly separating access to those two types of services, \nyou want to be able to check what a malicious scanner can see of the services available on \nyour public-facing network interfaces.", "doc_id": "58a56288-3abe-4112-b787-c20bf2e77407", "embedding": null, "doc_hash": "b2b8c6df77d6bec8b84163c87ecbcb2472eb93b35e39645f91d825cba2bedbbb", "extra_info": {"page_label": "689"}, "node_info": {"start": 0, "end": 2266}, "relationships": {"1": "867713ac-988a-4213-886b-116fddadccbf"}}, "__type__": "1"}, "d888f7d4-24bf-4b41-bf12-849a09e0ffb6": {"__data__": {"text": "Chapter 25: Securing Linux on a Network\n669\n25The idea here is to compare what your Linux server looks like from the inside versus what \nit looks like from the outside. If you determine that some network services are accessible \nthat you intended to keep private, you can take steps to block access to them from external \ninterfaces.\nTip\nYou may be tempted to skip the scans from inside your organization\u2019s internal network. Don\u2019t. Malicious activity often \noccurs by a company\u2019s own employees or by someone who has already penetrated external defenses. Again, the \nnmap  utility is a great help here. To get a proper view of how your Linux server\u2019s ports are seen, you need to conduct \nscans from several locations. For example, a simple audit would set up scans in these places:\n\u25a0\u25a0On the Linux server itself\n\u25a0\u25a0From another server on the organization\u2019s same network\n\u25a0\u25a0From outside the organization\u2019s network\nIn the following examples, part of a simple audit is conducted. The nmap  utility is run on a \nFedora system, designated as Host-A. Host-A is the Linux server whose network services are \nto be protected. Host-B is a Linux server using the Linux Mint distribution and is on the \nsame network as Host-A.\nTip\nSecurity settings on various network components, such as the server\u2019s firewall and the company\u2019s routers, should all \nbe considered when conducting audit scans.\nFor this audit example, a scan is run from Host-A, using not the loopback address but the \nactual IP address. First, the IP address for Host-A is determined using the ip addr show \ncommand. The IP address is 10.140.67.23.\n# ip addr show\nfconfig\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN\n     group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host \n       valid_lft forever preferred_lft forever\n2: ens3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel \n     state UP group default qlen 1000\n    link/ether 52:54:00:c4:27:4e brd ff:ff:ff:ff:ff:ff\n    inet 10.140.67.23/24 brd 10.140.67.255 scope global dynamic ", "doc_id": "d888f7d4-24bf-4b41-bf12-849a09e0ffb6", "embedding": null, "doc_hash": "9ef0e56c69ffbbccb8b6e50d871c3422d3881fa62d990c33fc430f781751f925", "extra_info": {"page_label": "690"}, "node_info": {"start": 0, "end": 2160}, "relationships": {"1": "4ce82fef-382a-4ae1-9508-7d359838429b"}}, "__type__": "1"}, "1c32d2d2-a102-4e57-9a3d-e5bc8fca82d1": {"__data__": {"text": "Part V: Learning Linux Security Techniques670       noprefixroute ens3\n       valid_lft 3277sec preferred_lft 3277sec\n    inet6 fe80::5036:9ec3:2ae8:7623/64 scope link noprefixroute \n       valid_lft forever preferred_lft forever\nNow, using the Host-A IP address, an nmap  TCP Connect scan is issued from Host-A. The \nnmap  scan goes out to the network to conduct the scan. All ports are reported as having a \nstatus of closed .\n# nmap -sT 10.140.67.23\nStarting Nmap 7.80 ( https://nmap.org ) at 2020-1-31 11:53 EDT\n \nNmap scan report for rhel8 (10.140.67.23)\n \nHost is up (0.010s latency).\nAll 1000 scanned ports on 10.140.67.23 are closed\n \nNmap done: 1 IP address (1 host up) scanned in 1.48 seconds\n \nThe nmap  scan is moved from originating at Host-A to originating on Host-B. Now the TCP \nConnect scan is attempted on Host-A\u2019s ports from Host-B\u2019s command line.\n$ nmap -sT 10.140.67.23\nStarting Nmap 7.80 ( https://nmap.org ) at 2020-1-31 11:57 EDT\n \nNote: Host seems down. If it is really up,\n but blocking our ping probes, try -PN\n \nNmap done: 1 IP address (0 hosts up) scanned in 0.11 seconds\nHere, nmap  gives a helpful hint. Host-A appears to be down, or it could just be blocking the \nprobes. So, another nmap  scan is attempted from Host-B, using nmap \u2019s advice of disabling \nthe scan\u2019s ping  probes via the -PN  option.\n$ nmap -sT -PN 10.140.67.23\nStarting Nmap 7.80 ( https://nmap.org ) at 2020-1-31 11:58 EDT\nNmap scan report for rhel8 (10.140.67.23)\n \nHost is up (0.0015s latency).\nAll 1000 scanned ports on 10.140.67.23 are filtered\n \nNmap done: 1 IP address (1 host up) scanned in 5.54 seconds\nYou can see that Host-A ( 10.140.67.23 ) is up and running and all of its ports have a status \nof filtered . This means that there is a firewall in place on Host-A. These scans from Host-\nB give you a better idea of what a malicious scanner may see when scanning your Linux \nserver. In this example, the malicious scanner would not see much.", "doc_id": "1c32d2d2-a102-4e57-9a3d-e5bc8fca82d1", "embedding": null, "doc_hash": "fba8d1b0996e278c5f8acd5962079a24513986c261a20244c4954b22a4b88689", "extra_info": {"page_label": "691"}, "node_info": {"start": 0, "end": 1953}, "relationships": {"1": "3ee8390d-b4a1-48c4-9f88-15ebaa4e209e"}}, "__type__": "1"}, "e7c0957c-321f-4cbd-a91b-cb7e692c3874": {"__data__": {"text": "Chapter 25: Securing Linux on a Network\n671\n25The services currently running on Host-A are not that \u201cjuicy.\u201d In the example that follows, \nanother service, sshd , is started on Host-A using the systemctl  command (see Chap -\nter\u00a015, \u201cStarting and Stopping Services\u201d). This should give the nmap  utility a more inter -\nesting target to search for.\n# systemctl start sshd.service\n# systemctl status sshd.service\n\u2022 sshd.service - OpenSSH server daemon\n   Loaded: loaded (/usr/lib/systemd/system/sshd.service; enabled; \nvendor preset: enabled)\n   Active: active (running) since Fri 2020-1-30 15:08:29 EDT; 1 day \n20h ago\n     Docs: man:sshd(8)\n           man:sshd_config(5)\n Main PID: 807 (sshd)\n    Tasks: 1 (limit: 12244)\n   Memory: 10.9M\n   CGroup: /system.slice/sshd.service\n           \u2514\u2500807 /usr/sbin/sshd -D -oCiphers=...\nAlso, because Host-A\u2019s firewall is blocking the nmap  scans from Host-B, it would be inter -\nesting to see what an nmap  scan can report when the firewall is down. The example that \nfollows shows the firewall being disabled on Host-A for a Fedora 21 or RHEL 7 system (for \nother systems, you probably need to disable the iptables service):\n# systemctl stop firewalld.service\n# systemctl status firewalld.service\nWith a new service running and Host-A\u2019s firewall lowered, the nmap  scans should find \nsomething. In the following, nmap  scans are run again from Host-B. This time the nmap  \nutility shows the ssh  service running on open port 22. Notice that with the firewall down \non Host-A, both nmap  scans pick up much more information. This really demonstrates the \nimportance of your Linux server\u2019s firewall.\n# nmap -sT 10.140.67.23\nStarting Nmap 7.80 ( http://nmap.org ) at 2020-1-31 11:58 EDT\nNmap scan report for 10.140.67.23\nHost is up (0.016s latency).\nNot shown: 999 closed ports\n NoTe\nIf you are familiar with nmap, you know that the TCP SYN scan is the default scan nmap  uses. The TCP SYN scan \ndoes an excellent job of probing a remote system in a stealth manner. Because you are probing your own system for \nsecurity auditing purposes, it makes sense to use the more \u201cheavy-duty\u201d nmap  utility scans. If you still want to use \nthe TCP SYN scan, the command is nmap -sS ip _ address .", "doc_id": "e7c0957c-321f-4cbd-a91b-cb7e692c3874", "embedding": null, "doc_hash": "8624306b53f793f129a7a32657aa79208f745333cba9fa33685bf16a635e6f4d", "extra_info": {"page_label": "692"}, "node_info": {"start": 0, "end": 2222}, "relationships": {"1": "da05f072-ba87-42c8-9f5d-30fa9a97e347"}}, "__type__": "1"}, "361606aa-1713-4489-b56d-5285d1c27657": {"__data__": {"text": "Part V: Learning Linux Security Techniques672PORT   STATE SERVICE\n22/tcp open  ssh\n \nNmap done: 1 IP address (1 host up) scanned in 0.40 seconds\n \n# nmap -sU 10.140.67.23\n[sudo] password for johndoe: ***************\nStarting Nmap 5.21 ( http://nmap.org ) at 2020-1-31 11:59 EDT\nNmap scan report for 10.140.67.23\nHost is up (0.00072s latency).\nNot shown: 997 closed ports\n \nPORT     STATE         SERVICE\n68/udp   open|filtered dhcpc\n631/udp  open|filtered ipp\n...\nNmap done: 1 IP address (1 host up) scanned in 1081.83 seconds\nIn order to conduct a thorough audit, be sure to include the UDP scan. Also, there are addi-\ntional nmap  scans that may be beneficial to your organization. Look at the nmap  utility\u2019s \nwebsite for additional suggestions.\nCauTioN\nIf you have been following along and lowered your server\u2019s firewall to conduct these nmap  scans, be sure to raise it \nagain. Enter systemctl start firewalld.service .\nYou still need to implement controls for those services that your Linux server should offer. \nOne way to accomplish this is via firewall rules.\nEarly versions of Linux use TCP wrappers to allow or deny access to Linux services. It did \nthis by offering /etc/hosts.allow  and /etc/hosts.deny  files where you could spe -\ncifically indicate which services are available and which are blocked to particular outside \nsystem names and/or IP addresses. As of Fedora 28 and RHEL 8, the TCP wrappers feature \nwas dropped from those distributions. However, some features, such as vsftpd, still honor \nthose configuration files through other means.\nWorking with Firewalls\nA firewall in a building is a fireproof wall that prevents the spread of fire throughout the \nbuilding. A computer firewall  blocks the transmission of malicious or unwanted data into \nand out of a computer system or network. For example, a firewall can block malicious scans \nfrom your Linux server ports. A firewall can also change network packets flowing through \nyour system and redirect packets in various ways.", "doc_id": "361606aa-1713-4489-b56d-5285d1c27657", "embedding": null, "doc_hash": "231e944ed1c13fc7e525c58729444a691ca8e36e6d0a0bcac431065df102d100", "extra_info": {"page_label": "693"}, "node_info": {"start": 0, "end": 2003}, "relationships": {"1": "a8b8c19b-382a-4762-a808-cacb9d8e0e46"}}, "__type__": "1"}, "a63104b6-0e48-4923-a63f-1addaf3ca9cf": {"__data__": {"text": "Chapter 25: Securing Linux on a Network\n673\n25In Linux, iptables  is the kernel-level firewall feature. It is most commonly used to allow or \nblock access from outside systems to the services running on your local system. iptables \nworks by allowing you to create rules that can be applied to every packet that tries to enter \n(INPUT ), leave (OUTPUT ), or cross through your system ( FORWARD ).\nAlthough allowing or blocking packets trying to enter your system is the primary feature of \niptables, you can also create rules for iptables that let you do the following:\n\u25a0\u25a0Block packets leaving your system effectively to prevent a process on your system \nfrom reaching a remote host, range of addresses, or selected services.\n\u25a0\u25a0Forward packets from one network interface on your system to another, effectively \nallowing your computer to act as a router between two networks.\n\u25a0\u25a0Port forward a packet intended for a selected port to be rerouted to another port \non your local system, or to a remote system, so that other locations can handle the \nrequest from the packet.\n\u25a0\u25a0Change information in a packet header (called mangling ) to redirect the packet or \nsomehow mark it for more processing.\n\u25a0\u25a0Allow multiple computers on a private network (such as the computers, televisions, \nor other devices on your home network) to communicate with the Internet over a \nsingle public IP address. (This is referred to as IP masquerading .)\nIn the following sections, I describe many of these features but focus mostly on the rules to \nblock or allow access to the services running on your Linux system.\nUnderstanding firewalls\nAlthough you may tend to think of a firewall as a complete barrier, a Linux firewall is really \njust a filter that checks each network packet or application request coming into or out of a \ncomputer system or network.\nNoTe\nWhat is a network packet? A network packet  is data that has been broken up into transmittable chunks. The \nchunks, or packets, have additional data added to them as they traverse down the OSI model. It\u2019s like putting a letter \ninside an envelope at each stage as it moves down the protocol stack. One of the purposes of this additional data is \nto ensure the packet\u2019s safe and intact arrival at its destination. The additional data is stripped off of the packet as \nit traverses back up the OSI model at its destination (like taking off the outer envelope and handing the letter to the \nlayer above).\nFirewalls can be placed into different categories, depending upon their function. Each cat -\negory has an important place in securing your server and network.\nA firewall is either network-based or host-based. A network-based firewall is one \nthat is protecting the entire network or subnet. For example, a network firewall \nwould be used in your workplace, where the network should be protected by a \nscreening router\u2019s firewall.", "doc_id": "a63104b6-0e48-4923-a63f-1addaf3ca9cf", "embedding": null, "doc_hash": "ace76adca162410dc99fd42653d584614f821676de213589f93e672517d077bf", "extra_info": {"page_label": "694"}, "node_info": {"start": 0, "end": 2868}, "relationships": {"1": "1c097be0-c362-4948-a985-ce4722b74ac1"}}, "__type__": "1"}, "0ed7352f-f67c-4486-ae62-a431450d5bdf": {"__data__": {"text": "Part V: Learning Linux Security Techniques674A host-based firewall is one that is running on and protecting an individual host or \nserver. You most likely have a firewall on your PC at home. This is a host-based fire -\nwall.\nA firewall is either a hardware or a software firewall. Firewalls can be located on \nnetwork devices, such as routers. Their filters are configured in the router\u2019s firm-\nware. In your home, your Internet service provider (ISP) may provide a router to let \nyou gain access to the Internet. The router contains firewall firmware, and it is con -\nsidered a hardware firewall.\nFirewalls can be located on a computer system as an application. The application \nallows filtering rules to be set that filter the incoming traffic. This is an example of \na software firewall. A software firewall is also called a rule-based firewall.\nA firewall is either a network-layer filter or an application-layer filter. A firewall \nthat examines individual network packets is also called a packet filter . A network-\nlayer firewall  allows only certain packets into and out of the system. It operates on \nthe lower layers of the OSI reference model.\nAn application-layer firewall  filters at the higher layers of the OSI reference model. \nThis firewall allows only certain applications access to and from the system.\nYou can see how these firewall categories overlap. The best firewall setup is a combination \nof all of the categories. As with many security practices, the more layers you have, the \nharder it is for malicious activity to penetrate.\nImplementing firewalls\nOn a Linux system, the firewall is a host-based, network-layer, software firewall managed \nby the iptables  utility and related kernel-level components. With iptables , you can \ncreate a series of rules for every network packet coming through your Linux server. You can \nfine-tune the rules to allow network traffic from one location but not from another. These \nrules essentially make up a network access control list for your Linux server.\nFedora, RHEL, and other Linux distributions have added the firewalld  service to pro -\nvide a more dynamic way of managing firewall rules than were offered previously. For \nrecent RHEL and Fedora releases, the iptables firewall backend was replaced with nftables. \nThe Firewall Configuration window ( firewall-config  command) provides an easy way \nto open ports on your firewall and do masquerading (routing private addresses to a public \nnetwork) or port forwarding. The firewalld  service can react to changes in conditions, \nwhich the static iptables service can\u2019t do as well on its own. By enabling access to a service, \nfirewalld  can also do things like load modules needed to allow access to a service.\nTip\nThe iptables  utility manages the Linux firewall, called netfilter . Thus, you will often see the Linux firewall \nreferred to as netfilter/iptables . The iptables syntax is still supported, but in the latest RHEL and Fedora \nreleases, nftables actually provides the backend for iptables.", "doc_id": "0ed7352f-f67c-4486-ae62-a431450d5bdf", "embedding": null, "doc_hash": "2eae3eb953de82aa3f0e88b6cc032def4a77641211f45661837ceca4815cf01f", "extra_info": {"page_label": "695"}, "node_info": {"start": 0, "end": 3022}, "relationships": {"1": "4bc6c501-037a-4978-9f40-01330752c35f"}}, "__type__": "1"}, "94d60388-c035-4160-83f5-6954ce104677": {"__data__": {"text": "Chapter 25: Securing Linux on a Network\n675\n25Starting with firewalld\nThe firewalld  service may already be installed on your Linux system. To check this, type \nthe following:\n# systemctl status firewalld\n\u2022 firewalld.service - firewalld - dynamic firewall daemon\n   Loaded: loaded (/usr/lib/systemd/system/firewalld.service; ena>\n   Active: active (running) since Sat 2019-10-19 11:43:13 EDT; 5m>\n     Docs: man:firewalld(1)\n Main PID: 776 (firewalld)\n    Tasks: 2 (limit: 2294)\n   Memory: 39.6M\n   CGroup: /system.slice/firewalld.service\n           \u2514\u2500776 /usr/bin/python3 /usr/sbin/firewalld --nofork -->\nIf it\u2019s not, you can still install the service and the associated graphical user interface and \nthen start the firewalld  service as follows:\n# yum install firewalld firewall-config\n# systemctl start firewalld.service\n# systemctl enable firewalld.service\nTo manage the firewalld  service, you can start the Firewall Configuration window. Do \nthis by entering the following:\n# firewall-config &\nFigure\u00a025.1 shows an example of the Firewall Configuration window.\nWith firewalld , you can select from a set of firewall zones, depending on which services \nyou want to share and the level of protection you want for your system. The default set of \nFedora Workstation rules selected in this example is appropriate for a Linux workstation \noperating on a home network. For example, it allows the following:\nDHCPv6 Client : To enable automatic assignment of addresses on IPv6 networks.\nMulticast DNS (mDNS) : To allow domain name system interfaces on small network \ninterfaces, without requiring a regular DNS server.\nNetwork printing client and server (IPP) : To allow printer sharing on your local \nsystem and network.\nSamba client : To allow file sharing with Windows systems and other systems on your \nlocal network.\nSSH: To allow others to try to log into your system from the network.\nCockpit : To allow access to Cockpit web-based administration from the network. \nCockpit is installed by default in RHEL 8, but it is not installed by default on Fedora \n30 Workstation. So, Cockpit won\u2019t appear in the Firewall Configuration window until \nyou install the cockpit package.", "doc_id": "94d60388-c035-4160-83f5-6954ce104677", "embedding": null, "doc_hash": "40bfffc5a51dbe2b55732f346068e68bde0d1e46dd85abb48b833d1b7f62c975", "extra_info": {"page_label": "696"}, "node_info": {"start": 0, "end": 2177}, "relationships": {"1": "41bd9b9a-e3e1-4a1b-a0ac-7de912c26555"}}, "__type__": "1"}, "417849c6-6071-459d-b333-1e0dabb002c2": {"__data__": {"text": "Part V: Learning Linux Security Techniques676If you connect your computer to networks on which you have different levels of trust (such \nas a wireless network at an airport), you can adjust your firewall rules by selecting a dif -\nferent zone. For example, to change to the public zone from the Firewall Configuration \nwindow, do the following:\n1. Under the Active Bindings column, select your active connection (in this example, \nWired connection 1 ).\n2. Select a new zone (for example, public ).\n3. Select Change Zone.\nThe public  zone, while still allowing IPv6 connections, remote login (SSH), and mDNS ser -\nvice, does not allow access to more potentially vulnerable printing, Windows file sharing \n(Samba), and Cockpit services.\nBesides changing zones, another common task that you might want to do is just open some \nfirewall ports to allow access to selected services. From the Firewall Configuration window, \nwith the Fedora Workstation zone set as the current zone, just click each service that you \nwant to open. The port allowing access to each service is opened immediately (when you \nselect the Runtime configuration) and opened permanently (when you select the Permanent \nconfiguration).\nFIGURE 25.1\nFirewall Configuration window", "doc_id": "417849c6-6071-459d-b333-1e0dabb002c2", "embedding": null, "doc_hash": "be91f47826f4824e22ee323491f3e4b5134a6d63599c666ce434ae1013a07de2", "extra_info": {"page_label": "697"}, "node_info": {"start": 0, "end": 1244}, "relationships": {"1": "da0c6e3c-c875-4770-9b0c-ac33eb48a994"}}, "__type__": "1"}, "315db3c9-3770-4b9c-b9a5-e0960820f2e2": {"__data__": {"text": "Chapter 25: Securing Linux on a Network\n677\n25One nice feature of the Firewall Configuration window is that when you choose to allow \naccess to a service, you might do more than just open a port. For example, enabling the FTP \nservice also causes connection tracking modules to be loaded that allow nonstandard ports \nto be accessed through the firewall when needed.\nChanging firewall rules with Cockpit\nCockpit offers another intuitive way of working with your system\u2019s firewall. To view and \nmodify your firewall with Cockpit, do the following:\n1. Open your web browser to the Cockpit interface ( https://yourhost:9090 ) and \nlog in with root privilege.\n2. Select Networking \u27aa Firewall to see the Firewall screen, as shown in Figure\u00a025.2:\n3. Select Add Services. The Add Service pop-up appears.\n4. Click the check box next to the service that you want to enable in the current zone \nand select Add Services.\nAccess to the selected port is enabled. Assuming that you have a service running on that \nport, someone requesting the service (such as access to your web server on ports 80 and \n443) will be allowed.\nFIGURE 25.2\nFirewall Configuration", "doc_id": "315db3c9-3770-4b9c-b9a5-e0960820f2e2", "embedding": null, "doc_hash": "eb72d5bf68423098bed100c9d4c905c7386e30600a076bdc6f8f473e6d32b983", "extra_info": {"page_label": "698"}, "node_info": {"start": 0, "end": 1145}, "relationships": {"1": "006c351f-4d17-4a7a-ba15-53d74145587e"}}, "__type__": "1"}, "0bd98659-5e9d-4acf-8449-76d03659f49f": {"__data__": {"text": "Part V: Learning Linux Security Techniques678As mentioned earlier, underlying the Cockpit and firewalld  services is the iptables facil -\nity. If you have a Linux system without the Cockpit or firewalld  services (or with fire -\nwalld  disabled), you can still use the iptables service. The next sections describe how you \ncan set iptables firewall rules manually and use the iptables service directly, without the \nfirewalld  service.\nUnderstanding the iptables utility\nBefore you start changing the firewall rules via the iptables  utility, you need to under -\nstand netfilter/iptables  basics, which include the following:\n\u25a0\u25a0Tables\n\u25a0\u25a0Chains\n\u25a0\u25a0Policies\n\u25a0\u25a0Rules\nUnderstanding these basics will help you set up and manage your Linux server fire -\nwall properly.\nnetfilter/iptables tables\nThe iptables  firewall has the ability to do more than just low-level packet filtering. It \ndefines what type of firewall functionality is taking place. There are four tables in the \niptables  utility, with an additional table added by SELinux. The tables offer the follow -\ning functionalities:\nfilter : The filter  table is the packet filtering feature of the firewall. In this table, \naccess control decisions are made for packets traveling to, from, and through your \nLinux system.\nnat: The nat  table is used for Network Address Translation (NAT). NAT table rules let \nyou redirect where a packet goes.\nmangle : As you would suspect, packets are mangled (modified) according to the rules \nin the mangle  table. Using the mangle  table directly is less common and typically \ndone to change how a packet is managed.\nraw: The raw  table is used to exempt certain network packets from something called \n\u201cconnection tracking.\u201d This feature is important when you are using Network \nAddress Translation and virtualization on your Linux server.\nsecurity : This table is available only on Linux distributions that have SELinux. \n(See Chapter\u00a024, \u201cEnhancing Linux Security with SELinux.\u201d) Although typically not \nused directly, the security table allows SELinux to allow or block a packet based \non SELinux policies, adding another layer of filtering on top of standard packet \nfilter rules.\nOf all the tables listed, three focus on Network Address Translation. Therefore, the filter  \ntable is the primary table that this chapter focuses on for basic firewall packet filtering.", "doc_id": "0bd98659-5e9d-4acf-8449-76d03659f49f", "embedding": null, "doc_hash": "0c98461172171043235e54f68009342dc24eada6bb365c7b6fa042b65edf28ae", "extra_info": {"page_label": "699"}, "node_info": {"start": 0, "end": 2361}, "relationships": {"1": "ce302011-ea0e-4aac-9044-67703edac036"}}, "__type__": "1"}, "85671103-136c-4829-a6ed-047bf9c5cef7": {"__data__": {"text": "Chapter 25: Securing Linux on a Network\n679\n25netfilter/iptables chains\nThe netfilter/iptables  firewall categorizes network packets into categories, called \nchains . There are five chains (categories) to which a network packet can be designated:\nINPUT : Network packets coming into  the Linux server\nFORWARD : Network packets coming into the Linux server that are to be routed  out \nthrough another network interface on the server\nOUTPUT : Network packets coming out  of the Linux server\nPREROUTING : Used by NAT for modifying network packets when they come into the \nLinux server\nPOSTROUTING : Used by NAT for modifying network packets before they come out of \nthe Linux server\nWhich netfilter/iptables  table you choose to work with determines what chains are \navailable for categorizing network packets. Table\u00a025.1 shows what chains are available for \neach table.\nAfter a network packet is categorized into a specific chain, iptables  can determine what \npolicies or rules apply to that particular packet.\nnetfilter/iptables rules, policies, and targets\nFor each network packet, a rule can be set up defining what to do with that individual \npacket. Network packets can be identified many ways by the netfilter/iptables  fire-\nwall. These are a few of the ways:\n\u25a0\u25a0Source IP address\n\u25a0\u25a0Destination IP address\n\u25a0\u25a0Network protocol\n\u25a0\u25a0Inbound port\n\u25a0\u25a0Outbound port\n\u25a0\u25a0Network stateTABLE 25.1  Chains Available for Each netfilter/iptables Table\nTable Chains Available\nfilter INPUT , FORWARD , OUTPUT\nnat PREROUTING , OUTPUT , POSTROUTING\nmangle INPUT , FORWARD , PREROUTING , OUTPUT , POSTROUTING\nraw PREROUTING , OUTPUT\nsecurity INPUT , FORWARD , OUTPUT", "doc_id": "85671103-136c-4829-a6ed-047bf9c5cef7", "embedding": null, "doc_hash": "86647a9090c8b2007e9d8cdd0cfc199b79318c236ebcd610a3f4291869539c47", "extra_info": {"page_label": "700"}, "node_info": {"start": 0, "end": 1648}, "relationships": {"1": "14034c9c-3c49-484d-a612-9fd3d4b19a84"}}, "__type__": "1"}, "3e96e818-54b5-45f1-abbf-dbe284c9d3c4": {"__data__": {"text": "Part V: Learning Linux Security Techniques680If no rule exists for a particular packet, then the overall policy is used. Each packet cate -\ngory or chain has a default policy. After a network packet matches a particular rule or falls \nto the default policy, then action on the packet can occur. The action taken depends upon \nwhat iptables  target is set. Here are a couple of actions (targets) that can be taken:\nACCEPT : Network packet is accepted into the server.\nREJECT : Network packet is dropped and not allowed into the server. A rejection mes -\nsage is sent.\nDROP : Network packet is dropped and not allowed into the server. No rejection mes -\nsage is sent.\nWhile REJECT  gives a rejection message, DROP  is quiet. You may consider using REJECT  \nfor internal employees who should be told that you are rejecting their outbound network \ntraffic and why. Consider using DROP  for inbound traffic so that any malicious personnel \nare unaware that their traffic is being blocked.\nTip\nThere are a couple of additional, more sophisticated targets for iptables , such as QUEUE . You can find out more \nabout these targets via the iptables  man page.\nThe iptables  utility implements a software firewall using the filter  table via policies \nand rules. Now that you have a general understanding of the software firewall implementa -\ntion, you can begin to dig deeper into the specific commands for implementing the firewall \nvia the iptables  utility.\nUsing the iptables utility\nYour Linux server should come with the firewall up and running. However, it\u2019s a good idea \nto check and see if it really is enabled.\nRHEL 7, RHEL 8, and recent Fedora systems netfilter/iptables firewall The firewall \ninterface service running on these distributions is firewalld . The iptables  ser-\nvice is not run directly by default on these systems. To see if this firewall service is \nrunning, type systemctl status firewalld.service  at the command line.\n\u25a0\u25a0To enable the firewall, enter systemctl start firewalld.service  and \nsystemctl enable firewalld.service  at the command line.\n\u25a0\u25a0To disable the firewall, enter systemctl stop firewalld.service  at the \ncommand line.\nUbuntu netfilter/iptables firewall The firewall interface service running on this dis -\ntribution is ufw . To see if the firewall service is running, enter sudo ufw status \nat the command line. The ufw  service is an interface to the iptables  utility that \ndoes not run as a service on Ubuntu. You can use ufw  commands to manipulate ", "doc_id": "3e96e818-54b5-45f1-abbf-dbe284c9d3c4", "embedding": null, "doc_hash": "5ef718af4bc881d27a8891a0d98abb2915f8054ea19df83521111c554ffc9973", "extra_info": {"page_label": "701"}, "node_info": {"start": 0, "end": 2493}, "relationships": {"1": "94d775a2-73be-46c1-b15d-c53d7f14e686"}}, "__type__": "1"}, "5b57012d-16ae-4703-8d1f-33797dcc6c24": {"__data__": {"text": "Chapter 25: Securing Linux on a Network\n681\n25firewall rules. However, all of the iptables  utility commands are still valid \nfor Ubuntu:\n\u25a0\u25a0To enable the firewall, enter sudo ufw enable at the command line.\n\u25a0\u25a0To disable the firewall, enter sudo ufw disable at the command line.\nAfter you have checked the status and enabled or disabled the netfilter/iptables  fire-\nwall, the differences between the distributions end.\nTo see what policies and rules are currently in place for the filter  (default) table, enter \niptables -vnL  at the command line:\n# iptables -vnL\nChain INPUT (policy ACCEPT 0 packets, 0 bytes)...\nNote that on systems with firewalld  enabled, there are many more iptables chains and \nrules listed by default than you might be used to on a system using iptables directly. This \nis done to offer more flexibility in building your firewalls by allowing your rules to be split \ninto zones for different levels of security.\nOnly the first line of the iptables output is shown in the preceding example. That line \nshows that the INPUT  chain\u2019s default policy is applied to all the network packets that don\u2019t \nmatch another rule. Currently, all of the default INPUT , FORWARD , and OUTPUT  policies \nare set to ACCEPT . All network packets are allowed in, through, and out. A firewall in this \nstate is essentially disabled until specific REJECT  or DROP  rules are added.\nTip\nIf your Linux server is dealing with IP v6 network packets, you can use the ip6tables  utility to manage your fire -\nwall for IPv6 addresses. The ip6tables  utility is nearly identical to the iptables  utility. For more information, \nenter man ip6tables  at the command line.\nModifying iptables policies and rules\nBefore you begin to modify a netfilter/iptables  firewall directly by using the  \niptables  command, you should go on a system that you can use for testing and turn  \noff the firewalld  service.\nTo get started, it is helpful to understand a few command options.\nA few options for modifying the firewall follow:\n-t table\nThe iptables  command listed along with this switch is applied to the table . By \ndefault, the filter  table is used. Example:\n# iptables -t filter -P OUTPUT DROP", "doc_id": "5b57012d-16ae-4703-8d1f-33797dcc6c24", "embedding": null, "doc_hash": "b5a630c0718129d0c678cdc49477e8847efc2329058f3b86997acaee4e96d4fa", "extra_info": {"page_label": "702"}, "node_info": {"start": 0, "end": 2184}, "relationships": {"1": "ca8d2549-51b5-48ef-aa2c-584cb3f2e7af"}}, "__type__": "1"}, "72db3bb3-a494-402e-884c-9d3149ce5141": {"__data__": {"text": "Part V: Learning Linux Security Techniques682-P chain target\nSets the overall policy for a particular chain . The rules in the chain  are checked \nfor matches. If no match occurs, then the chain \u2019s listed target  is used. Example:\n# iptables -P INPUT ACCEPT\n-A chain\nSets a rule called an \u201cappended rule,\u201d which is an exception to the overall policy for \nthe chain  designated. Example:\n# iptables -A OUTPUT -d 10.140.67.25 -j REJECT\n-I rule# chain\nInserts an appended rule into a specific location, designated by the rule# , in the \nappended rule list for the chain  designated. Example:\n# iptables -I 5 INPUT -s 10.140.67.23 -j DROP\n-D chain rule#\nDeletes a particular rule, designated by the rule# , from the chain  designated. \nExample:\n# iptables -D INPUT 5\n-j target\nIf the criteria in the rule are met, the firewall should jump to this designated  \ntarget  for processing. Example:\n# iptables -A INPUT -s 10.140.67.25 -j DROP\n-d IP address\nAssigns the rule listed to apply to the designated destination IP address .  \nExample:\n# iptables -A OUTPUT -d 10.140.67.25 -j REJECT\n-s IP address\nAssigns the rule listed to apply to the designated source IP address . Example:\n# iptables -A INPUT -s 10.140.67.24 -j ACCEPT\n-p protocol\nAssigns the rule listed to apply to the protocol  designated. For example, here \nincoming ping ( icmp ) requests are dropped:\n# iptables -A INPUT -p icmp -j DROP\n--dport  port#\nAssigns the rule listed to apply to certain protocol packets coming into the \ndesignated port# . Example:\n# iptables -A INPUT -p tcp --dport 22 -j DROP", "doc_id": "72db3bb3-a494-402e-884c-9d3149ce5141", "embedding": null, "doc_hash": "a86a320ab3e088ad7f52e6e4e9d1d096bf761fede821ca46d1b49517c701715e", "extra_info": {"page_label": "703"}, "node_info": {"start": 0, "end": 1561}, "relationships": {"1": "e740c590-c233-44ec-a3b2-15e56d0a7974"}}, "__type__": "1"}, "e0f8dd35-9d54-44c0-9b49-96d51aec6707": {"__data__": {"text": "Chapter 25: Securing Linux on a Network\n683\n25--sport port#\nAssigns the rule listed to apply to certain protocol packets going out of the \ndesignated port# . Example:\n# iptables -A OUTPUT -p tcp --sport 22 -j ACCEPT\n-m state --state  network _ state\nAssigns the rule listed to apply to the designated network state (s). Example:\n# iptables -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT\nTo see how the iptables  options work, consider the following example. You have a Linux \nserver (Host-A) at IP address 10.140.67.23. There are two other Linux servers on your \nnetwork. One is Host-B at IP address 10.140.67.22 and the other is Host-C at IP address \n10.140.67.25. Your goal is to accomplish the following:\n\u25a0\u25a0Allow Host-C full access to Host-A.\n\u25a0\u25a0Block remote login connections using ssh  from Host-B to Host-A.\nSetting a policy of Drop\nThe following code shows the default policies of Host-A\u2019s firewall. In this example, the fire -\nwall is wide open with no restrictions implemented. No rules are set, and the policies are all \nset to ACCEPT .\n# iptables -vnL\n \nChain INPUT (policy ACCEPT)\ntarget     prot opt source               destination\n \nChain FORWARD (policy ACCEPT)\ntarget     prot opt source               destination\n \nChain OUTPUT (policy ACCEPT)\ntarget     prot opt source               destination\nFirst, what would happen if the INPUT  policy was changed from ACCEPT  to DROP ? Would \nthat reach the goal? Look at what happens when this is tried. Remember that if no rules are \nlisted for an incoming packet, then the chain \u2019s policy  is followed. This change is made \nto Host-A\u2019s firewall in the example that follows.\n# iptables -P INPUT DROP\n# iptables -vnL\n \nChain INPUT (policy DROP)\ntarget     prot opt source               destination\n \nChain FORWARD (policy ACCEPT)\ntarget     prot opt source               destination\n ", "doc_id": "e0f8dd35-9d54-44c0-9b49-96d51aec6707", "embedding": null, "doc_hash": "cea9c13616a2bdbc2795e03129e0eca98b4b99789b97bfa4c7c403ae5421f82c", "extra_info": {"page_label": "704"}, "node_info": {"start": 0, "end": 1853}, "relationships": {"1": "2f96ea1d-df89-4345-9626-0b69f3d894d0"}}, "__type__": "1"}, "113aeaf7-a055-4606-997e-1f445cb3eae1": {"__data__": {"text": "Part V: Learning Linux Security Techniques684Chain OUTPUT (policy ACCEPT)\ntarget     prot opt source               destination\n \nTip\nFor policies, you cannot set the target to REJECT . It fails, and you receive the message \u201ciptables: Bad policy name.\u201d \nUse DROP  as your policy instead.\nHost-B attempts to ping  Host-A and then attempts an ssh  connection, as shown in the \nexample that follows. As you can see, both attempts fail. Because ping  commands are \nblocked, this does not meet the objective to block only remote login connections using ssh  \nfrom Host-B.\n$ ping -c 2 10.140.67.23\nPING 10.140.67.23 (10.140.67.23) 56(84) bytes of data.\n \n--- 10.140.67.23 ping statistics ---\n2 packets transmitted, 0 received, 100% packet loss, time 1007ms\n$ ssh root@10.140.67.23\n \nssh: connect to host 10.140.67.23 port 22: Connection timed out\nWhen Host-C attempts to ping  Host-A and make an ssh  connection, both attempts fail. \nThus, it is confirmed that the firewall setting, INPUT  policy equals DROP , is not what is \nneeded to reach the goal.\n$ ping -c 2 10.140.67.23\nPING 10.140.67.23 (10.140.67.23) 56(84) bytes of data.\n \n--- 10.140.67.23 ping statistics ---\n2 packets transmitted, 0 received, 100% packet loss, time 1008ms\n$ ssh root@10.140.67.23\n \nssh: connect to host 10.140.67.23 port 22: Connection timed out\nBlocking a source IP address\nWhat if instead only Host-B\u2019s IP address were blocked? That would allow Host-C to reach \nHost-A. Would this setting reach the desired goal?\nIn the example that follows, the policy of DROP  must first be changed to ALLOW  in Host-\nA\u2019s iptables . After that, a specific rule must be appended to block network packets from \nHost-B\u2019s IP address, 10.140.67.22, alone.\n# iptables -P INPUT ACCEPT\n# iptables -A INPUT -s 10.140.67.22 -j DROP\n# iptables -vnL\n ", "doc_id": "113aeaf7-a055-4606-997e-1f445cb3eae1", "embedding": null, "doc_hash": "0d5b6fd631c6ae0a0ca6b23a3e195a8f5f655e83dd5a7ee4b4146549fb91faab", "extra_info": {"page_label": "705"}, "node_info": {"start": 0, "end": 1800}, "relationships": {"1": "3465da41-ac3e-4605-90ad-08609dfecc54"}}, "__type__": "1"}, "74ffd9a6-73b5-4627-a211-b5b309351d1c": {"__data__": {"text": "Chapter 25: Securing Linux on a Network\n685\n25Chain INPUT (policy ACCEPT)\ntarget     prot opt source               destination\nDROP       all  --  10.140.67.22             anywhere\n \nChain FORWARD (policy ACCEPT)\ntarget     prot opt source               destination\n \nChain OUTPUT (policy ACCEPT)\ntarget     prot opt source               destination\n \nHost-C can now successfully ping  and ssh  into Host-A, meeting one of the set goals.\n$ ping -c 2 10.140.67.23\nPING 10.140.67.23 (10.140.67.23) 56(84) bytes of data.\n64 bytes from 10.140.67.23: icmp_req=1 ttl=64 time=11.7 ms\n64 bytes from 10.140.67.23: icmp_req=2 ttl=64 time=0.000 ms\n \n--- 10.140.67.23 ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 1008ms\nrtt min/avg/max/mdev = 0.000/5.824/11.648/5.824 ms\n$ ssh root@10.140.67.23\nroot@10.140.67.23's password:\n \nHowever, Host-B can neither ping  nor ssh  into Host-A. Thus, the appended rule is not \nquite what is needed to reach the entire goal.\n$ ping -c 2 10.140.67.23\n \nPING 10.140.67.23 (10.140.67.23) 56(84) bytes of data.\n \n--- 10.140.67.23 ping statistics ---\n2 packets transmitted, 0 received, 100% packet loss, time 1007ms\n \n$ ssh root@10.140.67.23\n \nssh: connect to host 10.140.67.23 port 22: Connection timed out\nBlocking a protocol and port\nWhat if, instead of blocking Host-B\u2019s IP address entirely, only connections to the ssh  port \n(port 22) from Host-B\u2019s IP address were blocked? Would that reach the goal of allowing Host-\nC full access to Host-A and only blocking ssh  connections from Host-B?\nIn the example that follows, the iptables  rules for Host-A are modified to try blocking \nHost-B\u2019s IP address from port 22. Note that the --dport  option must accompany a par -\nticular protocol, such as, for example, -p tcp . Before the new rule is added, the rule from \nthe previous example must be deleted using the -D  option. Otherwise, the rule from the \nprevious example would be used by the netfilter/iptables  firewall for packets from \n10.140.67.22 (Host-B).", "doc_id": "74ffd9a6-73b5-4627-a211-b5b309351d1c", "embedding": null, "doc_hash": "4cace9990aec366a188335913a91a5cb6d793227d43e702912d55c55125cf68d", "extra_info": {"page_label": "706"}, "node_info": {"start": 0, "end": 2014}, "relationships": {"1": "d2ca7a75-2731-40e7-95ed-37761509be0c"}}, "__type__": "1"}, "b2af3b2d-d93e-4473-be74-d54fa1bcd703": {"__data__": {"text": "Part V: Learning Linux Security Techniques686# iptables -D INPUT 1\n# iptables -A INPUT -s 10.140.67.22 -p tcp --dport 22 -j DROP\n# iptables -vnL\n \nChain INPUT (policy ACCEPT)\ntarget     prot opt source      destination\nDROP       tcp  --  10.140.67.22    anywhere     tcp dpt:ssh\n \nChain FORWARD (policy ACCEPT)\ntarget     prot opt source      destination\n \nChain OUTPUT (policy ACCEPT)\ntarget     prot opt source      destination\nFirst, the new iptables  rule is tested from Host-C to ensure that both ping  attempts and \nssh connections remain unaffected. It works successfully.\n$ ping -c 2 10.140.67.23\nPING 10.140.67.23 (10.140.67.23) 56(84) bytes of data.\n64 bytes from 10.140.67.23: icmp_req=1 ttl=64 time=1.04 ms\n64 bytes from 10.140.67.23: icmp_req=2 ttl=64 time=0.740 ms\n \n--- 10.140.67.23 ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 1000ms\nrtt min/avg/max/mdev = 0.740/0.892/1.045/0.155 ms\n \n$ ssh root@10.140.67.23\nroot@10.140.67.23's password:\n \nNext, the new iptables  rule is tested from Host-B to ensure that ping  works and ssh  \nconnections are blocked. It also works successfully!\n$ ping -c 2 10.140.67.23\n \nPING 10.140.67.23 (10.140.67.23) 56(84) bytes of data.\n64 bytes from 10.140.67.23: icmp_req=1 ttl=64 time=1.10 ms\n64 bytes from 10.140.67.23: icmp_req=2 ttl=64 time=0.781 ms\n \n--- 10.140.67.23 ping statistics ---\n \n2 packets transmitted, 2 received, 0% packet loss, time 1001ms\nrtt min/avg/max/mdev\u00a0=\u00a00.781/0.942/1.104/0.164 ms\n \n$ ssh root@10.140.67.23\n \nssh: connect to host 10.140.67.23 port 22: Connection timed out\nAgain, your organization\u2019s Access Control Matrix (see Chapter\u00a022, \u201cUnderstanding Basic \nLinux Security\u201d) helps you in creating the necessary rules for the netfilter/iptables  ", "doc_id": "b2af3b2d-d93e-4473-be74-d54fa1bcd703", "embedding": null, "doc_hash": "a8f2c2143b89d0d9b538c5aa920699927bf8cfe4dc5c695d6e737581190392be", "extra_info": {"page_label": "707"}, "node_info": {"start": 0, "end": 1753}, "relationships": {"1": "75adfeb4-7053-4522-b1e3-01b71b7864c1"}}, "__type__": "1"}, "f48d65d8-1c5d-4e61-ad55-05d173dad989": {"__data__": {"text": "Chapter 25: Securing Linux on a Network\n687\n25firewall on your Linux server. Then each modification should be tested in a test or virtual \nenvironment before implementing it in your production Linux systems firewall.\nSaving an iptables configuration\nBecause firewalld  is the recommended service for creating firewalls in RHEL, Fedora, and \nother Linux systems, manual creation of permanent firewall rules is less common. However, \nif you like, you can still manually save and restore firewall rules that you create directly \nwith iptables .\nIn the example that follows, the modifications made earlier are still in the firewall. You can \nsave the current set of firewall filter rules using the iptables-save  command.\n# iptables -vnL\nChain INPUT (policy ACCEPT 8 packets, 560 bytes)\n pkts bytes target prot opt in  out source        destination\n    0     0 DROP   tcp  --  *   *   10.140.67.22  0.0.0.0/0   tcp dpt:22\n    0     0 DROP   tcp  --  *   *   0.0.0.0/0     0.0.0.0/0   tcp dpt:33\n    0     0 DROP   icmp --  *   *   0.0.0.0/0     0.0.0.0/0\n...\n \n# iptables-save > /tmp/myiptables\nTo restore those rules later, you can start by flushing the current rules ( iptables -F ) and \nrestoring them ( iptables-restore ).\n# iptables -F\n# iptables -vnL\nChain INPUT (policy ACCEPT 8 packets, 560 bytes)\n pkts bytes target prot opt in out source       destination\n    0     0 DROP   tcp  --  *  *   0.0.0.0/0    0.0.0.0/0  tcp dpt:33\n    0     0 DROP   icmp --  *  *   0.0.0.0/0    0.0.0.0/0\n...\nA flush of the rules does not affect the iptables  configuration file. To restore the fire -\nwall to its original condition, use the iptables-restore  command. In the example that \nfollows, the iptables  configuration file is redirected into the restore  command and the \noriginal DROP  rule for 10.140.67.22  is restored.\n# iptables-restore < /tmp/myiptables\n# iptables -vnL\nChain INPUT (policy ACCEPT 16 packets, 1120 bytes)\n pkts bytes target prot opt in out source       destination\n    0     0 DROP   tcp  --  *  *   10.140.67.22 0.0.0.0/0      tcp dpt:22\n    0     0 DROP   tcp  --  *  *   0.0.0.0/0    0.0.0.0/0      tcp dpt:33\n    0     0 DROP   icmp --  *  *   0.0.0.0/0    0.0.0.0/0", "doc_id": "f48d65d8-1c5d-4e61-ad55-05d173dad989", "embedding": null, "doc_hash": "70d20d3b3f5726c55cbb7b0e809e98735b40b046fc3ba65f7aa3930d5629a62d", "extra_info": {"page_label": "708"}, "node_info": {"start": 0, "end": 2186}, "relationships": {"1": "49094575-b561-4013-ad25-973ec0330a0a"}}, "__type__": "1"}, "7b323e31-7a2e-45de-80d8-5f2094542b59": {"__data__": {"text": "Part V: Learning Linux Security Techniques688You can also save your netfilter/iptables  firewall rules to create an audit report. \nReviewing these rules periodically should be part of your organization\u2019s System Life Cycle \nAudit/Review phase.\nSummary\nSecuring your Linux server is critical on a network. Inherently, a majority of the malicious \nattacks originate from a network, especially the Internet. This chapter covered some of the \nbasics that you need in order to get started on this process.\nProtecting your network services can be simplified after you determine and remove any \nunneeded network services. The nmap  utility helps you here. Also, you can use nmap  to \naudit your Linux server\u2019s advertising of network services. These audits assist in deter -\nmining what firewall modifications are needed.\nRecent versions of Fedora and RHEL have added the firewalld  service as a front end to \nthe iptables  firewall facility that is built into the Linux kernel. By using the fire -\nwalld-config  tool and Cockpit web UI, you can easily open ports in your firewall to allow \naccess to selected services. The netfilter/iptables  firewall facility is a host-based, \nnetwork-layer, software firewall. It is managed by the iptables  and ip6tables  utilities. \nWith these utilities, a series of policies and rules can be created for every network packet \ncoming through your Linux server.\nAt this point in this book, you should have a good grasp of what goes into setting up and \nsecuring Linux desktop and server systems. In the next two chapters, I\u2019m going to help you \nextend that knowledge into cloud computing and virtualization.\nExercises\nRefer to the material in this chapter to complete the tasks that follow. If you are stuck, \nsolutions to the tasks are shown in Appendix B (although in Linux, you can often complete \na task in multiple ways). Try each of the exercises before referring to the answers. These \ntasks assume you are running a Fedora or Red Hat Enterprise Linux system (although some \ntasks work on other Linux systems as well). Please don\u2019t use a production system to try \nout the iptables  commands in these exercises. Although the commands shown here do NoTe\nFor an Ubuntu system, the way of saving and restoring your netfilter/iptables  modifications are very similar \nto the way it is done in Fedora. You can still use the iptables-save  command to create an iptables  con-\nfiguration file from the current iptables  setting and use iptables-restore  to restore it. There are several \noptions for loading a configuration file upon system boot. See the Ubuntu community website at https://help  \n.ubuntu.com/community/IptablesHowTo  for the various options.", "doc_id": "7b323e31-7a2e-45de-80d8-5f2094542b59", "embedding": null, "doc_hash": "e761ae2d14bc048c62c60ccc027366fd93b4d4b4e9cf50d4c43d9561f9745139", "extra_info": {"page_label": "709"}, "node_info": {"start": 0, "end": 2687}, "relationships": {"1": "acfa5488-ed43-4658-bdbe-a1cf66df7d9b"}}, "__type__": "1"}, "9b73e692-0940-4775-b2fe-59fab7521895": {"__data__": {"text": "Chapter 25: Securing Linux on a Network\n689\n25not permanently change your firewall (the old rules will return when the firewall service \nrestarts), improperly modifying your firewall can result in unwanted access.\n1. Install the Network Mapper utility on your local Linux system.\n2. Run a TCP Connect scan on your local loopback address. What ports have a service \nrunning on them?\n3. Run a UDP port scan on your Linux system from a remote system.\n4. Check to see if your system is running the firewalld  service. If not, install \nfirewalld  and firewall-config  and then start and enable that service.\n5. Use the Firewall Configuration window to open access to secure (TCP port 443) and \ninsecure (TCP port 80) ports for a web service.\n6. Determine your Linux system\u2019s current netfilter/iptables  firewall policies \nand rules.\n7. Save your Linux system\u2019s current firewall rules, flush them, and then restore them.\n8. For your Linux system\u2019s firewall, set a filter table policy for the input \nchain to DROP .\n9. Change your Linux system firewall\u2019s filter table policy back to accept  for the \ninput chain, and then add a rule to drop all network packets from the IP address \n10.140.67.23.\n10. Without flushing or restoring your Linux system firewall\u2019s rules, remove the rule \nyou just added.", "doc_id": "9b73e692-0940-4775-b2fe-59fab7521895", "embedding": null, "doc_hash": "b6cbca692e2b3999cbfa7464ce985c238aeb61fda3ccea26eff8e40bd7eb3b61", "extra_info": {"page_label": "710"}, "node_info": {"start": 0, "end": 1291}, "relationships": {"1": "65411d11-aa0a-4ca3-9dce-6290f875780e"}}, "__type__": "1"}, "32b208e7-d5a5-4108-bfae-ff251648cafd": {"__data__": {"text": "Part VIIN THIS PART\nChapter\u00a026 \nShifting to Clouds and Containers\nChapter\u00a027 \nUsing Linux for Cloud Computing\nChapter\u00a028 \nDeploying Linux to the Cloud\nChapter\u00a029 \nAutomating Apps and Infrastructure with Ansible\nChapter\u00a030 \nDeploying Applications as Containers with KubernetesEngaging with \nCloud Computing\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "32b208e7-d5a5-4108-bfae-ff251648cafd", "embedding": null, "doc_hash": "f1fa84cadfa4ef7549bd86d28a9d8b221c985b4beb1c23308f75d2f1ec2a87a8", "extra_info": {"page_label": "711"}, "node_info": {"start": 0, "end": 428}, "relationships": {"1": "f3bd6321-354e-460f-9c44-aedb4c7d8eec"}}, "__type__": "1"}, "9b244cca-6c48-4263-8db8-0664b66b0c1b": {"__data__": {"text": "693\nCHAPTER26\nShifting to Clouds and \nContainers\nIN THIS CHAPTER\nUnderstanding key technologies for cloud computing\nLearning how Linux containers workInstalling and starting container softwarePulling and running container imagesRestarting a stopped containerBuilding a container imageTagging and pushing container images to a registry\nWhile most of this book focuses on installing and managing individual computers, services, \nand applications, this part takes you into the technologies needed to bring Linux into large data centers. For a data center to operate efficiently, its computers must become as generic \nas possible and running components must become more automated. Chapters in this part focus on technologies that make those two things happen.\nComputers become more generic by separating the applications from the operating systems. This means not just packaging applications into things you install on an operating system (like RPM or Deb packages), but also putting together sets of software into packages that themselves can run once they are delivered in ways that keep them separate from the operating system. Virtual machines  (VMs) \nand containers  are two ways of packaging sets of software and their dependencies in ways that are \nready to run.\nFrom a high level, a virtual machine  is a complete operating system that runs on another operating \nsystem, allowing you to have many VMs active at a time on one physical computer. Everything an \napplication or a service needs to run can be stored within that VM or in attached storage.\nA VM has its own kernel, file system, process table, network interfaces, and other operating system \nfeatures separate from the host, while sharing the CPU and RAM with the host system. You can deploy that VM to a physical system in a way that makes it easy to run the application and then discard the VM when you are done. You can run multiple instances of the VM on the same computer \nLinux\u00ae Bible , Tenth Edition. Christopher Negus.\n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "9b244cca-6c48-4263-8db8-0664b66b0c1b", "embedding": null, "doc_hash": "3ce8074ef05dad4c265a093cdaa9ae77a4ddb42b73f9dce0848b39fddf50d478", "extra_info": {"page_label": "712"}, "node_info": {"start": 0, "end": 2062}, "relationships": {"1": "f611d14a-8ccb-4592-b449-4915ff7a903f"}}, "__type__": "1"}, "25d69c77-9650-4202-81fb-1773ea2bb043": {"__data__": {"text": "Part VI: Engaging with Cloud Computing694or clone and run the VM across multiple computers. The term virtual machine  comes from \nthe fact that each VM sees an emulation of computer hardware and not the hardware \nitself directly.\nA container  is like a VM, with the major difference being that a container doesn\u2019t have its \nown kernel. In most other ways, it is like a VM in that its name spaces are separate from \nthe host operating system and you can move it from host to host to run wherever it is \nconvenient.\nThe chapters in this part introduce you to the concepts, tools, and technologies that you \nneed to know to engage with cloud computing. You can try out virtual machines on a single \nLinux host using KVM. You can then deploy virtual machines to cloud technologies such as \nOpenStack and Amazon Web Services (AWS).\nTo deploy sets of hosts, either on bare metal or the cloud, you will learn how to use Ansible. \nWith Ansible playbooks, you can also define the software that is installed and run on each \nhost system.\nAs for containers, the Kubernetes project has grabbed the spotlight as the premier technol -\nogy for orchestrating massive numbers of containers across large data centers. Products such \nas Red Hat OpenShift provide supported Kubernetes platforms for large enterprises.\nThe technology that started the rush to containers a few years ago was the Docker project. \nThe docker  command and daemon offered simplified ways to build and run containers on \nLinux systems. Today, standardized container formats (such as the Open Container Initiative) \nand other container tools, such as podman , offer ways of working with containers that align \nmore tightly with the Kubernetes ecosystem.\nThe remainder of this chapter is devoted to getting started with containers. It covers the \ndocker  and podman  commands, along with other popular tools for working with individual \ncontainers.\nUnderstanding Linux Containers\nContainers make it simple to get and run applications and then discard them when you are \ndone. There are a few things that you should know about containers before you get started.\nIn working with containers, people refer to the entity that you move around as a container \nimage  (or simply an image ). When you run that image, or when it is paused or stopped, it is \nreferred to as a container .\nA container remains separate from the host system by using its own set of namespaces . You \ntypically would build your own container images by getting a secure base image  and then \nadding your own layers of software on top of that image to create a new image. To share \nyour images, you push them to shared container registries  and allow others to pull them.", "doc_id": "25d69c77-9650-4202-81fb-1773ea2bb043", "embedding": null, "doc_hash": "26980ebf49901793d4dc7a38ac598832f67eb73b94e8ac05986c4ff0489ff3f7", "extra_info": {"page_label": "713"}, "node_info": {"start": 0, "end": 2691}, "relationships": {"1": "1c779ef8-e622-43ae-ab05-8a5ee97aa1cb"}}, "__type__": "1"}, "1cdd62fc-fa0a-41eb-a95f-1b8b5f199934": {"__data__": {"text": "Chapter 26: Shifting to Clouds and Containers\n695\n26Namespaces\nLinux support for namespaces  is what allows containers to be contained. With namespaces, \nthe Linux kernel can associate one or more processes with a set of resources. Normal \nprocesses, not those run in a container, all use the same host namespaces. By default, \nprocesses in a container only see the container\u2019s namespaces and not those of the host. \nNamespaces include the following:\nProcess table A container has its own set of process IDs and, by default, can only see \nprocesses running inside the container. While PID 1 on the host is the init  process \n(systemd ), in a container PID 1 is the first process run inside the container.\nNetwork interfaces  By default, a container has a single network interface ( eth0 ) \nand is assigned an IP address when the container runs. By default, a service run \ninside a container (such as a web server listening on ports 80 and 443) is not \nexposed outside of the host system. The upside of this is that you could have hun -\ndreds of web servers running on the same host without conflict. The downside is \nthat you need to manage how those ports are exposed outside of the host.\nMount table  By default, a container can\u2019t see the host\u2019s root file system, or any other \nmounted file system listed in the host\u2019s mount table. The container brings its own \nfilesystem, consisting of the application and any dependencies it needs to run. \nFiles or directories needed from the host can be selectively bind-mounted inside the \ncontainer.\nUser IDs  Although containerized processes run as some UID within the host\u2019s \nnamespace, another set of UIDs is nested within the container. This can, for exam-\nple, let a process run as root within a container but not have any special privileges \nto the host system.\nUTS A UTS namespace allows a containerized process to have a different host and \ndomain name from the host.\nControl group (cgroup) In some Linux systems (such as Fedora and RHEL), a con -\ntainerized process runs within a selected control group and cannot see the other \ncgroups available on the host system. Likewise, it cannot see the identity of its \nown cgroup.\nInterprocess communications (IPC) A containerized process cannot see the IPC \nnamespace from the host.\nAlthough access to any host namespace is restricted by default, privileges to host \nnamespaces can be opened selectively. In that way, you can do things like mount config -\nuration files or data inside the container and map container ports to host ports to expose \nthem outside of the host.\nContainer registries\nPermanent storage for containers is done in what is referred to as a container registry . When \nyou create a container image that you want to share, you can push  that image to a public ", "doc_id": "1cdd62fc-fa0a-41eb-a95f-1b8b5f199934", "embedding": null, "doc_hash": "d20edb0d23f5c17b7f0d03f20e44a41c3de62a29c4dd4259d72a1577a96d4b95", "extra_info": {"page_label": "714"}, "node_info": {"start": 0, "end": 2776}, "relationships": {"1": "4fe23b2e-6b35-4860-8d21-99385f08f73f"}}, "__type__": "1"}, "154d101d-f3d0-44cb-bdeb-541bf45ad455": {"__data__": {"text": "Part VI: Engaging with Cloud Computing696registry or a private registry that you maintain yourself (such as a Red Hat Quay registry). \nSomeone who wants to use the image will pull  it from the registry.\nThere are large, public container image registries, such as the Docker Hub (docker.io) and \nQuay Registry (Quay.io). They offer free accounts to get started. If you want access to more \nfeatures, such as the ability to keep your registry private, premium accounts are avail -\nable as well.\nBase images and layers\nAlthough you can create containers from scratch, most often a container is built by starting \nwith a well-known base image and adding software to it. That base image typically aligns \nwith the operating system from which you are installing software into your container.\nYou can get official base images from Ubuntu ( https://hub.docker.com/ _ /ubuntu ), \nCentOS (https://hub.docker.com/ _ /centos ), Fedora (https://hub.docker.\ncom/ _ /fedora ), and many other Linux distributions. Those Linux distributions may \noffer base images in different forms, such as standard and minimal versions. In fact, there \nare base images that you can build on that offer runtimes for php, Perl, Java, and other \ndevelopment environments.\nAlthough Red Hat offers a subscription model for its software, if you want to use Red Hat \nsoftware as the foundation for your container images, Red Hat offers freely available Uni-\nversal Base Images (UBIs) for standard, minimal, and a variety of runtime containers. You \ncan find those images by searching the Red Hat Container Catalog for UBI images ( https://\ncatalog.redhat.com/software/containers/explore ).\nYou can add software to a base image using commands such as docker build  or pod-\nman. By using a Dockerfile to define the build, you can add yum  or apt-get  commands to \ninstall software from software repositories into your new container.\nWhen you add software to an image, it creates a new layer to become part of the new \nimage. Reusing the same base images for the containers that you build offers several \nadvantages. One advantage is that when you run the container image, only one copy of the \nbase image is needed on the host. So, if you were running 10 different containers based on \nthe same base image, you only need to pull and store the base image once, then possibly \nonly add a few megabytes of extra data for each new image.\nIf you look at the contents of a base image, it would look like a little Linux filesystem. You \nsee configuration files in /etc , executables in /bin  and /sbin , and libraries in /lib . In \nother words, it would have the basic components that an application would need from a \nLinux host system.\nKeep in mind that the container images you run don\u2019t necessarily need to match the host \nLinux system. So, for example, you could run a Fedora base image on an Ubuntu system, as \nlong as there are no specific kernel requirements or libraries built into the container image.", "doc_id": "154d101d-f3d0-44cb-bdeb-541bf45ad455", "embedding": null, "doc_hash": "26a2ed7f4ed4eaf236b3363dc9c387ec083fc6bba764192fe66d0bf3787ea125", "extra_info": {"page_label": "715"}, "node_info": {"start": 0, "end": 2964}, "relationships": {"1": "f4fe7fa4-7991-42a2-bfa4-c0c840620002"}}, "__type__": "1"}, "0222f807-3aa1-4b6c-a24e-4d4ac6877556": {"__data__": {"text": "Chapter 26: Shifting to Clouds and Containers\n697\n26Starting with Linux Containers\nVery little preparation is needed to start running containers on your own Linux system. \nThe following procedures describe how to prepare your Linux system to start using \ncontainers.\nDocker Inc. now makes a free version of its software available via the Moby project, \nwith Docker having become its commercial product. To try an older version of the docker \npackage, you can run the following on a RHEL 7 system to install the docker package and \nthen start and enable the docker service:\n# yum install docker -y\n# systemctl start docker\n# systemctl enable docker\n \nThe podman  command supports most of the docker  command line options for working \nwith containers, so you can use it instead of docker . Keep in mind that podman  repre -\nsents a different code base from docker , even though it supports similar management \ncommand options. With podman , you don't need to have a service running, as you do with \ndocker . To install podman on Fedora or RHEL, do the following:\n# yum install podman -y\nYou can now start using the podman  or docker  commands to work with containers and \ncontainer images for the examples in this chapter.\nPulling and running containers\nWith the docker or podman packages installed and ready to use, you can try running a con -\ntainer. To start, you can pull a container to your local system and then run it. If you like, \nyou can skip the pull  command since running the container will pull it if the requested \nimage is not already on your system.\nPulling a container\nChoose a reliable container image to try out, as in one that comes from an official project, \nis up to date, and preferably has been scanned for vulnerabilities. Here is an example of \npulling a RHEL 8 UBI base image with the podman  command (you can replace podman  \nwith docker  in these examples):\n# podman pull registry.access.redhat.com/ubi8/ubi\nTrying to pull .../ubi8/ubi...Getting image source signatures\nCopying blob fd8daf2668d1 done\nCopying blob cb3c77f9bdd8 done\nCopying config 096cae65a2 done\nWriting manifest to image destination\nStoring signatures\n096cae65a2078ff26b3a2f82b28685b6091e4e2823809d45aef68aa2316300c7", "doc_id": "0222f807-3aa1-4b6c-a24e-4d4ac6877556", "embedding": null, "doc_hash": "1aac0f265424d0dd42ea6910de65effe80c94c909616f7ddadf48e8f898ce9d4", "extra_info": {"page_label": "716"}, "node_info": {"start": 0, "end": 2212}, "relationships": {"1": "419a09ed-8c0a-458d-83f7-d616fd7fd378"}}, "__type__": "1"}, "0c89e2e2-545b-4398-b16c-9e0d1247f8d9": {"__data__": {"text": "Part VI: Engaging with Cloud Computing698To see that the image is on your system, run the following:\n# podman images\nREPOSITORY   TAG     IMAGE ID      CREATED      SIZE\n/ubi8/ubi    latest  096cae65a207  2 weeks ago  239 M\nRunning a shell from a container\nUse podman  or docker  to run a shell within a container. You can identify the image \neither by the image ID ( 096cae65a207 ) or name ( registry.access.redhat.com/\nubi8/ubi ). Use the -i  (interactive) and -t  (terminal) options so that you can have an \ninteractive session within the container from the bash shell:\n# podman run -it 096cae65a207 bash\n[root@e9086da6ed70 /]#\nWith the shell running, commands that you type will operate within the container. For \nexample, you list the container\u2019s filesystem or check out the os-release  file to see the \noperating system on which the container is based:\n[root@e9086da6ed70 /]# ls /\nbin   dev  home   lib64       media  opt   root  sbin  sys  usr\nboot  etc  lib    lost+found  mnt    proc  run   srv   tmp  var\n[root@e9086da6ed70 /]# cat /etc/os-release | grep ^NAME\nNAME=\"Red Hat Enterprise Linux\"\nBecause containers are meant to have the minimal amount of content needed to run the \nintended application, many standard tools may not be inside the container. You can install \nsoftware inside a running container. However, keep in mind that containers are meant to \nbe discarded. So, if you want to add software permanently, you should build a new image to \ninclude the software you want.\nHere\u2019s an example of adding software to a running container:\n[root@e9086da6ed70 /]# yum install procps iproute -y\nNow you can run commands such as ps  and ip  inside the container:\n[root@e9086da6ed70 /]# ps -ef\nUID        PID  PPID  C STIME TTY          TIME CMD\nroot         1     0  0 17:44 pts/0    00:00:00 bash\nroot        40     1  0 17:45 pts/0    00:00:00 ps -ef\n[root@e9086da6ed70 /]# ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 ...\n    inet 127.0.0.1/8 scope host lo\n    ...\n3: eth0@if11: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 ...\n    inet 10.88.0.6/16 brd 10.88.255.255 scope global eth0\n    ...\nNotice that from within the container, you see only two running processes (the shell and \nthe ps  command). PID 1 is the bash shell. The trimmed output from ip a  shows that there ", "doc_id": "0c89e2e2-545b-4398-b16c-9e0d1247f8d9", "embedding": null, "doc_hash": "0ae5b3735dcf4bbc22e25e40dbdcfd3ba42909dec2f019e4bfb9c431adfd608d", "extra_info": {"page_label": "717"}, "node_info": {"start": 0, "end": 2286}, "relationships": {"1": "9be2a220-1ea5-431f-b3b9-1d8768354e09"}}, "__type__": "1"}, "90c51afa-1fb6-4bb1-93af-904c97a505ff": {"__data__": {"text": "Chapter 26: Shifting to Clouds and Containers\n699\n26is only one external network interface from the container ( eth0@if11 ) and that interface \nis assigned the IP address of 10.88.0.6/16.\nWhen you are done, you can type exit  to quit the shell and stop the container:\n[root@e9086da6ed70 /]# exit\nAlthough the shell and the container are no longer running, the container is still available \non your system in a stopped state. Notice that podman ps  alone doesn\u2019t show the con -\ntainer. You need to add --all :\n[root@e9086da6ed70 /]# podman ps\nCONTAINER ID  IMAGE  COMMAND  CREATED  STATUS  PORTS  NAMES\n[root@e9086da6ed70 /]# podman ps --all\nCONTAINER ID IMAGE         COMMAND CREATED    STATUS         PORTS \nNAMES\n437ec53386ca ...ubi:latest bash    1 hour ago Up 1 minute ago       \ngo_ein\nLater you can see how to delete and restart a stopped container.\nRunning an FTP server from a container\nBecause you want to be able to throw away a container when you are done, in general you \nwant any changeable data to be stored outside of the container. The following is a simple \nexample of an FTP server (vsftpd) being run from a container. If you want to try this exam-\nple yourself, I recommend that you skip to the section \u201cBuilding a container image\u201d later in \nthis chapter for instructions on how to build the vsftpd container image yourself.\nFor this procedure, you need a configuration file ( vsftpd.conf ) and an FTP directory that \ncontains a file or two to share ( /var/ftp/pub ) on the host system. When the vsftpd con -\ntainer starts, it bind mounts those items into the container as volumes.\n1. Create a vsftpd.conf  file: Create the vsftpd.conf  file in the default location, \n/etc/vsftpd/vsftpd.conf . See the vsftpd.conf  man page for details. Here is \nan example:\nanonymous_enable=YES\nlocal_enable=YES\nwrite_enable=YES\nlocal_umask=022\ndirmessage_enable=YES\nxferlog_enable=NO\nconnect_from_port_20=YES\nlisten=NO\nlisten_ipv6=YES\npam_service_name=vsftpd\nuserlist_enable=YES\ntcp_wrappers=NO\nvsftpd_log_file=/dev/stdout\nsyslog_enable=NO", "doc_id": "90c51afa-1fb6-4bb1-93af-904c97a505ff", "embedding": null, "doc_hash": "b2d50e9d9d79d5851f946b1c8f5b2cfbc168a46905bc7290ad4a53dbd906ee06", "extra_info": {"page_label": "718"}, "node_info": {"start": 0, "end": 2043}, "relationships": {"1": "d6db9eac-2e2f-433d-a1a2-aab4456c7702"}}, "__type__": "1"}, "901c04f6-05a9-4087-aafa-6d8508e13ebd": {"__data__": {"text": "Part VI: Engaging with Cloud Computing700background=NO\npasv_enable=Yes\npasv_max_port=21100\npasv_min_port=21110\n2. Create an ftp directory : Create an anonymous FTP directory for vsftpd to share \nin the standard location on the host ( /var/ftp/pub ) and copy a few files to that \ndirectory:\n# mkdir -p /var/ftp/pub\n# cp /etc/services /etc/login.defs /var/ftp/pub/\n3. Get the vsftpd container image : Build the vsftpd image as described in \u201cBuilding \na container image\u201d later in this chapter. To check that it is available to run, enter \nthe following:\n# podman images\nREPOSITORY  TAG    IMAGE ID     CREATED        SIZE\nvsftpd      latest 487d0db26098 5 seconds ago  208 MB\n4. Run the vsftpd container image : When you run the vsftpd container, you need \nto expose ports and mount files from the host to the container. Here\u2019s an example \n(you can use docker  instead of podman ):\n# podman run -d -p 20:20 -p 21:21 \\\n   -p 21100-21110:21100-21110 \\\n-v /etc/vsftpd/:/etc/vsftpd/ \\\n-v /var/ftp/pub:/var/ftp/pub \\\n--name vsftpd vsftpd\n# podman ps\nCONTAINER ID  IMAGE         COMMAND          CREATED\n    STATUS             PORTS                     NAMES\n3a5d094dd4b5  vsftpd:latest /usr/local/s2... 9 seconds ago\n    Up 10 seconds ago  0.0.0.0:20-21->20-21/tcp  vsftpd\nThis example uses the following options:\n-d: Runs the container in detached mode, so the vsftpd service runs in the \nbackground.\n-p: Standard FTP ports (TCP 20 and TCP 21) are mapped to the same port numbers \non the host network interfaces, so the service can be accessed outside of the \nlocal host. A range of ports needed for passive FTP are opened to their counter -\nparts on the host as well (21100-21110).\n--rm : Although not included in this example, adding --rm  to the command line \nwill remove the container when it exits.\n-v: To use the configuration files ( /etc/vsftpd  directory) and content that you \nwant to share ( /var/ftp  directory) from the host system, those directories are \nbind-mounted to the same locations on the container with the -v  option.\n--name : Set the name of the container to vsftpd (or any name you like).", "doc_id": "901c04f6-05a9-4087-aafa-6d8508e13ebd", "embedding": null, "doc_hash": "fdab60261ad7a92bbde4fb130e7674c555d0d22f397557796d231cced24e04a6", "extra_info": {"page_label": "719"}, "node_info": {"start": 0, "end": 2107}, "relationships": {"1": "4947b4fd-eef4-4527-87fb-f6216660ef9e"}}, "__type__": "1"}, "c52e9a6a-74ce-44a4-bd42-367e0d5be239": {"__data__": {"text": "Chapter 26: Shifting to Clouds and Containers\n701\n26Keep in mind that you can bind container content and ports to other locations on the host. \nIn that way, you can have multiple versions of the same software running on the same host \nwithout conflicting with each other.\nTo make your vsftpd service accessible outside of the local system, be sure to open the FTP \nports and passive FTP ports that you just assigned as follows:\n        # firewall-cmd --zone=public --add-service=ftp\n        # firewall-cmd --zone=public \\\n             --permanent --add-service=ftp\n        # firewall-cmd --zone=public \\\n             --add-port=21100-21110/tcp\n        # firewall-cmd --zone=public \\\n             --permanent --add-port=21100-21110/tcp\n        # firewall-cmd reload\nYou can now use any FTP client to access the FTP service via the anonymous user. To con -\nfigure your vsftpd service further and check that it is working, refer to Chapter\u00a018, \u201cConfig -\nuring an FTP Server.\u201d\nStarting and stopping containers\nUnless you specifically set a container to be removed when is stops ( --rm  option), if the \ncontainer is stopped, paused, or just fails, the container is still on your system. You can see \nthe status of all containers on your system (currently running or not) using the ps  option:\n# podman ps\nCONTAINER ID  IMAGE                    COMMAND           CREATED\n    STATUS                PORTS                     NAMES\n4d6be3e63fe3  localhost/vsftpd:latest  /usr/local/s2...  About an \nhour ago\n    Up About an hour ago  0.0.0.0:20-21->20-21/tcp  vsftpd\n# podman ps -a\nCONTAINER ID  IMAGE                    COMMAND              CREATED\n    STATUS                PORTS                     NAMES\n7da88bd62667  ubi8/ubi:latest          bash                 2 minutes \nago\n    Exited 7 seconds ago                            silly_wozniak\n4d6be3e63fe3  localhost/vsftpd:latest  /usr/local/s2i/ru... About an \nhour ago\n    Up About an hour ago  0.0.0.0:20-21->20-21/tcp  vsftpd\nOnly running containers are shown with podman ps . By adding -a , you can see all con -\ntainers, including those that are no longer running but have not yet been removed. You can \nrestart an existing container that is no longer running using the start  option:\n# podman start -a 7da88bd62667\n[root@7da88bd62667 /]#", "doc_id": "c52e9a6a-74ce-44a4-bd42-367e0d5be239", "embedding": null, "doc_hash": "3f7380d6cc3c93a19c30b6087fc52428578a2328722afc8c81d0f20cfc09076f", "extra_info": {"page_label": "720"}, "node_info": {"start": 0, "end": 2293}, "relationships": {"1": "c1ac35dc-e744-48d4-99b1-e15fe2eb2b2b"}}, "__type__": "1"}, "f13c919f-ff6a-4d74-9ecf-1132a47d4282": {"__data__": {"text": "Part VI: Engaging with Cloud Computing702The restarted container was running a bash shell. Because the container\u2019s terminal session \nalready existed, I didn\u2019t need to start a new one ( -it). I just needed to attach ( -a) to the \nexisting session. For a container that was just running in detached mode, I can simply start \nand stop it as required:\n# podman stop 4d6be3e63fe3\n4d6be3e63fe3...\n# podman start 4d6be3e63fe3\n4d6be3e63fe3\nNote that if the container had been started with the --rm  option, the container would be \nremoved as soon as you stopped it. So, you would have to run a new container instead of \njust restarting the old one. Because the configuration files and data are stored outside of \nthe container, running a new container is easy and painless. Upgrading the application in \nthe future is as easy as removing the old container and starting up one from the updated \ncontainer image.\nBuilding a container image\nTo build a container image, all you need is a Dockerfile describing how to build the image \nand any other content that you want to include with the image. The following proce -\ndures describe how to create a simple container from your own Dockerfile and how to get \nthe software you need to build a vsftpd service into a container from software available \non GitHub.\nBuild a simple container image\nThis procedure creates a simple container from a Dockerfile. In this process, you create a \nDockerfile and a simple script, then build that content into a new container image.\n1. Create a directory to hold your container project and then enter that directory:\n# mkdir myproject\n# cd myproject\n2. Create a script called cworks.sh  in the current directory that contains the fol -\nlowing text:\n#!/bin/bash\nset -o errexit\nset -o nounset\nset -o pipefail\necho \"This Container Works!\"\n3. Create a file named Dockerfile  in the current directory that contains the follow -\ning content:\nFROM registry.access.redhat.com/ubi7/ubi-minimal\nCOPY ./cworks.sh /usr/local/bin/\nCMD [\"/usr/local/bin/cworks.sh\"]", "doc_id": "f13c919f-ff6a-4d74-9ecf-1132a47d4282", "embedding": null, "doc_hash": "48266319e42514308801d292800fae83e73af5ab1012510d973c04eb674b198a", "extra_info": {"page_label": "721"}, "node_info": {"start": 0, "end": 2021}, "relationships": {"1": "e04481bf-705c-4bbf-9bd7-a21d9db126bb"}}, "__type__": "1"}, "7aa6bc14-c7f1-4fa5-ab2e-a3635d549fa8": {"__data__": {"text": "Chapter 26: Shifting to Clouds and Containers\n703\n264. Build a container image called myproject  from the Dockerfile:\n# podman build -t myproject .\nSTEP 1: FROM registry.access.redhat.com/ubi7/ubi-minimal\nSTEP 2: COPY ./cworks.sh /usr/local/bin/\n6382dfd00f7bedf1a64c033515a09eff37cbc6d1244cbeb4f4533ad9f00aa970\nSTEP 3: CMD [\"/usr/local/bin/cworks.sh\"]\nSTEP 4: COMMIT myproject\n6837ec3a37a241...\n5. Run the container to make sure it works. To do that, you can use either the con -\ntainer name ( myproject ) or its image ID ( 6837ec3a37a241 ):\n# podman run 6837ec3a37a241\nThe Container Works!\nBuild an FTP container from GitHub\nThe following procedure describes how to get the software you need to build a vsftpd ser -\nvice into a container from software available on GitHub. It then shows you how to build \nand run that container.\n1. If you don\u2019t already have it, install git on your local system:\n# yum install git -y\n2. For this example, we are starting with the vsftpd container-images project on \nGitHub. Clone a copy of that software to a local directory as follows:\n# git clone \nhttps://github.com/container-images/vsftpd.git\n# cd vsftpd\n# ls\ndefault-conf/  Dockerfile  LICENSE  Makefile  README.md\nroot/          s2i/        tests/\n3. Modify the files as needed. In particular, go through the Dockerfile and use the \nlatest Fedora image available. Leaving off the :tag  at the end of the image name \nsays to look for the version of that image that includes the :latest  tag, which is \na special tag that identifies the latest available version of that image. For example, \nmodify the FROM  line at the beginning so that it appears as follows:\nFROM registry.fedoraproject.org/fedora\n4. From the vsftpd directory, use either the docker  or podman  commands to build \nthe container image. For example:\n# podman build -t vsftpd .\nSTEP 1: FROM registry.fedoraproject.org/fedora:31\nGetting image source signatures\nCopying blob c0a89efa8873 done\nCopying config aaaa3e1d6a done", "doc_id": "7aa6bc14-c7f1-4fa5-ab2e-a3635d549fa8", "embedding": null, "doc_hash": "ac5d09238af4d5262ac4ec112520737ee5200c020b06d508cd0979b8629efbac", "extra_info": {"page_label": "722"}, "node_info": {"start": 0, "end": 1975}, "relationships": {"1": "7db99afb-4a36-4ba7-8645-d0b26e9ea86a"}}, "__type__": "1"}, "4e77d0aa-c908-479e-b0e6-aeb072188df0": {"__data__": {"text": "Part VI: Engaging with Cloud Computing704Writing manifest to image destination\nStoring signatures\nSTEP 2: ENV SUMMARY=\"Very Secure Ftp Daemon\" ...\nSTEP 3: LABEL maintainer=\"Dominika Hodovska <dhodovsk@redhat.com>\"       \n...\nSTEP 4: RUN dnf install -y vsftpd && dnf clean all\n          && mkdir /home/vsftpd\n...\nInstalling:\nvsftpd    x86_64   3.0.3-32.fc31   fedora   164 k\n...\nComplete!\n99931652dceacc2e9...\nSTEP 5: VOLUME /var/log/vsftpd\nb79b229d09f726356...\nSTEP 6: EXPOSE 20 21\nb0af5428800140104...\nSTEP 7: RUN mkdir -p ${APP_DATA}/src\nb3652e0d07e35af79...\nSTEP 8: WORKDIR ${APP_DATA}/src\nf9d96dee640c5cedc...\nSTEP 9: COPY ./s2i/bin/ /usr/local/s2i\nded9b512693ccabaa...\nSTEP 10: COPY default-conf/vsftpd.conf /etc/vsftpd/vsftpd.conf\n0c48af8d4f72b76c7...\nSTEP 11: CMD [\"/usr/local/s2i/run\"]\nSTEP 12: COMMIT vsftpd\naa0274872f23ae94dfee...\n5. Check that the new image was created:\n# podman images\nREPOSITORY       TAG    IMAGE ID     CREATED       SIZE\nlocalhost/vsftpd latest aa0274872f23 4 minutes ago 607 MB\n \nThis build process consisted of 12 steps. The FROM  line in the first step pulls the fedora  \nimage from registry.fedoraproject.org  container registry. Each subsequent step \nruns a command. If content is added during the command, a new layer is created for the \nimage. Step 2 and Step 3 set environment variables and labels that are used during the \nbuild as well as to identify attributes of the container image when it is used later.\nStep 4 runs the dnf  command that installs the vsftpd package from the Fedora yum  repos \nto the container. Notice that the RUN  instruction has both dnf install  and dnf clean  \nin the same instruction. This is good practice since it prevents an additional layer of \ncached dnf data from being included with the image.\nStep 5 identifies the volume used to store vsftpd log files. Step 6 exposes TCP port 20 and \nTCP 21 for the FTP service. Note that even though the ports are exposed (meaning that they \ncan be seen from outside of the container), they will still need to be mapped to host ports ", "doc_id": "4e77d0aa-c908-479e-b0e6-aeb072188df0", "embedding": null, "doc_hash": "5bd9685abc7279bed35a06dda8ade129065856c2fc97ce4cda15d8155c0db7cd", "extra_info": {"page_label": "723"}, "node_info": {"start": 0, "end": 2048}, "relationships": {"1": "43030402-104b-4b6b-9922-fc04306332d8"}}, "__type__": "1"}, "b697a4c6-bdfe-4623-bbd8-75b54ca71517": {"__data__": {"text": "Chapter 26: Shifting to Clouds and Containers\n705\n26when you run the container later, if you want those ports to be available outside of the \nlocal system.\nStep 7 and Step 8 create a directory and set that as the working directory for the applica -\ntion. Step 9 copies source-to-image (s2i) scripts into the container to run the vsftpd ser -\nvice. Step 10 copies a default vsftpd.conf  configuration file into the container.\nThe CMD instruction in Step 11 sets /usr/local/s2i/run  as the default command to \nexecute if the container is run without overriding that command. Step 12 commits the final \nvsftpd image to local storage (which you can see by typing podman images ).\nFor more information on creating and using a Dockerfile to build container images, refer to \nthe Dockerfile Reference ( https://docs.docker.com/engine/reference/builder/ ). \nTo learn more about options for building container images, refer to the podman  man pages \n(man podman build ).\nTagging and pushing an image to a registry\nSo far, I have shown an example of building a container image and running it on your local \nsystem. To make your image available to other people on other systems, you typically add \nthat image to a container registry. Follow these instructions to tag an image on your local \nsystem and push it to a remote container registry.\nTo try out a simple registry on your local system, install the docker-distribution  \npackage on a Fedora or RHEL 7 system. For a more permanent solution, you can get \naccounts on public container registries such as Quay.io and Docker Hub. Both free trials \nand subscriptions are available from Quay.io ( https://quay.io/plans/ ). You can also set \nup and run your own supported container registry, such as Red Hat Quay ( https://www.\nopenshift.com/products/quay ).\nTo get you started, the following procedure has you install the docker-distribution  \npackage on the local system and then tag and push an image to it:\n1. Install docker-distribution : On a RHEL 7 or recent Fedora system, install and start \nthe docker-distribution:\n# yum install docker-distribution -y\n# systemctl start docker-distribution\n# systemctl enable docker-distribution\n# systemctl status docker-distribution\n\u2022 docker-distribution.service-v2 Registry server for Docker\n   Loaded: loaded\n    (/usr/lib/systemd/system/docker-distribution.service;\n    enabled; vendor pres>\n    Active: active (running) since Wed 2020-01-01...\n2. Open the registry port : To be able to push and pull container images from other \nhost systems, you need to open TCP port 5000 on the firewall:\n# firewall-cmd --zone=public\n --add-port=5000/tcp --permanent", "doc_id": "b697a4c6-bdfe-4623-bbd8-75b54ca71517", "embedding": null, "doc_hash": "47a26758df00ff9578e6ac090d9451c15fb98ce9a532ea735023c74404490451", "extra_info": {"page_label": "724"}, "node_info": {"start": 0, "end": 2638}, "relationships": {"1": "3ec56ac8-fbc6-4a4a-b16b-e7e5d4a0af87"}}, "__type__": "1"}, "6f412e81-1f46-4200-8eb0-1af4b28cdbba": {"__data__": {"text": "Part VI: Engaging with Cloud Computing7063. Tag the image : By tagging a local image, you identify the location of the registry \nwhere the image will be stored. Replace the image id and host.example.com  with \nyour image ID and hostname or IP address to tag the image:\n# podman images | grep vsftpd\nlocalhost/vsftpd  latest  aa0274872f23  2 hours ago  607 MB\n# podman tag aa0274872f23 \nhost.example.com:5000/myvsftpd:v1.0\n4. Push the image : Push the image to the local registry (substitute your hostname or \nIP address). Turn off tls-verify , because docker-registry uses http protocol:\n# podman push --tls-verify=false \nhost.example.com:5000/myvsftpd:v1.0\n5. Pull the image : To make sure that the image is available from your registry, try \nto pull the image. Either delete the image from your local system or go to another \nhost to try this:\n# podman pull --tls-verify=false \\\n              host.example.com:5000/myvsftpd:v1.0\nAt this point, you should be able to share your images with others from your registry.\nIf you were using a public registry, which is a better solution for sharing images with \na wider audience, the procedure for pushing and pulling images would look like the \nfollowing.\n# podman login quay.io\nUsername: myownusername\nPassword: ***************\n# podman tag aa0274872f23 \\\n    quay.io/myownusername/myvsftpd:v1.0\n# podman push quay.io/myownusername/myvsftpd:v1.0\nUsing containers in the enterprise\nAlthough the Docker project made huge strides in simplifying how individual containers \ncan be used, it was the Kubernetes project that helped propel Linux containers into the \nenterprise. While command-line tools like docker  and podman  are good for managing \nindividual containers, Kubernetes offers a platform for deploying large, complex applica -\ntions across huge data centers. Refer to Chapter\u00a030, \u201cDeploying Applications as Containers \nwith Kubernetes,\u201d for information on how to use Kubernetes to deploy and manage contain -\nerized applications in the enterprise.\nSummary\nContainerizing applications has seen widespread adoption over the past few years. The \nDocker project was a huge contributor to the simplification of containerizing individual ", "doc_id": "6f412e81-1f46-4200-8eb0-1af4b28cdbba", "embedding": null, "doc_hash": "c3ec2eb476a497631ee156a1fb2354e9e78ad736573d6367d71fd0d47cc30838", "extra_info": {"page_label": "725"}, "node_info": {"start": 0, "end": 2186}, "relationships": {"1": "ed4e0f49-ef51-4c83-8c86-6d60b8dc81e6"}}, "__type__": "1"}, "f9a0291d-3501-476f-ad1c-22f14ae9fb9c": {"__data__": {"text": "Chapter 26: Shifting to Clouds and Containers\n707\n26applications and running them on single systems. Tools such as podman  also became avail -\nable to deploy and manage individual containers on Linux systems.\nThis chapter described how to pull, run, build, and otherwise manage containers using \ncommand-line tools like docker  and podman . You can use this knowledge as a foundation \nfor understanding how containerization works and for how those concepts are applied later \nin Chapter\u00a030, as it describes how Kubernetes can manage containerized applications across \nan entire enterprise.\nExercises\nThe exercises in this section describe tasks related to working with containers. If you are \nstuck, solutions to the tasks are shown in Appendix B. Keep in mind that the solutions \nshown in Appendix B are usually just one of multiple ways to complete a task.\n1. Choose either podman  (for any RHEL or Fedora system) or docker  (RHEL 7), install \nthe software package containing the tool of your choice, and start any necessary \nservices to use those commands.\n2. Using either docker  or podman , pull this image to your host:  \nregistry.access.redhat.com/ubi7/ubi .\n3. Run the ubi7/ubi  image to open a bash shell.\n4. With the bash shell open within a container, run a few commands to see the \noperating system on which the container is based, install the proc-ps  package, \nrun a command to see the processes running inside the container, and then exit.\n5. Restart the container again and connect to it using an interactive shell. Exit the \nshell when you are finished.\n6. Create a simple Dockerfile from a ubi7/ubi  base image, include a script named \ncworks.sh  that uses echo  to output the string \u201cThe Container Works!\u201d and add \nthat script to the image so that it runs as the default command.\n7. Use docker  or podman  to build an image named containerworks  from the \nDockerfile you just created.\n8. Gain access to a container registry, either by installing the docker-distribution \npackage or by getting an account on Quay.io or Docker Hub.\n9. Tag and push your new image to your chosen container registry.", "doc_id": "f9a0291d-3501-476f-ad1c-22f14ae9fb9c", "embedding": null, "doc_hash": "bc04da8bb8aef603d511ba3d26f0851492bc40c682f82d5113050ff8f3d7980b", "extra_info": {"page_label": "726"}, "node_info": {"start": 0, "end": 2114}, "relationships": {"1": "db739bdd-96b2-44f2-90ed-ab44d2b177da"}}, "__type__": "1"}, "7e08609c-80e0-41b1-806a-3e52b1562344": {"__data__": {"text": "709\nCHAPTER27\nUsing Linux for Cloud Computing\nIN THIS CHAPTER\nHow Linux is used in clouds\nUnderstanding basic cloud technology\nSetting up a hypervisor\nCreating virtual machines\nComputer operating systems were originally designed to be installed directly on computer \nhardware. When it needed memory, storage, processing power, or network interfaces, a com-\nputer operating system looked for physical RAM, hard disks, CPUs, and network interface \ncards. When it needed more of those things than were physically installed, you turned the machine \noff and physically added them to the computer. Nowadays, virtualizing these items is what makes \ncloud computing possible.\nVirtualization , as is relates to computers, is the act of making computing resources that were origi -\nnally designed as physical objects to be represented by virtual ones. For example, a virtual operating \nsystem (referred to as a virtual machine ) doesn\u2019t communicate directly with the hardware. Instead, a \nvirtual machine (VM) interacts with a specially configured host computer referred to as a hypervisor . \nSo, instead of being able to run one operating system on a physical computer, you could potentially \nrun dozens or even hundreds of VMs on a single physical computer.\nThe advantages gained from running VMs are massive. Not only can you have multiple operating sys -\ntems running on the same computer, but those systems can be different ones\u2014Linux, BSD, Windows, \nor any other system made to run on the computer\u2019s hardware. If you need to shut down the host com -\nputer for maintenance, you can migrate the running VMs to another hypervisor with an imperceptible \namount of downtime.\nTo support virtual machines across multiple hypervisors, you can virtualize the features they rely \nupon as well. For example, virtual networks and virtual storage can span multiple hypervisors, so if a \nVM needed to move to another hypervisor, the same virtual networks and storage would be available \nto a newly migrated virtual machine.\nYou don\u2019t need to build a whole data center to begin understanding virtualization and to use some \nof the underlying technologies that make cloud computing possible. This chapter starts you off by \nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "7e08609c-80e0-41b1-806a-3e52b1562344", "embedding": null, "doc_hash": "d4b690d1206e9cd8a9b7fbeeec8f952bca463543942fffa23452c838efc47eb3", "extra_info": {"page_label": "727"}, "node_info": {"start": 0, "end": 2326}, "relationships": {"1": "6253098d-23e5-469c-8864-a80f547a9c2e"}}, "__type__": "1"}, "4c3776b5-ee4c-402f-aba7-71874bece099": {"__data__": {"text": "Part VI: Engaging with Cloud Computing710helping you to set up a host computer to run as a hypervisor, start running VMs on that \nhypervisor, and then learn how to migrate VMs to other hypervisors (in order to prevent \ndowntime or just to grow your capacity).\nOverview of Linux and Cloud Computing\nCloud computing moves us into an arena where everything you learned previously in \nthis book is being abstracted and automated. In a cloud environment, when you install a \nsystem, you are probably not booting from a physical DVD, erasing the local hard drive, and \ninstalling Linux directly on a computer sitting in front of you. You are also probably not \nlogging into the installed system and manually configuring the software and features you \nwant to run on that system.\nInstead, you are installing to a VM or running a container that is on some host system in \nthe cloud. The network interfaces that you see may not be represented by a physical switch, \nrather they may be virtual networks that exist on a single computer or span multiple \nhypervisors.\nToday, every software aspect of cloud computing can be fulfilled using open source technol -\nogy running on Linux systems. To get a feel for how some of the basic technologies in cloud \ncomputing work, this chapter explains some of those technologies and then describes how \nto set up a hypervisor and start using VMs on that hypervisor.\nCloud hypervisors (aka compute nodes)\nIn cloud computing, the operating systems serving cloud users are not running directly on \ncomputer hardware. Instead, hypervisors are configured to run many operating systems as \nwhat are referred to as virtual machines (VMs).\nDepending on your cloud environment, you may hear a hypervisor referred to as a compute \nnode, a worker node , or simply as a host. Because hypervisors tend to be commodity items \n(dozens or hundreds of hypervisors may be set up for a location), Linux is the logical choice \nas the operating system running as hypervisors directly on hardware.\nKernel-based Virtual Machine (KVM) is the basic virtualization technology implemented in \nmost Linux distributions to make a Linux system into a hypervisor. KVM is supported on \nUbuntu, Red Hat Enterprise Linux, Fedora, CentOS, and many other Linux systems.\nThe other major technology that can be used instead of KVM to make a Linux system into a \nhypervisor is Xen ( www.xenproject.org ). Xen has been around longer than KVM, and it \nis supported in products from Citrix Systems and Oracle.\nLater in this chapter, I describe how to check to see if a computer has the required  \nhardware features to be used as a hypervisor and how to configure it to be used with KVM.", "doc_id": "4c3776b5-ee4c-402f-aba7-71874bece099", "embedding": null, "doc_hash": "f74edfdd39a0de9e326db87ac66158a8780a898608fab57a0e7535ad71f64486", "extra_info": {"page_label": "728"}, "node_info": {"start": 0, "end": 2672}, "relationships": {"1": "0a6ddb55-2c90-4763-9d49-cc259a2a5aac"}}, "__type__": "1"}, "73b42b33-9509-4c87-80fe-48948b430738": {"__data__": {"text": "Chapter 27: Using Linux for Cloud Computing\n711\n27Cloud controllers\nBecause a cloud configuration can include multiple hypervisors, pools of storage, multiple \nvirtual networks, and many virtual machines, you need centralized tools to manage and \nmonitor those features. You can use both graphical and command-based tools for control -\nling cloud environments.\nAlthough not considered a full cloud controller, the Virtual Machine Manager ( virt-\nmanager ) GUI and virsh  command can be used to manage a small cloud-like environ -\nment. Using virt-manager , you can get a feel for managing multiple virtual machines \nacross several hypervisors, and you can learn how to deal with virtual networks and shared \nstorage pools.\nFull-blown cloud platforms have their own controllers for offering much more complex \ninteractions between cloud components. For example, the Red Hat OpenStack platform \n(https://access.redhat.com/products/red-hat-openstack-platform ) and its \nupstream RDO project ( https://www.rdoproject.org ) provide flexible and expandable \ncloud environments for managing VMs and all associated supporting features. For Red Hat \nVirtualization (RHV), the RHV Manager provides many of the same features.\nIf you want to start out more simply, however, you can start by using virt-manager , the \nVM Desktop tool, to manage your first mini cloud-like environment.\nCloud storage\nNew demands on data storage arise when you move your operating systems and applications \ninto a cloud environment. To be able to move a virtual machine to run on another hyper -\nvisor, its storage must be available from that new hypervisor. Storage needs for clouds \ninclude back-end storage for your VMs, images for launching VMs, and databases for storing \ninformation about the cloud itself.\nShared storage between hypervisors can be done as simply as creating an NFS share (see \nChapter\u00a020, \u201cConfiguring an NFS File Server\u201d) and mounting it on the same mount point \nbetween multiple hypervisors. NFS is one of the easiest ways to implement shared storage.\nMore robust shared storage that can handle disk failures and provide better performance \nworks better for clouds providing critical services. Shared block storage, where you mount \na whole disk or disk partition, can be accomplished using technologies such as iSCSI or \nFibre Channel.\nCeph (http://ceph.com ) is an open source project for managing both block and object \nstorage that is popular for managing storage in cloud environments. GlusterFS ( www.glus -\nter.org ) is a scale-out filesystem that is often used in cloud environments.\nFor the simple mini-cloud example in this chapter, I used NFS to provide shared storage \nbetween the hypervisors. Ceph and GlusterFS are more appropriate for enterprise-quality \ninstallations.", "doc_id": "73b42b33-9509-4c87-80fe-48948b430738", "embedding": null, "doc_hash": "a89ddc212669f54b0cf0c032db3c90133f59af14f71798c5405e4955de0e58dc", "extra_info": {"page_label": "729"}, "node_info": {"start": 0, "end": 2778}, "relationships": {"1": "d549d3bf-ac3f-45a1-8e84-6d3e17cea0bb"}}, "__type__": "1"}, "4659fa20-1455-4a24-a6e0-8e2089721696": {"__data__": {"text": "Part VI: Engaging with Cloud Computing712Cloud authentication\nTo be able to limit how much cloud resources a user can consume, and possibly track and \ncharge for that use, you need authentication mechanisms. Authentication is necessary \nfor those who are using cloud features as well as for those who are allowed to administer \ncloud features.\nCloud platform projects sometimes let you connect centralized authentication mechanisms \nto validate and authorize cloud users. These can include Kerberos, Microsoft Active Direc -\ntory, and others. In Linux, Identity, Policy, and Audit (IPA) software (see www.freeipa  \n.org ) offers a full set of authentication features that can be used across an enterprise \ncloud platform.\nCloud deployment and configuration\nIf you are managing a large cloud infrastructure, you don\u2019t want to have to walk over to \neach machine and click through a graphical installation every time you want to add a \nhypervisor or other node on your network. Today, many tools can deploy and configure \nLinux systems as simply as rebooting the computer and having it boot up to a preconfigured \ninstaller.\nIn Chapter\u00a09, \u201cInstalling Linux,\u201d I talked about how to use a PXE server (to boot a Linux \ninstaller automatically over the network from your network interface card) and Kickstart \nfiles (to identify all of the answers you need to complete an installation). With that setup \nin place, you can simply boot a computer from a network interface and come back a short \ntime later to find a fully installed Linux system.\nAfter a computer is deployed, systems can be configured and possibly monitored and \nupdated using tools such as Puppet ( http://puppetlabs.com ) and Chef ( www.chef.io ). \nWhole work environments can be deployed in virtual machines using Vagrant ( www.vag-\nrantup.com ). Ansible ( www.ansible.com ) is another tool for automating IT infrastruc -\ntures and the applications that run on them.\nCloud platforms\nIf you want to implement your own, private cloud within your organization, the open \nsource OpenStack platform is probably the most popular choice. It offers a huge amount of \nflexibility and power in how you configure and use it.\nRed Hat Virtualization (RHV) is another popular cloud platform. RHV makes it easy to \nstart with a simple RHV Manager and one or two hypervisors to run the VMs it manages \nand then grow your own cloud platform by adding more hypervisors, storage pools, and \nother features.\nIf you want to use public clouds based on open source technology to run the operating  \nsystems that you need, you can use any of several different cloud providers. Public cloud \nproviders that you can use to run Linux VMs include Amazon Web Services ( www.amazon  \n.com/aws ), Google Cloud Platform ( https://cloud.google.com ), and Rackspace ( www \n.rackspace.com ). Chapter\u00a028, \u201cDeploying Linux to the Cloud,\u201d covers how to deploy \nLinux to some of these cloud providers.", "doc_id": "4659fa20-1455-4a24-a6e0-8e2089721696", "embedding": null, "doc_hash": "42add97ec53c4af48fc038977603f969dd2234ef9b17f0d69d25dcfbb99e873c", "extra_info": {"page_label": "730"}, "node_info": {"start": 0, "end": 2923}, "relationships": {"1": "65b56197-393e-4d6f-a4f4-a95fe3f8054b"}}, "__type__": "1"}, "a18ca057-d03a-4958-9661-9c4041de861e": {"__data__": {"text": "Chapter 27: Using Linux for Cloud Computing\n713\n27Trying Basic Cloud Technology\nTo help you understand cloud technology from the ground up, this section illustrates some \nof the basic building blocks of a modern cloud infrastructure. Using three computers, I\u2019ll \nhelp you create a setup that includes the following:\nHypervisors  A hypervisor  is a software component that allows you to run other mul -\ntiple computer systems on it. Those other systems are referred to as virtual machines \n(VMs) . A cloud infrastructure may have dozens or hundreds of hypervisors running, \npossibly running thousands of virtual machines.\nVirtual machines  The virtual machines that you run on a Linux hypervisor can be \nthe same type of Linux system, a different Linux system, a Windows system, or any \nother type of system that is compatible with the hardware on which the hypervisor \nruns. Thus, the virtual machines that run on the hypervisors that we will build here \ncould include Fedora, Ubuntu, RHEL, CentOS, Microsoft Windows, and others.\nShared storage To offer the greatest flexibility, the storage that hypervisors make \navailable to virtual machines is often shared among a pool of hypervisors. This \nallows a set of hypervisors to share a set of images that they use to install or start \nvirtual machines. It also lets the same set of virtual machines run on any hypervi-\nsor in that group and even move to a different hypervisor without shutting down \nthe VM. Moving running VMs can be useful if a hypervisor becomes overloaded or if \nit needs to be shut down for maintenance.\nThe setup we build in the following procedure allows you to work with VMs in these ways:\n\u25a0\u25a0Installing a new VM on a hypervisor\n\u25a0\u25a0Setting features on your VMs\n\u25a0\u25a0Logging in to and using a VM running on a hypervisor\n\u25a0\u25a0Migrating running VMs to another hypervisor\nWe will explore the following technologies:\nKernel-based Virtual Machine (KVM))  KVM is the basic kernel technology that \nallows virtual machines to interact with the Linux kernel.\nQEMU Processor Emulator  One qemu  process runs for each active virtual machine on \nthe system. QEMU provides features that make it appear to each virtual machine as \nthough it is running on physical hardware.\nLibvirt Service Daemon ( libvirtd ) A single libvirtd  service runs on each \nhypervisor. The libvirtd  daemon listens for requests to start, stop, pause, and \notherwise manage virtual machines on a hypervisor. Those requests can come from \nan application designed to manage virtual machines (such as virt-manager  or \nOpenStack Dashboard) or from an application that you create to talk directly to the \nlibvirt  application programming interface.", "doc_id": "a18ca057-d03a-4958-9661-9c4041de861e", "embedding": null, "doc_hash": "3b4cf34d97c091fcab67941c327d1a2534730f509fadb33164bbd5a8dfb0f649", "extra_info": {"page_label": "731"}, "node_info": {"start": 0, "end": 2670}, "relationships": {"1": "0704ec82-dd9d-4475-bfc2-d8c760d8c7f1"}}, "__type__": "1"}, "a7ca5fee-0582-4e4a-99d9-d423af12be95": {"__data__": {"text": "Part VI: Engaging with Cloud Computing714Virtual Machine Manager  The Virtual Machine Manager ( virt-manager  command) \nis a GUI tool for managing virtual machines. Besides letting you request to start and \nstop virtual machines, virt-manager  lets you install, configure, and manage VMs \nin different ways. You can use the virsh  command to pass options to the command \nline to work with virtual machines instead of clicking in a GUI window.\nVirtualization Viewer  The virt-viewer  command launches a virtual machine \nconsole window on your Desktop. The window that appears allows you to work \nfrom a console window to a Desktop or command-line interface to the selected vir -\ntual machine (depending on what that VM has to offer). What this means is that \nsomeone consuming your PaaS could bundle together their own operating system, \napplication, configuration files, and data and deploy them. They would rely on your \nPaaS to provide the compute power, storage, memory, network interfaces, and man -\nagement features needed to run the virtual machines containing their applications.\nThe next section gives you your first taste of some of the foundational technologies of \nLinux clouds. It describes how to set up a small cloud by configuring your own hypervisors, \nvirtual machines, and virtual storage.\nSetting Up a Small Cloud\nWith three physical machines connected together on a network, you can illustrate some \nof the basic concepts that you need in order to understand how to build your own cloud. \nThe three computers running Fedora 30 and the network connecting them are configured \nas follows:\nNetworking  A high-speed, wired network was set up to connect the three computers. \nFast network connections are critical to successful VM migration. In this example, \neach hypervisor also has a network bridge configured so that each virtual machine \ncan pick up an IP address directly from a DHCP service on the network.\nHypervisors  Two of the computers are configured as hypervisors. A hypervisor  (some -\ntimes referred to as a host  or a compute node ) allows you to run virtual machines. \nIn Fedora 30, the basic hypervisor technology is called Kernel-based Virtual Machine \n(KVM) , while the actual virtual machines are managed by the libvirtd  service.\nStorage  One computer is configured to offer shared storage between the two hypervi-\nsors. For simplicity, NFS is used to create the shared storage, although in a produc -\ntion environment, iSCSI or Fibre Channel would be better solutions.\nNote\nFor test purposes, you could use one of the two hypervisors to provide the shared storage. However, one of the main \npurposes of configuring two hypervisors and separate shared storage is that you want to be able to shut down any \nhypervisor and still have all of your virtual machines operate normally. If you have shared storage available from \none of the hypervisors, you could never bring that hypervisor down without shutting down all of the VMs using that \nstorage.", "doc_id": "a7ca5fee-0582-4e4a-99d9-d423af12be95", "embedding": null, "doc_hash": "1eb40b25c3192a253c2ac375f46343bbd96e02ca694d81471eab7e89b8fda2f7", "extra_info": {"page_label": "732"}, "node_info": {"start": 0, "end": 2984}, "relationships": {"1": "31d4c388-bbe8-4bc2-bd60-10ed6c3a934d"}}, "__type__": "1"}, "3472e04c-a05a-421d-ba58-dffc4bbb0d78": {"__data__": {"text": "Chapter 27: Using Linux for Cloud Computing\n715\n27Configuring hypervisors\nIn the following procedure, I installed Fedora 30 on two physical computers and configured \nthem as KVM hosts running the libvirtd  service. Follow these steps to accomplish this \nfor yourself.\nStep 1: Get Linux software\nGo to the Get Fedora page ( https://getfedora.org ) and download Fedora 30. I chose to \ndownload the Fedora 30, 64-bit Workstation edition DVD ISO. If a later version of Fedora is \navailable, you could likely use that instead.\nUse any available DVD burning application to burn the image to a DVD or otherwise make \nthe image available to install (such as by PXE booting).\nStep 2: Check your computers\nThe computers you use as hypervisors in Fedora 30 need to meet a few requirements. You \nshould check the following on your computer before you start installing:\nSupports virtualization . You can check for virtualization support by looking at the \nflags set in the CPU.\nMemory . The computer must have enough RAM not only to run the host operating \nsystem, but also for each virtual machine that you expect to run on the system.\nProcessing power . Keep in mind that each virtual machine consumes processing power \nfor itself and any application running inside the virtual machine.\nStorage is another consideration. However, because we intend to configure storage from a \nseparate node on the network, we will address that issue later.\nTo check that the available features of your computers meet the requirements, boot a Linux \nLive CD or DVD, open a Terminal window, and type the following commands:\n# cat /proc/cpuinfo | grep --color -E \"vmx|svm|lm\"\n \nflags  : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca\ncmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe\nsyscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts\nrep_good xtopology nonstop_tsc aperfmperf pni pclmulqdq dtes64\nmonitor ds_cpl vmx smx es...\n...\n \nRunning the above command shows that this computer is a 64-bit computer ( lm) and that \nan Intel chip supports virtualization features ( vmx). If the CPU were an AMD chip that sup -\nported virtualization, instead of vmx , you would see svm  highlighted. Those settings show \nthat this computer can be used as a hypervisor.\nWhen you start running VMs on a host, memory is often the bottleneck. For memory \nrequirements, you must add what is needed by the host to whatever you need for each VM. ", "doc_id": "3472e04c-a05a-421d-ba58-dffc4bbb0d78", "embedding": null, "doc_hash": "fb646f013ebc0ef2ca7c4138065aed059227f7fbab2fd7e5a56b3198a613e02f", "extra_info": {"page_label": "733"}, "node_info": {"start": 0, "end": 2432}, "relationships": {"1": "866cb3a8-b37b-4511-9e51-6cf018461fad"}}, "__type__": "1"}, "37dd03c3-47b0-4189-af7b-eefceac8e947": {"__data__": {"text": "Part VI: Engaging with Cloud Computing716You can lower memory requirements by not having Desktop software installed, as most \nhypervisors do. In this case, however, I performed a Fedora Workstation install, which \ncomes with a Desktop. To check the memory and swap on the computer, I entered the \nfollowing:\n# free -m\n              total        used        free      shared  buff/cache   available\nMem:          15318        4182        6331        1047        4805        9678\nSwap:          7743           0        7743\n \nThis system has about 16Gb of RAM and 8Gb of swap. I estimate that 4Gb is good for a Desk -\ntop system. If I allow 1Gb or 2Gb for each VM, this system should be able to run 6\u201312 VMs \nalong with the Desktop. Check the memory requirements for the operating systems and the \napplications that you plan to run to determine your particular memory needs.\nTo check the number and types of processors on your computer, enter the following:\n# grep processor /proc/cpuinfo\n \nprocessor : 0\n...\nprocessor : 6\nprocessor : 7\n# head /proc/cpuinfo\nprocessor  : 0\nvendor_id  : GenuineIntel\ncpu family : 6\nmodel      : 60\nmodel name : Intel(R) Core(TM) i7-4800MQ CPU @ 2.70GHz\nstepping   : 3\ncpu MHz    : 2701.000\ncache size : 6144 KB\n...\nThe first command in the preceding code shows that there are eight (0 through 7) proces -\nsors on the computer. The second command for the first processor shows that it is Genuin -\neIntel, the model number, model name, CPU speed, and other information.\nTo do live VM migration between the two hypervisors, the CPUs must be in the same fam-\nily. If they don\u2019t have compatible CPUs, you could migrate a VM by shutting it down on one \nhypervisor and starting it up from shared storage on the other.\nAfter you have sized up the two hypervisor computers, start installing Fedora on them.\nStep 3: Install Linux on hypervisors\nUsing the Fedora 30 Workstation installation media, begin installing the two hypervisors. \nFollow descriptions in Chapter\u00a09, \u201cInstalling Linux,\u201d for installing Fedora. You should know \nthe following things, which are specific to the installation for this procedure:", "doc_id": "37dd03c3-47b0-4189-af7b-eefceac8e947", "embedding": null, "doc_hash": "1afb6ccfbebcca7820264a51d4f35c765627fcdf707025272f96d0dd444d14a7", "extra_info": {"page_label": "734"}, "node_info": {"start": 0, "end": 2130}, "relationships": {"1": "dfcf074c-7e32-42b5-a0a9-ad2028f486a2"}}, "__type__": "1"}, "4e3c3e71-2216-4e46-a310-a2a425c2839a": {"__data__": {"text": "Chapter 27: Using Linux for Cloud Computing\n717\n27Name the hypervisors  I set the hostnames on the hypervisors to host1.example  \n.com  and host2.example.com .\nPartitioning  When partitioning, I erase the entire hard disk. Then I create a 500Mb \n/boot  partition and a 12Gb swap partition, and I assign the rest of the disk \nspace to the root partition ( /). The /var/lib/libvirt/images  directory holds \nmost of the data on this system, but that is a shared directory, available from \nanother system on the network and shared between the two hypervisors. (More on \nthat later.)\nNetworking  If given the option, turn on wired network interfaces for each hypervi-\nsor. The hypervisors and storage should all be on the same local network, because \nthe speed of your network connection among those machines is critical to getting \ngood performance.\nSoftware packages During installation, I install only the default Fedora Workstation \npackages. After installation is complete and the system is rebooted, I install more of \nthe software that\u2019s needed for each hypervisor.\nReboot the computer when installation is finished (ejecting the DVD and starting up on the \nhard drive). After the system is rebooted, update the Fedora software, add new packages, \nand reboot the system again as follows:\n# yum update -y\n# yum install virt-manager libvirt-daemon-config-network\n# reboot\nThe virt-manager  package contains the GUI tool for managing your virtual machines. \nThe libvirt-daemon-config-network  package creates the default network interface \nthat lets the virtual machines access external networks (through the host) using Network \nAddress Translation (NAT). The default address range assigned to the virtual machines is \n192.168.122.2 through 192.168.122.254.\nOther packages that you will need should already be included with the Fedora Workstation \ninstall. If you did a different install type, make sure that you have the following packages \nalso added:\n\u25a0\u25a0libvirt-client  (for the virsh  command)\n\u25a0\u25a0libvirt-daemon  (to get the libvirtd  service)\nStep 4: Start services on the hypervisors\nYou need to make sure that the libvirtd  service is running on both hypervisors. Start \nthe sshd  service as well. They may already be running, but just to make sure, do the fol -\nlowing as root on both hypervisors:\n# systemctl start sshd.service\n# systemctl enable sshd.service\n# systemctl start libvirtd.service\n# systemctl enable libvirtd.service", "doc_id": "4e3c3e71-2216-4e46-a310-a2a425c2839a", "embedding": null, "doc_hash": "9c43fe228ca8d7966c45c79cd828c9019a7560381ef65044ec9732a5330b6e6b", "extra_info": {"page_label": "735"}, "node_info": {"start": 0, "end": 2437}, "relationships": {"1": "503e268c-d523-44c1-aabc-e63da374754e"}}, "__type__": "1"}, "e54a2b40-ca83-465a-9256-c30746d157d3": {"__data__": {"text": "Part VI: Engaging with Cloud Computing718The sshd  service allows you to log into the hypervisors over the network, if necessary. The \nlibvirtd  service is the one with which you may be unfamiliar. It is listening for requests \nto manage your virtual machines on each host.\nStep 5: Edit /etc/hosts, or set up DNS\nTo make it convenient to communicate between the hypervisors and storage system, you \nshould assign hostnames to each system and map those names to IP addresses. Setting up a \nDNS server to which all the systems point is probably the best way to do that. However, for \nour simple example, you can just edit the /etc/hosts  file on each system and add entries \nfor each host.\nHere is an example of what additional entries to your /etc/hosts  file might look like for \nthe three systems used in this procedure:\n192.168.0.138  host1.example.com host1\n192.168.0.139  host2.example.com host2\n192.168.0.1    storage.example.com storage\nNext you need to configure the storage.\nConfiguring storage\nYou can provide networked storage to the hypervisors for this procedure in many ways. I \nchose to set up a separate Fedora system on the same local network as the hypervisors and \nuse NFS to attach the shared storage to both hypervisors.\nNFS is not the most efficient method of sharing storage among hypervisors, but it is one of \nthe easiest and most common to set up. In this procedure, I use the Virtualization Manager \nGUI tool (virt-manager ) to configure the NFS storage pool.\nFor consistency\u2019s sake, the NFS share set up from the storage system is the /var/lib/\nlibvirt/images  directory. It is mounted in the same place on each of the hypervisors. \n(For testing, if you only have two machines available, you can configure storage from one \nof the hypervisors. Keep in mind, however, that this means that you can\u2019t turn off that \nhypervisor without shutting down all of your VMs.)\nStep 1: Install Linux software\nTo set up your storage on an NFS server, you can use pretty much any Linux system that \nhas an NFS service available. Consider these things when you install Linux:\nDisk space . Make sure that you have enough storage space available on the partition \nthat contains the shared directory. For this example, /var/lib/libvirt/images  \nis the shared directory.\nPerformance . For best performance, you want to have a disk that has fast access times \nand data transfer rates.", "doc_id": "e54a2b40-ca83-465a-9256-c30746d157d3", "embedding": null, "doc_hash": "02978fca17d2e41de1b6e1228238f50e7045883e4adf7e6b4d62633c0a3fe381", "extra_info": {"page_label": "736"}, "node_info": {"start": 0, "end": 2389}, "relationships": {"1": "4077461b-f287-48d2-bb79-8afb97915f45"}}, "__type__": "1"}, "a2900eb4-d0be-4a22-804b-79eaee783be5": {"__data__": {"text": "Chapter 27: Using Linux for Cloud Computing\n719\n27For Fedora and RHEL, NFS server software is available from the nfs-utils  package. For \nUbuntu, you need the nfs-kernel-server  package. After initial installation is finished, \ncheck that the NFS server software is installed. If it isn\u2019t, you can install it on Fedora or \nRHEL with this command:\n# yum install nfs-utils\nFor Ubuntu and similar systems, type this:\n# apt-get install nfs-kernel-server\nStep 2: Configure NFS share\nTo create an NFS share, you need to identify the directory to share and add information \nabout it to the /etc/exports  file. Follow these steps:\na. Create a directory . You can share any directory containing the space that you \nwant to share. Consider making a new directory and mounting a whole disk or \npartition on it. For this example, I create a directory named /var/storage  \nas follows:\n# mkdir -p /var/storage\nb. Allow exporting . On your storage system, create an entry in the /etc/exports  \nfile to share the directory with selected systems (by name or IP address). For \nthis example, I allowed read-write access ( rw) to all systems on the 192.168.0 \nsubnetwork:\n/var/storage 192.168.0.*(no_root_squash,rw,sync)\nStep 3: Start the NFS service\nStart the NFS service and open the firewall on the storage system to allow access to that \nservice. Here\u2019s how:\na. Start and enable NFS . On the latest Fedora and RHEL systems, enter the following \nto start the NFS server:\n# systemctl start nfs-server.service\n# systemctl enable nfs-server.service\nOn RHEL 6, older Fedora, and some Ubuntu systems, use these commands to start \nand enable the NFS service:\n# service nfs start\n# chkconfig nfs on\nb. Open the firewall . To open the firewall ports so that those outside the local system \ncan use your NFS share, do the following on Fedora 30:\n# firewall-cmd --permanent --add-service=rpc-bind\n# firewall-cmd --permanent --add-service=nfs\n# systemctl restart firewalld\nFor systems using iptables  directly, see Chapter\u00a020 for information on how to open your \nfirewall for the NFS service.", "doc_id": "a2900eb4-d0be-4a22-804b-79eaee783be5", "embedding": null, "doc_hash": "7a444cba5ec23c6b907b1130b70fa787180fb9905084442fe788f93e778854b3", "extra_info": {"page_label": "737"}, "node_info": {"start": 0, "end": 2064}, "relationships": {"1": "303a2888-9f58-4433-a6d0-75f9a5a3c7e4"}}, "__type__": "1"}, "f753a8db-e056-458e-be3c-f95c3e4306cb": {"__data__": {"text": "Part VI: Engaging with Cloud Computing720Step 4: Mount the NFS share on the hypervisors\nLog in to each hypervisor and follow these steps to make the share available locally. Note \nthat the location of the mount point directory on each hypervisor must be the same. \nHere\u2019s how:\na. Check the NFS share availability . From each of the two hypervisors, make sure \nthat you can see the available share by entering the following:\n# showmount -e storage.example.com\nExport list for storage.example.com:\n \n/var/storage 192.168.0.*\nb. Mount the NFS share . Add information about the share to the /etc/fstab  file. \nFor our example, to allow the directory from the 192.168.0.1 system to be mounted \non the same directory locally each time the system boots, the entry in the /etc/\nfstab  file could look like this:\nstorage.example.com:/storage /var/lib/libvirt/images nfs defaults 0 0\nc. Set SELInux boolean. If SELinux is in enforcing mode, set the following boolean to \nallow qemu-kvm to use the NFS share:\n# setsebool -P virt_use_nfs 1\nd. Test the NFS mount . To check that you got the mount entry correct, run the fol -\nlowing command to mount all entries in the /etc/fstab  that have not already \nbeen mounted, and check that the NFS share was mounted:\n# mount -a\n# mount | grep libvirt\nstorage.example.com:/var/storage on /var/lib/libvirt/images type nfs4\n(rw,relatime,vers=4.0,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,\nport=0,timeo=600,retrans=2,sec=sys,clientaddr=192.168.0.1,local_lock=none,\naddr=192.168.0.138)\nWith your hypervisors and storage now in place, you can begin creating your virtual  \nmachines.\nCreating virtual machines\nThe Virtual Machine Manager ( virt-manager ) is a good tool to use to create you first vir -\ntual machines. It steps you through the installation and setup of virtual machines, and it \nprovides a way to view and change the status of your existing virtual machines.\nLater, when you understand the kinds of features that go into creating virtual machines, \nyou can use the virt-install  command to create virtual machines instead. The ", "doc_id": "f753a8db-e056-458e-be3c-f95c3e4306cb", "embedding": null, "doc_hash": "7ae2fba56f3e1fa3b8739690369bd8b6165b42a5589074b43a605f764f12281f", "extra_info": {"page_label": "738"}, "node_info": {"start": 0, "end": 2078}, "relationships": {"1": "863b2bcd-a573-44f0-b222-dbf493fea942"}}, "__type__": "1"}, "45edf86d-776f-4c15-a56d-9fab04adc046": {"__data__": {"text": "Chapter 27: Using Linux for Cloud Computing\n721\n27advantage of virt-install  is that you can script or easily copy and paste a command \nline to create a virtual machine instead of having to click through a GUI window.\nYou downloaded the Fedora 30 Workstation ISO image earlier in this chapter, so I\u2019ll use that \nin the example for creating a virtual machine. However, if you prefer, you can install many \ndifferent versions of Linux or Windows as your virtual machine.\nStep 1: Get images to make virtual machines\nYou can create a virtual machine in many ways. In general, you start with either a pre-built \nimage (basically a copy of a working virtual machine) or just install from an installation \nISO image into a fresh storage area. Here we are going to do the latter and create a VM from \nthe Fedora 30 Workstation installation ISO image.\nAssuming that you are logged in to one of the hypervisors as root and the ISO image is in \nthe current directory, copy the ISO to the default directory used by virt-manager  for \nstorage (/var/lib/libvirt/images ):\n# cp Fedora-Workstation-Live-x86_64-30-1.2.iso /var/lib/libvirt/images/\nBecause that directory is shared by both hypervisors, you can go to either hypervisor to \nuse that image.\nStep 2: Check the network bridge\nOn each hypervisor, there should be a default network bridge named virbr0 . All virtual \nmachines will be added to this network interface and automatically assigned an IP address. \nThis default bridge exists due to libvirtd\u2019s default virtual network. By default, the hypervi-\nsor uses the address range of 192.168.122.2 through 192.168.122.254 to assign to the virtual \nmachines. Using Network Address Translation (NAT), the host can route packets from the \nvirtual machines using these private addresses to external network interfaces.\nDo the following on each hypervisor to check the bridge for each:\n# brctl show virbr0\n \nbridge name  bridge id            STP enabled  interfaces\nvirbr0       8000.001aa0d7483e    yes          vnet0\n# ip addr show virbr0\n \n5: virbr0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue\n        state UP group default\n    link/ether fe:54:00:57:71:67 brd ff:ff:ff:ff:ff:ff\n    inet 192.168.122.1 brd 192.168.122.255 scope global \ndynamic virbr0", "doc_id": "45edf86d-776f-4c15-a56d-9fab04adc046", "embedding": null, "doc_hash": "f4945096549c351298845d03a1db268c2bf1ef29b339327d640a36c9beb3772b", "extra_info": {"page_label": "739"}, "node_info": {"start": 0, "end": 2254}, "relationships": {"1": "c3473cf6-b761-4ea4-91d8-d17ad08b6f45"}}, "__type__": "1"}, "1c733f74-dbbd-4cbe-8890-8fefb5eb9adc": {"__data__": {"text": "Part VI: Engaging with Cloud Computing722Step 3: Start Virtual Machine Manager (virt-manager)\nFrom the Desktop on either hypervisor, do the following to open Virtual Machine Manager \nand connect it to the hypervisor:\na. Start virt-manager . Go to the Activities screen, type Virtual Machine Man -\nager into the search box, and press Enter, or type virt-manager  from the shell. \nType the root password when prompted. You should see the Virtual Machine Man -\nager window.\nb. Check the connection to the hypervisor . From the Add Connection pop-up, the \nhypervisor (QEMU/KVM) should already be set and the Autoconnect check box \nshould be checked. Click Connect to connect to the local hypervisor if it has not \nalready been done.\nStep 4: Check connection details\nAfter connecting to the hypervisor, set up some connection details. To do that, from the \nVirtual Machine Manager window, do the following:\na. View the connection details . Select Edit \u27aa  Connection Details to see the Connec -\ntion Details window. Select the Overview, Virtual Networks, Storage, and Network \nInterfaces tabs to familiarize yourself with connection information for your hyper -\nvisor. For example, the Storage tab appears in Figure\u00a027.1, showing that there are \n438.40Gb of free space in the location used by default for storage by this hypervisor \n(/var/lib/libvirt/images  directory).\nb. Check that the network bridge is available . Select the Virtual Networks tab, and \nmake sure that the bridge ( virbr0)  is in the list of available network interfaces.\nStep 5: Create a new virtual machine\nTo create a new virtual machine from the Virtual Machine Manager window, do the \nfollowing:\na. Start the wizard . To start the Create a New Virtual Machine Wizard, select File \u27aa \nNew Virtual Machine. The Create a New Virtual Machine window appears.\nb. Choose the installation method . Four ways of creating the virtual machine are \npresented. The first three are ways to identify the location of installation media. \nThe fourth lets you import an existing disk image. For our example, choose the first \nselection (Local install media) and click Forward.\nc. Choose the ISO . Select the Use ISO Image button and choose Browse. In the window \nthat appears, select or browse to the Fedora 3021 Workstation ISO, select Choose \nVolume, and click Forward to continue.\nd. Choose the memory and CPU . Choose the amount of RAM and number of proces -\nsors available to the VM and click Forward. I suggest at least 1024Mb of RAM and at \nleast one processor. Using 2048Mb of RAM, if it is available, is better.", "doc_id": "1c733f74-dbbd-4cbe-8890-8fefb5eb9adc", "embedding": null, "doc_hash": "a31c475b619535ca90d2b890e044bd0e87cbd6a87092a684d1912986d094f7e7", "extra_info": {"page_label": "740"}, "node_info": {"start": 0, "end": 2570}, "relationships": {"1": "cd7d2a43-f9e0-4d69-b7f6-cd9f96eaf9a6"}}, "__type__": "1"}, "651bb172-6715-486c-a170-f215d4de72ca": {"__data__": {"text": "Chapter 27: Using Linux for Cloud Computing\n723\n27e. Enable storage . Choose the amount of disk space that you want the VM to con -\nsume. I suggest at least 10Gb for a Fedora Workstation, but you could probably get \nby with less. The qcow2  image that is created grows to the size you actually con -\nsume (up to the amount allocated), so over-allocating space causes no problem until \nyou actually try to use that space. Set the cache mode to none  or directsync  to \nbe able to migrate the VM later. Click Forward.\nf. Review the settings before the installation starts . Choose the name for the vir -\ntual machine, and review the other settings for your installation. Select Customize \nConfiguration Before Install to further review settings. Leave other settings at the \ndefault for now, and click Finish.\ng. Review the hardware settings . If you selected Customize on the previous screen, \nyou can review the settings in more detail. Make sure the cache mode is set to \nnone  or directsync . When you are satisfied, select Begin Installation.\nlocalhostFIGURE 27.1\nStart Virtual Machine Manager and check connection details.", "doc_id": "651bb172-6715-486c-a170-f215d4de72ca", "embedding": null, "doc_hash": "82cd17883aea4eceb7de6ac8fa7e2b6753f09974b1d6c084cc185e6ba9e594a6", "extra_info": {"page_label": "741"}, "node_info": {"start": 0, "end": 1126}, "relationships": {"1": "e353f117-93bb-4029-a9a0-32e620df4146"}}, "__type__": "1"}, "40d35dc9-d9c3-4975-8b0a-7bd7daae3b4e": {"__data__": {"text": "Part VI: Engaging with Cloud Computing724h. Install the virtual machine . You are prompted to install the system just as you \nwould be if you were installing directly to hardware. Complete the installation, and \nreboot the virtual machine. If the VM window isn\u2019t open, double-click the VM entry \n(in this case, fedora1) in the virt-manager  window and log in. Figure\u00a027.2 shows \nan example of the virt-manager  window with the Fedora Workstation virtual \nmachine displayed.\nManaging virtual machines\nAfter you have one or more virtual machines installed on a hypervisor, you can manage \neach VM in much the same way that you manage a computer system installed directly on \nhardware. You can do the following:\n\u25a0\u25a0View the system from a console . Double-click a running VM in the virt-man -\nager  window. A console window opens to the VM, allowing you to use the VM \nFIGURE 27.2\nOpen the virtual machine and begin using it.", "doc_id": "40d35dc9-d9c3-4975-8b0a-7bd7daae3b4e", "embedding": null, "doc_hash": "4e9b73c2e4654d92c44b4acb0d6c726ff8032e908f94b7d75fbc505a26dfc36e", "extra_info": {"page_label": "742"}, "node_info": {"start": 0, "end": 920}, "relationships": {"1": "c247cee0-02b6-47ae-905e-342b98d6915c"}}, "__type__": "1"}, "ad195f0c-e603-4a5b-93d3-37bd6c81afef": {"__data__": {"text": "Chapter 27: Using Linux for Cloud Computing\n725\n27just as you would from a physical console to access an operating system installed \ndirectly on the hardware. You can bypass virt-manager  to display a VM\u2019s console \ndirectly with virt-viewer . For example, for a VM named rhel8-01 , type  \nvirt-viewer rhel8-01 .\n\u25a0\u25a0Shut down the VM . Right-click the VM entry and select Shut Down. Then select \neither Shut Down (to shut down properly) or Force Off (effectively pulling the plug). \nOr, you can select Reboot.\n\u25a0\u25a0Start the VM . If the VM is currently shut down, right-click the entry and select \nRun to start the VM running.\n\u25a0\u25a0Delete the VM . If you are totally finished using the VM, select Delete. You are \nasked if you want to delete the storage as well. Uncheck the box if you want to \nkeep the storage associated with the VM.\nNow that you are comfortable using your virtual machines, you can try migrating a VM to \nanother hypervisor.\nMigrating virtual machines\nBeing able to migrate your virtual machines between different hypervisors gives you \ntremendous flexibility in managing your computer workloads. Here are some of the \nadvantages:\n\u25a0\u25a0Improve performance  by moving VMs from hypervisors that are overloaded to ones \nthat have more available memory and CPU capacity.\n\u25a0\u25a0Do routine maintenance  on a hypervisor while keeping your VMs running.\n\u25a0\u25a0Move VMs off underutilized hypervisors so that you can shut them off to save energy \nuntil they are needed again.\n\u25a0\u25a0Move VMs off site if you are expecting to shut down a data center or you are expect -\ning a hurricane or other catastrophe to hit your data center.\nLive migration, in particular, is valuable if you need work to continue on the VMs without \ninterruption. The key to getting live VM migration to work is setting up your environment \nproperly. Make sure the following things are in place (keep in mind that these are the \nkinds of features that something like Red Hat Virtualization does for you):\n\u25a0\u25a0Shared networked storage among the hypervisors.\n\u25a0\u25a0The same network interfaces configured on each hypervisor.\n\u25a0\u25a0Compatible CPUs between hypervisors. (Often, a set of hypervisors have the exact \nsame hardware.)\n\u25a0\u25a0A fast network connection between the hypervisors and storage.\n\u25a0\u25a0The same or similar versions of virtualization software on the hypervisors. (In our \ncase, we used Fedora 30 on both and installed them similarly.)\nWith all that in place, live migration requires only a few steps to get going.", "doc_id": "ad195f0c-e603-4a5b-93d3-37bd6c81afef", "embedding": null, "doc_hash": "2ea1ac9e72f79a88359ef7eebce77ac116203afb3d72f65a47bbac3a9dfc5b7d", "extra_info": {"page_label": "743"}, "node_info": {"start": 0, "end": 2466}, "relationships": {"1": "2abad730-9c71-4820-b774-819fdc23548f"}}, "__type__": "1"}, "c0a78c56-41da-417e-bed8-694a2948df90": {"__data__": {"text": "Part VI: Engaging with Cloud Computing726Step 1: Identify other hypervisors\nAssuming the Virtual Machine Manager window is still up and running on one of your \nhypervisors, go to that window and do the following to connect to the other hypervisor:\na. Connect to the hypervisor. Select File \u27aa  Add Connection. The Add Connection \nwindow should appear.\nb. Add the connection . Select the Connect to Remote Host check box, choose SSH as \nthe method, use the user name root, and type the hostname of the other hyper -\nvisor (for example, host1.example.com ). When you click Connect, you may be \nprompted to enter a password for the remote hypervisor\u2019s root user and enter other \ninformation. Note that you might need to install the openssh-askpass  package \nto be prompted for the password.\nAn entry for the new hypervisor should appear on the Virtual Machine Manager window.\nStep 2: Migrate running VM to Other hypervisor\nBefore you can migrate the VM to another hypervisor, you might need to adjust your \nfirewall rules. With the default firewall rules in place, direct libvirt migration will fail. \nA random TCP port needs to be opened to allow the migration. The default is 49152, but \nany available, non-privileged port can be chosen. Tunneled migration requires SSH key \nauthentication.\nWith the Virtual Machine Manager open, right-click your mouse on any VM that is currently \nrunning and select Migrate. The Migrate the Virtual Machine window appears, as shown in \nFigure\u00a027.3:\nSelect the new host. In my example, the VM is currently running on host2 , so I want to \nselect host1  as the new host. After a bit of time for the memory image of the VM to copy \nover to the other host, the VM should appear as running on that host.\nIf for some reason your migration fails (incompatible CPUs or other problems), you can \nalways shut down the VM on one host and start it again on the other host. Doing that only \nrequires that your shared storage is in place. On the second host, simply run the Create \na New Virtual Machine Wizard, but select to run an existing image instead of an instal -\nlation ISO.\nThe hypervisor configuration I just demonstrated might suit you well for your home work -\nstation or even for a small business. Although it is beyond the scope of this book to help \nyou develop an entire cloud computing platform, it is within my charter to help you \nuse different cloud platforms to run your Linux systems. The next chapter helps you do \njust that.", "doc_id": "c0a78c56-41da-417e-bed8-694a2948df90", "embedding": null, "doc_hash": "166085a4055c271682bb577a88ddeede51ed7f16239e9fcb3ba5b99066560eab", "extra_info": {"page_label": "744"}, "node_info": {"start": 0, "end": 2467}, "relationships": {"1": "93173e0a-b205-4d75-b5a0-bac84604e7ea"}}, "__type__": "1"}, "7568404e-7c21-4f77-9a30-6c446080308e": {"__data__": {"text": "Chapter 27: Using Linux for Cloud Computing\n727\n27Summary\nLinux is the foundation on which most of today\u2019s emerging cloud technologies are being \nbuilt. This chapter describes many of the basic components that go into building a cloud \nbased on Linux and other open source technologies. It then helps you to learn about \nsome of those basic technologies by setting up a couple of hypervisors and launching vir -\ntual machines.\nExercises\nThe exercises in this section describe tasks related to setting up a hypervisor (KVM host \ncomputer) and using it to run virtual machines. If you are stuck, solutions to the tasks are \nshown in Appendix B. Keep in mind that the solutions shown in Appendix B are usually \njust one of many ways to complete a task.\nFIGURE 27.3\nChoose which hypervisor to migrate the VM to.", "doc_id": "7568404e-7c21-4f77-9a30-6c446080308e", "embedding": null, "doc_hash": "d945f89224163f6a64cc8079dd184205de079de7f1ebf72dcb342aa05b92c28b", "extra_info": {"page_label": "745"}, "node_info": {"start": 0, "end": 807}, "relationships": {"1": "c1814021-75e4-48f0-bc68-c2bd30930482"}}, "__type__": "1"}, "55177e0f-2164-4617-8a6e-520c63f7dd48": {"__data__": {"text": "Part VI: Engaging with Cloud Computing728Although the example shown in this chapter for setting up hypervisors uses three physical \nmachines, these exercises can be done on a single physical machine.\n1. Check your computer to see if it can support KVM virtualization.\n2. Install a Linux system along with the packages needed to use it as a KVM host and \nto run the Virtual Machine Manager application.\n3. Make sure that the sshd  and libvirtd  services are running on the system.\n4. Get a Linux installation ISO image that is compatible with your hypervisor and \ncopy it to the default directory used by Virtual Machine Manager to store images.\n5. Check that the default network bridge ( virbr0 ) is currently active.\n6. Install a virtual machine using the ISO image you copied earlier.\n7. Make sure that you can log into and use the virtual machine.\n8. Check that your virtual machine can connect to the Internet or other network out -\nside of the hypervisor.\n9. Stop the virtual machine so that it is no longer running.\n10. Start the virtual machine again so that it is running and available.", "doc_id": "55177e0f-2164-4617-8a6e-520c63f7dd48", "embedding": null, "doc_hash": "d595dfcc7f8cadafcc9028455fb92709fb86e0f30df49e0db4c80315b7ca44af", "extra_info": {"page_label": "746"}, "node_info": {"start": 0, "end": 1094}, "relationships": {"1": "c5d6f6da-a902-42de-a038-ab7d91dc437a"}}, "__type__": "1"}, "0dc3a88c-c314-4277-b5cd-486ab8b71110": {"__data__": {"text": "729\nCHAPTER28\nDeploying Linux to the Cloud\nIN THIS CHAPTER\nCreating Linux cloud images\nDeploying a cloud image with virt-manager  (libvirtd )\nDeploying a cloud image to OpenStack\nDeploying a cloud image to Amazon EC2\nTo get a new Linux system to use, instead of just running, a standard installation program from \na physical DVD, you can get a Linux image and deploy it to a cloud. One way to do that is to \ntake a generic Linux image (one that is bootable but unconfigured) and provide information \nto configure it to suit your needs. Another way is to go to a cloud provider, choose an image, click \nthrough selections to configure it, and launch it.\nThe point is that cloud computing is offering up new ways to start up and use Linux systems. In \nChapter\u00a027, I had you do a standard Linux installation to create a virtual machine that runs on \na Linux hypervisor. In this chapter, I will show you how to use cloud images to start up a fresh \nLinux system.\nFirst, I describe how to use cloud-init  to combine a Linux cloud image manually with configu -\nration information in order to allow it to run in a variety of environments. Next, I tell you how a \nsimilar process is done on an OpenStack cloud or an Amazon Elastic Compute Cloud (EC2) by clicking \nthrough easy-to-use cloud controllers to choose images and settings to run the Linux cloud instance \nthat you want.\nGetting Linux to Run in a Cloud\nCloud platforms are great for spinning up new virtual machines quickly and efficiently. They \ncan do so because a fresh install is not required each time you want a new instance of an \noperating system.\nPublic clouds, such as Amazon EC2 ( http://aws.amazon.com/ec2 ), offer instances of different \nLinux distributions for you to start and use. You choose a Linux instance, such as Ubuntu, Red Hat \nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "0dc3a88c-c314-4277-b5cd-486ab8b71110", "embedding": null, "doc_hash": "2495f7293f899335876a487c8050708fdb3983343b2d7d22de42978c52cd5eb8", "extra_info": {"page_label": "747"}, "node_info": {"start": 0, "end": 1924}, "relationships": {"1": "09218358-23df-4ae9-8aeb-3d543942ec9f"}}, "__type__": "1"}, "984a3c16-f732-40e9-928f-d7552e54ec20": {"__data__": {"text": "Part VI: Engaging with Cloud Computing730Enterprise Linux (RHEL), or SUSE Linux Enterprise Server (SLES), which is tuned for spe -\ncific purposes. For example, there are instances that are optimized for high-performance \nprocessing or memory-intensive applications.\nThe content of a cloud instance tends to be generic in nature. It is expected that more \ninformation is attached to the image by the cloud user or the cloud provider using a service \nsuch as cloud-init . This information falls into two general categories: meta-data  and \nuser-data :\nmeta-data  Included with meta-data  is information that is needed before the image \nboots. This is data that is outside of the contents of the image and is typically \nmanaged by the cloud provider. Some of this data comes from the fact that things \nsuch as storage, memory, and processing power are drawn from a pool of resources \nrather than from the physical machine on which you are installing. So, the meta-\ndata  tells the cloud provider how many of those resources, and possibly others, to \nallocate early in the process of starting up the instance.\nuser-data  The user-data  information is inserted into the operating system that \nexists on the image. This is data that the person using the virtual machine pro -\nvides. This might include a user account and password, configuration files, com-\nmands to run on first boot, the identities of software repositories, or anything else \nthat you might want to run or change within the operating system itself.\nWhen you go to run a Linux instance in a cloud environment, you typically enter the \nmeta-data  and user-data  information by clicking check boxes and filling in forms from \na web-based cloud controller (such as the OpenStack Dashboard or Red Hat Virtualization \nManager). The information may not be identified as meta-data  and user-data  when you \nconfigure the instance through the cloud controller.\nThe cloud you use to run your Linux virtual machines may be a public cloud, a private \ncloud, or a hybrid cloud. The type of cloud you choose may depend on your needs and \nyour budget:\nPublic cloud  Amazon EC2 and Google Compute Engine are examples of cloud plat -\nforms that let you launch and use Linux virtual machines from a web-based inter -\nface. You pay for the time that the instance is running. The amount of memory, \nstorage, and virtual CPUs you use to run the service are also figured into the costs. \nThe advantage of public clouds is that you don\u2019t have to purchase and maintain \nyour own cloud infrastructure.\nPrivate cloud  With a private cloud, you put your own computing infrastructure in \nplace (hypervisors, controllers, storage, network configuration, and so on). Setting \nup your own private cloud means taking on more up-front costs to own and main -\ntain infrastructure. But it gives you added security and control of your comput -\ning resources. Because you control the infrastructure, you can create the images \nto which users have access in your OpenStack infrastructure and account for user \nusage of that infrastructure in your own way.", "doc_id": "984a3c16-f732-40e9-928f-d7552e54ec20", "embedding": null, "doc_hash": "9b0a2a7ae99a7f7b04cfdedba7b497d5da9a6561bbb2ca663e3a8592e1c8fd1a", "extra_info": {"page_label": "748"}, "node_info": {"start": 0, "end": 3079}, "relationships": {"1": "ab820acd-18bd-4912-a2a5-a20299e213cd"}}, "__type__": "1"}, "41b5f004-6fc0-4de8-a337-57090114b000": {"__data__": {"text": "Chapter 28: Deploying Linux to the Cloud\n731\n28Hybrid cloud  Many companies are looking toward hybrid cloud solutions. A hybrid \ncloud can allow multiple cloud platforms to be managed by a central facility. For \nexample, Red Hat CloudForms can deploy and manage virtual machines on Open -\nStack, VMware vSphere, and Red Hat Enterprise Virtualization platforms, provi-\nsioning different types of workloads to appropriate environments. At times of peak \ndemand, CloudForms can also direct virtual machines to run on Amazon EC2 clouds. \nThese cloud environments have different ways of provisioning and configuring vir -\ntual machines. However, the features that clouds need to provide to virtual machine \nmanagement are similar. Having an understanding of those features can help you \nwhen you configure a Linux system to run in a cloud.\nTo help you get a better feel for configuring Linux cloud instances, in the next sections I\u2019ll \ndescribe how cloud-init  works to configure Linux cloud instances. I\u2019ll then help you cre -\nate your own meta-data  and user-data  files and apply them to your cloud instance so \nthe information can be used when the cloud image boots.\nCreating Linux Images for Clouds\nThink about what you did when you installed a Linux system in Chapter\u00a09, \u201cInstalling \nLinux.\u201d During the manual installation process, you set a root password, created a reg -\nular user account and password, possibly defined your network interfaces, and did other \ntasks. The information you entered became a permanent part of the operating system that \nremained each time you booted the system.\nWhen you start with a prebuilt cloud image as your Linux system, you can use cloud-\ninit  to get a Linux system ready to run. The cloud-init  facility (http://launchpad.\nnet/cloud-init ) sets up a generic virtual machine instance to run in the way that you \nwant it to run without going through an install process. The next section describes some \nways of using cloud-init .\nConfiguring and running a cloud-init cloud instance\nIn the next procedure, I show you how to create data manually; the data can be combined \nwith a bootable Linux cloud image so that when that image boots, it is configured based on \nyour data. Combining data with the image at runtime allows you to change the data each \ntime before the image is run instead of installing it permanently in the image.\nI suggest that you run this procedure on one of the hypervisors you configured in Chap -\nter\u00a027, \u201cUsing Linux for Cloud Computing.\u201d This not only allows you to create the cus -\ntomized data for your Linux cloud image, but it also lets you run that image as a virtual \nmachine on that hypervisor.\nTo add data and run an existing cloud image, this procedure requires you to obtain a cloud \nimage, create data files, and generate a new image that combines those elements. This \nprocedure is meant to be very simple to get a cloud image booted. Later, I will tell you ", "doc_id": "41b5f004-6fc0-4de8-a337-57090114b000", "embedding": null, "doc_hash": "adcf2c10650ba24895d853e30e5ab7bc02665f12cec56c2590513bcc1645c3ac", "extra_info": {"page_label": "749"}, "node_info": {"start": 0, "end": 2934}, "relationships": {"1": "73d22555-4e99-4e66-87a8-9b98ef6d761f"}}, "__type__": "1"}, "f0d54a8e-f08c-4ca0-88e7-d9c82d4d2bc1": {"__data__": {"text": "Part VI: Engaging with Cloud Computing732how to add more features to these data files. To configure and run a cloud image, follow \nthese steps:\n1. Create cloud-init meta-data  file. Create a file named meta-data  to hold \ndata that identifies information about the cloud instance from the outside. For \nexample, you can add a name to identify the instance ( instance-id ), a hostname \n(local-hostname ), and other information. To keep your first try simple, I assign \nonly two fields. (You can set them to any names you like.)\ninstance-id: FedoraWS01\nlocal-hostname: fedora01\n2. Create cloud-init user-data  file. Create a file named user-data  to hold \ndata that configures inside the operating system on the image itself. For this \nsimple case, I just set a password for the default user (fedora) to cloudpass  and \nensured that cloud-init  does not expire the password:\n#cloud-config\npassword: cloudpass\nchpasswd: {expire: False}\n3. Combine data into a separate image . With the meta-data  and user-data  files \nin the current directory, create an ISO image that contains that data. Later, we \npresent this image as a CD-ROM to the Linux image so cloud-init  knows how \nto configure the Linux image. (Install the genisoimage  and cloud-init  pack -\nages first, if you haven\u2019t already. The cloud-init  package isn\u2019t required on the \nhypervisor.)\n# yum install genisoimage cloud-init\n# genisoimage -output fedora31-data.iso -volid cidata \\\n      -joliet-long -rock user-data meta-data\n4. Get a base cloud image . Cloud images for Ubuntu, Fedora, and RHEL are config -\nured for use with cloud-init . Get an official Fedora cloud image (images for other \ndistributions are described later), and do the following:\na. Go to getfedora.org. Open a web browser, and go to https://getfedora.org/\nen/cloud/download/ .\nb. Click OpenStack . Click the Download button that appears for the OpenStack  \nimage in order to get a qcow2  image that can be used in an OpenStack \nenvironment. The image name is something like Fedora-Cloud-Base-31-\n1.9.x86_64.qcow2 .\n5. Snapshot the image . You probably need to run this procedure a few times before \nyou get the exact image that you want. So, instead of using the downloaded image \ndirectly, make a snapshot of it. To keep track of my versions, I added 01  to the new \nsnapshot name:\n# qemu-img create -f qcow2 \\\n   -o backing_file=Fedora-Cloud-Base-31-1.9.x86_64.qcow2 \\\n   Fedora-Cloud-Base-01.qcow2", "doc_id": "f0d54a8e-f08c-4ca0-88e7-d9c82d4d2bc1", "embedding": null, "doc_hash": "5dbadff477ebed15489c67400c4327b52629979cf4a543269639a0a9bc156c45", "extra_info": {"page_label": "750"}, "node_info": {"start": 0, "end": 2433}, "relationships": {"1": "f754b4d5-cfc5-4423-b343-dd2b3e115f7f"}}, "__type__": "1"}, "4bc8c3b3-5f84-4fe4-86aa-5eadc27832ea": {"__data__": {"text": "Chapter 28: Deploying Linux to the Cloud\n733\n286. Copy files to the images directory . It\u2019s good practice to copy images to the /\nvar/lib/libvirt/images/  directory when you are using them on a hypervisor \n(libvirtd  service). For example, to copy the cloud image and data image to that \ndirectory, type the following:\n# cp Fedora-Cloud-Base-31-1.9.x86_64.qcow2 \\\n    Fedora-Cloud-Base-01.qcow2 \\\n    fedora31-data.iso          \\\n    /var/lib/libvirt/images/\n7. Start the cloud instance . With the files in place, run the following commands to \nstart an instance of your cloud image:\n# cd /var/lib/libvirt/images\n# virt-install --import --name fedora31-01 --ram 4096 --vcpus 2 \\\n  --disk path=Fedora-Cloud-Base-01.qcow2,format=qcow2,bus=virtio \\\n  --disk path=fedora21-data.iso,device=cdrom \\\n  --network network=default &\nThe previous virt-install  example shows that the virtual machine is assigned to con -\nsume 4Gb of RAM ( --ram 4096 ) and two virtual CPUs ( --vcpus 2 ). The RAM and VCPU \nvalues on your system may be different, depending on your computer\u2019s resources.\nAt this point, a virtual machine named fedora31-01  is running on your hypervisor. As \nthe virtual machine boots up, a console window should open allowing you to log into the \nnew cloud virtual machine.\nInvestigating the cloud instance\nTo investigate the cloud image that we created, you can open up the running instance and \nlook inside. One way to do that, if it is not already open, is to open the virtual machine \nwith virt-viewer :\n# virt-viewer fedora31-01\nFrom the console window that appears, use the data that we added to the image in order \nto log in. Use fedora  as the user and cloudpass  as the password to log in. The fedora  \nuser has sudo  privileges, so you can use that account to investigate the instance by enter -\ning some commands.\nHere you can see where the user-data  was copied into the instance:\n$ sudo cat /var/lib/cloud/instances/FedoraWS01/user-data.txt\n#cloud-config\npassword: cloudpass\nchpasswd: {expire: False}\nThe basic cloud configuration is done in the /etc/cloud/cloud.cfg file. You can see \nhere that the root user account is disabled by default. At the bottom of the file, you can \nsee that the user named fedora is the default user and has sudo privileges without \nrequiring a password.", "doc_id": "4bc8c3b3-5f84-4fe4-86aa-5eadc27832ea", "embedding": null, "doc_hash": "e2efc559afce72f25edb70459040016ade8de447291b665183e5250dcaff7efd", "extra_info": {"page_label": "751"}, "node_info": {"start": 0, "end": 2300}, "relationships": {"1": "f5e2a8b9-9d7d-4b95-a25c-eb5cee17d274"}}, "__type__": "1"}, "fa1d5db5-c4f5-43ec-b936-92b8e9c7752a": {"__data__": {"text": "Part VI: Engaging with Cloud Computing734$ sudo cat /etc/cloud/cloud.cfg\nusers:\n - default\ndisable_root: 1\n...\nsystem_info:\n  default_user:\n    name: fedora0\n    lock_paswd: true\n    gecos: Fedora Cloud User\n    groups: [wheel, adm, systemd-journal]\n    sudo: [\"ALL=(ALL) NOPASSWD:ALL\"]\n    shell: /bin/bash\n  distro: fedora\n  paths:\n    cloud_dir: /var/lib/cloud\n    templates_dir: /etc/cloud/templates\n  ssh_svcname: sshd\n \n# vim:syntax=yaml\n \nYou can see other things in the cloud.cfg  file as well. You can see which cloud_init_\nmodules run during initialization (such as those that set the hostname or start rsyslog  \nlogging). You can see cloud_config_modules that set the locale and the time zone and \nrun further configuration tools (such as Chef and Puppet).\nBecause yum  repositories are enabled, provided that you have an available network con -\nnection (DHCP should have assigned addresses to the virtual machine by default), you can \ninstall any packages available from the Fedora repositories.\nCloning the cloud instance\nIf you decide that you like the cloud instance you created, you can save a copy of it to run later \nby making a clone of the two images (cloud and data image) that make up the cloud instance. \nTo create a clone of the running cloud instance, using virt-manager, do the following:\n1. Launch virt-manager . On the host system running the virtual machine, run the \nvirt-manager  command or start Virtual Machine Manager from the Activities \nscreen on your desktop.\n2. Pause the virtual machine . Right-click the virtual machine instance entry in the \nvirt-manager  window and select Pause. This makes the virtual machine inactive \nfor the moment.\n3. Clone the virtual machine . Right-click the virtual machine instance entry \nagain and select Clone. The Clone Virtual Machine window appears, as shown in \nFigure\u00a028.1", "doc_id": "fa1d5db5-c4f5-43ec-b936-92b8e9c7752a", "embedding": null, "doc_hash": "c107dbedacec1c6791b946474b199ed00a29c327d4998a18b5b3e7314ccdec0f", "extra_info": {"page_label": "752"}, "node_info": {"start": 0, "end": 1848}, "relationships": {"1": "40b22f2a-b2e1-4bbc-b8cd-201976d3362b"}}, "__type__": "1"}, "85f672b6-0a8c-4ce9-8490-ea311f17ddb5": {"__data__": {"text": "Chapter 28: Deploying Linux to the Cloud\n735\n284. Choose clone settings . For the cloud-based image and the data image, you can \nchoose either to make new copies or share them with the existing virtual machine. \nAfter you do, select Clone.\nThe cloned cloud instance is now available to start, stop, and otherwise manage as you like \nfrom the Virtual Machine Manager window or the virsh  command. A great advantage of \nmaking clones is that you can make any changes that you like to them, without having to \nchange the originals. Just delete the clone when you are done, and you can quickly gen -\nerate a new one when you need it.\nExpanding your cloud-init configuration\nYou can add much more information to your meta-data  and user-data  files to configure \nyour cloud instances. Examples of cloud-init  settings can be found on the Cloud-Init \nFIGURE 28.1\nCloning lets you save a permanent copy of a cloud instance.", "doc_id": "85f672b6-0a8c-4ce9-8490-ea311f17ddb5", "embedding": null, "doc_hash": "e52784dc22eac793faf2b89d91f693753a895fe871b331b9fc6818d17c55cc9b", "extra_info": {"page_label": "753"}, "node_info": {"start": 0, "end": 916}, "relationships": {"1": "67f998e2-fbc6-415a-b844-846d76725cb6"}}, "__type__": "1"}, "c527ea3b-8a08-4c25-9e82-053f85f64fe0": {"__data__": {"text": "Part VI: Engaging with Cloud Computing736Config Examples page ( http://cloudinit.readthedocs.org/en/latest/topics/\nexamples.html ). The following sections show examples of settings that you can add to \nyour user-data  files.\nNote \nThe user-data  and meta-data  files are in yaml format. The yaml format uses indents and well-known delimiters. \nItems in a list are preceded by a hyphen and a space. Keys and values are separated by a colon and a space. If you are \nnot familiar with YAML, I recommend digging around the Yaml Project site ( https://github.com/yaml ).\nAdding ssh keys with cloud-init\nInstead of using passwords to log into your cloud instances, you can use key-based authen -\ntication along with the ssh  command to log in over the network. This is commonly used by \ncloud providers to allow user access to cloud images.\nIf you have already generated public and private ssh  keys for the user account that you plan \nto use to ssh  into the cloud instance, you can use that public key for this procedure. If you \nhad generated an RSA key pair, the public key is located in the id_rsa.pub  file by default:\n# cat $HOME/.ssh/id_rsa.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDMzdq6hqDUhueWzl7rIUwjxB/rrJY4\noZpoWINzeGVf6m8wXlHmmqd9C7LtnZg2P24/ZBb3S1j7vK2WymOcwEoWekhbZHBAyYeqX\nKYQQjUB2E2Mr6qMkmrjQBx6ypxbz+VwADNC\nwegY5RCUoNjrN43GVu6nSOxhFf7hv6dtCjvosOvtt0979YS3UcEyrobpNzreGSJ8FMPM\nRFMWWg68Jz5hOMCIE1IldhpODvQVbTNsn/STxO7ZwSYV6kfDj0szvdoDDCyh8mPNC1kI\nDhf/qu/Zn1kxQ9xfecQ+SUi+2IwN69o1fNpexJPFr+Bwjkwcrk58C6uowG5eNSgnuu7G\nMUkT root@host2.example.com\nThe public key from that file is typically copied to the $HOME/.ssh/authorized_keys file \nfor the user on the remote system to which you wish to log in. We can have the key added to that \nfile on our cloud instance using entries in the user-data file that looks like the following:\nusers:\n  - default\n  - name: wsmith\n    gecos: William B. Smith\n    primary-group: wsmith\n    sudo: ALL=(ALL) NOPASSWD:ALL\n    lock-passwd: true\n    ssh-authorized-keys:\n      - ssh-rsa", "doc_id": "c527ea3b-8a08-4c25-9e82-053f85f64fe0", "embedding": null, "doc_hash": "d489eac6b45f387cc5a777f0b9eecab4f2fd2c35e6dd723b19f046c4d5acea9c", "extra_info": {"page_label": "754"}, "node_info": {"start": 0, "end": 2024}, "relationships": {"1": "00dcaa36-b41e-4b15-ab57-ff02b18a2594", "3": "aab4a435-1f5e-4d16-9a48-a1d09227d2a9"}}, "__type__": "1"}, "aab4a435-1f5e-4d16-9a48-a1d09227d2a9": {"__data__": {"text": "root@host2.example.com\nThe public key from that file is typically copied to the $HOME/.ssh/authorized_keys file \nfor the user on the remote system to which you wish to log in. We can have the key added to that \nfile on our cloud instance using entries in the user-data file that looks like the following:\nusers:\n  - default\n  - name: wsmith\n    gecos: William B. Smith\n    primary-group: wsmith\n    sudo: ALL=(ALL) NOPASSWD:ALL\n    lock-passwd: true\n    ssh-authorized-keys:\n      - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDMzdq6hqDUhueWzl7rIUwj\nxB/rrJY4oZpoWINzeGVf6m8wXlHmmqd9C7LtnZg2P24/\nZBb3S1j7vK2WymOcwEoWekhbZHBAyYeqXKYQQjUB2E2Mr6qMkmrjQBx6ypxbz+V\nwADNCwegY5RCUoNjrN43GVu6nSOxhFf7hv6dtCjvosOvtt0979YS3UcEyrobpNz\nreGSJ8FMPMRFMWWg68Jz5hOMCIE1IldhpODvQVbTNsn/\nSTxO7ZwSYV6kfDj0szvdoDDCyh8mPNC1kIDhf/qu/\nZn1kxQ9xfecQ+SUi+2IwN69o1fNpexJPFr+Bwjkwcrk58C6uowG5eNS\ngnuu7GMUkT root@host2.example.com", "doc_id": "aab4a435-1f5e-4d16-9a48-a1d09227d2a9", "embedding": null, "doc_hash": "eb017b8a1cf4686103db0086b5b839064f0c5cd12f1756fd558b50cd8af457a9", "extra_info": {"page_label": "754"}, "node_info": {"start": 1534, "end": 2427}, "relationships": {"1": "00dcaa36-b41e-4b15-ab57-ff02b18a2594", "2": "c527ea3b-8a08-4c25-9e82-053f85f64fe0"}}, "__type__": "1"}, "7609dc0c-5228-437d-b533-ea5de7edf12a": {"__data__": {"text": "Chapter 28: Deploying Linux to the Cloud\n737\n28From the previous information, you can see that wsmith  is the default user. The gecos  \nentry is typically the user\u2019s full name, used in the fifth field of the /etc/passwd  file. \nThe password is locked for this user. However, because the ssh-rsa  entry from my root \naccount on host2.example.com  is provided here under ssh-authorized-keys  for the \nuser, I can log into the cloud instance as wsmith  over ssh  without entering a password \n(provided my private key is associated with that public key).\nAdding software with cloud-init\nYou aren\u2019t limited to the software already on your cloud image. Inside your user-data  \nfile, you can define YUM  repositories (in Fedora and RHEL) or apt  repositories (in Ubuntu \nor Debian) and then identify any packages that you want to have installed when the cloud \ninstance starts.\nThe following example shows what entries in a user-data  file might look like to add a \nYUM repository (for Fedora or RHEL) to your cloud instance and then install packages from \nthat repository or any other enabled repository:\nmyownrepo:\n    baseurl: http://myrepo.example.com/pub/myrepo/\n    enabled: true\n    gpgcheck: true\n    gpgkey: file:///etc/pki/rpm-gpg/RPM-GPG-KEY-MYREPO\n    name: My personal software repository\npackages:\n - nmap\n - mycoolcmd\n - [libmystuff, 3.10.1-2.fc21.noarch]\nIn the example just shown, a new yum  repository is created in the file /etc/yum  \n.repos.d/myownrepo.repo . A gpgkey  is provided to check the validity of installed \npackages, and GPG checking is turned on. After that, the nmap  package is installed (that\u2019s \nin the standard Fedora yum  repository), the mycoolcmd  package is installed (from my pri-\nvate repository), and a specific version of the libmystuff  package is installed.\nConfiguring apt  software repositories for Ubuntu is done a bit differently. Failsafe primary \nand security apt  package mirrors are configured by default (in the cloud.cfg  file in the \nimage), along with settings to cause the instance, if run in an Amazon EC2 cloud, to search \nthe closest region for packages. To add more repositories, entries in your user-data  file \ncould look like the following:\napt_mirror: http://us.archive.ubuntu.com/ubuntu/\napt_mirror_search:\n - http://myownmirror.example.com\n - http://archive.ubuntu.com\npackages:\n - nmap\n - mycoolcmd\n - [libmystuff, 3.16.0-25]", "doc_id": "7609dc0c-5228-437d-b533-ea5de7edf12a", "embedding": null, "doc_hash": "428ad5eaf20ed1dad7a71bc5159a1c8248e3720cdd564b79bc48e080b1cab9fa", "extra_info": {"page_label": "755"}, "node_info": {"start": 0, "end": 2388}, "relationships": {"1": "11944dd5-fa5d-44e3-b988-58f724312d1a"}}, "__type__": "1"}, "b7505f6a-f2ab-4742-851b-6e9130cd8cd5": {"__data__": {"text": "Part VI: Engaging with Cloud Computing738The myownmirror.example.com  entry tells apt  to use your own private apt  repository \nto search for packages. Note that packages you want to install can be entered in basically \nthe same format as you did with Fedora, although specific version information (if entered) \nmight look different in some cases.\nYou can add many other settings to your user-data  and meta-data  files. Again, refer to \nthe Cloud-Init Cloud Config Examples page ( http://cloudinit.readthedocs.org/en/\nlatest/topics/examples.html ) for details.\nUsing cloud-init in enterprise computing\nSo far, the cloud-init  examples in this chapter have focused on taking a cloud image, \nmanually adding configuration data, and running it as a virtual machine temporarily on \nyour local hypervisor. This approach is useful if you want to understand how cloud-init  \nworks and the opportunities you have for tuning cloud images to your specifications. \nThis approach doesn\u2019t scale well, however, if you are managing large enterprises of vir -\ntual machines.\nCloud-init  supports the concept of datasources . By placing user-data  and meta-data  \nin a datasource, you don\u2019t have to inject that information manually into a cloud instance, \nas we did earlier in this chapter. Instead, when the cloud-init  service starts running on \nthe instance, it knows to not only look on the local system for data sources, but also out -\nside of it.\nFor Amazon EC2 clouds, cloud-init  queries a particular IP address \n(http://169.254.169.254/ ) for data. For example, it may check \nhttp://169.254.169.254/2009-04-04/meta-data/  for meta-data  and \nhttp://169.254.169.254/2009-04-04/user-data/  for user-data . This allows the \nconfiguration data to be stored and accessed from a central location.\nAs for what might be inside the meta-data  and user-data , far more complex config -\nuration schemes can be developed for deployment of your cloud instances. Cloud-init  \nsupports configuration tools, such as Puppet ( http://puppetlabs.com/puppet/\npuppet-open-source ) and Chef ( https://www.chef.io/chef/ ). These tools let \nyou apply scripts of configuration information to your cloud instances, even doing such \nthings as replacing components or restarting services as needed to return the system to a \ndesired state.\nAt this point, however, my job is not to make you into full-blown cloud administrators \n(a few hundred pages ago, you could have been a Linux novice). Instead, I want you to \nunderstand what you will be dealing with if you eventually land in a cloud data center \n.\u00a0.\u00a0. because many people believe that most data centers will be managed as cloud infra -\nstructures in the not-too-distant future.\nSo far in this chapter, you have looked at the inside of configuring Linux for cloud com-\nputing. Next, let\u2019s step back and look at how you can use two of the most popular Linux-\nbased cloud platforms to run your own Linux-based virtual machines: OpenStack and \nAmazon EC2.", "doc_id": "b7505f6a-f2ab-4742-851b-6e9130cd8cd5", "embedding": null, "doc_hash": "32472cd8e5cd4dcf8f310b11e1a92a1aad7a5a501723b5a66e0b43f5866ae8e3", "extra_info": {"page_label": "756"}, "node_info": {"start": 0, "end": 2973}, "relationships": {"1": "a72b0fc9-6f28-40a5-adcb-6c6457635267"}}, "__type__": "1"}, "2844b63b-9431-4a3a-81f1-8d29b25495df": {"__data__": {"text": "Chapter 28: Deploying Linux to the Cloud\n739\n28Using OpenStack to Deploy Cloud Images\nWith OpenStack , you get a continually evolving platform for managing your physical cloud \ncomputing infrastructure, as well as the virtual systems that run on it. OpenStack lets you \ndeploy your own private cloud or offer it up to the world as a public cloud.\nRather than have you set up your own OpenStack cloud, I\u2019m going to show how you can use \nOpenStack to deploy virtual machines from an OpenStack Dashboard. If you want to try it \nyourself, OpenStack is available in the following ways:\nLinux distributions Fedora, Ubuntu, and CentOS have free versions of OpenStack \nthat you can deploy yourself. Red Hat Enterprise Linux offers a version of Open -\nStack that is available by subscription. It\u2019s tricky to set up. Some all-in-one setups \nfor OpenStack can run on a single machine, but I think you will have a better \nexperience if you start with three physical machines: one controller node and two \nhypervisors.\nPublic OpenStack clouds You can try out public OpenStack clouds for varying costs. \nA list of public OpenStack clouds is available from the OpenStack project site \n(http://www.openstack.org/marketplace/public-clouds/ ).\nMy first point is to help you run a Linux system in a cloud when you lack the capacity to do \nwhat you want on your own computers. However, my other point is to show you how a cloud \nprovider\u2019s web-based interface (like OpenStack Dashboard) can greatly simplify the cloud \nconfiguration we did manually with cloud-init  earlier in this chapter.\nStarting from the OpenStack Dashboard\nI\u2019m going to start with an OpenStack setup that is already in place. The OpenStack environ -\nment\u2019s administrator has created a project for me called cnegus-test-project  and a \nuser account ( cnegus ) that lets me access that project. Here\u2019s what I plan to do:\n\u25a0\u25a0Configure networking . Just as I would set up a router and physically plug my com-\nputers into that router, I\u2019m going to set up a virtual network. That virtual network \nwill include a set of addresses that are distributed to my virtual machines via DHCP.\n\u25a0\u25a0Configure virtual machines . I\u2019ll step through the process of choosing, configuring, \nand deploying a couple of virtual machines.\nThe version of OpenStack used for this demonstration is Red Hat OpenStack Platform \n(RHEL-OSP). However, the experience would be similar on any OpenStack environment. The \nnext section shows you how to start configuring your network.\nConfiguring your OpenStack virtual network\nFollow these steps to configure your OpenStack virtual network.\n1. Log in to OpenStack . Using the username and password assigned to you by the \nOpenStack administrator, log in to the OpenStack Dashboard from your web browser. \nYou should see an Overview screen, similar to the one shown in Figure\u00a028.2:", "doc_id": "2844b63b-9431-4a3a-81f1-8d29b25495df", "embedding": null, "doc_hash": "2a468293582c678e98463dcefa73bbcb5247c29f6a289a317b07d07d45d0eeaf", "extra_info": {"page_label": "757"}, "node_info": {"start": 0, "end": 2840}, "relationships": {"1": "b40fccb6-19aa-4ed0-9769-023837188635"}}, "__type__": "1"}, "dbbd8e66-facf-4807-a645-263efdff6462": {"__data__": {"text": "Part VI: Engaging with Cloud Computing7402. Create a network . To create a network, from the left column on the Overview \nscreen, select Networks. From the Networks screen that appears, create a new net -\nwork as follows (the examples I used are in parentheses):\na. Select the Create Network button .\nb. On the Network tab, type a network name ( mynet ).\nc. On the Subnet tab, type a subnet name ( mysub01 ), network address \n(192.168.100.0/24 ), IP version ( IPv4 ), and gateway IP ( 192.168.100.1 ). \nLeave Disable Gateway unchecked .\nd. On the Subnet Detail tab, enter a comma-separated range of IP \naddresses in the Allocation Pool box . For my example, I chose \n192.168.100.10,192.168.100.50  to hand out a range of IP addresses to cli-\nents from 192.168.100.10 to 192.168.100.50. Get a name server suggestion from \nthe administrator of your OpenStack cloud or use a public DNS server (such as \nGoogle\u2019s 8.8.8.8 or 8.8.4.4)\ne. Select Create to create the new network . The new network appears on the Net -\nworks screen.\n3. Create a router . For your virtual machines to be able to access the Internet, \nyou need to identify a router that is attached to your private network on one \nFIGURE 28.2\nLog in to the OpenStack Dashboard.", "doc_id": "dbbd8e66-facf-4807-a645-263efdff6462", "embedding": null, "doc_hash": "81309e62f0132b0908a4bcc1c6652b5f4ded3a4c5286ff1ee0e415b13a416ce0", "extra_info": {"page_label": "758"}, "node_info": {"start": 0, "end": 1233}, "relationships": {"1": "498f43fe-e516-430b-921f-f220a4bca135"}}, "__type__": "1"}, "aab9ab3d-9841-408e-9257-680a81fae8c6": {"__data__": {"text": "Chapter 28: Deploying Linux to the Cloud\n741\n28interface and a network that can reach the public Internet on the other. Here\u2019s \nhow to do that:\na. From the left column, select Routers .\nb. Click the Create Router button .\nc. Type a router name ( myrouter01 ) and click Create Router .\nd. Select the Set Gateway button .\ne. From the Set Gateway screen, click the External Network box and choose from \nthe available external networks . Leave the Router Name and Router ID fields as \nthey are. Click Set Gateway. The new router appears on the Routers screen.\n4. Connect your network to the external router . From the Routers screen (you \nshould still be on that screen), select the name of the router that you just created \n(myrouter1 ):\na. From the Router Details screen, select the Add Interface button.\nb. From the Add Interface screen, click the Subnet box and choose the subnet \nyou created earlier ( mynet: 192.168.100.0/24 mysub01 ). You shouldn\u2019t \nhave to change Router Name or Router ID.\nc. Click Add Interface .\n5. View network topology . Click Network Topology from the left column. Then, hover \nyour mouse button over the router name ( myroute01 ). Figure\u00a028.3 shows an exam-\nple of what your network configuration might look like.\nWith your networking in place, you can create keys to access your virtual machines in \nOpenStack.\nConfiguring keys for remote access\nThe normal way to configure access to your virtual machines in a cloud environment is to \ncreate a public/private key pair that provides secure access to your virtual machines using \nssh and related tools from your desktop system. The private key is stored in your desktop \nuser\u2019s home directory, and the public key is injected into the virtual machine so that you \ncan log in remotely (via ssh) to the virtual machine without entering a password. Here\u2019s \nhow to set up your keys:\n1. Select Access & Security . From the left column, select Access & Security.\n2. Create Keypairs . If you already have a keypair, you can skip to the next step. If \nnot, select the Keypairs tab and click the Create Keypair button. When the Create \nKeypair window appears, do the following:\na. Enter a keypair name ( mycloudkey ), and click the Create Keypair button . \nA pop-up window asks if you want to open or save the *.pem  file.", "doc_id": "aab9ab3d-9841-408e-9257-680a81fae8c6", "embedding": null, "doc_hash": "afb0d303877758b43787f161d910f2f8a34d1bb9142cbcc60830b8ea8e9a1b7e", "extra_info": {"page_label": "759"}, "node_info": {"start": 0, "end": 2289}, "relationships": {"1": "5bb20df2-8c98-4fcc-91ca-14c25d9e1254"}}, "__type__": "1"}, "e8a222f3-e1d5-4cb0-a90a-5cafff2932f9": {"__data__": {"text": "Part VI: Engaging with Cloud Computing742b. Select Save File and click OK . When prompted where to save it, save it to the \n.ssh  directory in your home directory.\nYou are ready to deploy an OpenStack instance (cloud-based virtual machine).\nLaunching a virtual machine in OpenStack\nTo begin launching a new cloud virtual machine instance, go to the left column and select \nInstances. Then click the Launch instance button. The Launch Instance screen appears. To \nfill in the information that you need to launch the instance, follow these steps:\n1. Select Details . From the Details tab, select the following items:\na. Availability Zone . An availability zone  consists of a group of compute hosts. \nSeparate zones are sometimes created to identify a group of computers that are \nphysically together (such as on the same rack) or that have the same hardware \nfeatures (so they could be used for the same types of applications). Choose one \nof the zones from the list.\nFIGURE 28.3\nView your network topology from the OpenStack Dashboard.", "doc_id": "e8a222f3-e1d5-4cb0-a90a-5cafff2932f9", "embedding": null, "doc_hash": "9e6831e23dad7d4303c25c86d5576c19137d3ef8e52983ddc662b117f76a9e18", "extra_info": {"page_label": "760"}, "node_info": {"start": 0, "end": 1035}, "relationships": {"1": "ea0233c7-f6a0-4969-8a38-3de709801e21"}}, "__type__": "1"}, "18d18cd7-b1af-408b-8cb8-bcc9d16cad52": {"__data__": {"text": "Chapter 28: Deploying Linux to the Cloud\n743\n28b. Instance Name . Give the instance any name that helps you remember \nwhat it is.\nc. Flavor . By choosing a flavor, you allocate a set of resources to your virtual \nmachine instance. The resources include the number of virtual CPU cores, the \namount of memory available, the disk space assigned, and ephemeral disk space \navailable. ( Ephemeral space  is space available from the local disk while the in -\nstance is running but is not saved when the instance shuts down.) Default \nflavors include m1.tiny , m1.small , m1.medium , m1.large , and m1.xlarge . \nOther flavors can be added by your cloud administrator.\nd. Instance Count . By default, this is set to 1, meaning to start one instance. \nChange the number to start more instances if you like.\ne. Instance Boot Source . The instance can be booted from an image, a snapshot, \na volume, an image that includes a new volume, or a volume snapshot that \nincludes a new volume.\nf. Image Name . Select the image that you want to start. The names typically \ninclude the names of the operating systems that you are booting.\ng. Device size and Device Name (optional) . If you selected to include a new \nvolume when you chose your instance boot source, you set the size (in GB) and \ndevice name for the volume in these fields. For the device name, if you choose \nvda as the device name (for the first disk on a virtual machine), the device rep -\nresenting that device would be /dev/vda .\n2. Select Access & Security . Select the Access & Security tab and choose the keypair \nthat you created earlier.\n3. Select Networking . Select the Networking tab. From the list of available net -\nworks, grab the one that you want with your mouse and drag it into the Selected \nNetworks box.\n4. Add Post-Creation settings . You can add commands and scripts that configure the \nsystem further after it is booted. This is where you can add the kinds of informa -\ntion you added in the user-data  files described in the sections on cloud-init  \nearlier in this chapter.\nSelect Launch to start up the virtual machine. With the virtual machine running, you can \nlog in to that system by selecting the instance and clicking the Console tab. The virtual \nmachine\u2019s console window should present you with a login prompt. If you want to be able to \ngain access to the virtual machine using ssh  over the network, go on to the next section.\nAccessing the virtual machine via ssh\nWith your public key injected into your running virtual machine, it is ready for you to log \nin using ssh . However, before you can do that, you must take these steps:\n1. Add floating IP address . From the OpenStack Dashboard, select the instances, \nclick More on the entry containing the instance, and click Associate Floating IP. ", "doc_id": "18d18cd7-b1af-408b-8cb8-bcc9d16cad52", "embedding": null, "doc_hash": "f3f5459e9b01f7292a1a5328e81eefc7dcb0a508e5518bc2ce0195a6d0faf633", "extra_info": {"page_label": "761"}, "node_info": {"start": 0, "end": 2782}, "relationships": {"1": "fe6d9ee0-4f0b-4e6b-ba7e-f8b421f70ba1"}}, "__type__": "1"}, "337573b8-eb9b-49b3-8c4f-6a9062f14fdd": {"__data__": {"text": "Part VI: Engaging with Cloud Computing744Select the plus sign ( +) next to the IP Address box, select a pool that has floating \nIPs available, and click Allocate IP. The allocated address should appear in the IP \nAddress field. Select the port to be associated and click Associate.\n2. Use ssh  to access instance . From a Linux system that has access to the net -\nwork on which the floating address was assigned, run the ssh  command to log in. \nAssuming that your key\u2019s .pem  file was called mycloud.pem , the default user on \nthe instance is cloud-user , and the IP address is 10.10.10.100, you could enter \nthe following to log in:\n# ssh -i mycloud.pem cloud-user@10.10.10.100\nYou should be able to log in now without a password. To do administration on the system, \nyou can use the sudo  command as the default user.\nUsing Amazon EC2 to Deploy Cloud Images\nAmazon Elastic Computer Cloud (Amazon EC2) is a cloud platform that is particularly suited \nfor pay-as-you-go cloud computing. Like OpenStack, it lets you choose from preconfigured \nvirtual machine images and configure them as you need.\nTo start using Amazon EC2 to launch virtual machines, go to the Getting Started with Ama -\nzon Web Services page and follow links to create a new account ( http://aws.amazon.\ncom/getting-started/ ). After you log in, the full range of AWS services is displayed. \nSelect Sign In to the Console, and you will see the AWS Management Console, as shown in \nFigure\u00a028.4:\nFIGURE 28.4\nLaunch cloud instances using the Amazon EC2 Management Console.", "doc_id": "337573b8-eb9b-49b3-8c4f-6a9062f14fdd", "embedding": null, "doc_hash": "e5c8c800d78c1ae48ad404cd90c6eb5c38cf56b64aa6ea42ace559f84c889cd3", "extra_info": {"page_label": "762"}, "node_info": {"start": 0, "end": 1538}, "relationships": {"1": "84bce283-64b9-4711-b47e-8a483514a7a9"}}, "__type__": "1"}, "fd928c51-48b4-4355-bdb2-e134c90349b0": {"__data__": {"text": "Chapter 28: Deploying Linux to the Cloud\n745\n28To start your first Linux virtual machine instance, do the following:\n1. Select Launch a Virtual Machine . You are then given a choice of Linux (Red Hat \nEnterprise Linux, SUSE Linux, Ubuntu, and so on) and Windows AMIs (Amazon \nMachine Images) to start up.\n2. Find the image that you want, and click the Select button .\n3. From the Choose an Instance Type page, select the particular instance type \nthat you want . Make that selection based on the number of CPUs, amount of mem-\nory, type of storage, and networking features.\n4. With the instance type selected, click Next: Configure Instance Details .\n5. From the Configure Instance Details screen, select an existing VPC, or create a \nnew one . Then change any other settings. For example, select Enable under Auto-\nassign Public IP to be able to log in to your instance over the Internet.\n6. Select Review and Launch . The Review Instance Launch screen appears.\n7. Review the instance settings and select Launch to start the instance . \nFigure\u00a028.5 shows an example of a RHEL 8 instance ready to launch.\n8. Select an existing key pair or choose Create a New Key Pair to create a private \nand public key to use to ssh  into the instance .\n9. Select Launch Instances to start the instance .\n10. Select View Instances to see a list of running instances . Use the search box to \nsearch for a string in the instance name if there is a long list from which to choose.\nFIGURE 28.5\nConfigure and launch a RHEL 8 instance on AWS.", "doc_id": "fd928c51-48b4-4355-bdb2-e134c90349b0", "embedding": null, "doc_hash": "518e032c0ccda57ab7e92a7a3fc0d181fb20f9fb27c896e6bb9c5de8f8354ec9", "extra_info": {"page_label": "763"}, "node_info": {"start": 0, "end": 1521}, "relationships": {"1": "3dd800bf-1697-423b-af73-bcf226c96649"}}, "__type__": "1"}, "807bf418-8695-4f2d-ab0c-3aec705b11ae": {"__data__": {"text": "Part VI: Engaging with Cloud Computing74611. Select your instance and then select the Connect button . Follow the instructions \nto use ssh  to log into the public IP address you created. For example, the command \nto log in to the AWS instance would look similar to the following:\n# ssh -i \"youraws.pem\" ec2-user@ec2-w-xx-yyy-zz.us-east-2.compute  \n.amazonaws.com\n12. When you are done with the instance, you can terminate it by selecting the \ninstance from the Instances page and then selecting Actions \u27aa Instance State  \n\u27aa Terminate . When prompted, select Yes, Terminate to remove the instance and its \nassociated storage.\nIt is important to remember to get rid of the instance when you are done or you will con -\ntinue to be charged for it.\nSummary\nUnderstanding how cloud computing differs from simply installing an operating system \ndirectly on computer hardware will help you to adapt as more and more data centers move \ntoward cloud computing. In the beginning of this chapter, I encouraged you to get your \nhands on some cloud images, combine them with data, and launch them on a local Linux \nhypervisor to understand how cloud images work.\nAfter that, I demonstrated how you can launch your own virtual images in an OpenStack \ncloud platform. That included configuring network interfaces, choosing how the virtual in -\nstance would run, and launching the virtual image. I also quickly introduced the Amazon \nElastic Compute Cloud service, where you can pay to use cloud storage and processing time \nif you don\u2019t have enough computing resources of your own.\nThe next chapter describes how to use Ansible to automate the deployment of host systems \nand applications to your data center.\nExercises\nThe exercises in this section assume that you have already set up a host system as a hyper -\nvisor (KVM host computer). You need to use that hypervisor to run the virtual machine \ncreated in the exercises. If you are stuck, solutions to the tasks are shown in Appendix B. \nKeep in mind that the solutions shown in Appendix B are usually just one of multiple ways \nto complete a task.\n1. To be able to create a custom virtual machine image, install the genisoimage , \ncloud-init , qemu-img , and virt-viewer  packages.\n2. Obtain a cloud image from the Fedora project.\n3. Use qemu-img  to create a snapshot of that image in qcow2 format called myvm  \n.qcow2 , which you can use later to combine with your own data.", "doc_id": "807bf418-8695-4f2d-ab0c-3aec705b11ae", "embedding": null, "doc_hash": "01c518af0538694221940f705e67ce5ac91279bd514d2624f2497572f34ccc1c", "extra_info": {"page_label": "764"}, "node_info": {"start": 0, "end": 2416}, "relationships": {"1": "8877f80b-a1f6-4fed-894a-c8b2082898d7"}}, "__type__": "1"}, "da7cdcd9-373e-4065-a663-3496d4dd9d08": {"__data__": {"text": "Chapter 28: Deploying Linux to the Cloud\n747\n284. Create a cloud-init  meta data file named meta-data  that sets the instance-\nid to myvm  and local-hostname to myvm.example.com .\n5. Create a cloud-init  user data file called user-data  that sets the default user\u2019s \npassword  to test  and sets chpasswd  never to expire with {expire: False} .\n6. Run the genisoimage  command to combine the meta-data  and user-data  \nfiles to create a mydata.iso  file that you can combine with a virtual machine \nimage later.\n7. Use the virt-install  command to combine the myvm.qcow2  virtual machine \nimage with the mydata.iso  image to create a new virtual machine image named \nnewvm  that starts running on your hypervisor.\n8. Use virt-viewer to open a console to the newvm  virtual machine.\n9. Log into the newvm  virtual machine, using the fedora  user and test  password \nthat you set earlier.", "doc_id": "da7cdcd9-373e-4065-a663-3496d4dd9d08", "embedding": null, "doc_hash": "7590d972141cb68c5641a1e5d944ace8528ba99ef49b280f5fd4a7262534b7be", "extra_info": {"page_label": "765"}, "node_info": {"start": 0, "end": 885}, "relationships": {"1": "434f312b-f8a3-449c-9cac-29b1cd1dacfd"}}, "__type__": "1"}, "9d6c8f93-f858-4c0b-84db-f1245c83c18b": {"__data__": {"text": "749\nCHAPTER29\nAutomating Apps and \nInfrastructure with Ansible\nIN THIS CHAPTER\nUnderstanding Ansible\nInstalling Ansible\nStepping through a deployment\nRunning ad-hoc commands\nTo this point in the book, we have mostly focused on manually configuring individual Linux \nsystems. You have learned how to install software, edit configuration files, and start services \ndirectly on the machines where they run. While knowing how to work on individual Linux \nhosts is foundational to managing Linux systems, by itself it doesn\u2019t scale well. That\u2019s where Ansi-\nble comes in.\nAnsible changes the mindset of Linux administration from a focus on single systems to groups of \nsystems. It moves configuration of those nodes from each individual machine to a control node. It \nreplaces the user interface of a shell on each machine with Ansible playbooks that run tasks on other \nmachines over a network.\nAlthough our focus here is on managing Linux systems, Ansible can manage many things around \nthose Linux systems as well. There are Ansible modules for making sure that machines are powered \non, that network devices are properly configured, and that remote storage is accessible\nIn all but the smallest data centers, knowing how to deploy and manage Linux systems and surround -\ning infrastructure automatically is becoming a requirement for many IT jobs these days. For fully \ncontainerized data centers, Kubernetes-based application platforms such as OpenShift are becoming \nthe industry standard for container orchestration and automation (see Chapter\u00a030, \u201cDeploying Appli -\ncations as Containers with Kubernetes\u201d). For infrastructure and more traditional application deploy -\nments, Ansible is becoming a leader.\nThis chapter takes you through what you should know about Ansible to get started. It then steps you \nthrough deploying an application across a set of Linux systems with Ansible and shows you how to \nwork with those systems later by redeploying playbooks and running ad-hoc commands.\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "9d6c8f93-f858-4c0b-84db-f1245c83c18b", "embedding": null, "doc_hash": "269c72fa00109ad5e2759d59259a068259e4bc048b7daabfeba5f2df8cfb422f", "extra_info": {"page_label": "766"}, "node_info": {"start": 0, "end": 2112}, "relationships": {"1": "e1ebea8b-cb1f-46bb-9efe-5411510df6f3"}}, "__type__": "1"}, "bfd71d47-9022-49f4-bb9f-5fc1c150641e": {"__data__": {"text": "Part VI: Engaging with Cloud Computing750Understanding Ansible\nAnsible extends, rather than replaces, what you have already learned about Linux. At its \nmost basic level, Ansible comprises the following:\n\u25a0\u25a0An automation language that describes the tasks that you want to perform to reach \na particular state. These are gathered into playbooks .\n\u25a0\u25a0The automation engine that is used to run the playbooks.\n\u25a0\u25a0Interfaces you can use to manage and secure playbooks and other automation com-\nponents, implemented with commands and RESTful APIs.\nUsing inventories (that define sets of hosts) and playbooks (that define sets of actions to \ntake on those hosts), Ansible configures host systems in the following ways:\nSimple feature configuration : You create inventories and playbooks as plain-text \nfiles, where you identify Linux components that are acted upon by modules. No cod -\ning experience is required.\nSetting the results that you want : What you describe here are resources that define \nthe state you want a feature to be in on a node. That state can be a systemd  ser-\nvice running, a network interface with particular addresses set, or a disk partition \nof a certain size created. If, for some reason, the state changes for a feature, you \ncan run a playbook again to have Ansible return a node to the intended state.\nSSH connections : By default, each host node must be running an SSH service that is \nconfigured to allow Ansible to communicate to it from the control node. Key-based \nauthentication to regular user accounts allows this to happen, with sudo  available \nwhen root privilege escalation is needed. Because you are using an SSH service that \nis probably already running on the host, you don\u2019t need to run additional agents or \nconfigure special firewall rules for this to work.\nOnce you learn the basics about how Ansible works, you can do a wide range of advanced, \ncomplex activities, such as the following:\nProvisioning infrastructure : Using Ansible, you can provision the infrastructure that \nyour applications need, whether that is installing operating systems on bare metal \nor as hypervisors (along with their virtual machines), setting up storage devices, \nor configuring network devices. In each of those cases, Ansible can leverage your \nexisting provisioning tools so that they can all be managed in one place.\nDeploying applications : By describing the desired state of your applications, Ansible \ncan not only use tasks to deploy sets of applications across multiple nodes and \ndevices, but it can also replay those playbooks to return an application to its desired \nstate when a feature may have broken or have been changed unintentionally.\nManaging containers and operators : Recent additions to Ansible allow it to deploy \ncontainerized applications to a Kubernetes infrastructure such as OpenShift. Oper -\nators in OpenShift, which can be managed by an Ansible Operator, can not only \ndefine the state of containerized applications, but they can also respond to changes ", "doc_id": "bfd71d47-9022-49f4-bb9f-5fc1c150641e", "embedding": null, "doc_hash": "a4e39867661d64a833265fc075507a48e60e96a19143957f36eddaad50b97265", "extra_info": {"page_label": "767"}, "node_info": {"start": 0, "end": 3007}, "relationships": {"1": "a498bf8f-fc93-46cf-9a59-e4e462273221"}}, "__type__": "1"}, "75ab2bf1-a216-4168-8961-1275c31b1162": {"__data__": {"text": "Chapter 29: Automating Apps and Infrastructure with Ansible\n751\n29in real time and make upgrades easier. See the description of the Ansible Operator \nfor details ( https://www.ansible.com/blog/ansible-operator ).\nManaging networking and storage : Tasks that are often done manually to configure, \ntest, validate, and enhance your networking infrastructure can be automated with \nAnsible. Tons of commercial and community playbooks are available that offer the \nsame Ansible intuitive tools that you use to deploy Linux systems, but they are made \nfor specific network ( https://docs.ansible.com/ansible/latest/network/\nindex.html ) and storage ( https://docs.ansible.com/ansible/latest/  \nmodules/list_of_storage_modules.html ) devices and environments.\nManaging cloud environments : Just as you can deploy infrastructures to bare metal, \nAnsible offers tools for provisioning infrastructure and applications to cloud envi-\nronments. For Amazon Web Services (AWS) alone, there are about 200 Ansible mod -\nules available for managing infrastructure and applications. Modules for Alibaba, \nAzure, Google, and a few dozen other cloud environments are also available.\nExploring Ansible Components\nWhen a playbook is run, it acts on one or more target host systems (represented by inven -\ntories ) and executes items referred to as plays . Each play  contains one or more tasks  that are \nset to be achieved by that play. To carry out a task, the task calls modules , which are exe -\ncuted in the order that they appear. Before you start using Ansible, it helps to understand \na little more about these components.\nInventories\nBy gathering host systems (nodes) that you want to manage in what are referred to as \ninventories , you can manage machines that are similar in some way into groups. Similarities \ncould include the following:\n\u25a0\u25a0Located in a similar location\n\u25a0\u25a0Provide the same kind of service\n\u25a0\u25a0Assigned to a particular stage in a process, such as sets of machines for develop -\nment, testing, staging, and production\nJoining hosts together into more than one group allows them to be acted on based on these \ndifferent kinds of attributes. For example, host01  might be both in a group called newy -\nork (for its location) and a group called ftp  (for the application it provides). Tasks run on \nthose inventory groups might allow each host to get network settings based on its location \nand the applications it runs based on its purpose, respectively.\nThere are multiple ways of creating inventories. You can set a line of static servers or create \na range of systems. You can also use dynamic lists of servers from cloud providers, such as \nAzure, AWS, and GCP.\nUsing variables, you can assign attributes to a set of hosts in an inventory. Those vari-\nables can configure such things as the port from which a service is available from a host, a ", "doc_id": "75ab2bf1-a216-4168-8961-1275c31b1162", "embedding": null, "doc_hash": "a02fea202bfde232632cc4172ffff1b06f58b43cc80a57efcf2c6c402725613d", "extra_info": {"page_label": "768"}, "node_info": {"start": 0, "end": 2852}, "relationships": {"1": "8eb0b328-a36f-43bf-a1e8-9553048e7105"}}, "__type__": "1"}, "c1e5b5ea-3695-4d1d-98b6-f0eb6765c84c": {"__data__": {"text": "Part VI: Engaging with Cloud Computing752timeout value for a service, or the location of a service used by a host (such as a database \nfor a Network Time Protocol server).\nLike playbooks, inventories can be simple text files. They can also be implemented from an \ninventory script.\nPlaybooks\nPlaybooks  are created as YAML-formatted files that describe the end state of something. \nThat something can cause software to be installed, applications to be configured, or ser -\nvices to be launched. It can focus on the application alone, or it can include the entire \nenvironment (networking, storage, authentication, or other feature) surrounding that \napplication.\nPlaybooks are meant to be reusable\u2014to deploy the same components later, be adapted for \nother components, or replayed to reestablish the original intent of a specific instance of \nthe playbook. Because playbooks are intended for reuse, many people keep their playbooks \nunder source control. In that way, you can track changes over time and make the playbooks \neasily available.\nPlays\nInside a playbook is one or more plays . Each play has a target, such as a hosts  identifier \nthat tells the playbook which host systems to act on. That can be followed by a remote_\nuser that tells the playbook which user to authenticate to on the host. The play can also \nindicate that it needs to escalate privileges with sudo  before it starts executing the tasks. \nAfter that, there can be one or more tasks to define the actual activity that is carried out \non the hosts.\nTasks\nAt the most basic level, each task runs one or more modules. A task provides a way to \nassociate the module being run with the parameters and return values associated with \nthat module.\nModules\nThere are hundreds of Ansible modules available today, with more being created all the \ntime. When run, a module  makes sure that a requested state is achieved by checking that \nintended state, as indicated by parameters that are provided, and if the target is not in \nthat state, then doing what needs to be done to get there. The Module Index organizes \nthose modules by category: ( https://docs.ansible.com/ansible/latest/modules/\nmodules_by_category.html ).\nExamples of modules include yum , mysql_db and ipmi_power . The yum  module can \ninstall, remove, or otherwise manage software packages and repositories from the YUM \nfacility. A mysql_db module lets you add or remove a MySQL database from a host. The \nipmi_power module lets you check the state of computers with IPMI interfaces and make \nsure they get to the requested state (on or off).", "doc_id": "c1e5b5ea-3695-4d1d-98b6-f0eb6765c84c", "embedding": null, "doc_hash": "19fba9e245c3e304903e508af1ae6ee963f3759a7fb9f20852b0a142c738c886", "extra_info": {"page_label": "769"}, "node_info": {"start": 0, "end": 2576}, "relationships": {"1": "f9734b26-5554-4247-8603-cd66954275de"}}, "__type__": "1"}, "4c8e04b9-b476-4ef7-8431-46e54244f8de": {"__data__": {"text": "Chapter 29: Automating Apps and Infrastructure with Ansible\n753\n29Conditionals  can be applied to each task. For example, with the yum  module, you can condi-\ntion whether or not to install a package by its state. You could say that if the state of the \npackage is installed , then don\u2019t install the package (even if a newer version is avail -\nable). However, if you use latest , then a newer version of the package will be installed if \nthe current package is not the latest.\nParameters  let you add information to modify the task. For example, with the user  \nmodule, when you add a user to a system, you can identify the user\u2019s name, password, uid, \nand shell.\nBesides setting up modules to be executed from playbooks, you can also run modules \ndirectly from the command line. This is useful if you want to act on a host immediately, \nwithout running an entire playbook. For example, you can ping a set of hosts to make sure \nthat they are running or check the status of a service. (See the section \"Running Ad-Hoc \nAnsible Commands\" later in this chapter for further information.)\nTo learn more about a particular module, go to the Ansible documentation website (select \nModules from the https://docs.ansible.com page) or use the ansible-doc command. \nFor example, to learn more about how to use the copy  module to copy files to a remote \nlocation, enter the following:\n# ansible-doc copy\n> COPY    (/usr/lib/python3.7/site-packages/ansible/modules/files/\ncopy.py)\n \n        The 'copy' module copies a file from the local or\n        remote machine to a location on the remote machine...\nMost modules have return values to provide information about the results of that  \nmodule\u2019s action. Common return values include Booleans, indicating if the task was  \nsuccessful ( failed ), whether or not the task was skipped ( skipped ), or if the task had to \nmake changes ( changed ).\nRoles, imports, and includes\nAs your collection of playbooks grows, you may find that you want to break up those play -\nbooks into smaller pieces that you can include in multiple playbooks. You can separate \nparts of a large playbook into separate, reusable files, then call those files into the main \nplaybook using includes  and imports . Roles  are similar, but can they encompass more things \nthan tasks, such as modules, variables, and handlers.\nFor information on using includes, imports, and roles, see \u201cCreating Reusable Playbooks\u201d \nat https://docs.ansible.com/ansible/latest/user_guide/playbooks_\nreuse.html .\nStepping Through an Ansible Deployment\nTo get you started using Ansible, we are going to step through a procedure to deploy a web \nservice to a set of hosts. After installing Ansible, the procedure shows you how to create ", "doc_id": "4c8e04b9-b476-4ef7-8431-46e54244f8de", "embedding": null, "doc_hash": "51ef1d5647e02167c6b172ca455f5be619c3e4cf640ef7c4747f19dbdbf6c5a1", "extra_info": {"page_label": "770"}, "node_info": {"start": 0, "end": 2722}, "relationships": {"1": "71158a50-fcd1-4ac5-8056-0298f0a66f88"}}, "__type__": "1"}, "aca903d7-7a60-421f-a56c-e9d5b056fbb6": {"__data__": {"text": "Part VI: Engaging with Cloud Computing754the inventory and playbook which you need to deploy that service. Then it shows how to \nuse ansible-playbook  to actually deploy the playbook.\nPrerequisites\nTo get started, I created four virtual machines with the following names:\nansible     Used as the Ansible control node\nhost01      First target node\nhost02      Second target node\nhost03      Third target node\nThen I ran the following steps to prepare to use those hosts with Ansible:\n1. Installed Fedora on each of the virtual machines (RHEL should work as well).\n2. For each of the three target nodes ( host01 , host02 , and host03 ), I made sure to \ndo the following:\na. Have the SSH service running and available (opening TCP port 22 if necessary) \nto the Ansible control node.\nb. Create a non-root user account. Later, when you use the playbook, add the \n--ask-become-pass  option to be prompted for the password that you\u2019ll need \nto escalate privileges.\nc. Set a password for that user.\nWhen running Ansible, I use the regular user account to connect to each system, then I \nescalate to root privilege using sudo .\nSetting up SSH keys to each node\nLog in to the control node ( ansible ) and ensure that it can reach the three other nodes \nthat you are configuring. Either make sure that you can reach the hosts through a DNS \nserver or add them to the /etc/hosts  file on the control node. Then set up keys to access \nthose nodes. For example:\n1. As root user, add the IP address and name for each node to which you want to \ndeploy your Ansible playbooks to the /etc/hosts  file:\n192.168.122.154   host01\n192.168.122.94    host02\n192.168.122.189   host03\n2. Still on the ansible  system, generate ssh  keys so that you can have passwordless \ncommunications with each host. You can run this and the later Ansible commands \nas a regular user on the ansible  host system:\n$ ssh-keygen\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/home/joe/.ssh/id_rsa): <ENTER>", "doc_id": "aca903d7-7a60-421f-a56c-e9d5b056fbb6", "embedding": null, "doc_hash": "b08dc05452aaed93f80ef9a615ede0af7786d7bcf3d889a5eef31f47f753bd89", "extra_info": {"page_label": "771"}, "node_info": {"start": 0, "end": 1994}, "relationships": {"1": "8a7f3c50-63f3-4ed4-9928-34859934bb94"}}, "__type__": "1"}, "ac9a4381-79c9-4434-b7c2-b50b81e7f11f": {"__data__": {"text": "Chapter 29: Automating Apps and Infrastructure with Ansible\n755\n29Created directory '/home/joe/.ssh'.\nEnter passphrase (empty for no passphrase): <ENTER>\nEnter same passphrase again:\nYour identification has been saved in /home/joe/.ssh/id_rsa.\nYour public key has been saved in /home/joe/.ssh/id_rsa.pub.\nThe key fingerprint is:\nSHA256:Wz63Ax1UdZnX+qKDmefSAZc3zoKS791hfaHy+usRP7g joe@ansible\nThe key's randomart image is:\n+---[RSA 3072]----+\n|             ...*|\n|            .  o+|\n|           . . ..|\n|          . + +  |\n|        S..= * + |\n|        o+o + O.o|\n|        .ooB.Bo+o|\n|          *+O+o.o|\n|         ..=BEo  |\n+----[SHA256]-----+\n3. Using ssh-copy-id , copy your public key to the root account on each host. The \nfollowing for  loop steps through copying the user\u2019s password to all three hosts:\n$ for i in 1 2 3; do ssh-copy-id joe@host0$i; done\n/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed:\n \"/home/joe/.ssh/id_rsa.pub\"\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the\nnew key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed \n-- if you are prompted now it is to install the new keys\njoe@host01's password: <password>\n \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh 'joe@host01'\"\nand check to make sure that only the key(s) you wanted were added.\n \n/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed:\n \"/home/joe/.ssh/id_rsa.pub\"\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the\nnew key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed\n-- if you are prompted now it is to install the new keys\n \njoe@host02's password: <password> ...\nThe next step is to install the ansible  package on the control node ( ansible ). From that \npoint on, all that work is done from the control node.", "doc_id": "ac9a4381-79c9-4434-b7c2-b50b81e7f11f", "embedding": null, "doc_hash": "d064f58702f949b536c44ff45269cbd9c6fe69cff6782fd794644036b250f926", "extra_info": {"page_label": "772"}, "node_info": {"start": 0, "end": 1884}, "relationships": {"1": "8611bba9-39ec-460b-b6ef-4d34003024dc"}}, "__type__": "1"}, "bd86a9c7-a2f3-498a-82bc-c323271d3d39": {"__data__": {"text": "Part VI: Engaging with Cloud Computing756Installing Ansible\nAnsible software packages are available for RHEL, Fedora, Ubuntu, and other Linux \ndistributions. Because Ansible playbooks are run from a control node, there is no need to \ninstall Ansible software on any of the nodes that it targets.\nSo, start by installing the ansible  package on the RHEL, Fedora, Ubuntu, or other Linux \nsystem that you want to use as your control node. That control node must simply be able to \nconnect to the SSH service running on the host nodes to which you want to deploy.\nInstall the ansible  package in one of the following ways:\nRHEL 8:\n# subscription-manager repos \\\n    --enable ansible-2.9-for-rhel-8-x86_64-rpms\n# dnf install ansible -y\nFedora:\n# dnf install ansible -y\nUbuntu:\n$ sudo apt update\n$ sudo apt install software-properties-common\n$ sudo apt-add-repository --yes --update ppa:ansible/ansible\n$ sudo apt install ansible\nWith Ansible installed, you can start to build the inventory that provides the targets for \nthe playbooks that you will run.\nCreating an inventory\nA simple inventory can consist of the name representing the target for a playbook and the \nhost systems associated with that name. To get started, here is an inventory example that \ncontains three groups of static hosts:\n[ws]\nhost01\nhost02\nhost03\n \n[newyork]\nhost01\n \n[houston]\nhost02\nhost03\nAdding these entries to the /etc/ansible/hosts  file makes them available when you \nrun Ansible commands and playbooks.", "doc_id": "bd86a9c7-a2f3-498a-82bc-c323271d3d39", "embedding": null, "doc_hash": "2b1d3ce99253ddf6ead034a0d87af7ff6f7040afa0c646ad5f0e5154921c7c6a", "extra_info": {"page_label": "773"}, "node_info": {"start": 0, "end": 1482}, "relationships": {"1": "fdcd0ccd-aa6b-499d-bbd0-18295092af4a"}}, "__type__": "1"}, "6804bb6e-2a8c-4db9-b10d-ced299655fe5": {"__data__": {"text": "Chapter 29: Automating Apps and Infrastructure with Ansible\n757\n29Although this procedure just deploys to the set of hosts in the ws  group, the other two \ngroups illustrate how you might want to set up playbooks for separate tasks based on the \nlocation of the machines ( newyork  and houston ).\nAuthenticating to the hosts\nJust to make sure that you can access each host from the Ansible system, ssh  to each host. \nYou should not have to enter a password:\n$ ssh joe@host01\nLast login: Wed Feb  5 19:28:39 2020 from 192.168.122.208\n$ exit\nRepeat for each host.\nCreating a playbook\nThis playbook results in web server software being installed and started on the hosts \ndefined earlier in the ws  group. Likewise, the playbook checks that firewall software is \ninstalled and running, and that port 80 (http port) is open in the firewall to access the web \nserver. I added the following content to a file called simpl e_web.yaml :\n---\n- name: Create web server\n  hosts: ws\n  remote_user: joe\n  become_method: sudo\n  become: yes \n  tasks:\n  - name: Install httpd\n    yum:\n      name: httpd\n      state: present\n  - name: Check that httpd has started\n    service:\n      name: httpd\n      state: started\n  - name: Install firewalld\n    yum:\n      name: firewalld\n      state: present\n  - name: Firewall access to https\n    firewalld:\n      service: http\n      permanent: yes\n      state: enabled\n  - name: Restart the firewalld service to load in the firewall \nchanges", "doc_id": "6804bb6e-2a8c-4db9-b10d-ced299655fe5", "embedding": null, "doc_hash": "2cfd6f79330c945a47a4ad60c5cd3a426a6ac8ee21b0a5451a2a76e579b70b75", "extra_info": {"page_label": "774"}, "node_info": {"start": 0, "end": 1464}, "relationships": {"1": "85fb3d01-ca41-4156-8d9d-8a11e98b0ecb"}}, "__type__": "1"}, "17981f9d-35ff-4299-94ad-4fe65db58d04": {"__data__": {"text": "Part VI: Engaging with Cloud Computing758    service:\n      name: firewalld\n      state: restarted\n \nThe three hyphens at the beginning of the simple_web.yaml playbook indicate the start \nof the YAML content in the file. Here's a breakdown of the rest of the file:\nname : The play is identified as \u201cCreate web server.\u201d\nhosts : Apply this inventory to the hosts in the ws  group.\nremote_user : The regular user that is used to authenticate to each remote system. \nThis is done because it is a good security practice not to allow direct root login to a \nremote system.\nbecome : Enabling this feature ( yes) tells Ansible to become a different user than the \nremote_user to run the modules in the task.\nbecome_method : What feature to use to escalate privilege ( sudo ).\nbecome_user : Which user to authenticate to (root).\ntasks : Starts the section containing the tasks.\nname : The name is a title given to the task. In the first case, \u201cInstall httpd,\u201d then \n\u201cCheck that httpd has started,\u201d and so on. The next line starts with the name of a \nmodule (yum, service , firewalld , and so on).\nFor yum , it says to check if the httpd  package is present , and if it is not, then install it.\nFor service , it checks whether or not the httpd  daemon is running ( started ). If httpd  \nis not running, Ansible starts it.\nFor yum , it says to check if the firewalld  package is present , and if it is not, then \ninstall it.\nFor firewalld , make the port for the http  service (TCP 80) available immediately \n(enabled ) and permanently ( permanent: yes ) through the firewall.\nFor service , restart the firewalld  service (restarted ) to enable access to the new \nhttp  service firewall port.\nRun the playbook\nUse the ansible-playbook  command to run the playbook. To test the playbook before \nrunning it live, use the -C  option. To see more details (at least until you are sure that it\u2019s \nworking), add the -v  option to see verbose output.\nKeep in mind that if you run a playbook with -C , it cannot fully test the playbook to make \nsure that it is correct. The reason is that a later step might require that an earlier step be \ncompleted before it can be done. In this example, the httpd  package would need to be \ninstalled before the httpd  service can be running.", "doc_id": "17981f9d-35ff-4299-94ad-4fe65db58d04", "embedding": null, "doc_hash": "dcd1358a4705b9e0f4881fd62fe6a9b33de8b8672237406eb793c93ec47ab9c3", "extra_info": {"page_label": "775"}, "node_info": {"start": 0, "end": 2259}, "relationships": {"1": "dc869f38-7e85-4ea9-940a-d67f7288e491"}}, "__type__": "1"}, "ea624d00-b60f-4e8c-8128-997996b781b5": {"__data__": {"text": "Chapter 29: Automating Apps and Infrastructure with Ansible\n759\n29Here\u2019s an example of running the Ansible playbook in verbose mode:\n$ ansible-playbook -v simple_web.yaml\nUsing /etc/ansible/ansible.cfg as config file\n \nPLAY [Create web server] ***************************************\n \nTASK [Gathering Facts] *****************************************\nok: [host03]\nok: [host02]\nok: [host01]\n \nTASK [Install httpd]  \n****************************************************************\nchanged: [host01] => {\"changed\": true, \"msg\": \"\", \"rc\": 0,\n    \"results\": [\"Installed: httpd\", ...\nchanged: [host02] => {\"changed\": true, \"msg\": \"\", \"rc\": 0,\n    \"results\": [\"Installed: httpd\", ...\nchanged: [host03] => {\"changed\": true, \"msg\": \"\", \"rc\": 0,\n    \"results\": [\"Installed: httpd\", ...\n \nTASK [Check that httpd has started]  \n****************************************************************\nchanged: [host03] => {\"changed\": true, \"name\": \"httpd\",\n    \"state\": \"started\", \"status\":\nchanged: [host02] => {\"changed\": true, \"name\": \"httpd\",\n    \"state\": \"started\", \"status\": ...\nchanged: [host01] => {\"changed\": true, \"name\": \"httpd\",\n    \"state\": \"started\", \"status\": ...\n...\nTASK [Install firewalld]****************************************\nchanged: [host03] => {\"changed\": true, \"msg\": \"\", \"rc\": 0, \"results\":\n    [\"Installed: firewalld\", \"Installed: python3-decorator...\nchanged: [host02] => {\"changed\": true, \"msg\": \"\", \"rc\": 0, \"results\":\n    [\"Installed: firewalld\", \"Installed: python3-decorator...\nchanged: [host01] => {\"changed\": true, \"msg\": \"\", \"rc\": 0, \"results\": \n  [\"Installed: firewalld\"...\n \n \nTASK [Firewall access to https]*************************************\n****\nok: [host03] => {\"changed\": false, \"msg\": \"Permanent operation,\n    (offline operation: only on-disk configs were altered)\"}\nok: [host02] => {\"changed\": false, \"msg\": \"Permanent operation,\n    (offline operation: only on-disk configs were altered)\"}\nok: [host01] => {\"changed\": false, \"msg\": \"Permanent operation,\n    (offline operation: only on-disk configs were altered)\"}\n ", "doc_id": "ea624d00-b60f-4e8c-8128-997996b781b5", "embedding": null, "doc_hash": "53f5ac18c4bb9bfbca4101ed9acc0a9f6c869c34a25b3eda2a2b1c6d5fffe27c", "extra_info": {"page_label": "776"}, "node_info": {"start": 0, "end": 2047}, "relationships": {"1": "471ae22a-39ee-4f3e-8990-79cdb10cb0d2"}}, "__type__": "1"}, "93bc5df9-d52a-4496-8064-41969f751d2c": {"__data__": {"text": "Part VI: Engaging with Cloud Computing760PLAY RECAP *****************************************************\nhost01: ok=6 changed=4 unreachable=0 failed=0 skipped=0 rescued=0 \nignored=0\nhost02: ok=6 changed=4 unreachable=0 failed=0 skipped=0 rescued=0 \nignored=0\nhost03: ok=6 changed=4 unreachable=0 failed=0 skipped=0 rescued=0  \nignored=0\nThe output from ansible-playbook  steps through each task. The first task ( Gathering \nFacts ) shows that all three host systems in the ws  inventory are accessible. What you \ncan\u2019t see is that it is using the credentials to connect to each system and then escalating \nthat user to root privilege before completing each subsequent task.\nThe \u201cInstall httpd\u201d task checks to see if the httpd package is yet installed on each host. \nIf it is not, Ansible asks to install the package, along with any dependent packages. Next, \nAnsible checks the status of the httpd  service on each host and, if it is not running, then \nstarts it.\nAfter that, each host is checked to see if the firewalld  package is installed and installs \nit if it is not there. Then Ansible adds a firewall rule to each host to allow access to the \nhttp  service (TCP port 80) and makes that setting permanent.\nThe PLAY RECAP  then shows you the results of all of the tasks. Here you can see that all \nsix tasks on all hosts were ok . If there had been any failed, skipped, rescued, or ignored \ntasks, they would be listed.\nYou can rerun this playbook if you think that something may have gotten out of place or if \nyou made a modification to it. You could also use it later to deploy the playbook on differ -\nent systems.\nAlthough you have seen how Ansible is good at deploying multiple tasks in playbooks, it \ncan also be used for one-off actions. In the next section, I show how to run some ad-hoc \nAnsible commands to query and further modify the hosts that we just deployed.\nRunning Ad-Hoc Ansible Commands\nThere may be times when you want to do one-off tasks on your Ansible-managed nodes. \nYou can do those tasks using ad-hoc commands . With an ad-hoc command, you can directly \ncall a module from the Ansible command line and have it act on an inventory. Some of \nthose tasks could include the following:\n\u25a0\u25a0Installing RPM software packages\n\u25a0\u25a0Managing user accounts\n\u25a0\u25a0Copying files to and from nodes\n\u25a0\u25a0Changing permissions on a file or directory\n\u25a0\u25a0Rebooting a node", "doc_id": "93bc5df9-d52a-4496-8064-41969f751d2c", "embedding": null, "doc_hash": "d05e32bab4f9782967ec1392c4f30fabb5f7b6a4be394c79547ccb999a8ee8a4", "extra_info": {"page_label": "777"}, "node_info": {"start": 0, "end": 2374}, "relationships": {"1": "4e6147a6-8446-4e20-a7a6-395667d3847c"}}, "__type__": "1"}, "fc0b1b56-06d4-4d94-8a55-90e48d0de69d": {"__data__": {"text": "Chapter 29: Automating Apps and Infrastructure with Ansible\n761\n29Just as when you run playbooks, running ad-hoc commands focuses on reaching a desired \nstate. The ad-hoc command takes a declarative statement, figures out what is being \nrequested, and does what it needs to do to reach the requested state.\nTo try these examples of ad-hoc Ansible commands, you can use the ws  inventory created  \nearlier.\nTrying ad-hoc commands\nWhen you run an ad-hoc Ansible command, you take some action using an Ansible module. \nThe command  module is used by default if no other module is indicated. Using the module, \nyou indicate which command and options you want to run on a group of nodes as a one-\ntime activity.\nCheck that an inventory is up and running. Here, you see that hosts are all running in the \nws inventory:\n$ ansible ws -u joe -m ping\nhost03 | SUCCESS => {\n    \"ansible_facts\": {\n        \"discovered_interpreter_python\": \"/usr/bin/python\"\n    },\n    \"changed\": false,\n    \"ping\": \"pong\"\n}\nhost02 | SUCCESS => { ...\nhost01 | SUCCESS => { ...\nYou can find out if the httpd  service is running on the hosts in the ws  inventory by \nchecking the state of that service with this ansible  command as follows:\n$ ansible ws -u joe -m service \\\n     -a \"name=httpd state=started\" --check\nhost02 | SUCCESS => {\n    \"ansible_facts\": {\n        \"discovered_interpreter_python\": \"/usr/bin/python\"\n    },\n    \"changed\": false,\n    \"name\": \"httpd\",\n    \"state\": \"started\",\n    \"status\": { ...\nhost 01 | SUCCESS => { ...\nAt the moment, there is no content on the web servers. To add an index.html  file (con -\ntaining the text \u201cHello from your web server!\u201d) to all of the hosts in the ws  inventory, you \ncould run this command (type the root password when prompted):\n$ echo \"Hello from your web server!\" > index.html\n$ ansible ws -m copy -a \\\n    \"src=./index.html dest=/var/www/html/ \\", "doc_id": "fc0b1b56-06d4-4d94-8a55-90e48d0de69d", "embedding": null, "doc_hash": "8b94919e6db137f10ad975f9446a14159e2b688521f05e344aefcdf25f6bdd5d", "extra_info": {"page_label": "778"}, "node_info": {"start": 0, "end": 1876}, "relationships": {"1": "12dbd2e0-bd6a-4678-9455-24b430b4a4b1"}}, "__type__": "1"}, "b22f537f-ea44-4e7f-bc31-b6bce9f7e89b": {"__data__": {"text": "Part VI: Engaging with Cloud Computing762    owner=apache group=apache mode=0644\" \\\n    -b --user joe --become --ask-become-pass\nBECOME password: *********\nhost01 | CHANGED => {\n    \"ansible_facts\": {\n        \"discovered_interpreter_python\": \"/usr/bin/python\"\n    },\n    \"changed\": true,\n    \"checksum\": \"213ae4bb07e9b1e96fbc7fe94de372945a202bee\",\n    \"dest\": \"/var/www/html/index.html\",\n    \"gid\": 48,\n    \"group\": \"apache\",\n    \"md5sum\": \"495feb8ad508648cfafcf69681d94f97\",\n    \"mode\": \"0644\",\n    \"owner\": \"apache\",\n    \"secontext\": \"system_u:object_r:httpd_sys_content_t:s0\",\n    \"size\": 52,\n    \"src\": \"/home/joe/.ansible/tmp/ansible-tmp-1581027374.649223-\n29961128730253/source\",\n    \"state\": \"file\",\n    \"uid\": 48\nhost02 | CHANGED => { ...\nhost03 | CHANGED => { ...\nYou can see that the index.html  file is created with the apache  owner (UID 48) and \napache  group (GID 48) in the /var/www/html  directory on host01 . The copy was then \nrepeated to host02  and host03 . You can check that everything is working by trying to \naccess that file from the ansible  host through the web server using the curl  command:\n$ curl host01\nHello from your web server!\nAutomating Tasks with Ansible Tower \nAutomation Framework\nAlthough running Ansible playbooks and commands are great for automating and later \nmodifying sets of hosts, for a fully managed enterprise, you can go even further with Ansi-\nble. Using Ansible Tower, you can add a larger framework to your Ansible deployments.\nAnsible Tower  provides a web-based interface for managing your entire IT infrastructure \nwith Ansible playbooks and other components. By centralizing your Ansible assets in one \nplace, you have a single place to receive notifications. You can manage different adminis -\ntrative roles across your enterprise.\nThe Ansible Tower interface makes it easy to update your provisioned assets continuously. \nInstead of having to remember command-line options, you can just click to configure and ", "doc_id": "b22f537f-ea44-4e7f-bc31-b6bce9f7e89b", "embedding": null, "doc_hash": "c3a5ca5a47ad571d1c3133d808c7e2d21eaed80aeb7501a8f452fb147b9490bb", "extra_info": {"page_label": "779"}, "node_info": {"start": 0, "end": 1971}, "relationships": {"1": "500f4b48-da17-4a63-a7ee-37bacbcda968"}}, "__type__": "1"}, "edaf2361-3251-4533-bcdb-d5372a2b1e83": {"__data__": {"text": "Chapter 29: Automating Apps and Infrastructure with Ansible\n763\n29launch your Ansible tasks. Inventory management is graphical and job scheduling can be \ndone in intuitive, visual ways.\nA REST API is available with Ansible Tower that can help you embed your existing infra -\nstructure tools into Ansible. So, you can usually just continue the processes that you \nalready have in place but manage them with Ansible instead.\nYou can learn more about Ansible Tower from the Ansible Tower site ( https://www  \n.ansible.com/products/tower ).\nSummary\nAnsible provides a unique formatting language and set of tools to automate many of the \ntasks that you have learned in other parts of this book. Once you know how to build an \nAnsible playbook, you can identify the exact configuration that you want on a system and \nthen easily deploy that configuration to one or more host systems.\nWith Ansible playbooks, you define the exact state of an application and surrounding com-\nponents and then apply that state to Linux host systems, network devices, or other targets. \nYou can save those playbooks and reuse them to produce similar results on other systems or \nadapt them to create new and different results.\nAnsible can also use ad-hoc commands to update systems. From the ansible  command \nline, you can add users, copy files, install software, or do almost anything else you can do \nwith playbooks. With those commands, you can quickly apply a set of changes across mul -\ntiple hosts or respond to a problem that requires a quick fix that needs to be made immedi-\nately to a set of hosts.\nIn this chapter, you learned about the different components that make up an Ansible tool -\nset. You created your own playbook for deploying a simple web server. Then you ran some \nad-hoc commands to modify the systems to which you deployed your playbook.\nExercises\nThese exercises test your ability to get Ansible installed on your system, create your first \nAnsible playbook, and run a few ad hoc Ansible commands. These tasks assume that you \nare running a Fedora or Red Hat Enterprise Linux system (although some tasks work on \nother Linux systems as well).\nAlthough Ansible is meant to deploy tasks to remote systems, the exercises here will just \nlet you try out a playbook and a few commands on a single system. If you are stuck, solu -\ntions to the tasks are shown in Appendix B (although in Linux, you can often complete a \ntask in multiple ways).\n1. Install Ansible on your Fedora or RHEL system.\n2. Add sudo  privilege for the user that you want to use to do these exercises.", "doc_id": "edaf2361-3251-4533-bcdb-d5372a2b1e83", "embedding": null, "doc_hash": "7b9c11f4617050c2ff058c115256b37d8eae2e078328c5eb25ba674cb563fc46", "extra_info": {"page_label": "780"}, "node_info": {"start": 0, "end": 2569}, "relationships": {"1": "1fe0db50-fe6f-459d-a8d7-eb8d77f775fa"}}, "__type__": "1"}, "3f612755-36ff-4fb4-8251-f518832cafb7": {"__data__": {"text": "Part VI: Engaging with Cloud Computing7643. Create a start to an Ansible playbook (call it my_playbook.yaml ) that includes \nthe following content.\n---\n- name: Create web server\n  hosts: localhost\n  tasks:\n  - name: Install httpd\n    yum:\n      name: httpd\n      state: present\n4. Run ansible-playbook  on the my_playbook.yaml in check mode to see if \nthere is a problem completing the playbook ( hint: there is).\n5. Modify my_playbook.yaml to escalate privileges so that the tasks are run as the \nroot user.\n6. Run ansible-playbook  again until the httpd  package successfully installs on \nyour system.\n7. Modify my_playbook.yaml again to start the httpd  service, and set it so that it \nwill start every time the system boots.\n8. Run an ansible  command that checks whether or not the httpd  service is up on \nlocalhost .\n9. Create an index.html  file that contains the text \u201cWeb server is up,\u201d and use \nthe ansible  command to copy that file to the /var/www/html  directory on \nlocalhost .\n10. Use the curl  command to view the contents of the file that you just copied to the \nweb server.", "doc_id": "3f612755-36ff-4fb4-8251-f518832cafb7", "embedding": null, "doc_hash": "d9e2f850c8a9e68e3092f20aeb5c6040368a03a461e4cf9b3022f4d880311929", "extra_info": {"page_label": "781"}, "node_info": {"start": 0, "end": 1092}, "relationships": {"1": "08c2b015-4b23-470e-9e2e-8432121c910c"}}, "__type__": "1"}, "26886055-1272-404f-86cf-43b0a7c8fb9f": {"__data__": {"text": "765\nCHAPTER30\nDeploying Applications as \nContainers with Kubernetes\nIN THIS CHAPTER\nUnderstanding Kubernetes\nTrying Kubernetes\nRunning the Kubernetes Basics Tutorials\nEnterprise-quality Kubernetes with OpenShift\nLinux containers separate the applications they contain from the operating systems on which \nthey run. Built properly, a container will hold a discrete set of software that can be trans -\nported and run efficiently. But the story doesn\u2019t end there. Once you have some containers,  \nthe next step is to engage them with a platform like Kubernetes that allows you to do the \nfollowing:\n\u25a0\u25a0Group sets of containers together to form a larger application. For example, deploy a web \nserver, a database, and monitoring tools together.\n\u25a0\u25a0Scale up your containers as the demand requires. In fact, you want to be able to scale each \ncomponent of the larger application individually, without having to scale up everything.\n\u25a0\u25a0Set the state of your application and not just run it. What this means is that, instead of \njust saying to run a container, you want to be able to say something like \u201crun three copies \nof container X, and if one goes down, be sure to start another one to replace it.\u201d\n\u25a0\u25a0Recover from host computers going down or becoming overloaded. If the host running \na container fails, you want the container to recover quickly and start up on another \nhost computer.\n\u25a0\u25a0Not be concerned about the infrastructure. You want your application to connect to the \nservices that it needs without having to know the hostnames, IP addresses, or port num-\nbers associated with those services.\n\u25a0\u25a0Upgrade your containerized applications without downtime.\nKubernetes offers all of those features and more. While at first there were others competing to be the \nplatform of choice for orchestrating containers, such as Mesos and Docker Swarm, Kubernetes has \nbecome the undisputed leader in orchestrating, deploying, and managing containerized applications.\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "26886055-1272-404f-86cf-43b0a7c8fb9f", "embedding": null, "doc_hash": "77f58a6cc83c23ee9bdb7dd65973ea25b0c346214d49a9cecb5ceec5a857e5ee", "extra_info": {"page_label": "782"}, "node_info": {"start": 0, "end": 2078}, "relationships": {"1": "0f3ea944-b933-43bd-a972-60faca64ac6b"}}, "__type__": "1"}, "e97a197b-33a9-4148-bf5e-a64690ce6f73": {"__data__": {"text": "Part VI: Engaging with Cloud Computing766This chapter introduces you to Kubernetes and the enterprise-quality Kubernetes platform \ncalled OpenShift. The best way to learn Kubernetes is to start up a Kubernetes cluster and \nrun commands in order to explore Kubernetes and deploy a containerized application. Before \nyou do that, you should understand a bit about what a Kubernetes cluster is and what compo -\nnents you need to deploy an application to a cluster.\nUnderstanding Kubernetes\nA Kubernetes cluster  is made up of master and worker nodes. You can run all master and \nworker services on the same system for personal use. For example, with Minikube, as \ndescribed later in this chapter, you can run a Kubernetes cluster from a virtual machine on \nyour laptop ( https://kubernetes.io/docs/tasks/tools/install-minikube ).\nIn a production environment, you would spread Kubernetes across multiple physical or vir -\ntual systems. Here are the different components you need to consider if you were to set up \na production-quality Kubernetes infrastructure:\nMasters : A master node  manages the components running in the Kubernetes cluster. \nIt manages communications between components, schedules applications to run on \nthe workers, scales up the applications as needed, and makes sure that the proper \nnumber of containers (distributed in pods ) are running. You should have at least \none master node, but you would typically have three or more available to make sure \nthere is always at least one available master.\nWorkers : A worker node  is where the deployed containers actually run. The number \nof workers that you need depends on your workload. For a production environ -\nment, you would certainly want more than one worker in case one failed or needed \nmaintenance.\nStorage : Networked storage allows containers to access the same storage, regardless of \nthe node that runs them.\nOther services : To integrate a Kubernetes environment into an existing data center, \nyou might want to tap into existing services. For example, you would probably use \nyour company\u2019s DNS server for the hostname to address resolution, LDAP or Active \nDirectory service for user authentication, and a Network Time Protocol (NTP) server \nto synchronize time.\nIn Kubernetes, the smallest unit with which you can deploy a container is referred to as a \npod. A pod can hold one or more containers, along with metadata describing its containers. \nAlthough a pod can hold only one container, it is sometimes appropriate for a pod to have \nmore than one. For example, a pod might contain a sidecar container , which is meant to \nmonitor the service running in the primary container in the pod.\nKubernetes masters\nA Kubernetes master node  directs the activities of a Kubernetes cluster. Master nodes \noversee all of the activities of the cluster through a set of services. The centerpiece of a ", "doc_id": "e97a197b-33a9-4148-bf5e-a64690ce6f73", "embedding": null, "doc_hash": "be7cf4111d4adfe037dfcd0c44bbc20c2266f41c73ff39d8322a311595835bd6", "extra_info": {"page_label": "783"}, "node_info": {"start": 0, "end": 2876}, "relationships": {"1": "b1a5e353-fb42-4039-9815-9ed3f5a9f91d"}}, "__type__": "1"}, "681e643d-69a5-440a-b889-4e0b278e7a16": {"__data__": {"text": "Chapter 30: Deploying Applications as Containers with Kubernetes\n767\n30Kubernetes master  is the API server ( kube-apiserver ), which receives object requests. \nCommunications between all of the nodes in the cluster pass through the API server.\nWhen a Kubernetes master is presented with an object , such as a request that a certain \nnumber of pods be running, the Kubernetes scheduler ( kube-scheduler ) finds avail -\nable nodes to run each pod and schedules them to run on those nodes. To make sure that \neach object remains in the prescribed state, Kubernetes controllers ( kube-controller-\nmanager ) run continuously to do things such as to make sure that namespaces exist, that \ndefined service accounts are available, that the right number of replicas are running, and \nthat defined endpoints are active.\nKubernetes workers\nAt the heart of each Kubernetes worker node  is the kubelet service. A kubelet registers its \nworker node with the API server. The API server then directs the kubelet to do things like \nrun a container that is requested from the API server through a PodSpec and make sure \nthat it continues to run in a healthy state.\nAnother service that runs on each node is a container engine  (often referred to as a run -\ntime). Originally, the docker service was by far the most popular container engine used to \nlaunch, manage, and delete containers as required by the PodSpec. However, other con -\ntainer engines are now available, such as the CRI-O container engine ( https://cri-o.\nio/), which is used with some commercial Kubernetes platforms such as OpenShift.\nWorker nodes are meant to be as generic as possible so that you can simply spin up a new \nnode when additional capacity is needed and it will be configured to handle most requests \nto run containers. There are, however, ways in which a container might not be appropriate \nto run on a particular node. For example, a pod might request to run on a node that has a \nminimum amount of memory and CPU available, or it might request to run on a node that \nis running a related container. Likewise, if a pod requires something special to run, such \nas a particular computer architecture, hardware, or operating system, there are ways to \nschedule pods on workers that meet those needs.\nKubernetes applications\nIn Kubernetes, applications are managed by defining API objects that set the state of \nresources on the cluster. For example, you can create a Deployment  object in a YAML \nfile that defines pods  that each run one or more containers, along with the namespace  \nin which it runs and the number of replicas  of each pod it runs. That object could also \ndefine the ports  that are open and any volumes  that are mounted for each container. \nKubernetes master  nodes respond to those kinds of requests and make sure that the \nrequests are carried out on the Kubernetes worker  nodes.\nKubernetes uses the concept of services  to separate the location of an application from its \nactual IP address and port number. By assigning a service name to the set of pods that \nprovide that service, the exact location of each pod does not need to be known outside \nof the cluster. Instead, it is up to Kubernetes to direct a request for that service to an \navailable pod.", "doc_id": "681e643d-69a5-440a-b889-4e0b278e7a16", "embedding": null, "doc_hash": "704bd4820927f26d5d47a95d04305f6abb7d74f20038f86ba4debe7e15e6317c", "extra_info": {"page_label": "784"}, "node_info": {"start": 0, "end": 3246}, "relationships": {"1": "8faa3c2f-4fd1-41a1-8db5-716aad00c402"}}, "__type__": "1"}, "f9fb1eb8-6fb5-48b1-875b-edef37e28451": {"__data__": {"text": "Part VI: Engaging with Cloud Computing768IP addresses associated with active pods are not directly addressable from outside the  \ncluster by default. It is up to you to define how you want to expose a service associated \nwith a set of pods outside of the cluster. Using a Service  object, you can expose services \nin different ways.\nBy default, exposing a service via a ClusterIP  service type  makes it available only to \nother components within the cluster. To expose the service outside of the cluster, you can use \nNodePort , which makes the pod providing the service accessible through the same Kuber -\nnetes-assigned port on an external IP address from each node on which the pod is running.\nA third method is to use LoadBalancer  to assign an external, fixed IP address that acts \nas a load balancer to the pods providing the service. With LoadBalancer , a cloud\u2019s exter -\nnal load balancer directs traffic to the backend pods. Finally, you can expose the service \nwith ExternalName , which associates the service with a particular DNS CNAME record.\nRegardless of how you expose a Kubernetes service, when there is a request for that service, \nKubernetes acts to route communications to the set of pods that provide that service. In \nthat way, pods can come up and down without disrupting the clients using the service.\nKubernetes interfaces\nKubernetes has both command-line and web console interfaces for accessing a Kubernetes \ncluster. The examples in this chapter focus on command-line tools. Commands include \nminikube , which is used to manage the Kubernetes virtual machine and bring the cluster \nup and down, and kubectl , which is the general-purpose tool for managing the Kuber -\nnetes cluster.\nTrying Kubernetes\nBecause setting up your own production-quality Kubernetes cluster requires some fore -\nthought, this chapter will focus on a couple of easy ways to get a personal Kubernetes clus -\nter running and accessible quickly. In particular, here are two different ways that you can \ngain access to a Kubernetes cluster:\nKubernetes Tutorials : The official Kubernetes site offers interactive, web UI tutorials, \nwhere you can start up your own cluster and try out Kubernetes. From Kubernetes \nTutorials (https://kubernetes.io/docs/tutorials/ ), you can choose from \nbasic, configuration, stateless applications, and other tutorial topics.\nMinikube : With Minikube, you can run Kubernetes on your own computer. A Linux, \nMacOS, or Windows system that can run virtual machines can get the Minikube \nVM and have a Kubernetes cluster running on a laptop or desktop system within a \nfew minutes.\nDocker Desktop : Another option (not detailed here) is Docker Desktop, which lets you \nenable a pre-configured Kubernetes cluster that runs a master and worker node on \nyour workstation.", "doc_id": "f9fb1eb8-6fb5-48b1-875b-edef37e28451", "embedding": null, "doc_hash": "167fc81d0d00d7a0f69198f2671ce8f7203d39a1530a86ffa5efd85fc2014407", "extra_info": {"page_label": "785"}, "node_info": {"start": 0, "end": 2797}, "relationships": {"1": "6fa3618d-a757-42ed-b3c2-ef687e91db76"}}, "__type__": "1"}, "814a6b8b-bb00-4c6b-8ecc-d3aaa5ebe9bd": {"__data__": {"text": "Chapter 30: Deploying Applications as Containers with Kubernetes\n769\n30To get you started, I\u2019ll step you through some of the Kubernetes tutorials and explain the \nconcepts behind what they are doing. You can follow along in the tutorial or run the same \ncommands on your own Minikube setup. I describe how to get Kubernetes in one of these \ntwo ways next.\nNote\nIf you have an OpenShift environment up and running, you can follow most of these steps in OpenShift as well. In \nmost case, you can use the kubectl  command, but typically the same options and arguments can be used by the \noc command for OpenShift.\nGetting Kubernetes\nThe following descriptions tell you how to access a Kubernetes cluster either through the \nKubernetes Basics Tutorial or by installing and starting Minikube.\nStarting the Kubernetes Basics Tutorial\nTo start up the Kubernetes project basic interactive tutorial, visit the following URL from \nyour web browser:\nhttps://kubernetes.io/docs/tutorials/kubernetes-basics/create-cluster/\ncluster-interactive\nFigure\u00a030.1 shows the start of the Kubernetes Basics Tutorial.\nFIGURE 30.1\nStep through the Kubernetes project tutorials", "doc_id": "814a6b8b-bb00-4c6b-8ecc-d3aaa5ebe9bd", "embedding": null, "doc_hash": "78b3a6744f08e59e2961705572b02c4f33796dd5d861b502ec300a886d44e95e", "extra_info": {"page_label": "786"}, "node_info": {"start": 0, "end": 1150}, "relationships": {"1": "d2dcfd9b-20d2-45dc-9442-480d1e9a40f6"}}, "__type__": "1"}, "5a36ffa5-2364-48b1-a318-d05e7ff4b80a": {"__data__": {"text": "Part VI: Engaging with Cloud Computing770At this point, you can follow the prompts through the tutorial. Because the tutorial starts a \nlive cluster, you can use that interface to try other commands as well.\nStarting Minikube\nGetting Minikube running on your personal computer requires a few things. This includes \nthe following:\n\u25a0\u25a0The computer needs to be configured as a hypervisor, so it can run the Minikube \nvirtual machines.\n\u25a0\u25a0You need to install the kubectl  command (used to access and work with the  \ncluster) and the Minikube VM itself.\nFor Linux, MacOS, and Windows systems, go here to find the latest instructions:\nhttps://kubernetes.io/docs/tasks/tools/install-minikube/\nYou can install Minikube as root user, but you need to run it later from a regular user \naccount. The steps for installing Minikube on a Fedora, RHEL, Ubuntu, or other Linux \nsystem are as follows (refer to the install-minikube  page if something has changed):\n1. Install the kubectl  command : Get a version of the kubectl  command that is \nwithin one version of Kubernetes in your Minikube. Installing the latest versions \nof kubectl  and minikube  should take care of that. Enter the following (all on \none line):\n# curl -LO \\\n https://storage.googleapis.com/kubernetes-release/release/`curl \\\n-s https://storage.googleapis.com/kubernetes-release/release/\n   stable.txt \\\n`/bin/linux/amd64/kubectl\n2. Copy kubectl  to a bin directory : Copy the kubectl  command to an accessible \nbin directory and make it executable. For example:\n# mkdir /usr/local/bin\n# cp kubectl /usr/local/bin\n# chmod 755 /usr/local/bin/kubectl\n3. Configure hypervisor : Configure your Linux system as a hypervisor. For KVM, use \nthe descriptions found in the section \u201cConfiguring hypervisors\u201d in Chapter\u00a027.\n4. Get minikube: Get the minikube  executable, and enter the following (on \none line):\n# curl -Lo minikube \\\nhttps://storage.googleapis.com/minikube/releases/latest/minikube-\nlinux-amd64 \\\n&& chmod +x minikube\n5. Install Minikube : Enter the following:\n# install minikube /usr/local/bin/", "doc_id": "5a36ffa5-2364-48b1-a318-d05e7ff4b80a", "embedding": null, "doc_hash": "610229de352f8c83828ac55a3d6b3aef8a6fb4a844af9a473f0fa91a93fdefb3", "extra_info": {"page_label": "787"}, "node_info": {"start": 0, "end": 2055}, "relationships": {"1": "482cb469-8738-46cd-9b26-e7ad65c66bed"}}, "__type__": "1"}, "95b57879-58d4-40c8-92c9-4ff3d9aac971": {"__data__": {"text": "Chapter 30: Deploying Applications as Containers with Kubernetes\n771\n306. Run Minikube : As a regular user, enter the following commands to identify the \ndriver if your hypervisor is KVM (see https://minikube.sigs.k8s.io/docs/\nreference/drivers  if you are using a different hypervisor):\n$ minikube config set vm-driver kvm2\n$ minikube start --vm-driver=kvm2\n7. Start using Minikube : You can start using Minikube by running some mini -\nkube  and kubectl  commands. Examples of how to do that are shown in the \nnext tutorial.\nRunning the Kubernetes Basics tutorial\nThe Kubernetes Basics Tutorial take you through a good set of commands to start familiar -\nizing yourself with Kubernetes:\nhttps://kubernetes.io/docs/tutorials/kubernetes-basics/create-cluster/\ncluster-interactive\nThe following text walks you through the first five modules of the Kubernetes Basics  \nTutorial.\nIf you are running through this procedure directly from the Kubernetes tutorials page, \ngo ahead and start Minikube ( minikube start ). If you are using Minikube from a VM \nalready running on your laptop, you can still follow this procedure. The steps are the same \nsince both use Minikube.\nGet information about your cluster\nRun these commands to get basic information about your cluster.\n1. List Minikube version : To see the version of minikube  you are using, enter the \nfollowing:\n$ minikube version\nminikube version: v1.7.2\ncommit: 50d543b5fcb0e1c0d7c27b1398a9a9790df09dfb\n2. List cluster information : To see the URL from which the Kubernetes master and \nDNS services are available, enter the following:\n$ kubectl cluster-info\nKubernetes master is running at https://192.168.39.150:8443\nKubeDNS is running at\nhttps://192.168.39.150:8443/api/v1/namespaces/kube-system/\nservices/kube-dns:dns/proxy\nTo further debug and diagnose cluster problems, use \n'kubectl cluster-info dump'.\n3. List node information : To see the number of nodes running (just one master node \nfor Minikube) and their status, enter the following:\n$ kubectl get nodes\nNAME     STATUS   ROLES  AGE   VERSION\nminikube Ready    master 23m   v1.17.2", "doc_id": "95b57879-58d4-40c8-92c9-4ff3d9aac971", "embedding": null, "doc_hash": "ca9c13d4fdcc444c5dcf952f1d60b266d858c860d39b43227dfa67cce28d9ffc", "extra_info": {"page_label": "788"}, "node_info": {"start": 0, "end": 2096}, "relationships": {"1": "25654a24-78bb-4c4e-b01c-e22f34789b33"}}, "__type__": "1"}, "5ea55572-9ace-4e57-8122-3618ad87ce1b": {"__data__": {"text": "Part VI: Engaging with Cloud Computing7724. List cluster and client versions : To list the versions of the kubectl  client and \nKubernetes cluster (to make sure that they are within one version of each other), \nenter the following:\n$ kubectl version\nClient Version: version.Info{Major:\"1\", Minor:\"17\",\nGitVersion:\"v1.17.2\", \nGitCommit:\"59603c6e503c87169aea6106f57b9f242f64df89\", \nGitTreeState:\"clean\", BuildDate:\"2020-01-18T23:30:10Z\", \nGoVersion:\"go1.13.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n \nServer Version: version.Info{Major:\"1\", Minor:\"17\",\nGitVersion:\"v1.17.2\", \nGitCommit:\"59603c6e503c87169aea6106f57b9f242f64df89\", \nGitTreeState:\"clean\", BuildDate:\"2020-01-18T23:22:30Z\", \nGoVersion:\"go1.13.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nDeploy a Kubernetes application\nRequests to run and manage containerized applications (in the form of pods) on a Kuber -\nnetes cluster is known as a deployment . Once a deployment is created, it is up to the Kuber -\nnetes cluster to make sure that the requested pods are always running. It does this by \ndoing the following:\n\u25a0\u25a0Accepting the deployment creation through the API server\n\u25a0\u25a0Asking the scheduler to run the requested containers from each pod on available \nworker nodes\n\u25a0\u25a0Watching the pods to make sure they continue to run as requested\n\u25a0\u25a0Starting a new instance of a pod (on the same or different node) if the pod fails \n(for example, if the container stops running)\nThe tutorial shows an example of how to create a simple deployment from a container \nimage. In this example, you just give it a name and identify the container image to use. \nThe rest of the deployment settings are filled in from defaults.\n1. Create a deployment : To start the deployment that pulls the kubernetes-  \nbootcamp  container with a deployment name of kubernetes bootcamp ,  \nenter the following:\n$ kubectl create deployment kubernetes-bootcamp \\\n      --image=gcr.io/google-samples/kubernetes-bootcamp:v1\ndeployment.apps/kubernetes-bootcamp created\n2. List deployments : To see that the deployment exists (and has one instance \nrequested and one running), enter the following.\n$ kubectl get deployments\nNAME                  READY   UP-TO-DATE   AVAILABLE   AGE\nkubernetes-bootcamp   1/1     1            1           4m38s", "doc_id": "5ea55572-9ace-4e57-8122-3618ad87ce1b", "embedding": null, "doc_hash": "0895dba48e557c15a14a0d84248e023d75555f3fc1ddf7b35eb7455c3e137d65", "extra_info": {"page_label": "789"}, "node_info": {"start": 0, "end": 2261}, "relationships": {"1": "03f3bc74-0219-4450-bfe4-7c07236a1542"}}, "__type__": "1"}, "48065c45-d81a-43d0-a2a4-77a5c1840b39": {"__data__": {"text": "Chapter 30: Deploying Applications as Containers with Kubernetes\n773\n303. Describe the deployment : To see details about the deployment, enter the \nfollowing:\n$ kubectl describe deployments kubernetes-bootcamp\nName:                   kubernetes-bootcamp\nNamespace:              default\n...\nReplicas:   1 desired | 1 updated | 1 total | 1 available | 0 \nunavailable\n...\nPod Template:\n  Labels:  app=kubernetes-bootcamp\n  Containers:\n   kubernetes-bootcamp:\n    Image:        gcr.io/google-samples/kubernetes-bootcamp:v1\n    Port:         <none>\n    Host Port:    <none>\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\n...\nIn the kubernetes-bootcamp  deployment, notice that it just set one instance ( replica ) \nof the pod associated with the deployment to be available. The deployment runs in the \ncurrent namespace, which happens to be default . Notice also that there are no ports open \nor volumes mounted by default for the pods.\nGet information on the deployment\u2019s pods\nWith the deployment created, you can ask for information about the pod created from that \ndeployment and expose the Kubernetes API from the VM to your local system, via a proxy \nservice, to connect to the pod directly.\n1. Expose the Kubernetes API to the local system : To open a proxy from your \nsystem to the Kubernetes API running in Minikube ( kubectl proxy ), enter the \nfollowing:\n$ kubectl proxy\nStarting to serve on 127.0.0.1:8001\n2. Query the Kubernetes API: Open a second terminal, and query the Kubernetes API \nrunning on Minikube by entering the following:\n$ curl http://localhost:8001/version\n{\n \"major\": \"1\",\n \"minor\": \"17\",\n \"gitVersion\": \"v1.17.2\",\n \"gitCommit\": \"59603c6e503c87169aea6106f57b9f242f64df89\",\n \"gitTreeState\": \"clean\",\n \"buildDate\": \"2020-01-18T23:22:30Z\",", "doc_id": "48065c45-d81a-43d0-a2a4-77a5c1840b39", "embedding": null, "doc_hash": "11e60f7797b8a8ee2140d7d537da49e65a0b4df70147db6ec48e2c4bb52e1f8b", "extra_info": {"page_label": "790"}, "node_info": {"start": 0, "end": 1787}, "relationships": {"1": "25cff5b1-1fa3-4392-97bf-894e6890b526"}}, "__type__": "1"}, "7f974e98-5d74-486e-8c28-253332114f72": {"__data__": {"text": "Part VI: Engaging with Cloud Computing774 \"goVersion\": \"go1.13.5\",\n \"compiler\": \"gc\",\n \"platform\": \"linux/amd64\"\n3. Get pod information : The name of the pod used in this deployment is kuber -\nnetes-bootcamp , followed by a unique string of characters. Enter these com-\nmands to output the name of the pod and then list a description of that pod:\n$ kubectl get pods\nNAME                                   READY   STATUS    RESTARTS   AGE\nkubernetes-bootcamp-69fbc6f4cf-njc4b   1/1     Running   0          12m\n$ kubectl describe pod kubernetes-bootcamp-69fbc6f4cf-njc4b\nName:         kubernetes-bootcamp-69fbc6f4cf-njc4b\nNamespace:    default\nPriority:     0\nNode:         minikube/192.168.39.150\n...\nContainers:\n  kubernetes-bootcamp:\n    Container ID:    \ndocker://dd24fd43ff19d6cf12f5c759036cee74adcf2d0e2c55a42e... \n    Image:          gcr.io/google-samples/kubernetes-bootcamp:v1\n    Image ID:       docker-pullable://gcr.io/google-samples...\n...\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  14m   default-scheduler  Successfully assigned \ndefault/kubernetes-bootcamp-69fbc6f4cf-njc4b to minikube\n  Normal  Pulled     14m   kubelet, minikube  Container image \n\"gcr.io/google-samples/kubernetes-bootcamp:v1\"\nalready present on machine\n  Normal  Created    14m   kubelet, minikube  Created container \nkubernetes-bootcamp\n  Normal  Started    14m   kubelet, minikube  Started container \nkubernetes-bootcamp\nFrom the trimmed output, you can see the name of the pod, the namespace it is in \n(default ), and the node on which it is running ( minikube/192.168.39.150 ). \nUnder Containers, you can see the name of the running container ( docker://\ndd24fd43ff19  .\u00a0.\u00a0.), the image it came from (.\u00a0.\u00a0. kubernetes-bootcamp:v1 ), \nand the image ID for that image. Under Events, starting from the bottom, you can \nsee the kubelet  on the node minikube , starting and creating the container. It \ngoes to pull the image and finds that it is already on the node. Then it assigns the \npod to run on that node.", "doc_id": "7f974e98-5d74-486e-8c28-253332114f72", "embedding": null, "doc_hash": "abc5629fcdde401cf2f69b1f116780b5316405909cd9a13932fec00f5b4da63c", "extra_info": {"page_label": "791"}, "node_info": {"start": 0, "end": 2089}, "relationships": {"1": "075b5552-9573-47dd-b334-c2c1577b3307"}}, "__type__": "1"}, "a18b9e57-86fb-408b-91bc-ced7c514871a": {"__data__": {"text": "Chapter 30: Deploying Applications as Containers with Kubernetes\n775\n304. Connect to the pod : Use the curl  command to contact the pod  and get it to \nrespond to your request for information:\n$ export POD_NAME=$(kubectl get pods -o go-template --template \\\n '{{range .items}}{{.metadata.name}}{{\"\\n\"}}{{end}}') ; \\\necho Name of the Pod: $POD_NAME\nName of the Pod: kubernetes-bootcamp-69fbc6f4cf-njc4b\n \n$ curl \\\n http://localhost:8001/api/v1/namespaces/default/pods/$POD_NAME/\nproxy/\nHello Kubernetes bootcamp!|Running on:kubernetes-bootcamp-\n5b48cfdcbd-lf9t2|v=1\n5. View the logs : To see the logs for any container that is running inside the selected \npod, run the following command:\n$ kubectl logs $POD_NAME\nKubernetes Bootcamp App Started At: 2020-02-13T21:29:21.836Z\n| Running On:  kubernetes-bootcamp-5b48cfdcbd-lf9t2\n \nRunning On: kubernetes-bootcamp-5b48cfdcbd-lf9t2 | Total Requests:\n1 | App Uptime: 34.086 seconds | Log Time: 2020-02-13T21:29:55.923Z\n6. Execute commands on the pod : Use kubectl exec  to run commands inside the \npod. The first command runs env  in order to view shell environment variables from \ninside of the pod, and the second opens a shell inside the pod so you can run the \nfollowing commands:\n$ kubectl exec $POD_NAME env\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nHOSTNAME=kubernetes-bootcamp-5b48cfdcbd-lf9t2\nKUBERNETES_SERVICE_HOST=10.96.0.1\nKUBERNETES_SERVICE_PORT=443\n...\n$ kubectl exec -ti $POD_NAME bash\nroot@kubernetes-bootcamp-5b48cfdcbd-lf9t2:/# date\nThu Feb 13 21:57:18 UTC 2020\n \nkubernetes-bootcamp-5b48cfdcbd-lf9t2:/# ps -ef\nUID        PID  PPID  C STIME TTY          TIME CMD\nroot         1     0  0 21:29 ?        00:00:00 /bin/sh -c node \nserver.js\nroot         6     1  0 21:29 ?        00:00:00 node server.js\nroot       115     0  0 21:55 pts/0    00:00:00 bash\nroot       123   115  0 22:01 pts/0    00:00:00 ps -ef\n ", "doc_id": "a18b9e57-86fb-408b-91bc-ced7c514871a", "embedding": null, "doc_hash": "e6dcbe909fd63c47f4e3e27f36d902a4dc679d5bb18f7662fff4d6d98d0cefbc", "extra_info": {"page_label": "792"}, "node_info": {"start": 0, "end": 1896}, "relationships": {"1": "bc864984-d54c-4ecf-a519-71ce4f74f090"}}, "__type__": "1"}, "98da43f3-872e-4d7e-9003-33320020571b": {"__data__": {"text": "Part VI: Engaging with Cloud Computing776root@kubernetes-bootcamp-5b48cfdcbd-lf9t2:/# curl localhost:8080\nHello Kubernetes bootcamp!|Running on:kubernetes-bootcamp-\n5b48cfdcbd-lf9t2|v=1\n \nroot@kubernetes-bootcamp-5b48cfdcbd-lf9t2:/# exit\nAfter starting a shell, you can see output from the date  and ps  commands. From ps , you \ncan see that the first process run in the container (PID 1) is the server.js  script. After \nthat, the curl  command is able to communicate successfully with the container on loc -\nalhost  port 8080 .\nExpose applications with services\nTo expose the kubernetes-bootcamp  pod described in these procedures so that it is \naccessible from an external IP address from the worker node on which it is running, you \ncan create a NodePort  object. Here is one way to do that:\n1. Check that the pod is running : Enter the following to see that the kubernetes-\nbootcamp  pod is running.\n$ kubectl get pods\nNAME                                   READY   STATUS    RESTARTS   AGE\nkubernetes-bootcamp-765bf4c7b4-fdl96   1/1     Running   0          26m\n2. Check the services : Enter the following to see the services running in the \ndefault  namespace. Notice that only the kubernetes  service is available and \nthat there is no service exposing the kubernetes-bootcamp  pod outside of \nthe cluster:\n$ kubectl get services\nNAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\nkubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   31m\n3. Create a service : Create a service that uses NodePort to make the pod available \nfrom an IP address on the host at a specific port number (8080). For example, enter \nthe following:\n$ kubectl expose deployment/kubernetes-bootcamp \\\n    --type=\"NodePort\" --port 8080\nservice/kubernetes-bootcamp exposed\n4. View the new service : Type the following to see the IP address (10.96.66.230) and \nport number (8080) from which the service is made available on the host:\n$ kubectl get services\nNAME                TYPE      CLUSTER-IP   EXTERNAL-IP  PORT(S)        AGE\nkubernetes          ClusterIP 10.96.0.1    <none>       443/TCP        33m", "doc_id": "98da43f3-872e-4d7e-9003-33320020571b", "embedding": null, "doc_hash": "b2ecf86486b6935853aede2b980a4b9b323f7a74cc8f5a140778bdef5b5c72de", "extra_info": {"page_label": "793"}, "node_info": {"start": 0, "end": 2107}, "relationships": {"1": "e02cbaf4-3a74-4e47-a3da-393e48cfe8f1"}}, "__type__": "1"}, "3ed1b11c-494a-4b15-aad7-a0d00d623b18": {"__data__": {"text": "Chapter 30: Deploying Applications as Containers with Kubernetes\n777\n30kubernetes-bootcamp NodePort  10.96.66.230 <none>       8080:32374/\nTCP 5s\n \n$ kubectl describe services/kubernetes-bootcamp\nName:                     kubernetes-bootcamp\nNamespace:                default\nLabels:                   app=kubernetes-bootcamp\nAnnotations:              <none>\nSelector:                 app=kubernetes-bootcamp\nType:                     NodePort\nIP:                        10.96.66.230\nPort:                     <unset>  8080/TCP\nTargetPort:               8080/TCP\nNodePort:                 <unset>  30000/TCP\nEndpoints:                172.17.0.6:8080\nSession Affinity:         None\nExternal Traffic Policy:  Cluster\n5. Get the assigned node port : To get the port assigned to the service and set the \n$NODE_PORT variable to that value, enter the following:\n$ export NODE_PORT=$(kubectl get services/kubernetes-bootcamp \\\n-o go-template='{{(index .spec.ports 0).nodePort}}')\n \n$ echo NODE_PORT=$NODE_PORT\nNODE_PORT=30000\n6. Access the service : To check that the service is available from the NodePort, use \nthe following curl  command (using the IP address for your Minikube instance):\n$ curl $(minikube ip):$NODE_PORT\nHello Kubernetes bootcamp!|Running on:kubernetes-bootcamp-\n765bf4c7b4-fdl96|v=1\nLabel a service\nUse this procedure to add a label to an existing service.\n1. Check the pod\u2019s label : So far, kubernetes-bootcamp  is the only label assigned \nto the pod. To make sure, enter the following:\n$ kubectl describe deployment\nName:                   kubernetes-bootcamp\nNamespace:              default\nCreationTimestamp:      Fri, 14 Feb 2020 05:43:49 +0000\nLabels:                 run=kubernetes-bootcamp\nAnnotations:            deployment.kubernetes.io/revision: 1\n...", "doc_id": "3ed1b11c-494a-4b15-aad7-a0d00d623b18", "embedding": null, "doc_hash": "b5c0e9b702fe4258663ff221ad982b697b5519099d358828562be162cf752019", "extra_info": {"page_label": "794"}, "node_info": {"start": 0, "end": 1777}, "relationships": {"1": "05a7174f-b169-4b6f-8e76-67bd0a33b5ca"}}, "__type__": "1"}, "076130c7-3a70-44a8-99a3-3626c990a964": {"__data__": {"text": "Part VI: Engaging with Cloud Computing7782. Add another label : To add an additional label ( v1) to the pod, get the name of the \npod and add the new label as follows:\n$ export POD_NAME=$(kubectl get pods -o go-template --template \\\n '{{range .items}}{{.metadata.name}}{{\"\\n\"}}{{end}}') ; \\\necho Name of the Pod: $POD_NAME\nName of the Pod: kubernetes-bootcamp-765bf4c7b4-fdl96\n \n$ kubectl label pod $POD_NAME app=v1\npod/kubernetes-bootcamp-765bf4c7b4-fdl96 labeled\n3. Check and use the label : Check that the v1  label has been assigned to the pod, \nand then use that label to list information about the pod:\n$ kubectl describe pods $POD_NAME\nName:         kubernetes-bootcamp-765bf4c7b4-fdl96\nNamespace:    default\nPriority:     0\nNode:         minikube/172.17.0.62\nStart Time:   Fri, 14 Feb 2020 05:44:08 +0000\nLabels:       app=v1\n              pod-template-hash=765bf4c7b4\n              run=kubernetes-bootcamp\n$ kubectl get pods -l app=v1\nNAME                                   READY   STATUS    RESTARTS   \nAGE\nkubernetes-bootcamp-765bf4c7b4-fdl96   1/1     Running   0          \n60m\nDelete a service\nIf you are done using the service, you can delete it. This removes access to the service from \nthe NodePort, but it does not delete the deployment itself.\n1. Check the service : Make sure that the kubernetes-bootcamp  service \nstill exists:\n$ kubectl get services\nNAME                TYPE      CLUSTER-IP   EXTERNAL-IP PORT(S)       \nAGE\nkubernetes          ClusterIP 10.96.0.1    <none>      443/TCP       \n63m\nkubernetes-bootcamp NodePort  10.96.66.230 <none>   8  080:32374/\nTCP 30m\n2. Delete the service : Using the label name, delete the service:\n$ kubectl delete service -l run=kubernetes-bootcamp\nservice \"kubernetes-bootcamp\" deleted", "doc_id": "076130c7-3a70-44a8-99a3-3626c990a964", "embedding": null, "doc_hash": "d69e8a78ab1d0ad32b759e5afb3d4f8f455b87a95cf2cfef3d5468e1b387cbbc", "extra_info": {"page_label": "795"}, "node_info": {"start": 0, "end": 1748}, "relationships": {"1": "8ae730a8-361a-4e03-b526-5fa922bcd689"}}, "__type__": "1"}, "a679f071-1377-490a-a369-e5249eb29995": {"__data__": {"text": "Chapter 30: Deploying Applications as Containers with Kubernetes\n779\n303. Check the service and deployment : Make sure the service has been deleted but \nthe deployment still exists:\n$ kubectl get services\nNAME                TYPE      CLUSTER-IP   EXTERNAL-IP  PORT(S)      \nAGE\nkubernetes          ClusterIP 10.96.0.1    <none>       443/TCP      \n64m\n$ kubectl get deployment\nNAME                 READY   UP-TO-DATE   AVAILABLE   AGE\nkubernetes-bootcamp  1/1     1            1           65m\nScale up an application\nOne of the most powerful features of Kubernetes is its ability to scale up an application as \nthe demand requires it. This procedure starts with the kubernetes-bootcamp  deploy -\nment, which is running one pod, and scales it up to have additional pods running using the \nReplicaSet  feature and a different means of exposing the application to outside access.\n1. Get the deployment : List information about the kubernetes-bootcamp   \ndeployment, and note that it is set to have only one replica set ( rs) active:\n$ kubectl get deployments\nNAME                  READY   UP-TO-DATE   AVAILABLE   AGE\nkubernetes-bootcamp   1/1     1            1           107s\n$ kubectl get rs\nNAME                             DESIRED   CURRENT   READY   AGE\nkubernetes-bootcamp-5b48cfdcbd   1         1         1       3m4s\n2. Scale up the replicas : To scale the deployment up to four replica sets, enter the \nfollowing:\n$ kubectl scale deployments/kubernetes-bootcamp --replicas=4\ndeployment.extensions/kubernetes-bootcamp scaled\n3. Check the new replicas : List the deployments to make sure that there are now \nfour replicas ready and available:\n$ kubectl get deployments\nNAME                  READY   UP-TO-DATE   AVAILABLE   AGE\nkubernetes-bootcamp   4/4     4            4           8m44s\n4. Check the pods : There should now also be four kubernetes-bootcamp  pods \nrunning, each with its own IP address inside the cluster. To make sure, enter the \nfollowing:\n$ kubectl get pods -o wide\nNAME                       READY   STATUS    RESTARTS AGE   IP\n   NODE      NOMINATED NODE   READINESS GATES", "doc_id": "a679f071-1377-490a-a369-e5249eb29995", "embedding": null, "doc_hash": "31b21ee498066b4c58f9739f78050c77632ce3289a2ed935aea128694652e60a", "extra_info": {"page_label": "796"}, "node_info": {"start": 0, "end": 2101}, "relationships": {"1": "76f9c77e-d394-44e7-b38b-f16c68225de3"}}, "__type__": "1"}, "071bd54c-1843-4eaf-8f29-f03b350d1fcb": {"__data__": {"text": "Part VI: Engaging with Cloud Computing780kubernetes-bootcamp-5b4... 1/1     Running   0        8m43s \n172.18.0.4\n   minikube  <none>           <none>\nkubernetes-bootcamp-5b4... 1/1     Running   0        12s   \n172.18.0.8\n   minikube  <none>           <none>\nkubernetes-bootcamp-5b4... 1/1     Running   0        12s   \n172.18.0.6\n   minikube  <none>           <none>\nkubernetes-bootcamp-5b4..  1/1     Running   0        12s   \n172.18.0.7\n   minikube  <none>           <none>\n5. View deployment details : To see details of the increased replicas in the deploy -\nment, enter the following:\n$ kubectl describe deployments/kubernetes-bootcamp\nName:                   kubernetes-bootcamp\nNamespace:              default\n...\nReplicas:    4 desired | 4 updated | 4 total | 4 available | 0 \nunavailable\n...\nNewReplicaSet:   kubernetes-bootcamp-5b48cfdcbd (4/4 replicas \ncreated)\nEvents:\n  Type    Reason             Age    From                   Message\n  ----    ------             ----   ----                   -------\n  Normal  ScalingReplicaSet  17m    deployment-controller  Scaled \nup\n     replica set kubernetes-bootcamp-5b48cfdcbd to 1\n  Normal  ScalingReplicaSet  9m25s  deployment-controller  Scaled \nup\nreplica set kubernetes-bootcamp-5b48cfdcbd to 4\nCheck the load balancer\nTo check that traffic is being distributed across all four replicated pods, you can get the \nNodePort and then use the curl  command to make sure that multiple connections to the \nNodePort result in different pods being accessed:\n1. List details about the service : To see details about the kubernetes-bootcamp  \nservice, enter the following:\n$ kubectl describe services/kubernetes-bootcamp\nName:            kubernetes-bootcamp\nNamespace:       default\nLabels:          run=kubernetes-bootcamp\nAnnotations:     <none>\nSelector:        run=kubernetes-bootcamp\nType:            NodePort\nIP:              10.99.183.8", "doc_id": "071bd54c-1843-4eaf-8f29-f03b350d1fcb", "embedding": null, "doc_hash": "d4140f76e6478556db0fbc88cdd3c116d29dda2dd87dc81012cfecd9a7ee5f2d", "extra_info": {"page_label": "797"}, "node_info": {"start": 0, "end": 1893}, "relationships": {"1": "f08f39a5-0668-4ac3-baa7-0e939ac22cec"}}, "__type__": "1"}, "affc46bc-a6cd-4d1b-b07d-4da9af6c9576": {"__data__": {"text": "Chapter 30: Deploying Applications as Containers with Kubernetes\n781\n30Port:            <unset>  8080/TCP\nTargetPort:      8080/TCP\nNodePort:        <unset>  31915/TCP\nEndpoints:       172.18.0.4:8080,172.18.0.6:8080,172.18.0.7:8080 + \n1 more...\nNotice that each pod has its own IP address and port ( 172.18.0.4:8080 , \n172.18.0.4:8080 , and so on).\n2. Get the NodePort : Enter the following to set $NODE_PORT to the value of the port \nnumber assigned to the service:\n$ export NODE_PORT=$(kubectl get services/kubernetes-bootcamp \\\n  -o go-template='{{(index .spec.ports 0).nodePort}}')\n \n$ echo NODE_PORT=$NODE_PORT\nNODE_PORT=31915\n3. Run curl : Run the curl  command a few times to query the service. If you run it a \nfew times, you should see that it is accessing different pods. That is how you know \nthat the load balancer is working:\n$ curl $(minikube ip):$NODE_PORT\nHello Kubernetes bootcamp!|Running on:kubernetes-bootcamp-\n5b48cfdcbd-9j4xp|v=1\nScale down an application\nTo scale the number of ReplicaSets defined in your deployment, simply change the number \nof replicas to a lower number.\n1. Scale down replicas : Enter the following to change the number of replicas for the \ndeployment to 2 :\n$ kubectl scale deployments/kubernetes-bootcamp \u2013replicas=2\ndeployment.extensions/kubernetes-bootcamp scaled\n2. Check the deployment : To see that the deployment is set to 2 , and that only two \npods are running, enter the following:\n$ kubectl get deployments\nNAME                  READY   UP-TO-DATE   AVAILABLE   AGE\nkubernetes-bootcamp   2/2     2            2           52m\n$ kubectl get pods -o wide\nNAME                       READY   STATUS    RESTARTS AGE   IP\n   NODE      NOMINATED NODE   READINESS GATES\nkubernetes-bootcamp-5b4... 1/1     Running   0        8m43s \n172.18.0.4\n   minikube  <none>           <none>\nkubernetes-bootcamp-5b4... 1/1     Running   0        12s   \n172.18.0.8\nAt this point, you should feel comfortable manually querying your Kubernetes cluster in var -\nious ways and starting up and working with deployments, pods, and replicas. To continue with ", "doc_id": "affc46bc-a6cd-4d1b-b07d-4da9af6c9576", "embedding": null, "doc_hash": "d6c24dcbf84e7410c881ef57d1d70beefe516a0065056ed198a4990c94d6b8e8", "extra_info": {"page_label": "798"}, "node_info": {"start": 0, "end": 2086}, "relationships": {"1": "f747a74f-7a6b-46e5-9b86-5a8c1155accf"}}, "__type__": "1"}, "dd338691-43f4-4ea2-9327-98a13f024efc": {"__data__": {"text": "Part VI: Engaging with Cloud Computing782more advanced Kubernetes tutorials, return to the main Kubernetes Tutorials page ( https://\nkubernetes.io/docs/tutorials/ ). I also recommend the Kubernetes By Example site for \nmore information on using Kubernetes ( https://kubernetesbyexample.com ).\nEnterprise-Quality Kubernetes with OpenShift\nRed Hat OpenShift Container Platform ( www.openshift.com ) is a product that is designed \nto deliver an enterprise-quality Kubernetes platform that can be used for mission-critical \napplications. As a hybrid cloud platform, OpenShift is built to be deployed in both bare \nmetal and cloud environments.\nWhile Kubernetes is an open source project that can be built and run in a tremendous \nnumber of ways, Kubernetes-based products, such as OpenShift, are meant to be used when \nyou need a solid, supported platform upon which your business can rely. OpenShift also \ncomes in different variants, which can be installed in your own data center and in cloud \nenvironments, such as AWS and Azure, or simply used from a dedicated OpenShift cluster \nmaintained for you by Red Hat.\nWhen you lock down the Kubernetes features that Red Hat builds into OpenShift, those \nfeatures can be thoroughly tested and supported. Training and documentation can be built \naround those features. Also, more complex features can be built in, such as advanced gov -\nernment compliance features and tight integrations with various cloud environments.\nWith an intuitive web console, Red Hat OpenShift is made to be easier to use for people \nstarting with Kubernetes. An example of the OpenShift console is shown in Figure\u00a030.2.\nFIGURE 30.2\nOpenShift features an intuitive web UI for deploying and managing Kubernetes objects.", "doc_id": "dd338691-43f4-4ea2-9327-98a13f024efc", "embedding": null, "doc_hash": "cd6eb9438e95d1e7d48f0f2a23dcba5a916538f28ee88e90bd26a15b8cbec470", "extra_info": {"page_label": "799"}, "node_info": {"start": 0, "end": 1736}, "relationships": {"1": "dcf5c681-296b-4d0d-94be-68053ccfc642"}}, "__type__": "1"}, "40711827-2ac4-4bef-bc6e-8f634f086b02": {"__data__": {"text": "Chapter 30: Deploying Applications as Containers with Kubernetes\n783\n30There are free trials of OpenShift available from https://try.openshift.com . There is \nalso an open source upstream project for OpenShift, called OKD, which you can get for free \nas well (www.okd.io ).\nSummary\nIn the past few years, Kubernetes has become the platform of choice for deploying contain -\nerized applications across large data centers. A Kubernetes cluster consists of master nodes \n(that direct the activities of a cluster) and worker nodes (that actually run the container -\nized payloads).\nAs someone using Kubernetes to run containerized applications, you can create deploy -\nments that define the state of the application you are running. For example, you can \ndeploy an application that is configured to run multiple replicas of the pods representing \nthat application. You can identify the application as a service and set up the application to \nbe available from defined ports on the nodes from which they are run.\nProducts based on Kubernetes are available when you need to run mission-critical appli-\ncations in environments that are stable and supported. One such product is the Red Hat \nOpenShift Container Platform. With OpenShift, you can run supported Kubernetes-based \ncluster configurations that run in a variety of environments, including bare metal and var -\nious cloud environments.\nExercises\nThe exercises in this section describe tasks related to trying out Kubernetes, either online \nor by setting up Minikube on a computer. If you are stuck, solutions to the tasks are shown \nin Appendix B. Keep in mind that the solutions shown in Appendix B are usually just one of \nmany ways to complete a task.\n1. Install Minikube on your local system or access a Minikube instance externally \n(such as through the Kubernetes.io  Tutorials).\n2. View your version of Minikube, as well as the versions of your kubectl  client and \nKubernetes service.\n3. Create a deployment that manages a pod running the hello-node  container image \n(gcr.io/hello-minikube-zero-install/hello-node ).\n4. Use the appropriate kubectl  commands to view the hello-node  deployment and \ndescribe the deployment in detail.\n5. View the current replica set associated with your hello-node  deployment.\n6. Scale up the hello-node  deployment to three (3) replicas.\n7. Expose the hello-node  deployment outside of the Kubernetes cluster using \nLoadBalancer .", "doc_id": "40711827-2ac4-4bef-bc6e-8f634f086b02", "embedding": null, "doc_hash": "db22ec3594898562302a849914cb14d3ced01023fd4debd07724395425fffe59", "extra_info": {"page_label": "800"}, "node_info": {"start": 0, "end": 2425}, "relationships": {"1": "57056ed8-fca9-4d6c-8390-23166faa0760"}}, "__type__": "1"}, "405109e0-dbf8-4f95-9514-8a68221fe332": {"__data__": {"text": "Part VI: Engaging with Cloud Computing7848. Get the IP address of your Minikube instance and the port number of the exposed \nhello-node  service.\n9. Use the curl  command to query the hello-node  service using the IP address and \nport number from the previous step.\n10. Use the kubectl  commands to delete the hello-node  service and deployment, \nand then use the minikube  command to stop the Minikube virtual machine.", "doc_id": "405109e0-dbf8-4f95-9514-8a68221fe332", "embedding": null, "doc_hash": "663a7e2233263d10a093e834d54566cadd90e86d753d60b5c2022a900b8ba813", "extra_info": {"page_label": "801"}, "node_info": {"start": 0, "end": 419}, "relationships": {"1": "61354d97-eab6-401e-bb8f-04c7386c5c29"}}, "__type__": "1"}, "0a12e305-b689-4399-8823-f8d7b6780a06": {"__data__": {"text": "Part VIIIN THIS PART\nAppendix\u00a0A  \nMedia\nAppendix\u00a0B  \nExercise AnswersAppendixes\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "0a12e305-b689-4399-8823-f8d7b6780a06", "embedding": null, "doc_hash": "3651974b3c3e539e4b6ef0d8dc9e897f2528bca292adc26bb0693a9305255cde", "extra_info": {"page_label": "802"}, "node_info": {"start": 0, "end": 202}, "relationships": {"1": "2442d659-21e0-4c92-91ea-227170c8c722"}}, "__type__": "1"}, "5f5a1e72-e813-455f-a8e7-701d96a13a83": {"__data__": {"text": "APPENDIXA787Media\nIN THIS APPENDIX\nGetting Linux distributions\nCreating a bootable CD or DVD\nUnless you bought a computer with Linux preinstalled or had someone install it for you, \nyou need to find a way to get a Linux distribution and then either install or run it live on your computer. Fortunately, Linux distributions are widely available and come in a vari-\nety of forms.\nIn this appendix, you learn how to do the following:\n\u25a0 \u25a0Get a few different Linux distributions\n\u25a0 \u25a0Create a bootable disk to install your distribution\n\u25a0 \u25a0Boot Linux from a USB drive\nTo use this book effectively, you should have a Linux distribution in front of you to work on. It\u2019s important to be able to experience Linux as you read. So, try the examples and do the exercises.\nLinux distributions are most commonly available from the websites of the organizations that produce \nthem. The following sections describe websites associated with Linux distributions that offer ISO images you can download.\nNote\nAn ISO is a disk image that is formatted in the ISO 9660 filesystem format, a format that is commonly used with CD \nand DVD images. Because this is a well-known format, it is readable by Windows, Mac, and Linux systems.\nAn ISO image can be used to create a bootable USB flash drive, CD, or DVD medium, depending on the size of the \nimage. An ISO image in your filesystem can be mounted in Linux in loopback mode, so you can view or copy its con-tents.\nWhen an ISO image contains a Linux Live CD or installation image, the images are bootable. This means that instead \nof starting up an operating system, such as Windows or Linux, from the computer\u2019s hard drive, you can tell your computer to boot from the CD or DVD instead. This enables you to run a totally different operating system than is installed on your hard drive without changing or damaging the data on that drive.\nLinux\u00ae Bible , Tenth Edition. Christopher Negus.\n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "5f5a1e72-e813-455f-a8e7-701d96a13a83", "embedding": null, "doc_hash": "7bcd81dd3e71d85567803311adcf3946c80135b4818bfee624e5231630a2f1a3", "extra_info": {"page_label": "803"}, "node_info": {"start": 0, "end": 1983}, "relationships": {"1": "aeabb0df-04d8-4039-8591-cb17ae8b5851"}}, "__type__": "1"}, "83410c06-7b57-47f1-8752-3f65b886cfaf": {"__data__": {"text": " Part VII: Appendixes788Getting Fedora\nTo test the examples in this book, I used Fedora 30 and 31, 64-bit Fedora Workstation \nimages, which you can get from GetFedora.org  (https://getfedora.org/en/workstation/\ndownload ). If you have a 64-bit machine, you must use the 64-bit ISO.\nLater versions of Fedora that come with a GNOME desktop should work as well. Here\u2019s a link \nto the exact ISO used for the Fedora 31 Workstation:\nhttps://download.fedoraproject.org/pub/fedora/linux/releases/31/Workstation/\nx86_64/iso/Fedora-Workstation-Live-x86_64-31-1.9.iso\nKeep in mind that the latest Fedora Workstation ISO image does not fit on a CD, so you must \nburn it to a DVD or USB flash drive. See the descriptions of CD/DVD burning tools available \nfor Windows, MacOS, and Linux later in this appendix.\nFigure\u00a0A.1 shows an example of the Get Fedora page.Note\nI recommend downloading the Fedora Workstation Live Image to use along with this book because most of the book \nworks with that distribution. You can run it live without committing to overwriting your computer\u2019s hard disk until you \nfeel comfortable enough to install it permanently.\nFIGURE A.1\nDownload Fedora ISO images from the Get Fedora page.", "doc_id": "83410c06-7b57-47f1-8752-3f65b886cfaf", "embedding": null, "doc_hash": "fc7fa7b76212c089434f47647f4c3f47de49c4efdb2f62805881e49852e2a0ec", "extra_info": {"page_label": "804"}, "node_info": {"start": 0, "end": 1200}, "relationships": {"1": "e50c0160-f7fa-40ae-a1b0-82f366fcfa65"}}, "__type__": "1"}, "15da190f-77d8-40fe-a107-550a480c11c5": {"__data__": {"text": "Appendix A: Media\nA\n789Today, the default download is an ISO image of a 64-bit PC-type Fedora Workstation \n(GNOME) Live DVD. You can boot this image on your computer, and if you choose, you \ncan permanently install it to your computer\u2019s hard drive. To download this image, do the \nfollowing:\n1. Select Workstation or Server from GetFedora.org . I recommend Workstation to \nfollow along with this book.\n2. Select the Download Now button and click the Download button. A pop-up should \nappear, asking what you want to do with the ISO.\n3. Select to save the ISO. Depending on your settings, either you are asked where you \nwant to download it or it simply begins downloading to a default folder (in Linux, it \nis probably a Downloads folder).\n4. If you are prompted for where to put the ISO, select a folder that has enough space \nto hold it. Remember where this folder is located, because you need to find the ISO \nwhen you go to burn it later.\nIf you need more information about what to do with the downloaded image, there are links \nto help you on the Fedora page that appears. At the time of this writing, the Learn Here \nlink takes you to descriptions of how to create live installation media. The exact instruc -\ntions might change as the website is updated.\nYou have other choices for downloading ISOs from Fedora. From the bottom of the  \nGetFedora.org  page, you can download specially configured Fedora ISO images called  \nspins (https://spins.fedoraproject.org ). Here are some special types of Fedora spins that \nmight interest you:\nKDE desktop spin : People who prefer the KDE desktop to the GNOME desktop can \ndownload the Plasma KDE spin.\nLightweight desktop spin : If you are trying Linux on a computer with less memory or \nprocessing power, consider Xfce and LXQt spins (representing lightweight desktops \nof the same name).\nDesktop effects spin : The MATE-Compiz spin offers more of the other extreme to the \nlightweight desktops, with desktop effects like wobbly windows and desktops that \nrotate on a cube.\nChild-friendly desktop spin : The SOAS desktop is a spin of the Sugar Learning Plat -\nform, made to provide a simplified setup and a child-friendly graphical interface. \nSOAS can be transported on a USB drive and run on any available computer.\nGetting Red Hat Enterprise Linux\nMany large corporations, government agencies, and universities use Red Hat Enterprise \nLinux to run their mission-critical applications. While most of the procedures in this book \nwill run well on Fedora, there are many references to how things are done differently in ", "doc_id": "15da190f-77d8-40fe-a107-550a480c11c5", "embedding": null, "doc_hash": "af746a862bcfe4dae4d65f2b8bef02ce091660bf4d1b68a36effd8615ea1104d", "extra_info": {"page_label": "805"}, "node_info": {"start": 0, "end": 2570}, "relationships": {"1": "4e25f31a-bcaf-4869-b5d0-fb6eeed3f609"}}, "__type__": "1"}, "3be11605-7bf7-46a5-85f3-77e090b3955a": {"__data__": {"text": " Part VII: Appendixes790Red Hat Enterprise Linux because, when you go to get a job as a Linux system administra -\ntor, you will, in most cases, be working with Red Hat Enterprise Linux systems.\nAlthough the source code for Red Hat Enterprise Linux is freely available, the ISOs contain -\ning the packages you install (often referred to as the binaries ) are available only to those \nwho have accounts on the Red Hat customer portal ( https://access.redhat.com ) or through \nevaluation copies.\nIf you don\u2019t have an account, you can try signing up for a 30-day trial. If either you or your \ncompany has an account with Red Hat, you can download the ISOs that you need. Go to the \nfollowing site and follow the instructions to download a Red Hat Enterprise Linux server \nISO or sign up to get an evaluation copy:\nhttps://access.redhat.com/downloads .\nRed Hat does not offer live versions of Red Hat Enterprise Linux. Instead, you can down -\nload installation DVDs that you can install as described in Chapter\u00a09, \u201cInstalling Linux,\u201d of \nthis book.\nGetting Ubuntu\nMany people new to Linux begin by downloading and installing Ubuntu. Ubuntu has a huge \nfan base and many active contributors. If you have problems with Ubuntu, there are large, \nactive forums where many people are willing to help you overcome problems.\nIf you already have an Ubuntu system installed, you can follow along with most of this \nbook. You can get Ubuntu with a GNOME desktop, and its default dash shell is similar to \nbash (or you can switch to bash in Ubuntu to match the shell examples in this book). \nAlthough most of the examples of this book focus on Fedora and RHEL, I have added many \nmore references to Ubuntu throughout the book in this edition.\nTo get Ubuntu, you can download a Live ISO image or installation medium from the Down -\nload Ubuntu page: http://www.ubuntu.com/download/ubuntu .\nFigure\u00a0A.2 shows an example of the Download Ubuntu Desktop page.Note\nIf you are unable to obtain a Red Hat Enterprise Linux installation DVD, you can get a similar experience using the \nCentOS installation DVD. CentOS is not exactly the same as RHEL. However, if you download the CentOS installation \nDVD for CentOS 8.x from links on the CentOS site ( http://www.centos.org/download/ ), the installation proce -\ndure is similar to the one described for Red Hat Enterprise Linux in Chapter\u00a09.", "doc_id": "3be11605-7bf7-46a5-85f3-77e090b3955a", "embedding": null, "doc_hash": "08120dacfa57053cbb170e7bac8e454c7d62ce7f1463cf4afebfd520f2306c7e", "extra_info": {"page_label": "806"}, "node_info": {"start": 0, "end": 2364}, "relationships": {"1": "e167a74d-a2c6-44d3-92db-347d485b0067"}}, "__type__": "1"}, "88f70560-ffdf-4d22-9a82-834977b85306": {"__data__": {"text": "Appendix A: Media\nA\n791As with Fedora, the easiest way to download Ubuntu is to select the 64-bit Ubuntu Live \nimage, download it, and burn it. Here\u2019s how to do that from the Download Ubuntu page:\n1. Click the Download button. By default, this downloads the most recent 64-bit \nUbuntu desktop Live ISO image.\n2. Either you are asked where you want to download the ISO image, or it simply begins \ndownloading to a default folder.\n3. If you are asked where to put the ISO, select a folder that has enough space to hold \nthe ISO. Remember where this folder is located because you need to find the ISO \nwhen you go to burn it later.\nAfter the download is complete, burn the ISO image to a DVD using procedures described in \nthe section \u201cCreating Linux CDs and DVDs\u201d.\nOther types of Ubuntu installation media are also available. To find other Ubuntu media, go to \nthe Alternative Downloads page ( http://www.ubuntu.com/download/alternative-downloads ). \nFrom this site, you can get media that contains a variety of desktop and server installs.\nBooting Linux from a USB Drive\nInstead of burning ISO images to a CD or DVD, you can put your Linux system on a USB \ndrive. USB drives offer the advantage of being writable as well as readable, so you can \nFIGURE A.2\nDownload Ubuntu Live ISO images, or choose an alternative download.", "doc_id": "88f70560-ffdf-4d22-9a82-834977b85306", "embedding": null, "doc_hash": "2b72c499c16b42a1e4568304503a9a445a39cf3da196509c753f87d11e34e0c6", "extra_info": {"page_label": "807"}, "node_info": {"start": 0, "end": 1323}, "relationships": {"1": "78759b27-e84d-4385-91d6-fc02f0e562ab"}}, "__type__": "1"}, "2ac42a22-4ef0-4714-a110-9afefc25d03b": {"__data__": {"text": " Part VII: Appendixes792save your content between sessions. Most modern computers can boot from a USB drive, \nalthough you may have to interrupt the boot process to tell the BIOS to boot from a USB \ndrive instead of hard drive or CD/DVD drive.\nYou can find procedures for putting Fedora and Ubuntu on a USB drive in the following \nlocations:\nFedora on a USB drive : Using a tool called Live USB Creator, you can install a Fedora \nISO image to a USB drive in either Windows or Linux. To run Fedora from that drive, \ninsert it into a USB port on your computer, reboot the computer, interrupt the BIOS \nas it is booting (possibly F12), and select to boot from a USB drive. The procedure for \nusing Live USB creator is located at\nhttps://docs.fedoraproject.org/en-US/quick-docs/creating-and-using-a-live-\ninstallation-image/index.html\nUbuntu on a USB drive: Ubuntu has procedures for creating a bootable USB drive with \nUbuntu on it that work from Windows, MacOS, or Linux. To find out how to do this, go \nto the Ubuntu Download page, and under \u201cEasy ways to switch to Ubuntu,\u201d look for  \nthe appropriate \u201cHow to create a bootable USB stick...\u201d procedure for Ubuntu,  \nWindows, or MacOS:\nhttps://ubuntu.com/tutorials/tutorial-create-a-usb-stick-on-ubuntu#1-overview\nCreating Linux CDs and DVDs\nAfter you have downloaded a Linux CD or DVD image, you can use several tools to create \nbootable CDs or DVDs for either installing or just running Linux live from those media. \nBefore you begin, you must have the following:\nDVD or CD ISO images : Download the ISO images to your computer that represent the \nphysical DVD or CD you will ultimately burn. Today, most Linux ISO images are too \nbig to fit on a CD (including those for RHEL, Fedora, and Ubuntu).\nBlank DVDs/CDs : You need blank DVDs or CDs to burn the images to. CDs hold up to \nabout 700MB; DVDs hold up to about 4.7GB (single layer).\nCD/DVD burner : You need a drive that is capable of burning CDs or DVDs, depending on \nwhich you are burning. Not all CD/DVD drives can burn DVDs (especially older ones). \nSo, you may need to find a computer with a drive that has that capability.\nThe following sections describe how to burn bootable CDs and DVDs from Windows, MacOS, \nand Linux systems.\nBurning CDs/DVDs in Windows\nIf you have downloaded your Linux ISO image to a Windows system, you can burn that \nimage to CD or DVD in different ways. Here are some examples:\nWindows : In the latest Windows releases, the function of burning ISO images to CD \nor DVD is built into Windows. After an ISO image is downloaded, simply insert the ", "doc_id": "2ac42a22-4ef0-4714-a110-9afefc25d03b", "embedding": null, "doc_hash": "e0d12f266bbdcdef1abcce217b1c6640a50c6800946de1d2a0d06ec42b83d7ed", "extra_info": {"page_label": "808"}, "node_info": {"start": 0, "end": 2582}, "relationships": {"1": "62cd556e-e921-4e66-b323-71d73b39d752"}}, "__type__": "1"}, "cb8ec7af-859b-4146-8fb4-1a5e94c27830": {"__data__": {"text": "Appendix A: Media\nA\n793appropriate CD or DVD into your computer\u2019s drive (assuming the drive is write -\nable), right-click the ISO image icon from the folder to which you downloaded it, \nand select Burn Disc Image. When the Windows Disc Image Burner window appears, \nselect Burn to burn the image.\nRoxio Creator : This third-party Windows application contains many features for rip -\nping and burning CDs and DVDs. You can read about the product here:\u00a0 http://www  \n.roxio.com/en/products/creator/ .\nNero CD/DVD Burning ROM : Nero is another popular CD/DVD burning software product \nfor Windows systems. You can find out more about Nero here: http://www.nero.com .\nBurning CDs/DVDs on a MacOS system\nLike Windows, MacOS has CD/DVD burning software built into the operating system. To \nburn an ISO image to disk on a MacOS system, follow these steps:\n1. Download the ISO image you want on your MacOS system. An icon representing the \nISO should appear on your desktop.\n2. Insert a blank CD or DVD into your CD/DVD burner, as appropriate for the size of \nthe image.\n3. Right-click the icon representing the Linux ISO that you just downloaded and select \nBurn \u201cLinux\u201d to Disk. A pop-up window appears, asking if you are sure you want to \nburn the image.\n4. Fill in the name that you want to give the ISO and the write speed and then select \nBurn. The image begins burning to disk.\n5. After the image has been burned, eject the disk; you are ready to boot the CD or \nDVD on an appropriate computer.\nBurning CDs/DVDs in Linux\nLinux has both graphical and command-line tools for burning CD and DVD images to physi-\ncal media. Examples in this section show how to use K3b  from the desktop or cdrecord  \n(or wodim ) to burn ISO images to CD or DVD. If they are not installed, you can install either \none as follows:\nFor Fedora or RHEL\n# yum install k3b\n# yum install wodim\nFor Debian or Ubuntu\n# apt-get install k3b\n# apt-get install wodim\n ", "doc_id": "cb8ec7af-859b-4146-8fb4-1a5e94c27830", "embedding": null, "doc_hash": "6f988e14dd0d004dddcd6a9a6e981c58c07269360f4544c11ba58049e3e6cecc", "extra_info": {"page_label": "809"}, "node_info": {"start": 0, "end": 1933}, "relationships": {"1": "4e526249-4874-4c6a-a424-0ac86e55c3e9"}}, "__type__": "1"}, "dd07ac46-671b-43e9-b591-1a177189c7b3": {"__data__": {"text": " Part VII: Appendixes794Burning CDs or DVDs from a Linux desktop\nHere's how to create bootable Linux CDs or DVDs from a running Linux system (such \nas Fedora) using K3b . K3b  comes with the KDE desktop but runs on the GNOME desk -\ntop as well.\n1. Download the ISO images that you want to your computer's hard drive. (A CD image \nis under about 700MB in size. Single-layer DVD images are under 4.7GB.)\n2. Open a CD/DVD burning application. For this procedure, I recommend K3b CD \nand DVD Kreator ( http://www.k3b.org ). In Fedora, select Activities and type \nK3b (or type k3b  from a Terminal window). The \u201cK3b \u2013 The CD and DVD Kreator\u201d \nwindow appears.\n3. From the K3b window, select Tools \u27aa Burn Image to burn a CD or DVD ISO Image. \nYou are asked to choose an image file.\n4. Browse to the image that you just downloaded or copied to hard drive and select \nit. After you select the image that you want, the Burn Image window appears, as \ndoes a checksum on the image. Figure\u00a0A.3 shows the K3b window ready to select an \nimage of Fedora.\n5. Insert a blank CD or DVD into the CD/DVD drive, which may be a combination CD/\nDVD drive. (If a CD/DVD Creator window pops up, you can close it.)\nFIGURE A.3\nUse K3b to burn your Linux CDs or DVDs.", "doc_id": "dd07ac46-671b-43e9-b591-1a177189c7b3", "embedding": null, "doc_hash": "f38dd3af5e16e1cd8eb1f18f9bae223845f9216d5ef3144b086c25da51fb3c91", "extra_info": {"page_label": "810"}, "node_info": {"start": 0, "end": 1238}, "relationships": {"1": "ede2e8b9-23b1-420e-baf6-afab6682a3fd"}}, "__type__": "1"}, "aeb0251d-ffde-4d17-8b1b-f523ec078c19": {"__data__": {"text": "Appendix A: Media\nA\n7956. Check the settings in the Burn Image window (often, the defaults are fine, but you \nmay want to slow down the speed if you get some bad burns). You can also select \nthe Simulate check box to test the burn before actually writing to the CD/DVD. \nClick Start to continue.\n7. When the CD/DVD is finished burning, eject it (or it may eject automatically) and \nmark it appropriately (information such as the distribution name, version number, \ndate, and name of the ISO image).\nNow you're ready to begin installing (or booting) the Linux distribution you just burned.\nBurning CDs or DVDs from a Linux command line\nIf you have no GUI, or you don't mind working from the shell, you can use the cdrecord  \ncommand to burn the ISOs. With a blank CD or DVD inserted and the ISO image you want to \nburn in the current directory, you can use the following simple command line for burning a \nCD image to CD or DVD using cdrecord :\n# cdrecord -v whatever.iso\nSee the cdrecord  man page ( man cdrecord ) for other options available with the  \ncdrecord  command.", "doc_id": "aeb0251d-ffde-4d17-8b1b-f523ec078c19", "embedding": null, "doc_hash": "340ff0be24113eacae9306e1d983ff55f3ce6312e300f926a555ddc8fba3e5bd", "extra_info": {"page_label": "811"}, "node_info": {"start": 0, "end": 1072}, "relationships": {"1": "de6351e0-b9b6-4fba-8bad-8c5bafafe7a3"}}, "__type__": "1"}, "bfbf9b8b-cbb2-4538-96d8-2cb969b1bf91": {"__data__": {"text": "APPENDIXB797Exercise Answers\nThis appendix provides answers to each of the chapter exercises. There are many ways to accom-\nplish tasks in Linux. Suggested answers are provided herein.\nSome of the exercises require that you modify system files that could change the basic func -\ntioning of your system, or even make your system unbootable. Therefore, I recommend that you do \nthe exercises on a Linux system that you are free to modify and erase if something should go wrong. \nUsing virtual machines, that you can discard when you are done, is an excellent option.\nChapter\u00a01: Starting with Linux\nThere are no exercises in Chapter\u00a01.\nChapter\u00a02: Creating the Perfect Linux Desktop\nThis section details some ways that these tasks can be completed on both the GNOME 2 and GNOME \n3 desktops.\n1. To get started, you need a Linux system in front of you to do the procedures in this book. \nAn installed system is preferable, so you don\u2019t lose your changes when you reboot. To start \nout, you can use a Fedora Live CD (or installed system), an Ubuntu installed system, or a \nRed Hat Enterprise Linux installed system. Here are your choices:\na. Fedora Live CD (GNOME 3) : Get a Fedora Live CD as described in Appendix A. Run \nit live, as described in the section \u201cStarting with the Fedora GNOME Desktop Live \nimage\u201d in Chapter\u00a02, or install it and run it from hard disk as described in Chapter\u00a09, \n\u201cInstalling Linux.\u201d\nb. Ubuntu (GNOME 3) : Install Ubuntu and the GNOME Shell software, as described at the \nbeginning of Chapter\u00a02.\nc. Red Hat Enterprise Linux 8 (GNOME 3) : Install Red Hat Enterprise Linux 7, as \ndescribed in Chapter\u00a09.\nd. Red Hat Enterprise Linux 6 or earlier (GNOME 2) : Install Red Hat Enterprise Linux 6.\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "bfbf9b8b-cbb2-4538-96d8-2cb969b1bf91", "embedding": null, "doc_hash": "bf137e9df881a0139b2047c13f2494e75aa9cc944a41466eee8ade8b4f6a9964", "extra_info": {"page_label": "812"}, "node_info": {"start": 0, "end": 1837}, "relationships": {"1": "f9ac0031-1183-429a-9ab7-f7aeeefd7335"}}, "__type__": "1"}, "9a8252b4-6a41-4612-ad7f-fefa06d4c477": {"__data__": {"text": "Part VII: Appendixes7982. To launch the Firefox web browser and go to the GNOME home page ( http://gnome  \n.org), there are some easy steps to take. If your network is not working, refer \nto Chapter\u00a014, \u201cAdministering Networking,\u201d for help on connecting to wired and \nwireless networks.\nGNOME 3\nFor GNOME 3, you can press the Windows key to get to the Overview screen. Then \ntype Firefox  to highlight just the Firefox web browser icon. Press Enter to \nlaunch it. Type http://gnome.org  in the location box, and press Enter.\nGNOME 2\nFor GNOME 2, select the Firefox icon from the top menu bar. Type http://gnome  \n.org  in the location box, and press Enter.\n3. To pick a background that you like from the GNOME art site ( http://gnome-look  \n.org), download it to your Pictures folder, and select it as your current background. \nOn both GNOME 2 and GNOME 3 systems, do the following:\na. Type http://gnome-look.org/  in the Firefox location box and press Enter.\nb. Find a background that you like and select it. Then click the Download button \nand download it to your Pictures folder.\nc. Open your Pictures folder, right-click the image, and select Set as Wallpaper.\nThe image is used as your desktop background.\n4. To start a Nautilus File Manager window and move it to the second workspace on \nyour desktop, do the following:\nFor GNOME 3\na. Press the Windows key.\nb. Select the Files icon from the Dash (left side). A new instance of Nautilus starts \nin the current workspace.\nc. Right-click the title bar in the Files window and select Move to Monitor Down. \nThe Files window moves to the second workspace.\nFor GNOME 2\na. Open the Home folder from the GNOME 2 desktop (double-click).\nb. Right-click in the Nautilus title bar that appears, and select either Move to \nWorkspace Right or Move to Another Workspace. (You can select which work -\nspace you want from the list.)\n5. To find the image that you downloaded to use as your desktop background and \nopen it in any image viewer, first go to your Home folder, then open the Pictures \nfolder. Double-click the image to open it in an image viewer.\n6. Moving back and forth between the workspace with Firefox on it and the one with \nthe Nautilus file manager is fairly straightforward.", "doc_id": "9a8252b4-6a41-4612-ad7f-fefa06d4c477", "embedding": null, "doc_hash": "e71dc2d3dbcbc5531026c6b65b0ff3af5b9f17ca13e1dae7ca9ff67dc91c1ce8", "extra_info": {"page_label": "813"}, "node_info": {"start": 0, "end": 2234}, "relationships": {"1": "a3a0f720-ca75-4c68-9015-b3ebe58ec7bd"}}, "__type__": "1"}, "7aa6bf04-da3c-4880-9509-9f992502290e": {"__data__": {"text": "Appendix B: Exercise Answers799BIf you did the previous exercises properly, Nautilus and Firefox should be in differ -\nent workspaces. Here\u2019s how you can move between those workspaces in GNOME 3 \nand GNOME 2:\nGNOME 3\nPress the Windows key, and select the workspace that you want in the right \ncolumn. As an alternative, you can go directly to the application that you want \nby pressing Alt+Tab and pressing Tab again and also arrow keys to highlight the \napplication that you want to open.\nGNOME 2\nSelect the workspace that you want with your mouse by clicking the small repre -\nsentation of the workspace in the right side of the lower panel. If you happen to \nhave Desktop Effects enabled (System \u27aa Preferences Desktop Effects \u27aa Compiz), \ntry pressing Ctrl+Alt+right arrow (or left arrow) to spin to the next workspace.\n7. To open a list of applications installed on your system and select an image \nviewer to open from that list using as few clicks or keystrokes as possible, do the \nfollowing:\nIn GNOME 3\nMove the mouse to the upper-left corner of the screen to get to the Overview \nscreen. Select Applications, then select Utilities from the right column, and then \nselect Image Viewer.\nIn GNOME 2\nSelect Applications \u27aa Graphics \u27aa Image Viewer to open an image viewer window on \nthe desktop.\n8. To change the view of the windows on your current workspace to smaller views of \nthose windows that you can step through, do the following:\nIn GNOME 3\nWith multiple windows open on multiple workspaces, press the Alt+Tab keys. While \ncontinuing to hold the Alt key, press Tab until you highlight the application \nthat you want. Release the Alt key to select it.\nIn GNOME 2\nWith multiple windows open on multiple workspaces, press and hold the \nCtrl+Alt+Tab keys. While continuing to hold the Ctrl+Alt keys, press Tab until \nyou have highlighted the application that you want. Release the Ctrl and Alt \nkeys to select it.\n9. To launch a music player from your desktop using only the keyboard, do the \nfollowing:\nIn GNOME 3\na. Press the Windows key to go to the Overview screen.", "doc_id": "7aa6bf04-da3c-4880-9509-9f992502290e", "embedding": null, "doc_hash": "647bedaf9bad95e567476fd37e50b3bbc9afd2913f05b55dd337e36af36339b2", "extra_info": {"page_label": "814"}, "node_info": {"start": 0, "end": 2075}, "relationships": {"1": "374f3c4b-3055-4a5f-b1b3-b0e2828169cc"}}, "__type__": "1"}, "ce3363c6-7184-4c5f-89ef-5833b752a39b": {"__data__": {"text": "Part VII: Appendixes800b. Type Rhyth  (until the icon appears and is highlighted) and press Enter.  \n(In Ubuntu, if you don\u2019t have Rhythmbox installed, type Bansh  to open the \nBanshee Media Player.)\nIn GNOME 2\nPress Alt+F2. From the Run Application box that appears. Then type rhythmbox  \nand press Enter.\n10. To take a picture of your desktop using only keystrokes, press the Print Screen key \nto take a screen shot of your entire desktop in both GNOME 3 and GNOME 2. Press \nAlt+Print Screen to take a screen shot of just the current window. In both cases, \nthe images are saved to the Pictures folder in your home folder.\nChapter\u00a03: Using the Shell\n1. To switch virtual consoles and return to the desktop in Fedora or Ubuntu (this fea -\nture is disabled in some RHEL systems), do the following:\na. Hold Ctrl+Alt and press F2 (Ctrl+Alt+F2). A text-based console should appear.\nb. Type your username (press Enter) and password (press Enter).\nc. Type a few commands, such as id , pwd , and ls .\nd. Type exit  to exit the shell and return to the login prompt.\ne. Press Ctrl+Alt+F1 to return to the virtual console that holds your desktop.  \n(On different Linux systems, the desktop may be on different virtual consoles. \nCtrl+Alt+F7 and Ctrl+Alt+F2 are other common places to find it.)\n2. For your Terminal window, make the font red and the background yellow.\na. From the GNOME desktop, select Applications \u27aa System Tools \u27aa Terminal to \nopen a Terminal window.\nb. From the Terminal window, select Edit \u27aa Profile Preferences.\nc. Select the Colors tab and deselect \u201cUse colors from system theme\u201d box.\nd. Select the box next to Text Color, click the color red that you want from the \navailable selections, and click Select.\ne. Select the box next to Background Color, click the color yellow that you want \nfrom the available selections, and click Select.\nf. Click Close on the Profile window to go back to the Terminal window with the \nnew colors.\ng. Go back and reselect \u201cUse colors from system theme\u201d box to go back to the \ndefault Terminal colors.\n3. Find the mount  command and tracepath  man page.\na. Run type mount  to see that the mount  command\u2019s location is either /usr/\nbin/mount  or /bin/mount .", "doc_id": "ce3363c6-7184-4c5f-89ef-5833b752a39b", "embedding": null, "doc_hash": "99045476a21df2031cb131e6512e54fd3650b9837bcc87f0ea492f8b903f45a1", "extra_info": {"page_label": "815"}, "node_info": {"start": 0, "end": 2202}, "relationships": {"1": "2d9bda5f-a5af-4f90-8e41-ee8baf9c0fce"}}, "__type__": "1"}, "f0559b9e-453f-4fd1-8877-6d531c44e7b5": {"__data__": {"text": "Appendix B: Exercise Answers801Bb. Run locate tracepath  to see that the tracepath  man page is at /usr/\nshare/man/man8/tracepath.8.gz .\n4. Run, recall, and change these commands as described:\n        $ cat /etc/passwd\n        $ ls $HOME\n        $ date\na. Press the up arrow until you see the cat /etc/passwd  command. If your cur -\nsor is not already at the end of the line, press Ctrl+E to get there. Backspace \nover the word passwd , type the word group , and press Enter.\nb. Type man ls , and find the option to list by time ( -t). Press the up arrow until \nyou see the ls $HOME  command. Use the left arrow key or Alt+B to position \nyour cursor to the left of $HOME . Type -t , so that the line appears as ls -t \n$HOME . Press Enter to run the command.\nc. Type man date  to view the date  man page. Use the up arrow to recall the \ndate  command and add the format indicator that you found. A single %D  \nformat indicator gets the results you need:\n        $ date +%D\n        04/27/20\n5. Use tab completion to type basename /usr/share/doc/ . Type basen<Tab> /\nu<Tab>sh<Tab>do<Tab>  to get basename/usr/share/doc/ .\n6. Pipe /etc/services  to the less  command: $ cat /etc/services | less .\n7. Make output from the date  command appear in this format: Today is Thursday, \nApril 23, 2020.\n        $ echo \"Today is $(date +'%A, %B %d, %Y')\"\n8. View variables to find your current hostname, username, shell, and home \ndirectories.\n        $ echo $HOSTNAME\n        $ echo $USERNAME\n        $ echo $SHELL\n        $ echo $HOME\n9. Add a permanent mypass  alias that displays the contents of the /etc/\npasswd  file.\na. Type nano $HOME/.bashrc .\nb. Move the cursor to an open line at the bottom of the page. (Press Enter to open \na new line if needed.)\nc. On its own line, type alias m=\"cat /etc/passwd\" .\nd. Type Ctrl+O to save and Ctrl+X to exit the file.\ne. Type source $HOME/.bashrc .", "doc_id": "f0559b9e-453f-4fd1-8877-6d531c44e7b5", "embedding": null, "doc_hash": "be9dbbb0f8e39f5681302da7411e9a8bd56508741a44c1168a1033c6a3999a5b", "extra_info": {"page_label": "816"}, "node_info": {"start": 0, "end": 1881}, "relationships": {"1": "501912db-1da0-4b69-b3c0-8204f2272b91"}}, "__type__": "1"}, "b5290997-ea94-4a07-a752-c0c616ce3ef5": {"__data__": {"text": "Part VII: Appendixes802f. Type alias m  to make sure that the alias was set properly: alias m='cat /\netc/passwd' .\ng. Type m . (The /etc/passwd  file displays on the screen.)\n10. To display the man page for the mount system call, use the man -k  command to \nfind man pages that include the word mount . Then use the mount  command with \nthe correct section number (8) to get the proper mount  man page:\n        $ man -k mount | grep ^mount\n        mount       (2)  - mount filesystem\n        mount       (8)  - mount a filesystem\n        ...\n        mountpoint  (1)  - see if a directory is a mountpoint\n        mountstats  (8)  - Displays various NFS client per-mount \nstatistics\n        $ man 2 mount\n        MOUNT(2)      Linux Programmer's Manual             \nMOUNT(2)\n        NAME\n              mount - mount file system\n        SYNOPSIS\n              #include <sys/mount.h>\n.\n.\n.\nChapter\u00a04: Moving Around the Filesystem\n1. Create the projects  directory, create nine empty files ( house1  to house9 ), and \nlist just those files.\n        $ mkdir $HOME/projects/\n        $ touch $HOME/projects/house{1..9}\n        $ ls $HOME/projects/house{1..9}\n2. Make the $HOME/projects/houses/doors/  directory path, and create some \nempty files in that path.\n        $ cd\n        $ mkdir $HOME/projects/houses\n        $ touch $HOME/projects/houses/bungalow.txt\n        $ mkdir $HOME/projects/houses/doors/\n        $ touch $HOME/projects/houses/doors/bifold.txt\n        $ mkdir -p $HOME/projects/outdoors/vegetation/\n        $ touch $HOME/projects/outdoors/vegetation/landscape.txt\n3. Copy the files house1  and house5  to the $HOME/projects/houses/  directory.\n        $ cp $HOME/projects/house[15] $HOME/projects/houses", "doc_id": "b5290997-ea94-4a07-a752-c0c616ce3ef5", "embedding": null, "doc_hash": "718892968b6fb894be89ff02666dcfa92a520d6783ffa7c73908ed95fb16c816", "extra_info": {"page_label": "817"}, "node_info": {"start": 0, "end": 1713}, "relationships": {"1": "c35662d5-4619-42fa-911b-6b9a7efa61d8"}}, "__type__": "1"}, "4cf74559-d5d6-4a98-ab19-1c7d7a9d7cde": {"__data__": {"text": "Appendix B: Exercise Answers\nB8034. Recursively copy the /usr/share/doc/initscripts*  directory to the $HOME/\nprojects/  directory.\n        $ cp -ra /usr/share/doc/initscripts*/ $HOME/projects/\n5. Recursively list the contents of the $HOME/projects/  directory. Pipe the output \nto the less  command so that you can page through the output.\n        $ ls -lR $HOME/projects/ | less\n6. Remove the files house6 , house7 , and house8  without being prompted.\n        $ rm -f $HOME/projects/house[678]\n7. Move house3  and house4  to the $HOME/projects/houses/doors  directory.\n        $ mv $HOME/projects/house{3,4} $HOME/projects/houses/doors/\n8. Remove the $HOME/projects/houses/doors  directory and its contents.\n        $ rm -rf $HOME/projects/houses/doors/\n9. Change the permissions on the $HOME/projects/house2  file so that it can be \nread and written to by the user who owns the file, only read by the group, and have \nno permission for others.\n        $ chmod 640 $HOME/projects/house2\n10. Recursively change the permissions of the $HOME/projects / directory so that \nnobody has write permission to any files or directories beneath that point in the \nfile system.\n        $ chmod -R a-w $HOME/projects/\n        $ ls -lR $HOME/projects/\n        /home/joe/projects/:\n \n        total 12\n \n        -r--r--r--. 1 joe joe    0 Jan 16 06:49 house1\n \n        -r--r-----. 1 joe joe    0 Jan 16 06:49 house2\n \n        -r--r--r--. 1 joe joe    0 Jan 16 06:49 house5\n \n        -r--r--r--. 1 joe joe    0 Jan 16 06:49 house9\n \n        dr-xr-xr-x. 2 joe joe 4096 Jan 16 06:57 houses\n \n        dr-xr-xr-x. 2 joe joe 4096 Jul  1  2014 initscripts-9.03.40\n \n        dr-xr-xr-x. 3 joe joe 4096 Jan 16 06:53 outdoors\n        ...", "doc_id": "4cf74559-d5d6-4a98-ab19-1c7d7a9d7cde", "embedding": null, "doc_hash": "785bcf464a46b60eda929caddfb82e6a2f7d9ac4d89dbdbaec3ff37aafd1ecae", "extra_info": {"page_label": "818"}, "node_info": {"start": 0, "end": 1713}, "relationships": {"1": "69873c8a-50a0-4dde-80a6-81c31a86ceba"}}, "__type__": "1"}, "bffa26b9-2431-408b-81ee-f959a3174845": {"__data__": {"text": "Part VII: Appendixes804Chapter\u00a05: Working with Text Files\n1. Follow these steps to create the /tmp/services  file, and then edit it so that \nWorldWideWeb  appears as World Wide Web .\n        $ cp /etc/services /tmp\n        $ vi /tmp/services\n        /WorldWideWeb<Enter>\n        cwWorld Wide Web<Esc>\nThe next two lines show the before and after:\n        http            80/tcp     www www-http    # WorldWideWeb HTTP\n        http            80/tcp     www www-http    # World Wide Web HTTP\n2. One way to move the paragraph in your /tmp/services  file is to search for the \nfirst line of the paragraph, delete five lines ( 5dd), go to the end of the file ( G), and \nput in the text ( p):\n        $ vi /tmp/services\n        /Note that it is<Enter>\n        5dd\n        G\n        p\n3. To use ex  mode to search for every occurrence of the term tcp  (case sensitive) \nin your /tmp/services  file, and change it to WHATEVER , you can enter the \nfollowing:\n        $ vi /tmp/services\n        :g/tcp/s//WHATEVER/g<Enter>\n4. To search the /etc  directory for every file named passwd  and redirect errors from \nyour search to /dev/null , you can enter the following:\n        $ find /etc -name passwd 2> /dev/null\n5. Create a directory in your home directory called TEST . Create files in that directory \nnamed one , two , and three  that have full read/write/execute permissions on \nfor everyone (user, group, and other). Construct a find  command that would find \nthose files and any other files that have write permission open to \u201cothers\u201d from \nyour home directory and below.\n        $ mkdir $HOME/TEST\n        $ touch $HOME/TEST/{one,two,three}\n        $ chmod 777 $HOME/TEST/{one,two,three}\n        $ find $HOME -perm -002 -type f -ls\n        148120  0 -rwxrwxrwx   1 chris chris 0 Jan  1 08:56 /home/\nchris/TEST/two", "doc_id": "bffa26b9-2431-408b-81ee-f959a3174845", "embedding": null, "doc_hash": "a8295c1778d68486e3d89c2f4d01aa74d6aa95f0d96452743118ce06c7e1da1a", "extra_info": {"page_label": "819"}, "node_info": {"start": 0, "end": 1811}, "relationships": {"1": "e99ea25d-0f86-4d10-bf3a-b3bfde792d53"}}, "__type__": "1"}, "0f9f74fc-05ca-4aa7-925d-df6bc371f754": {"__data__": {"text": "Appendix B: Exercise Answers\nB805        148918  0 -rwxrwxrwx   1 chris chris 0 Jan  1 08:56 home/chris/\nTEST/three\n        147306  0 -rwxrwxrwx   1 chris chris 0 Jan  1 08:56 /home/chris/\nTEST/one\n6. Find files under the /usr/share/doc  directory that have not been modified in \nmore than 300 days.\n        $ find /usr/share/doc -mtime +300\n7. Create a /tmp/FILES  directory. Find all files under the /usr/share  directory \nthat are more than 5MB and less than 10MB, and copy them to the /tmp/FILES  \ndirectory.\n        $ mkdir /tmp/FILES\n        $ find /usr/share -size +5M -size -10M -exec cp {} /tmp/FILES \\;\n        $ du -sh /tmp/FILES/*\n        6.6M    /tmp/FILES/BidiCharacterTest.txt\n        7.6M    /tmp/FILES/BidiTest.txt\n        5.2M    /tmp/FILES/day.jpg\n8. Find every file in the /tmp/FILES  directory, and make a backup copy of each file \nin the same directory. Use each file\u2019s existing name and append .mybackup  to cre -\nate each backup file.\n        $ find /tmp/FILES/ -type f -exec cp {} {}.mybackup \\;\n9. Install the kernel-doc  package in Fedora or Red Hat Enterprise Linux. Using \ngrep , search inside the files contained in the /usr/share/doc/kernel-doc*  \ndirectory for the term e1000  (case insensitive), and list the names of the files that \ncontain that term.\n        # yum install kernel-doc\n        $ cd /usr/share/doc/kernel-doc*\n        $ grep -rli e1000 .\n        ./Documentation/powerpc/booting-without-of.txt\n        ./Documentation/networking/e100.txt\n        ...\n10. Search for the e1000  term again in the same location. However, this time list every \nline that contains the term and highlight the term in color.\n        $ cd /usr/share/doc/kernel-doc-*\n        $ grep -ri --color e1000 .\nChapter\u00a06: Managing Running Processes\n1. To list all processes running on your system with a full set of columns, while piping \nthe output to less , enter the following:\n        $ ps -ef | less", "doc_id": "0f9f74fc-05ca-4aa7-925d-df6bc371f754", "embedding": null, "doc_hash": "a822e5ea6edc02fcd67d0c84cf153504f450d2f55043e254a86649605cb389db", "extra_info": {"page_label": "820"}, "node_info": {"start": 0, "end": 1918}, "relationships": {"1": "61c0fb7d-e00e-42b4-9b42-00ba59656909"}}, "__type__": "1"}, "422cd9fb-6433-4e96-8110-746a51d0c9d6": {"__data__": {"text": "Part VII: Appendixes8062. To list all processes running on the system and sort those processes by the name of \nthe user running each process, enter the following:\n        $ ps -ef --sort=user | less\n3. To list all processes running on the system with the column names process ID, \nusername, group name, nice value, virtual memory size, resident memory size, and \ncommand, enter the following:\n        $ ps -eo 'pid,user,group,nice,vsz,rss,comm' | less\n          PID USER     GROUP     NI    VSZ   RSS COMMAND\n            1 root     root       0  19324  1236 init\n            2 root     root       0      0     0 kthreadd\n            3 root     root       -      0     0 migration/0\n            4 root     root       0      0     0 ksoftirqd/0\n4. To run the top  command and then go back and forth between sorting by CPU usage \nand memory consumption, enter the following:\n        $ top\n        P\n        M\n        P\n        M\n5. To start the gedit process from your desktop and use the System Monitor window \nto kill that process, do the following:\n        $ gedit &\nNext, in GNOME 2, select Applications \u27aa System Tools \u27aa System Monitor, or in \nGNOME 3, from the Activities screen, type System Monitor and press Enter. Find \nthe gedit process on the Processes tab. (You can sort alphabetically to make it \neasier by clicking the Process Name heading.) Right-click the gedit command, and \nthen select either End Process or Kill Process; the gedit window on your screen \nshould disappear.\n6. To run the gedit process and use the kill  command to send a signal to pause \n(stop) that process, enter the following:\n        $ gedit &\n        [1] 21532\n \n        $ kill -SIGSTOP 21532\n7. To use the killall  command to tell the gedit command (paused in the previous \nexercise) to continue working, do the following:\n        $ killall -SIGCONT gedit\nMake sure that the text you typed after gedit was paused now appears in \nthe window.", "doc_id": "422cd9fb-6433-4e96-8110-746a51d0c9d6", "embedding": null, "doc_hash": "b6a8788e55b711f7a907a4bdd6c0ba260f9b84a8ce400656e380456c8628912b", "extra_info": {"page_label": "821"}, "node_info": {"start": 0, "end": 1926}, "relationships": {"1": "9b7a38ec-314b-4a36-b2f0-34f61f077cd9"}}, "__type__": "1"}, "818938df-3751-4856-ac52-756add4a2563": {"__data__": {"text": "Appendix B: Exercise Answers\nB8078. To install the xeyes  command, run it about 20 times in the background, and run \nkillall  to kill all 20 xeyes  processes at once, enter the following:\n        # yum install xorg-x11-apps\n        $ xeyes &\n        $ xeyes &\n        ...\n        $ killall xeyes &\nRemember, you need to be the root user to install the package. After that, remem-\nber to repeat the xeyes  command 20 times. Spread the windows around on your \nscreen, and move the mouse for fun to watch the eyes move. All the xeyes  win-\ndows should disappear at once when you type killall xeyes .\n9. As a regular user, run the gedit command so that it starts with a nice value of 5 .\n        # nice -n 5 gedit &\n        [1] 21578\n10. To use the renice  command to change the nice value of the gedit command you \njust started to 7 , enter the following:\n        # renice -n 7 21578\n        21578: old priority 0, new priority 7\nUse any command you like to verify that the current nice value for the gedit \ncommand is now set to 7 . For example, you could type the following:\n        # ps -eo 'pid,user,nice,comm' | grep gedit\n        21578 chris     7 gedit\nChapter\u00a07: Writing Simple Shell Scripts\n1. Here\u2019s an example of how to create a script in your $HOME/bin  directory called \nmyownscript . When the script runs, it should output information that appears \nas follows:\n        Today is Sat Jun 10 15:45:04 EDT 2019.\n        You are in /home/joe and your host is abc.example.com.\nThe following steps show one way to create the script named myownscript :\na. If it doesn\u2019t already exist, create a bin directory:\n        $ mkdir $HOME/bin\nb. Using any text editor, create a script called $HOME/bin/myownscript  that \ncontains the following:\n        #!/bin/bash\n        # myownscript\n        # List some information about your current system", "doc_id": "818938df-3751-4856-ac52-756add4a2563", "embedding": null, "doc_hash": "7bded3281f0b8588f4a56059818e5e26ae1fb86d7c2fd558ed93c64171c006fa", "extra_info": {"page_label": "822"}, "node_info": {"start": 0, "end": 1839}, "relationships": {"1": "5fd3d459-3cb7-4a37-887f-24b3655c941f"}}, "__type__": "1"}, "8ec416e8-3eb4-4bba-bae3-7ebe514589c4": {"__data__": {"text": "Part VII: Appendixes808        echo \"Today is $(date).\"\n        echo \"You are in $(pwd) and your host is $(hostname).\"\nc. Make the script executable:\n        $ chmod 755 $HOME/bin/myownscript\n2. Create a script that reads in three positional parameters from the command line, \nassigns those parameters to variables named ONE , TWO , and THREE , respectively. \nAlso, replace X with the number of parameters and Y with all of the parameters \nentered. Then replace A with the contents of variable ONE , B with variable TWO , \nand C with variable THREE , as shown below:\na. To create the script, open a file named $HOME/bin/myposition  and add the \nfollowing contents:\n#!/bin/bash\n# myposition\nONE=$1\nTWO=$2\nTHREE=$3\necho \"There are $# parameters that include: $@\"\necho \"The first is $ONE, the second is $TWO, the third is \n$THREE.\"\nb. To make the script called $HOME/bin/myposition  executable, enter the \nfollowing:\n        $ chmod 755 $HOME/bin/myposition\nc. To test it, run it with some command-line arguments, as in the following:\n        $ myposition Where Is My Hat Buddy?\n        There are 5 parameters that include: Where Is My Hat Buddy?\n        The first is Where, the second is Is, the third is My.\n3. To create the script described, do the following:\na. To create a file called $HOME/bin/myhome  and make it executable, enter the \nfollowing:\n        $ touch $HOME/bin/myhome\n        $ chmod 755 $HOME/bin/myhome\nb. Here\u2019s what the script myhome  might look like:\n        #!/bin/bash\n        # myhome\n        read -p \"What street did you grow up on? \" mystreet\n        read -p \"What town did you grow up in? \" mytown\n        echo \"The street I grew up on was $mystreet and the town \nwas $mytown.\"", "doc_id": "8ec416e8-3eb4-4bba-bae3-7ebe514589c4", "embedding": null, "doc_hash": "41bf701bf6b65d075d0070a691c8e4ee3a7488603f94393edbd64de00f7f22a8", "extra_info": {"page_label": "823"}, "node_info": {"start": 0, "end": 1704}, "relationships": {"1": "e804e772-93ae-4bef-8543-095c1308ecf9"}}, "__type__": "1"}, "e9eed08c-5847-49bc-9ec0-5ed92dc0b59a": {"__data__": {"text": "Appendix B: Exercise Answers\nB809c. Run the script to check that it works. The following example shows what the \ninput and output for the script could look like:\n        $ myhome\n        What street did you grow up on? Harrison\n        What town did you grow up in? Princeton\n        The street I grew up on was Harrison and the town was Princeton.\n4. To create the required script, do the following:\na. Using any text editor, create a script called $HOME/bin/myos  and make the \nscript executable:\n        $ touch $HOME/bin/myos\n        $ chmod 755 $HOME/bin/myos\nb. The script could contain the following:\n        #!/bin/bash\n        # myos\n        read -p \"What is your favorite operating system, Mac, \nWindows or Linux? \" opsys\n        if [ $opsys = Mac ] ; then\n          echo \"Mac is nice, but not tough enough for me.\"\n        elif [ $opsys = Windows ] ; then\n          echo \"I used Windows once. What is that blue screen \nfor?\"\n        elif [ $opsys = Linux ] ; then\n          echo \"Great Choice!\"\n        else\n          echo \"Is $opsys an operating system?\"\n        fi\n5. To create a script named $HOME/bin/animals  that runs through the words \nmoose , cow, goose , and sow  through a for  loop and have each of those words \nappended to the end of the line \u201cI have a.\u00a0.\u00a0.,\u201d do the following:\na. Make the script executable:\n        $ touch $HOME/bin/animals\n        $ chmod 755 $HOME/bin/animals\nb. The script could contain the following:\n        #!/bin/bash\n        # animals\n        for ANIMALS in moose cow goose sow ; do\n          echo \"I have a $ANIMALS\"\n        done\nc. When you run the script, the output should appear as follows:\n        $ animals\n        I have a moose", "doc_id": "e9eed08c-5847-49bc-9ec0-5ed92dc0b59a", "embedding": null, "doc_hash": "5336817547c8816f8755bfa1b1593824c46fe82472f3a75a86ad4ed29100e166", "extra_info": {"page_label": "824"}, "node_info": {"start": 0, "end": 1686}, "relationships": {"1": "0f86f60c-e3bd-4bc8-ba07-b253894009f3"}}, "__type__": "1"}, "211e4a13-6a0a-4d1c-981e-ee78d0c43353": {"__data__": {"text": "Part VII: Appendixes810        I have a cow\n        I have a goose\n        I have a sow\nChapter\u00a08: Learning System Administration\n1. To enable Cockpit on your system, enter the following:\n        # systemctl enable --now cockpit.socket\n        Created symlink /etc/systemd/system/sockets.target.wants/\ncockpit.socket\n           \u2192 /usr/lib/systemd/system/cockpit.socket\n2. To open the Cockpit interface in your web browser, enter the hostname or IP \naddress of the system holding your Cockpit service, followed by port number 9090. \nFor example, enter this into the location box of your browser:\n        https://host1.example.com:9090/\n3. To find all of the files under the /var/spool  directory that are owned by users \nother than root and do a long listing of them, enter the following. (I recommend \nbecoming root to find files that might be closed off to other users.)\n        $ su -\n        Password: *********\n        # find /var/spool -not -user root -ls | less\n4. To become root user and create an empty or plain-text file named /mnt/test.txt , \nenter the following:\n        $ su -\n        Password: *********\n        # touch /mnt/test.txt\n        # ls -l /mnt/test.txt\n        -rw-r--r--. 1 root root 0 Jan  9 21:51 /mnt/test.txt\n5. To become root and edit the /etc/sudoers  file to allow your regular user account \n(for example, bill ) to have full root privilege via the sudo  command, do the \nfollowing:\n        $ su -\n        Password: *********\n        # visudo\n        o\n        bill     ALL=(ALL)     ALL\n        Esc ZZ\nBecause visudo  opens the /etc/sudoers  file in vi , the example types o to \nopen a line, and then it types in the line to allow bill to have full root privilege. ", "doc_id": "211e4a13-6a0a-4d1c-981e-ee78d0c43353", "embedding": null, "doc_hash": "331ced2152468c0a773f3c0a3dac60a6ae0ef45863a42507d9192df7e8b2b817", "extra_info": {"page_label": "825"}, "node_info": {"start": 0, "end": 1698}, "relationships": {"1": "9748daf9-5e34-4e49-bb00-d2d9846475a7"}}, "__type__": "1"}, "5629088b-a33b-405d-b672-7158782478f1": {"__data__": {"text": "Appendix B: Exercise Answers\nB811After the line is typed, press Esc to return to command mode and type ZZ  to \nwrite and quit.\n6. To use the sudo  command to create a file called /mnt/test2.txt  and verify that \nthe file is there and owned by the root user, enter the following:\n        [bill]$ sudo touch /mnt/test2.txt\n        We trust you have received the usual lecture from the local System\n        Administrator. It usually boils down to these three things:\n            #1) Respect the privacy of others.\n            #2) Think before you type.\n            #3) With great power comes great responsibility.\n        [sudo] password for bill:  *********\n        [bill]$ ls -l /mnt/text2.txt\n        -rw-r--r--. 1 root root 0 Jan  9 23:37 /mnt/text2.txt\n7. Do the following to mount and unmount a USB drive and watch the system journal \nduring this process:\na. Run the journalctl -f  command as root in a Terminal window and watch \nthe output from here for the next few steps.\n        # journalctl -f\n        Jan 25 16:07:59 host2 kernel: usb 1-1.1: new high-speed USB device\n            number 16 using ehci-pci\n        Jan 25 16:07:59 host2 kernel: usb 1-1.1: New USB device found,\n            idVendor=0ea0, idProduct=2168\n        Jan 25 16:07:59 host2 kernel: usb 1-1.1: New USB device strings:\n            Mfr=1, Product=2, SerialNumber=3\n        Jan 25 16:07:59 host2 kernel: usb 1-1.1: Product: Flash Disk\n        Jan 25 16:07:59 host2 kernel: usb 1-1.1: Manufacturer: USB\n        ...\n        Jan 25 16:08:01 host2 kernel: sd 18:0:0:0: [sdb] Write Protect is off\n        Jan 25 16:08:01 host2 kernel: sd 18:0:0:0: [sdb]\n            Assuming drive cache: write through\n        Jan 25 16:08:01 host2 kernel:  sdb: sdb1\n        Jan 25 16:08:01 host2 kernel: sd 18:0:0:0: [sdb]\n            Attached SCSI removable disk\nb. Plug in a USB storage drive that mounts a filesystem from that drive automati-\ncally. If it does not, run the following commands in a second terminal (as root) \nto create a mount point directory and mount the device:\n        $ mkdir /mnt/test\n        $ mount /dev/sdb1 /mnt/test\n        $ umount /dev/sdb1", "doc_id": "5629088b-a33b-405d-b672-7158782478f1", "embedding": null, "doc_hash": "fc6ed9e0cc5d9538779e09c7c676e6fcb651a639778e48046cb40be16fa76da8", "extra_info": {"page_label": "826"}, "node_info": {"start": 0, "end": 2131}, "relationships": {"1": "8fcad5c1-ca7c-4974-90c9-81b7d00ac872"}}, "__type__": "1"}, "88a0ecf0-8a27-4b0a-bdba-150026a1317d": {"__data__": {"text": "Part VII: Appendixes8128. To see what USB devices are connected to your computer, enter the following:\n        $ lsusb\n9. To load the bttv  module, list the modules that were loaded, and unload it, enter \nthe following:\n        # modprobe -a bttv\n        # lsmod | grep bttv\n        ttv                  167936  0\n        tea575x                16384  1 bttv\n        tveeprom               28672  1 bttv\n        videobuf_dma_sg        24576  1 bttv\n        videobuf_core          32768  2 videobuf_dma_sg,bttv\n        v4l2_common            16384  1 bttv\n        videodev              233472  3 tea575x,v4l2_common,bttv\n        i2c_algo_bit           16384  1 bttv\nNotice that other modules ( v4l2_common , videodev , and others) were loaded \nwhen you loaded bttv  with modprobe -a .\n10. Enter the following to remove the bttv  module along with any other modules that \nwere loaded with it. Notice that they were all gone after running modprobe -r .\n        # modprobe -r bttv\n        # lsmod | grep bttv\nChapter\u00a09: Installing Linux\n1. To install a Fedora system from Fedora Live media, follow the instructions in the \nsection \u201cInstalling Fedora from Live Media\u201d in Chapter\u00a09. In general, those steps \ninclude the following:\na. Booting the Live media.\nb. Selecting to install to the hard drive when the system boots up.\nc. Adding information from the summary page needed to configure your system \ninitially.\nd. Rebooting your computer and removing the Live medium so that the newly \ninstalled system boots from the hard drive.\n2. To update the packages, after the Fedora Live media installation is complete, do the \nfollowing:\na. Reboot the computer and fill in the first boot questions as prompted.\nb. Using a wired or wireless connection, make sure that you have a connection \nto the Internet. Refer to Chapter\u00a014, \u201cAdministering Networking,\u201d if you have \ntrouble getting your networking connection to work properly. Open a shell as \nthe root user and type sudo dnf update .\nc. When prompted, type y to accept the list of packages displayed. The system \nbegins downloading and installing the packages.", "doc_id": "88a0ecf0-8a27-4b0a-bdba-150026a1317d", "embedding": null, "doc_hash": "84ecc5ec8f47cf04928f43c3cba57ee818e0e23317ae4d1900692a96fc7e3391", "extra_info": {"page_label": "827"}, "node_info": {"start": 0, "end": 2103}, "relationships": {"1": "9501fbb8-6fdc-4811-8fb1-00a70841f79e"}}, "__type__": "1"}, "42deb119-9cea-476a-9565-40728cee8d0e": {"__data__": {"text": "Appendix B: Exercise Answers\nB8133. To run the RHEL installation in text mode, do the following:\na. Boot the RHEL DVD.\nb. When you see the boot menu, highlight one of the installation boot entries and \npress Tab. Move the cursor right to the end of the kernel line, and type the lit -\neral option text  at the end of that line. Press Enter to start the installer.\nc. Try out the rest of the installation in text mode.\n4. To set the disk partitioning as described in question 4 for a Red Hat Enterprise \nLinux DVD installation, do the following:\nNote\nThis procedure ultimately deletes all content on your hard disk. If you just want to use this exercise to practice parti -\ntioning, you can reboot your computer before starting the actual installation process without harming your hard disk. \nAfter you go forward and partition your disk, assume that all data has been deleted.\na. On a computer that you can erase with at least 10GB of disk space, insert \na RHEL installation DVD, reboot, and begin stepping through the installa -\ntion screens.\nb. When you get to the Installation Summary screen, select Installation \nDestination.\nc. From the Installation Destination screen, select the device to use for the instal -\nlation (probably sda  if you have a single hard disk that you can completely \nerase or vda  for a virtual install).\nd. Select the Custom button.\ne. Select Done to get to the Manual Partitioning screen.\nf. If the existing disk space is already consumed, you need to delete the parti-\ntions before proceeding.\ng. Click the plus ( +) button at the bottom of the screen. Then add each of the fol -\nlowing mount points:\n/boot - 400M\n/ - 3G\n/var - 2G\n/home -2G\nh. Select Done. You should see a summary of changes.\ni. If the changes look acceptable, select Accept Changes. If you are just practicing \nand don\u2019t actually want to change your partitions, select Cancel & Return to \nCustom Partitioning. Then simply exit the installer.", "doc_id": "42deb119-9cea-476a-9565-40728cee8d0e", "embedding": null, "doc_hash": "b6a5dbc61ea5e510e3a7d2fc55e67b309f1b1b7d0589464fb626523f603ec1cb", "extra_info": {"page_label": "828"}, "node_info": {"start": 0, "end": 1941}, "relationships": {"1": "4d7dac46-ed9a-4fb8-bf50-dbe8498a5a0b"}}, "__type__": "1"}, "6e3047d6-c79a-4b2f-9448-0ed2b57eafb4": {"__data__": {"text": "Part VII: Appendixes814Chapter\u00a010: Getting and Managing Software\n1. To search the YUM repository for the package that provides the mogrify  \ncommand, enter the following:\n        # yum provides mogrify\n2. To display information about the package that provides the mogrify  command \nand determine what is that package\u2019s home page (URL), enter the following:\n        # yum info ImageMagick\nYou will see that the URL to the home page for ImageMagick is http://www.\nimagemagick.org.\n3. To install the package containing the mogrify  command, enter the following:\n        # yum install ImageMagick\n4. To list all of the documentation files contained in the package that provides the \nmogrify  command, enter the following:\n        # rpm -qd ImageMagick\n        ...\n        /usr/share/doc/ImageMagick/README.txt\n        ...\n        /usr/share/man/man1/identify.1.gz\n        /usr/share/man/man1/import.1.gz\n        /usr/share/man/man1/mogrify.1.gz\n5. To look through the change log of the package that provides the mogrify  \ncommand, enter the following:\n        # rpm -q --changelog ImageMagick | less\n6. To delete the mogrify  command from your system and verify its package against \nthe RPM database to see that the command is indeed missing, enter the following:\n        # type mogrify\n        mogrify is /usr/bin/mogrify\n        # rm /usr/bin/mogrify\n        rm remove regular file '/usr/bin/mogrify'? y\n        # rpm -V ImageMagick\n        missing   /usr/bin/mogrify\n7. To reinstall the package that provides the mogrify  command and make sure that \nthe entire package is intact again, enter the following:\n        # yum reinstall ImageMagick\n        # rpm -V ImageMagick\n8. To download the package that provides the mogrify  command to your current \ndirectory, enter the following:\n        # yum download ImageMagick\n        ImageMagick-6.9.10.28-1.fc30.x86_64.rpm", "doc_id": "6e3047d6-c79a-4b2f-9448-0ed2b57eafb4", "embedding": null, "doc_hash": "159ba792133f756e1fd8c93ba6e7142b8ce0187145b3d3f713ca04c82e4acf50", "extra_info": {"page_label": "829"}, "node_info": {"start": 0, "end": 1864}, "relationships": {"1": "5f05dd94-549a-412b-b345-044a86f73acb"}}, "__type__": "1"}, "abba1498-9599-436c-a66b-b355ec73979f": {"__data__": {"text": "Appendix B: Exercise Answers\nB8159. To display general information about the package that you just downloaded by que -\nrying the package\u2019s RPM file in the current directory, enter the following:\n        # rpm -qip ImageMagick-6.9.10.28-1.fc30.x86_64.rpm\n        Name        : ImageMagick\n        Epoch       : 1\n        Version     : 6.9.10.28\n        Release     : 1.fc30\n \n \n \n        ...\n10. To remove the package containing the mogrify  command from your system, enter \nthe following:\n        # yum remove ImageMagick\nChapter\u00a011: Managing User Accounts\nFor questions that involve adding and removing user accounts, you can use the Users \nwindow, the User Manager window, or command-line tools such as useradd  and usermod . \nThe point is to make sure that you get the correct results shown in the answers that follow, \nnot necessarily to do it exactly in the same way that I did.\nThere are multiple ways that you can achieve the same results. The answers here show \nhow to complete the exercises from the command line. (Become root user when you see a \n# prompt.)\n1. To add a local user account to your Linux system that has a username of jbaxter  \nand a full name of John Baxter, which uses /bin/sh  as its default shell and is the \nnext available UID (yours may differ from the one shown here), enter the following. \nYou can use the grep  command to check the new user account. Then set the pass -\nword for jbaxter  to: My1N1te0ut!\n        # useradd -c \"John Baxter\" -s /bin/sh jbaxter\n        # grep jbaxter /etc/passwd\n        jbaxter:x:1001:1001:John Baxter:/home/jbaxter:/bin/sh\n        # passwd jbaxter\n        Changing password for user jbaxter\n        New password: My1N1te0ut!\n        Retype new password: My1N1te0ut!\n        passwd: all authentication tokens updated successfully\n2. To create a group account named testing  that uses group ID 315, enter the \nfollowing:\n        # groupadd -g 315 testing\n        # grep testing /etc/group\n        testing:x:315:", "doc_id": "abba1498-9599-436c-a66b-b355ec73979f", "embedding": null, "doc_hash": "c65a719fcf07b5b95172298553ec73ee1c17bee1807c356893c413937ba47475", "extra_info": {"page_label": "830"}, "node_info": {"start": 0, "end": 1975}, "relationships": {"1": "c4219c03-66a7-458f-b05b-6137ada7713b"}}, "__type__": "1"}, "a7e99a7f-a9f2-41a2-a711-f81b42b28d89": {"__data__": {"text": "Part VII: Appendixes8163. To add jbaxter  to the testing  group and the bin  group, enter the following:\n        # usermod -aG testing,bin jbaxter\n        # grep jbaxter /etc/group\n        bin:x:1:bin,daemon,jbaxter\n        jbaxter:x:1001:\n        testing:x:315:jbaxter\n4. To become jbaxter  and temporarily have the testing  group be jbaxter \u2019s \ndefault group, run touch /home/jbaxter/file.txt  so that the testing  \ngroup is assigned as the file\u2019s group, and do the following:\n        $ su - jbaxter\n        Password: My1N1te0ut!\n        sh-4.2$ newgrp testing\n        sh-4.2$ touch /home/jbaxter/file.txt\n        sh-4.2$ ls -l /home/baxter/file.txt\n        -rw-rw-r--. 1 jbaxter testing 0 Jan 25 06:42 /home/jbaxter/file.\ntxt\n        sh-4.2$ exit ; exit\n5. Note what user ID has been assigned to jbaxter , and then delete the user account \nwithout deleting the home directory assigned to jbaxter .\n        $ userdel jbaxter\n6. Use the following command to find any files in the /home  directory (and any \nsubdirectories) that are assigned to the user ID that recently belonged to the user \nnamed jbaxter . (When I did it, the UID/GID were both 1001; yours may differ.) \nNotice that the username jbaxter  is no longer assigned on the system, so any \nfiles that user created are listed as belonging to UID 1001 and GID 1001, except for \na couple of files that were assigned to the testing  group because of the newgrp  \ncommand run earlier:\n        # find /home -uid 1001 -ls\n        262184  4 drwx------ 4 1001  1001  4096 Jan 25 08:00 /home/\njbaxter\n        262193  4 -rw-r--r-- 1 1001  1001   176 Jan 27  2011 /home/\njbaxter/.bash_profile\n        262196  4 -rw------- 1 13602 testing 93 Jan 25 08:00 /home/\njbaxter/.bash_history\n        262194  0 -rw-rw-r-- 1 13602 testing  0 Jan 25 07:59 /home/\njbaxter/file.txt\n        ...\n7. Run these commands to copy the /etc/services  file to the /etc/skel/  direc -\ntory; then add a new user to the system named mjones , with a full name of Mary \nJones and a home directory of /home/maryjones . List her home directory to \nmake sure that the services file is there.\n        # cp /etc/services /etc/skel/\n        # useradd -d /home/maryjones -c \"Mary Jones\" mjones", "doc_id": "a7e99a7f-a9f2-41a2-a711-f81b42b28d89", "embedding": null, "doc_hash": "bb38b31dc24fcfa9e0d9b3f731f0198932934fb9161b5007801a7ca6a3b0b702", "extra_info": {"page_label": "831"}, "node_info": {"start": 0, "end": 2208}, "relationships": {"1": "71d14e2e-9eed-48c5-9a6c-a1ee87faf124"}}, "__type__": "1"}, "721f0066-2b6a-4cd2-84d3-777a69dc4275": {"__data__": {"text": "Appendix B: Exercise Answers\nB817        # ls -l /home/maryjones\n        total 628\n        -rw-r--r--. 1 mjones mjones 640999 Jan 25 06:27 services\n8. Run the following command to find all files under the /home  directory that belong \nto mjones . If you did the exercises in order, notice that after you deleted the user \nwith the highest user ID and group ID, those numbers were assigned to mjones . \nAs a result, any files left on the system by jbaxter  now belong to mjones . (For \nthis reason, you should remove or change ownership of files left behind when you \ndelete a user.)\n        # find /home -user mjones -ls\n        262184 4 drwx------ 4 mjones mjones 4096 Jan 25 08:00 /\nhome/jbaxter\n        262193 4 -rw-r--r-- 1 mjones mjones 176 Jan 27 2011 /home/\njbaxter/.bash_profile\n        262189 4 -rw-r--r-- 1 mjones mjones 18 Jan 27 2011 /home/\njbaxter/.bash_logout\n        262194 0 -rw-rw-r-- 1 mjones testing 0 Jan 25 07:59 /home/\njbaxter/file.txt\n        262188 4 -rw-r--r-- 1 mjones mjones 124 Jan 27 2011 /home/\njbaxter/.bashrc\n        262197 4 drwx------ 4 mjones  mjones 4096 Jan 25 08:27 /\nhome/maryjones\n        262207 4 -rw-r--r-- 1 mjones mjones 176 Jan 27 2011 /home/\nmaryjones/.bash_profile\n        262202 4 -rw-r--r-- 1 mjones mjones 18 Jan 27 2011 /home/\nmaryjones/.bash_logout\n        262206 628 -rw-r--r-- 1 mjones mjones 640999 Jan 25 08:27 /\nhome/maryjones/services\n        262201 4 -rw-r--r-- 1 mjones mjones 124 Jan 27 2011 /home/\nmaryjones/.bashrc\n9. As the user mjones , you can use the following to create a file called /tmp/mary -\nfile.txt , and use ACLs to assign the bin  user read/write permission and the lp  \ngroup read/write permission to that file.\n        [mjones]$ touch /tmp/maryfile.txt\n        [mjones]$ setfacl -m u:bin:rw /tmp/maryfile.txt\n        [mjones]$ setfacl -m g:lp:rw /tmp/maryfile.txt\n        [mjones]$ getfacl /tmp/maryfile.txt\n        # file: tmp/maryfile.txt\n        # owner: mjones\n        # group: mjones\n        user::rw-\n        user:bin:rw-\n        group::rw-\n        group:lp:rw-\n        mask::rw-\n        other::r& \u2014", "doc_id": "721f0066-2b6a-4cd2-84d3-777a69dc4275", "embedding": null, "doc_hash": "f8cadd019bd1ab34ce1d450ccc9445878eef3fde3a31eccec6bcedaed952791a", "extra_info": {"page_label": "832"}, "node_info": {"start": 0, "end": 2083}, "relationships": {"1": "bf74a7d7-a4ee-4f6c-9b96-2a99c7f933f6"}}, "__type__": "1"}, "072f11c1-052d-459f-b45f-32e37d664ead": {"__data__": {"text": "Part VII: Appendixes81810. Run this set of commands (as mjones ) to create a directory named /tmp/mydir,  \nand use ACLs to assign default permissions to it so that the adm  user has read/\nwrite/execute permission to that directory and any files or directories created in it. \nTest that it worked by creating the /tmp/mydir/testing/  directory and /tmp/\nmydir/newfile.txt .\n        [mary]$ mkdir /tmp/mydir\n        [mary]$ setfacl -m d:u:adm:rwx /tmp/mydir\n        [mjones]$ getfacl /tmp/mydir\n        # file: tmp/mydir\n        # owner: mjones\n        # group: mjones\n        user::rwx\n        group::rwx\n        other::r-x\n        default:user::rwx\n        default:user:adm:rwx\n        default:group::rwx\n        default:mask::rwx\n        default:other::r-x\n        [mjones]$ mkdir /tmp/mydir/testing\n        [mjones]$ touch /tmp/mydir/newfile.txt\n        [mjones]$ getfacl /tmp/mydir/testing/\n        # file: tmp/mydir/testing/\n        # owner: mjones\n        # group: mjones\n        user::rwx\n        user:adm:rwx\n        group::rwx\n        mask::rwx\n        other::r-x\n        default:user::rwx\n        default:user:adm:rwx\n        default:group::rwx\n        default:mask::rwx\n        default:other::r-x\n        [mjones]$ getfacl /tmp/mydir/newfile.txt\n        # file: tmp/mydir/newfile.txt\n        # owner: mjones\n        # group: mjones\n        user::rw-\n        user:adm:rwx     #effective:rw-\n        group::rwx       #effective:rw-\n        mask::rw-\n        other::r--", "doc_id": "072f11c1-052d-459f-b45f-32e37d664ead", "embedding": null, "doc_hash": "ffe465bec5222b97904006d59df6e9d25071ad2e4163f81d081e02a719e0c887", "extra_info": {"page_label": "833"}, "node_info": {"start": 0, "end": 1476}, "relationships": {"1": "fc524ffb-6643-456e-a3ce-da9defa2b51c"}}, "__type__": "1"}, "9d61872e-852b-4c3a-9602-26775e1b10af": {"__data__": {"text": "Appendix B: Exercise Answers\nB819Notice that the adm  user effectively has only rw-  permission. To remedy that, you \nneed to expand the permissions of the mask. One way to do that is with the chmod  \ncommand, as follows:\n        [mjones]$ chmod 775 /tmp/mydir/newfile.txt\n        [mjones]$ getfacl /tmp/mydir/newfile.txt\n        # file: tmp/mydir/newfile.txt\n        # owner: mjones\n        # group: mjones\n        user::rwx\n        user:adm:rwx\n        group::rwx\n        mask::rwx\n        other::r-x\nChapter\u00a012: Managing Disks and Filesystems\n1. To determine the device name of a USB flash drive that you want to insert into \nyour computer, enter the following and insert the USB flash drive. (Press Ctrl+C \nafter you have seen the appropriate messages.)\n        # journalctl -f\n        kernel: [sdb] 15667200 512-byte logical blocks:\n             (8.02 GB/7.47 GiB)\n        Feb 11 21:55:59 cnegus kernel: sd 7:0:0:0:\n             [sdb] Write Protect is off\n        Feb 11 21:55:59 cnegus kernel: [sdb] Assuming\n             drive cache: write through\n        Feb 11 21:55:59 cnegus kernel: [sdb] Assuming\n             drive cache: write through\n2. To list partitions on the USB flash drive on a RHEL 6 system, enter the following:\n        # fdisk -c -u -l /dev/sdb\nTo list partitions on a RHEL 7, RHEL 8, or Fedora system, enter the following:\n        # fdisk -l /dev/sdb\n3. To delete partitions on the USB flash drive, assuming device /dev/sdb , do the \nfollowing:\n        # fdisk /dev/sdb\n        Command (m for help): d\n        Partition number (1-6): 6\n        Command (m for help): d\n        Partition number (1-5): 5\n        Command (m for help): d", "doc_id": "9d61872e-852b-4c3a-9602-26775e1b10af", "embedding": null, "doc_hash": "6b7f3781a5747bff52bf9ab17920275f88126faf3142b69e32d932cfd1e6b071", "extra_info": {"page_label": "834"}, "node_info": {"start": 0, "end": 1658}, "relationships": {"1": "6112b130-97de-479f-a591-cad320bdb332"}}, "__type__": "1"}, "1fa86231-e9e9-44ad-909b-975ca71145ea": {"__data__": {"text": "Part VII: Appendixes820        Partition number (1-5): 4\n        Command (m for help): d\n        Partition number (1-4): 3\n        Command (m for help): d\n        Partition number (1-4): 2\n        Command (m for help): d\n        Selected partition 1\n        Command (m for help): w\n        # partprobe /dev/sdb\n4. To add a 100MB Linux partition, 200MB swap partition, and 500MB LVM partition to \nthe USB flash drive, enter the following:\n        # fdisk /dev/sdb\n \n        Command (m for help): n\n        Command action\n           e   extended\n           p   primary partition (1-4)\n        p\n        Partition number (1-4): 1\n        First sector (2048-15667199, default 2048):  <ENTER>\n        Last sector, +sectors or +size{K,M,G} (default 15667199): +100M\n        Command (m for help): n\n        Command action\n           e   extended\n           p   primary partition (1-4)\n        p\n        Partition number (1-4): 2\n        First sector (616448-8342527, default 616448):  <ENTER>\n        Last sector, +sectors or +size{K,M,G} (default 15667199): +200M\n        Command (m for help): n\n        Command action\n           e   extended\n           p   primary partition (1-4)\n        p\n        Partition number (1-4): 3\n        First sector (616448-15667199, default 616448):  <ENTER>\n        Using default value 616448\n        Last sector, +sectors or +size{K,M,G} (default 15667199): +500M\n        Command (m for help): t\n        Partition number (1-4): 2\n        Hex code (type L to list codes): 82\n        Changed system type of partition 2 to 82 (Linux swap / Solaris)\n        Command (m for help): t\n        Partition number (1-4): 3\n        Hex code (type L to list codes): 8e\n        Changed system type of partition 3 to 8e (Linux LVM)", "doc_id": "1fa86231-e9e9-44ad-909b-975ca71145ea", "embedding": null, "doc_hash": "db496ea81e00569cc21518ced8979df989367a1355d0dc2e408fb3019e8aa26a", "extra_info": {"page_label": "835"}, "node_info": {"start": 0, "end": 1744}, "relationships": {"1": "de1fe382-3a35-441d-91c0-1f3ead489f21"}}, "__type__": "1"}, "38de855c-7a09-4c32-8715-0284d8052273": {"__data__": {"text": "Appendix B: Exercise Answers\nB821        Command (m for help): w\n        # partprobe /dev/sdb\n        # grep sdb /proc/partitions\n           8       16    7833600 sdb\n           8       17     102400 sdb1\n           8       18     204800 sdb2\n           8       19     512000 sdb3\n5. To put an ext4 filesystem on the Linux partition, enter the following:\n        # mkfs -t ext4 /dev/sdb1\n6. To create a mount point called /mnt/mypart  and mount the Linux partition on it, \ndo the following:\n        # mkdir /mnt/mypart\n        # mount -t ext4 /dev/sdb1 /mnt/mypart\n7. To enable the swap partition and turn it on so that additional swap space is imme -\ndiately available, enter the following:\n        # mkswap /dev/sdb2\n        # swapon /dev/sdb2\n8. To create a volume group called abc  from the LVM partition, create a 200MB logi-\ncal volume from that group called data , create a VFAT filesystem on it, temporarily \nmount the logical volume on a new directory named /mnt/test , and then check \nthat it was successfully mounted, enter the following:\n        # pvcreate /dev/sdb3\n        # vgcreate abc /dev/sdb3\n        # lvcreate -n data -L 200M abc\n        # mkfs -t vfat /dev/mapper/abc-data\n        # mkdir /mnt/test\n        # mount /dev/mapper/abc-data /mnt/test\n9. To grow the logical volume from 200MB to 300MB, enter the following:\n        # lvextend -L +100M /dev/mapper/abc-data\n        # resize2fs -p /dev/mapper/abc-data\n10. To remove the USB flash drive safely from the computer, do the following:\n        # umount /dev/sdb1\n        # swapoff /dev/sdb2\n        # umount /mnt/test\n        # lvremove /dev/mapper/abc-data\n        # vgremove abc\n        # pvremove /dev/sdb3\nYou can now safely remove the USB flash drive from the computer.", "doc_id": "38de855c-7a09-4c32-8715-0284d8052273", "embedding": null, "doc_hash": "72a900d90fc2d24e457a8706db82fca4ae303e87bca2eb1d714139c42e347862", "extra_info": {"page_label": "836"}, "node_info": {"start": 0, "end": 1749}, "relationships": {"1": "f5165019-a891-4a31-85d3-824f68533eb9"}}, "__type__": "1"}, "aeabcbe8-72fe-4356-918a-beeaa7f8fd30": {"__data__": {"text": "Part VII: Appendixes822Chapter\u00a013: Understanding Server Administration\n1. To log in to any account on another computer using the ssh  command, enter the \nfollowing and then enter the password when prompted:\n        $ ssh joe@localhost\n        joe@localhost's password:\n        *********\n        [joe]$\n2. To display the contents of a remote /etc/system-release  file and have its \ncontents displayed on the local system using remote execution with the ssh  \ncommand, do the following:\n        $ ssh joe@localhost \"cat /etc/system-release\"\n        joe@localhost's password: *******\n        Fedora release 30 (Thirty)\n3. To use X11 forwarding to display a gedit window on your local system and then \nsave a file on the remote home directory, do the following:\n        $ ssh -X joe@localhost \"gedit newfile\"\n        joe@localhost's password: ********\n        $ ssh joe@localhost \"cat newfile\"\n        joe@localhost's password: ********\n        This is text from the file I saved in joe's remote home \ndirectory\n4. To copy all of the files from the /usr/share/selinux  directory recursively on a \nremote system to the /tmp  directory on your local system in such a way that all \nof the modification times on the files are updated to the time on the local system \nwhen they are copied, do the following:\n        $ scp -r joe@localhost:/usr/share/selinux /tmp\n        joe@localhost's password:\n         ********\n        irc.pp.bz2                          100% 9673     9.5KB/s   00:00\n        dcc.pp.bz2                          100%   15KB  15.2KB/s   00:01\n        $ ls -l /tmp/selinux | head\n        total 20\n        drwxr-xr-x. 3 root root  4096 Apr 18 05:52 devel\n        drwxr-xr-x. 2 root root  4096 Apr 18 05:52 packages\n        drwxr-xr-x. 2 root root 12288 Apr 18 05:52 targeted\n5. To copy all of the files from the /usr/share/logwatch  directory recursively on a \nremote system to the /tmp  directory on your local system in such a way that all of \nthe modification times on the files from the remote system are maintained on the \nlocal system, try the following:\n        $ rsync -av joe@localhost:/usr/share/logwatch /tmp\n        joe@localhost's password: ********", "doc_id": "aeabcbe8-72fe-4356-918a-beeaa7f8fd30", "embedding": null, "doc_hash": "2e4cffbc8ff8a9bd232ac207b358c14bfeb8dd92c2cdc89a932c5ea81c4ff592", "extra_info": {"page_label": "837"}, "node_info": {"start": 0, "end": 2171}, "relationships": {"1": "cddfd9d5-f1ef-43e6-8cc7-4bb21f4d2d81"}}, "__type__": "1"}, "21142c1d-cfcf-4ae4-b2f4-4612bca3c454": {"__data__": {"text": "Appendix B: Exercise Answers\nB823        receiving incremental file list\n        logwatch/\n        logwatch/default.conf/\n        logwatch/default.conf/logwatch.conf\n        $ ls -l /tmp/logwatch | head\n        total 16\n        drwxr-xr-x. 5 root root 4096 Apr 19  2011 default.conf\n        drwxr-xr-x. 4 root root 4096 Feb 28  2011 dist.conf\n        drwxr-xr-x. 2 root root 4096 Apr 19  2011 lib\n6. To create a public/private key pair to use for SSH communications (no passphrase \non the key), copy the public key file to a remote user\u2019s account with ssh-copy-id , \nand use key-based authentication to log in to that user account without having to \nenter a password, use the following code:\n        $ ssh-keygen\n        Generating public/private rsa key pair.\n        Enter file in which to save the key (/home/joe/.ssh/id_\nrsa): ENTER\n        /home/joe/.ssh/id_rsa already exists.\n        Enter passphrase (empty for no passphrase):  ENTER\n        Enter same passphrase again:  ENTER\n        Your identification has been saved in /home/joe/.ssh/id_\nrsa.\n        Your public key has been saved in /home/joe/.ssh/id_rsa.\npub.\n        The key fingerprint is:\n        58:ab:c1:95:b6:10:7a:aa:7c:c5:ab:bd:f3:4f:89:1e joe@cnegus.\ncsb\n        The key's randomart image is:\n        ...\n        $ ssh-copy-id -i ~/.ssh/id_rsa.pub joe@localhost\n        joe@localhost's password: ********\n        Now try logging into the machine, with \"ssh 'joe@\nlocalhost'\",\n        and check in:\n        .ssh/authorized_keys\n        to make sure we haven't added extra keys that you weren't \nexpecting.\n        $ ssh joe@localhost\n        $ cat .ssh/authorized_keys\n        ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAyN2Psp5/\nLRUC9E8BDCx53yPUa0qoOPd\n        \nv6H4sF3vmn04V6E7D1iXpzwPzdo4rpvmR1ZiinHR2xGAEr2uZag7feKgLnww2KPcQ6S\n        iR7lzrOhQjV+SGb/a1dxrIeZqKMq1Tk07G4EvboIrq//9J47vI4l7iNu0x\nRmjI3TTxa\n        DdCTbpG6J3uSJm1BKzdUtwb413x35W2bRgMI75aIdeBsDgQBBiOdu+zuTM\nrXJj2viCA", "doc_id": "21142c1d-cfcf-4ae4-b2f4-4612bca3c454", "embedding": null, "doc_hash": "e1a02baf2bed8e8c0b0000e4ca4c5966d73a9608c466a832ab28b331554c7d96", "extra_info": {"page_label": "838"}, "node_info": {"start": 0, "end": 1950}, "relationships": {"1": "881e6be6-f8b3-498e-a977-e5cc27879c35"}}, "__type__": "1"}, "545857f2-f41e-493b-87dc-df30185c726b": {"__data__": {"text": "Part VII: Appendixes824        XeJ7gIwRvBaMQdOSvSdlkX353tmIjmJheWdgCccM/1jKdoELpaevg9anCe/\nyUP3so31\n        tTo4I+qTfzAQD5+66oqW0LgMkWVvfZI7dUz3WUPmcMw== chris@abc.\nexample.com\n7. To create an entry in /etc/rsyslog.conf  that stores all authentication messages \nat the info level and higher into a file named /var/log/myauth , do the follow -\ning. Watch from one terminal as the data comes in.\n        # vim /etc/rsyslog.conf\n        authpriv.info                             /var/log/myauth\n        # service rsyslog restart\n             or\n        # systemctl restart rsyslog.service\n        <Terminal 1>                             <Terminal 2>\n        # tail -f /var/log/myauth                $ ssh joe@\nlocalhost\n        Apr 18 06:19:34 abc unix_chkpwd[30631]   joe@localhost's \npassword:\n        Apr 18 06:19:34 abc sshd[30631]          Permission \ndenied,try again\n         :pam_unix(sshd:auth):\n         authentication failure;logname= uid=501\n         euid=501 tty=ssh ruser= rhost=localhost\n         user=joe\n        Apr 18 06:19:34 abc sshd[30631]:\n         Failed password for joe from\n         127.0.0.1 port 5564 ssh2\n8. To determine the largest directory structures under /usr/share , sort them from \nlargest to smallest, and list the top 10 of those directories in terms of size using \nthe du  command, enter the following:\n        $ du -s /usr/share/* | sort -rn | head\n        527800 /usr/share/locale\n        277108 /usr/share/fonts\n        196232 /usr/share/help\n \n        134984 /usr/share/backgrounds\n        ...\n9. To show the space that is used and available from all of the filesystems currently \nattached to the local system, but exclude any tmpfs  or devtmpfs  filesystems by \nusing the df  command, enter the following:\n        $ df -h -x tmpfs -x devtmpfs\n        Filesystem      Size  Used Avail Use% Mounted on\n        /deev/sda4       20G  4.2G 16G    22% /", "doc_id": "545857f2-f41e-493b-87dc-df30185c726b", "embedding": null, "doc_hash": "3ac1a24180ab273ace0f852f916ef475d9e00319d942498aed4a25b884c1993c", "extra_info": {"page_label": "839"}, "node_info": {"start": 0, "end": 1889}, "relationships": {"1": "487f46c1-e72e-457d-b89b-6f51f231071a"}}, "__type__": "1"}, "d9faf2bf-e266-4260-a896-606d1fde1a1a": {"__data__": {"text": "Appendix B: Exercise Answers\nB82510. To find any files in the /usr  directory that are more than 10MB in size, do the \nfollowing:\n        $ find /usr -size +10M\n        /usr/lib/locale/locale-archive\n        /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.212.b04-0.fc30.\nx86_64/jre/lib/rt.jar\n        /usr/libexec/cni/dhcp\n        /usr/libexec/gdb\n        /usr/libexec/gcc/x86_64-redhat-linux/9/lto1\n        /usr/libexec/gcc/x86_64-redhat-linux/9/cc1\nChapter\u00a014: Administering Networking\n1. To use the desktop to check that NetworkManager has successfully started your \nnetwork interface (wired or wireless), do the following:\na. Left-click the upper-right corner of your GNOME desktop to see the drop-down \nmenu. Any active wired or wireless network connections should appear on \nthat menu.\nb. If it has not connected to the network, select from the list of wired or wireless \nnetworks available, and then enter the username and password, if prompted, to \nstart an active connection.\n2. To run a command to check the active network interfaces available on your com-\nputer, enter the following:\n        $ ifconfig\nor\n        $ ip addr show\n3. Try to contact google.com  from the command line in a way that ensures that DNS \nis working properly:\n        $ ping google.com\n        Ctrl-C\n4. To run a command to check the routes being used to communicate outside of your \nlocal network, enter the following:\n        $ route\n5. To trace the route being taken to connect to google.com , use the tracer -\noute  command:\n        $ traceroute google.com\n6. To view the network interfaces and related network activities for your Linux system \nthrough Cockpit, open a web browser to port 9090 using an IP address or hostname. \nFor example: https://localhost:9090/network .", "doc_id": "d9faf2bf-e266-4260-a896-606d1fde1a1a", "embedding": null, "doc_hash": "6dd798eb66bf84ec70fc5b378f14ec99ae15bd032839cceff939ac2a17e9238f", "extra_info": {"page_label": "840"}, "node_info": {"start": 0, "end": 1753}, "relationships": {"1": "eb0140fb-3068-4780-8010-4c8afc3938d6"}}, "__type__": "1"}, "054f6bee-dd7e-4fd9-8edb-e5a07cefa5bd": {"__data__": {"text": "Part VII: Appendixes8267. To create a host entry that allows you to communicate with your local host system \nusing the name myownhost , edit the /etc/hosts  file (vi /etc/hosts ), and \nadd myownhost  to the end of the localhost entry so that it appears as follows \n(then ping myownhost  to see if it worked):\n        127.0.0.1        localhost.localdomain localhost myownhost\n        # ping myownhost\n        Ctrl+C\n8. To see the DNS name servers being used to resolve hostnames and IP addresses on \nyour system (yours will be different than those shown below), enter the following:\n \n# cat /etc/resolv.conf\n        nameserver 10.83.14.9\n        nameserver 10.18.2.10\n        nameserver 192.168.1.254\n        # dig google.com\n        ...\n        google.com.     91941   IN     NS     ns3.google.com.\n        ;; Query time: 0 msec\n        ;; SERVER: 10.18.2.9#53(10.18.2.9)\n        ;; WHEN: Sat Nov 23 20:18:56 EST 2019\n        ;; MSG SIZE  rcvd: 276\n9. To create a custom route that directs traffic destined for the \n192.168.99.0/255.255.255.0 network to some IP address on your local network, such \nas 192.168.0.5 (first ensuring that the 192.168.99 network is not being used at your \nlocation), do the following:\na. Determine the name of your network interface, for example enp4s0 . In that \ncase, as root run the following commands:\n        # cd /etc/sysconfig/network-scripts\n        # vi route-enp4s0\nb. Add the following lines to that file:\n        ADDRESS0=192.168.99.0\n        NETMASK0=255.255.255.0\n        GATEWAY0=192.168.0.5\nc. Restart networking and run route  to see that the route is active:\n        # systemctl restart NetworkManager\n        # route -n\n        Kernel IP routing table\n        Destination   Gateway       Genmask        Flags Metric \nRef Use Iface\n        192.168.0.1   0.0.0.0       255.255.255.0  U     600    \n0     0 enp4s0", "doc_id": "054f6bee-dd7e-4fd9-8edb-e5a07cefa5bd", "embedding": null, "doc_hash": "0e10baad524db2edbd67bee0a3f3a87927d2f3f7ef25fe5ad86eef79c6fae882", "extra_info": {"page_label": "841"}, "node_info": {"start": 0, "end": 1859}, "relationships": {"1": "b2dfe512-d151-4b39-b0ea-92be8970464e"}}, "__type__": "1"}, "2e45eb78-370e-4d14-b067-f102b9aab50f": {"__data__": {"text": "Appendix B: Exercise Answers\nB827        192.168.99.0  192.168.0.5   255.255.255.0  UG    600    \n0     0 enp4s0\n10. To check to see if your system has been configured to allow IPv4 packets to be \nrouted between network interfaces on your system, enter the following:\n        # cat /proc/sys/net/ipv4/ip_forward\n        0\nA 0 shows that IPv4 packet forwarding is disabled; a 1 shows that it is enabled.\nChapter\u00a015: Starting and Stopping Services\n1. To determine which initialization daemon your server is currently using, consider \nthe following:\na. In most cases today, PID 1 appears as the systemd  daemon:\n        # ps -ef | head\n        UID        PID  PPID  C STIME TTY          TIME CMD\n        root         1     0  0 17:01 ?        00:00:04 /usr/\nlib/systemd/systemd --\n             switched-root --system --deserialize 18\nIf you type ps -ef  and PID 1 is init , it still might be the systemd  daemon. \nUse the strings  command to see if systemd  is in use:\n        # strings /sbin/init | grep -i systemd\n        systemd.unit=\n        systemd.log_target=\n        systemd.log_level=\n        ...\nb. Most likely, you have the Upstart, SysVinit, or BSD init  daemon if your init  \ndaemon is not systemd . But double-check at http://wikipedia.org/wiki/Init .\n2. The tools you use to manage services depend primarily on which initialization \nsystem is in use. Try to run the systemctl  and service  commands to determine \nthe type of initialization script in use for the ssh  service on your system:\na. For systemd , a positive result, shown here, means that the sshd  has been \nconverted to systemd :\n        # systemctl status sshd.service\n        sshd.service - OpenSSH server daemon\n          Loaded: loaded (/lib/systemd/system/sshd.service; \nenabled)\n          Active: active (running) since Mon, 20 Apr 2020 \n12:35:20...\nb. If you don\u2019t see positive results for the preceding test, try the following \ncommand for the SysVinit init  daemon. A positive result here, along with ", "doc_id": "2e45eb78-370e-4d14-b067-f102b9aab50f", "embedding": null, "doc_hash": "081b8941009c9ebdd76f3855442fb221fe431c35d53b3dd1682bd7e1b151dbf4", "extra_info": {"page_label": "842"}, "node_info": {"start": 0, "end": 1984}, "relationships": {"1": "e0e63502-7f30-4614-8536-d3c58f97fc4c"}}, "__type__": "1"}, "6b21463d-93b6-4f4a-9305-5963bc2584cc": {"__data__": {"text": "Part VII: Appendixes828negative results for the preceding tests, means that sshd  is still using the \nSysVinit  daemon.\n        # service ssh status\n        sshd (pid 2390) is running...\n3. To determine your server\u2019 previous and current runlevel, use the runlevel  \ncommand. It still works on all init  daemons:\n        $ runlevel\n        N 3\n4. To change the default runlevel or target unit on your Linux server, you can do one \nof the following (depending upon your server\u2019s init  daemon):\na. For SysVinit, edit the file /etc/inittab  and change the # in the line \nid:#:initdefault:  to 2, 3, 4, or 5 .\nb. For systemd , change the default.target  to the desired runlevel #.tar-\nget, where # is 2 , 3, 4, or 5 . The following shows you how to change the target \nunit to runlevel3.target .\n        # systemctl set-default runlevel3.target\n        Removed /etc/systemd/system/default.target.\n        Created symlink /etc/systemd/system/default.target \u2192\n           /usr/lib/systemd/system/multi-user.target.\n5. To list out services running (or active) on your server, you need to use different \ncommands, depending upon the initialization daemon you are using.\na. For SysVinit, use the service  command as shown in this example:\n        # service --status-all | grep running | sort\n        anacron (pid 2162) is running...\n        atd (pid 2172) is running...\nb. For systemd , use the systemctl  command, as follows:\n        # systemctl list-unit-files --type=service | grep -v disabled\n        UNIT FILE                                   STATE\n        abrt-ccpp.service                           enabled\n        abrt-oops.service                           enabled\n        ...\n6. To list out the running (or active) services on your Linux server, use the appropri-\nate command(s) determined in answer 5 for the initialization daemon that your \nserver is using.\n7. For each initialization daemon, the following command(s) show a particular  \nservice\u2019s current status:\na. For SysVinit, the service  service_name status  command is used.\nb. For systemd , the systemctl status  service_name command is used.", "doc_id": "6b21463d-93b6-4f4a-9305-5963bc2584cc", "embedding": null, "doc_hash": "5fd7c2c43deec2f80f582bf526f697beb3f081012ee821902494561e79129da7", "extra_info": {"page_label": "843"}, "node_info": {"start": 0, "end": 2101}, "relationships": {"1": "19e28945-f05a-4405-8b64-989217737940"}}, "__type__": "1"}, "f6eb2aef-b06e-4c86-a8c7-2df6bb86c49b": {"__data__": {"text": "Appendix B: Exercise Answers\nB8298. To show the status of the cups  daemon on your Linux server, use the following:\na. For the SysVinit:\n        # service cups status\n        cupsd (pid 8236) is running...\nb. For systemd :\n        # systemctl status cups.service\n        cups.service - CUPS Printing Service\n        Loaded: loaded (/lib/systemd/system/cups.service; enabled)\n        Active: active (running) since Tue, 05 May 2020 04:43:5...\n        Main PID: 17003 (cupsd)\n        CGroup: name=systemd:/system/cups.service\n        17003 /usr/sbin/cupsd -f\n9. To attempt to restart the cups  daemon on your Linux server, use the following:\na. For SysVinit:\n        # service cups restart\n        Stopping cups:          [  OK  ]\nb. For systemd :\n        # systemctl restart cups.service\n10. To attempt to reload the cups  daemon on your Linux server, use the following:\na. For SysVinit:\n        # service cups reload\n        Reloading cups: [ OK ]\nb. For systemd , this is a trick question. You cannot reload the cups  daemon on a \nsystemd  Linux server!\n        # systemctl reload cups.service\n        Failed to issue method call: Job type reload is\n          not applicable for unit cups.service.\nChapter\u00a016: Configuring a Print Server\nFor questions that involve working with printers, you can use either graphical or command-\nline tools in most cases. The point is to make sure that you get the correct results, shown \nin the answers that follow. The answers here include a mix of graphical and command-line \nways of solving the exercises. (Become root user when you see a # prompt.)\n1. To use the Print Settings window to add a new printer called myprinter  to your \nsystem (generic PostScript printer, connected to a port), do the following from \nFedora 30:\na. Install the system-config-printer package:\n        # dnf install system-config-printer", "doc_id": "f6eb2aef-b06e-4c86-a8c7-2df6bb86c49b", "embedding": null, "doc_hash": "258f4fa34c549c3fbef99dfdcf653ade6f17197d60e97877a0bf271419f4d1ce", "extra_info": {"page_label": "844"}, "node_info": {"start": 0, "end": 1852}, "relationships": {"1": "90c81b4b-4258-4229-83d4-bbde0370722d"}}, "__type__": "1"}, "c65c1b32-2885-45d3-9467-892377aad75a": {"__data__": {"text": "Part VII: Appendixes830b. From the GNOME 3 desktop, select Print Settings from the Activities screen.\nc. Unlock the interface and enter the root password.\nd. Select the Add button.\ne. Select a USB or other port as the device and click Forward.\nf. For the driver, choose Generic and click Forward; then choose PostScript and \nclick Forward.\ng. Click Forward to skip any installable options, if needed.\nh. For the printer name, call it myprinter , give it any description and location \nyou like, and click Apply.\ni. Click Cancel in order not to print a test page. The printer should appear in the \nPrint Settings window.\n2. To use the lpstat -t  command to see the status of all of your printers, enter the \nfollowing:\n        # lpstat -t\n        deskjet-5550 accepting requests since Mon 02 Mar 2020 \n07:30:03 PM EST\n3. To use the lpr  command to print the /etc/hosts  file, enter the following:\n        $ lp /etc/hosts -P myprinter\n4. To check the print queue for that printer, enter the following:\n        # lpq -P myprinter\n        myprinter is not ready\n        Rank    Owner   Job     File(s)             Total Size\n        1st     root    655     hosts               1024 bytes\n5. To remove the print job from the queue (cancel it), enter the following.\n        # lprm -P myprinter\n6. To use the printing window to set the basic server setting that publishes your \nprinters so that other systems on your local network can print to your printers, do \nthe following:\na. On a GNOME 3 desktop, from the Activities screen, type Print Settings  and \npress Enter.\nb. Select Server \u27aa Settings and type the root password if prompted.\nc. Click the check box next to \u201cPublish shared printers connected to this system\u201d \nand click OK.", "doc_id": "c65c1b32-2885-45d3-9467-892377aad75a", "embedding": null, "doc_hash": "c9938b1fc838acd79f14f51ba5b92c071e247ef07fb4477b5eb83c8b9a575750", "extra_info": {"page_label": "845"}, "node_info": {"start": 0, "end": 1726}, "relationships": {"1": "2740fd29-d190-422d-9f73-7eb625649d25"}}, "__type__": "1"}, "bafb48b8-08ff-43ec-be6f-95a1bb58f15e": {"__data__": {"text": "Appendix B: Exercise Answers\nB8317. To allow remote administration of your system from a web browser, follow \nthese steps:\na. On a GNOME 3 desktop, from the Activities screen, type Print Settings , and \npress Enter.\nb. Select Server \u27aa Settings and type the root password if prompted.\nc. Click the check box next to \u201cAllow remote administration\u201d and click OK.\n8. To demonstrate that you can do remote administration of your system from a web \nbrowser on another system, do the following:\na. In the location box from a browser window from another computer on your net -\nwork, enter the following, replacing hostname  with the name or IP address of \nthe system running your print service: http:// hostname :631.\nb. Type root  as the user and the root password, when prompted. The CUPS home \npage should appear from that system.\n9. To use the netstat  command to see on which addresses the cupsd  daemon is lis -\ntening, enter the following:\n        # netstat -tupln | grep 631\n        tcp    0    0 0.0.0.0:631      0.0.0.0:*      LISTEN    6492/cupsd\n        tcp6   0    0 :::631           :::*           LISTEN    6492/cupsd\n10. To delete the myprinter  printer entry from your system, do the following:\na. Click the Unlock button and type the root password when prompted.\nb. From the Print Settings window, right-click the myprinter  icon and \nselect Delete.\nc. When prompted, select Delete again.\nChapter\u00a017: Configuring a Web Server\n1. To install all of the packages associated with the Web Server group on a Fedora \nsystem, do the following:\n        # yum groupinstall \"Web Server\"\n2. To create a file called index.html  in the directory assigned to DocumentRoot  in \nthe main Apache configuration file (with the words \u201cMy Own Web Server\u201d inside), \ndo the following:\na. Determine the location of DocumentRoot :\n        # grep ^DocumentRoot /etc/httpd/conf/httpd.conf\n \n        DocumentRoot \"/var/www/html\"", "doc_id": "bafb48b8-08ff-43ec-be6f-95a1bb58f15e", "embedding": null, "doc_hash": "99808ff2a5227638a2fbae1d30e72567d2b2489dc272439ddf938af63a9be283", "extra_info": {"page_label": "846"}, "node_info": {"start": 0, "end": 1908}, "relationships": {"1": "1841f743-8a20-49a9-b10a-f5acd89775ce"}}, "__type__": "1"}, "e6a76465-a51c-4132-bcc2-9420ebbc8629": {"__data__": {"text": "Part VII: Appendixes832b. Echo the words \u201cMy Own Web Server\u201d into the index.html  file located in \nDocumentRoot :\n        # echo \"My Own Web Server\" > /var/www/html/index.html\n3. To start the Apache web server and set it to start up automatically at boot time, \nthen check that it is available from a web browser on your local host, do the fol -\nlowing. (You should see the words \u201cMy Own Web Server\u201d displayed if it is working \nproperly.)\nThe httpd  service is started and enabled differently on different Linux systems. In \nrecent Fedora 30 or RHEL 7 or 8, enter the following:\n        # systemctl start httpd.service\n        # systemctl enable httpd.service\nIn RHEL 6 or earlier, enter the following:\n        # service httpd start\n        # chkconfig httpd on\n4. To use the netstat  command to see on which ports the httpd  server is listening, \nenter the following:\n        # netstat -tupln | grep httpd\n        tcp6     0   0 :::80      :::*    LISTEN   2496/httpd\n        tcp6     0   0 :::443     :::*    LISTEN   2496/httpd\n5. Try to connect to your Apache web server from a web browser that is outside of the \nlocal system. If it fails, correct any problems that you encounter by investigating \nthe firewall, SELinux, and other security features.\nIf you don\u2019t have DNS set up yet, use the IP address of the server to view your \nApache server from a remote web browser, such as http://192.168.0.1 . If you \nare not able to connect, retry connecting to the server from your browser after \nperforming each of the following steps on the system running the Apache server:\n        # iptables -F\n        # setenforce 0\n        # chmod 644 /var/www/html/index.html\nThe iptables -F  command flushes the firewall rules temporarily. If connecting to \nthe web server succeeds after that, you need to add new firewall rules to open tcp  \nports 80 and 443 on the server. On a system using the firewalld  service, do this \nby clicking the check box next to those ports on the Firewall window. For systems \nrunning the iptables  service, add the following rules before the last DROP  or \nREJECT  rule.\n        -A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j \nACCEPT\n        -A INPUT -m state --state NEW -m tcp -p tcp --dport 443 -j \nACCEPT", "doc_id": "e6a76465-a51c-4132-bcc2-9420ebbc8629", "embedding": null, "doc_hash": "d01a3f0a12c102051896e871c520583f5b024d9acc0d8bd93cf61f5fd10163c8", "extra_info": {"page_label": "847"}, "node_info": {"start": 0, "end": 2242}, "relationships": {"1": "66c2e118-111a-4834-8015-e93879f9adfb"}}, "__type__": "1"}, "e3be5459-f28b-4169-8cc1-be3bc3c42085": {"__data__": {"text": "Appendix B: Exercise Answers\nB833The setenforce 0  command puts SELinux in permissive mode temporarily. If \nconnecting to the web server succeeds after that, you need to correct SELinux file \ncontext and/or Boolean issues (probably file context in this case). The following \nshould work:\n        # chcon --reference=/var/www/html /var/www/html/index.html\nIf the chmod  command works, it means that the Apache user and group did not \nhave read permission to the file. You should be able to leave the new permissions \nas they are.\n6. To use the openssl  or similar command to create your own private RSA key and \nself-signed SSL certificate, do the following:\n        # yum install openssl\n        # cd /etc/pki/tls/private\n        # openssl genrsa -out server.key 1024\n        # chmod 600 server.key\n        # cd /etc/pki/tls/certs\n        # openssl req -new -x509 -nodes -sha1 -days 365 \\\n           -key /etc/pki/tls/private/server.key \\\n           -out server.crt\n        Country Name (2 letter code) [AU]: US\n        State or Province Name (full name) [Some-State]: NJ\n        Locality Name (eg, city) []: Princeton\n        Organization Name (eg, company) [Internet Widgits Pty\n        Ltd]:TEST USE ONLY\n        Organizational Unit Name (eg, section) []:TEST USE ONLY\n        Common Name (eg, YOUR name) []:secure.example.org\n        Email Address []:dom@example.org\nYou should now have a /etc/pki/tls/private/server.key  key file and a /\netc/pki/tls/certs/server.crt  certificate file.\n7. To configure your Apache web server to use your key and self-signed certificate to \nserve secure (HTTPS) content, do the following:\na. Edit the /etc/httpd/conf.d/ssl.conf  file to change the key and certificate \nlocations to use the ones that you just created:\n        SSLCertificateFile /etc/pki/tls/certs/server.crt\n        SSLCertificateKeyFile /etc/pki/tls/private/server.key\nb. Restart the httpd service:\n        # systemctl restart httpd.service\n8. To use a web browser to create an HTTPS connection to your web server and view \nthe contents of the certificate that you created, do the following:", "doc_id": "e3be5459-f28b-4169-8cc1-be3bc3c42085", "embedding": null, "doc_hash": "80b61a670e45572d9fbe55873d28a1d794b4fb6f1a6f1370d9ed649d128125da", "extra_info": {"page_label": "848"}, "node_info": {"start": 0, "end": 2096}, "relationships": {"1": "82bffdbd-d832-40b0-8b80-1720befb4cd6"}}, "__type__": "1"}, "a0229611-9fff-477f-acf4-e1962cba5ef9": {"__data__": {"text": "Part VII: Appendixes834From the system running the Apache server, type https://localhost  in the \nbrowser\u2019s location box. You should see a message that reads, \u201cThis Connection is \nUntrusted.\u201d To complete the connection, do the following:\na. Click I Understand the Risks.\nb. Click Add Exception.\nc. Click Get Certificate.\nd. Click Confirm Security Exception.\n9. To create a file named /etc/httpd/conf.d/example.org.conf , which turns on \nname-based virtual hosting and creates a virtual host that (1) listens on port 80 on \nall interfaces, (2) has a server administrator of joe@example.org , (3) has a server \nname of joe.example.org , (4) has a DocumentRoot  of /var/www/html/joe.\nexample.org , and (5) has a DirectoryIndex  that includes at least index.\nhtml  and then create an index.html  file in DocumentRoot  that contains the \nwords \u201cWelcome to the House of Joe\u201d inside, do the following.\nCreate an example.org.conf  file that looks like the following:\n        NameVirtualHost *:80\n        <VirtualHost *:80>\n            ServerAdmin     joe@\n        example.org\n            ServerName      joe.\n        example.org\n            ServerAlias     web.example.org\n            DocumentRoot    /var/www/html/joe.example.org/\n            DirectoryIndex  index.html\n        </VirtualHost>\nThis is how you could create the text to go into the index.html  file:\n        # echo \"Welcome to the House of Joe\" > \\\n             /var/www/html/joe.example.org/index.html\n10. To add the text joe.example.org  to the end of the localhost entry in your /etc/\nhosts  file on the machine that is running the web server, and check it by typing \nhttp://joe.example.org  into the location box of your web browser to see \u201cWel -\ncome to the House of Joe\u201d when the page is displayed, do the following:\na. Reload the httpd.conf  file modified in the previous exercise in one \nof two ways:\n        # apachectl graceful\n        # systemctl restart httpd", "doc_id": "a0229611-9fff-477f-acf4-e1962cba5ef9", "embedding": null, "doc_hash": "347fded493f019ebddc7867d2801b48c045ac12c30d0261c32aa872f0431d06c", "extra_info": {"page_label": "849"}, "node_info": {"start": 0, "end": 1928}, "relationships": {"1": "7a8d7a00-4781-462d-a8dd-f3b22e4c8070"}}, "__type__": "1"}, "fcd7a00c-f64a-4b94-a90e-31cd52c6e5c3": {"__data__": {"text": "Appendix B: Exercise Answers\nB835b. Edit the /etc/hosts  file with any text editor, so the local host line appears \nas follows:\n        127.0.0.1      localhost.localdomain localhost joe.\nexample.org\nc. From a browser on the local system where httpd  is running, you should be able \nto type http://joe.example.org  into the location box to access the Apache \nweb server using name-based authentication.\nChapter\u00a018: Configuring an FTP Server\nCautio N\nDon\u2019t do the tasks described here on a working, public FTP server, because these tasks will interfere with its opera -\ntions. (You could, however, use these tasks to set up a new FTP server.)\n1. To determine which package provides the Very Secure FTP Daemon service, enter \nthe following as root:\n        # yum search \"Very Secure FTP\"\n        ...\n        ================ N/S Matched: Very Secure FTP ============\n        vsftpd.i686 : Very Secure Ftp Daemon\nThe search found the vsftpd  package.\n2. To install the Very Secure FTP Daemon package on your system and search for the \nconfiguration files in the vsftpd  package, enter the following:\n        # yum install vsftpd\n        # rpm -qc vsftpd | less\n3. To enable anonymous FTP and disable local user login for the Very Secure FTP \nDaemon service, set the following in the /etc/vsftpd/vsftpd.conf  file:\n        anonymous_enable=YES\n        write_enable=YES\n        anon_upload_enable=YES\n        local_enable=NO\n4. To start the Very Secure FTP Daemon service and set it to start when the system \nboots, enter the following on a current Fedora or Red Hat Enterprise Linux system:\n        # systemctl start vsftpd.service\n        # systemctl enable vsftpd.service", "doc_id": "fcd7a00c-f64a-4b94-a90e-31cd52c6e5c3", "embedding": null, "doc_hash": "e7c89bb81a1d599320f52cbd37fc7d05e6240ed9ef4b64ad646f39c59511ad69", "extra_info": {"page_label": "850"}, "node_info": {"start": 0, "end": 1669}, "relationships": {"1": "180b6bb5-650a-44fb-9942-ca0e269a7209"}}, "__type__": "1"}, "0c69d54c-a254-4aa0-9969-68a4a4c112f5": {"__data__": {"text": "Part VII: Appendixes836On a Red Hat Enterprise Linux 6 system, enter the following:\n        # service vsftpd start\n        # chkconfig vsftpd on\n5. On the system running your FTP server, enter the following to create a file named \ntest  in the anonymous FTP directory that contains the words \u201cWelcome to your \nvsftpd server\u201d:\n        # echo \"Welcome to your vsftpd server\" > /var/ftp/test\n6. To open the test  file from the anonymous FTP home directory using a web browser \non the system running your FTP server, do the following.\nOpen a web browser, enter the following in the location box, and press Enter:\n        ftp://localhost/test\nThe text \u201cWelcome to your vsftpd server\u201d should appear in the browser window.\n7. To access the test  file in the anonymous FTP home directory, do the following. (If \nyou cannot access the file, check that your firewall, SELinux, and TCP wrappers are \nconfigured to allow access to that file, as described here.)\na. Enter the following into the location box of a browser on a system on your net -\nwork that can reach the FTP server (replace host  with your system\u2019s fully qual -\nified hostname or IP address):\n        ftp://host/test\nIf you cannot see the welcome message in your browser window, check what \nmay be preventing access. To turn off your firewall temporarily (flush your \niptables  rules), enter the following command as the root user from a shell on \nyour FTP server system and then try to access the site again:\n        # iptables -F\nb. To disable SELinux temporarily, enter the following and then try to access the \nsite again:\n        # setenforce 0\nAfter you have determined what is causing the file on your FTP server to be \nunavailable, go back to the section \u201cSecuring Your FTP Server\u201d in Chapter\u00a018, and \ngo through the steps to determine what might be blocking access to your file. These \nare the likely possibilities:\nc. For iptables , make sure that there is a rule opening TCP port 21 on \nthe server.\nd. For SELinux, make sure that the file context is set to public_content_t.", "doc_id": "0c69d54c-a254-4aa0-9969-68a4a4c112f5", "embedding": null, "doc_hash": "2036cc5685e6655d2e6e32e02a4410659ad63f05b883e9761d26ab58e57c211a", "extra_info": {"page_label": "851"}, "node_info": {"start": 0, "end": 2039}, "relationships": {"1": "f15e40f8-ac19-4f7d-ae34-3fe8d741f353"}}, "__type__": "1"}, "bc683263-7568-4a00-bc04-8260a60b66fe": {"__data__": {"text": "Appendix B: Exercise Answers\nB8378. To configure your vsftpd server to allow file uploads by anonymous users to a direc -\ntory named in , do the following as root on your FTP server:\na. Create the in  directory as follows:\n        # mkdir /var/ftp/in\n        # chown ftp:ftp /var/ftp/in\n        # chmod 777 /var/ftp/in\nb. For a recent Fedora or RHEL, open the Firewall Configuration window and check \nthe FTP box under services to open access to your FTP service. For earlier RHEL \nand Fedora systems, configure your iptables  firewall to allow new requests on \nTCP port 21 by adding the following rule at some point before a final DROP  or \nREJECT  rule in your /etc/sysconfig/iptables  file:\n        -A INPUT -m state --state NEW -m tcp -p tcp --dport 21 \n-j ACCEPT\nc. Configure your iptables  firewall to do connection tracking by loading the \nappropriate module to the /etc/sysconfig/iptables-config  file:\n        IPTABLES_MODULES=\"nf_conntrack_ftp\"\nd. For SELinux to allow uploading to the directory, first set file contexts properly:\n        # semanage fcontext -a -t public_content_rw_t \"/var/ftp/\nin(/.*)?\"\n        # restorecon -F -R -v /var/ftp/in\ne. Next, set the SELinux Boolean to allow uploading:\n        # setsebool -P allow_ftpd_anon_write on\nf. Restart the vsftpd  service (service vsftpd restart  or systemctl \nrestart vsftpd.service ).\n9. To install the lftp  FTP client (if you don\u2019t have a second Linux system, install \nlftp  on the same host running the FTP server). Optionally, try to upload the /\netc/hosts  file to the in  directory on the server, to make sure it is accessible. Run \nthe following commands as the root user:\n        # yum install lftp\n        # lftp localhost\n        lftp localhost:/> cd in\n        lftp localhost:/in> put /etc/hosts\n        89 bytes transferred\n        lftp localhost:/in> quit\nYou won\u2019t be able to see that you copied the hosts  file to the incoming directory. \nHowever, enter the following from a shell on the host running the FTP server to \nmake sure that the hosts  file is there:\n        # ls /var/ftp/in/hosts", "doc_id": "bc683263-7568-4a00-bc04-8260a60b66fe", "embedding": null, "doc_hash": "b71739297edf21ef3a8d5ff37a401be476cd1a3f2ac6fa9d27bd6764efe56c1c", "extra_info": {"page_label": "852"}, "node_info": {"start": 0, "end": 2076}, "relationships": {"1": "7e6b40c5-b572-4bb4-b0f5-1d1450726f88"}}, "__type__": "1"}, "1fd4fbeb-8b99-4feb-ac68-a45884dd6b58": {"__data__": {"text": "Part VII: Appendixes838If you cannot upload the file, troubleshoot the problem as described in Exercise 7, \nrecheck your vsftpd.conf  settings, and review the ownership and permissions on \nthe /var/ftp/in  directory.\n10. Using any FTP client you choose, visit the /pub/debian-meetings  directory on \nthe ftp://ftp.gnome.org  site and list the contents of that directory. Here\u2019s how \nto do that with the lftp  client:\n        # lftp ftp://ftp.gnome.org/pub/debian-meetings/\n        cd ok, cwd=/pub/debian-meetings\n        lftp ftp.gnome.org:/pub/debian-meetings>> ls\n        drwxr-xr-x    3 ftp      ftp             3 Jan 13  2014 2004\n        drwxr-xr-x    6 ftp      ftp             6 Jan 13  2014 2005\n        drwxr-xr-x    8 ftp      ftp             8 Dec 20  2006 2006\n        ...\nChapter\u00a019: Configuring a Windows File Sharing \n(Samba) Server\n1. To install the samba  and samba-client  packages, enter the following as root \nfrom a shell on the local system:\n        # yum install samba samba-client\n2. To start and enable the smb and nmb  services, enter the following as root from a \nshell on the local system:\n        # systemctl enable smb.service\n        # systemctl start smb.service\n        # systemctl enable nmb.service\n        # systemctl start nmb.service\nor\n        # chkconfig smb on\n        # service smb start\n        # chkconfig nmb on\n        # service nmb start\n3. To set the Samba server\u2019s workgroup to TESTGROUP , the NetBIOS name to MYTEST , \nand the server string to Samba Test System , as root user in a text editor, \nopen the /etc/samba/smb.conf  file, and change three lines so that they appear \nas follows:\n        workgroup = TESTGROUP\n        netbios name = MYTEST\n        server string = Samba Test System", "doc_id": "1fd4fbeb-8b99-4feb-ac68-a45884dd6b58", "embedding": null, "doc_hash": "13dacd45075734127b2eb518be12f24a88a5fb4775c7ad239492c76d3ede212a", "extra_info": {"page_label": "853"}, "node_info": {"start": 0, "end": 1739}, "relationships": {"1": "606c713f-2b55-424c-a12c-bdec48369f93"}}, "__type__": "1"}, "5a63eba7-3a52-4069-b2c8-ecf814f84e0d": {"__data__": {"text": "Appendix B: Exercise Answers\nB8394. To add a Linux user named phil  to your system, and add a Linux password and \nSamba password for phil , enter the following as root user from a shell. (Be sure to \nremember the passwords you set.)\n        # useradd phil\n        # passwd phil\n        New password: *******\n        Retype new password: *******\n        # smbpasswd -a phil\n        New SMB password: *******\n        Retype new SMB password: *******\n        Added user phil.\n5. To set the [homes]  section so that home directories are browseable ( yes) and \nwriteable ( yes), and that phil  is the only valid user, open the /etc/samba/smb.\nconf  file as root, and change the [homes]  section so that it appears as follows:\n        [homes]\n                comment = Home Directories\n                browseable = Yes\n                read only = No\n                valid users = phil\n6. To set SELinux Booleans that are necessary to make it so that phil  can access his \nhome directory via a Samba client, enter the following as root from a shell, and \nrestart the smb and nmb  services:\n        # setsebool -P samba_enable_home_dirs on\n        # systemctl restart smb\n        # systemctl restart nmb\n7. From the local system, use the smbclient  command to list that the homes  share \nis available.\n        # smbclient -L localhost\n        Enter TESTGROUP\\root's password: <ENTER>\n        Anonymous login successful\n \n             Sharename       Type      Comment\n             ---------       ----      -------\n             homes           Disk      Home Directories\n          ...\n8. To connect to the homes  share from a Nautilus (file manager) window on the \nSamba server\u2019s local system for the user phil  in a way that allows you to drag and \ndrop files to that folder, do the following:\na. Open the Nautilus window (select the files icon).\nb. In the left pane, select Other Locations and then click in the Connect to \nServer box.\nc. Type the Server address. For example, smb://localhost/phil/ .", "doc_id": "5a63eba7-3a52-4069-b2c8-ecf814f84e0d", "embedding": null, "doc_hash": "aeda9b329026711a1c1e4f8c78b720f68534c3f146bb0aacbea4632287bbd91c", "extra_info": {"page_label": "854"}, "node_info": {"start": 0, "end": 1994}, "relationships": {"1": "6da35135-2d29-418a-9915-ba76596b0184"}}, "__type__": "1"}, "00ac99c7-740b-4753-a700-a7f5e8126c3d": {"__data__": {"text": "Part VII: Appendixes840d. When prompted, select Registered User, type phil  as the username, enter the \ndomain (TESTGROUP ), and enter phil\u2019s password.\ne. Open another Nautilus window and drop a file to phil \u2019s homes folder.\n9. To open up the firewall so that anyone who has access to the server can access the \nSamba service ( smbd and nmbd  daemons), you can simply open the Firewall Config -\nuration window and check the samba  and samba-client  check boxes (for both \nRuntime and Permanent). If your system is running basic iptables  (and not the \nfirewalld  service), change the /etc/sysconfig/iptables  file so that the \nfirewall appears like the following (the rules you add being those in bold):\n        *filter\n        :INPUT ACCEPT [0:0]\n        :FORWARD ACCEPT [0:0]\n        :OUTPUT ACCEPT [0:0]\n        -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT\n        -A INPUT -p icmp -j ACCEPT\n        -A INPUT -i lo -j ACCEPT\n        -I INPUT -m state --state NEW -m udp -p udp --dport 137 -j ACCEPT\n        -I INPUT -m state --state NEW -m udp -p udp --dport 138 -j ACCEPT\n        -I INPUT -m state --state NEW -m tcp -p tcp --dport 139 -j ACCEPT\n        -I INPUT -m state --state NEW -m tcp -p tcp --dport 445 -j ACCEPT\n        -A INPUT -j REJECT --reject-with icmp-host-prohibited\n        -A FORWARD -j REJECT --reject-with icmp-host-prohibited\n        COMMIT\nThen enter the following for the firewall rules to be reloaded:\n        # service iptables restart\n10. To open the homes  share again as the user phil  from another system on your net -\nwork (Windows or Linux), and make sure that you can drag and drop fles to it, do \nthe following:\na. This step is really just repeating the Nautilus example described previously or \naccessing a Windows File Explorer window and opening the share (by selecting \nNetwork, then the Samba server). The trick is to make sure that the service has \nbeen made available through the Linux server security features.\nb. If you cannot access the Samba share, try disabling your firewall and then dis -\nabling SELinux. If the share is accessible when you turn off either of those ser -\nvices, go back and debug the problems with the service that is not working:\n        # setenforce 0\n        # service iptables stop", "doc_id": "00ac99c7-740b-4753-a700-a7f5e8126c3d", "embedding": null, "doc_hash": "84a77df49763988134c9b0bffb5430b24f736d6fb3ef5bb9fb175ba575431de4", "extra_info": {"page_label": "855"}, "node_info": {"start": 0, "end": 2263}, "relationships": {"1": "652ddc05-6ae1-474c-9ab0-0a34fdc41798"}}, "__type__": "1"}, "73db8ea4-bb21-4dc5-ace9-a3c08a609c38": {"__data__": {"text": "Appendix B: Exercise Answers\nB841c. When you have fixed the problem, set SELinux back to Enforcing mode and \nrestart iptables :\n        # setenforce 1\n        # service iptables start\nChapter\u00a020: Configuring an NFS File Server\n1. To install the packages needed to configure the NFS service on your chosen Linux \nsystem, enter the following as root user at a shell (Fedora or RHEL):\n        # yum install nfs-utils\n2. To list the documentation files that come in the package that provides the NFS \nserver software, enter the following:\n        # rpm -qd nfs-utils\n        /usr/share/doc/nfs-utils-1.2.5/ChangeLog\n        ...\n        /usr/share/man/man5/exports.5.gz\n        /usr/share/man/man5/nfs.5.gz\n        /usr/share/man/man5/nfsmount.conf.5.gz\n        /usr/share/man/man7/nfsd.7.gz\n        /usr/share/man/man8/blkmapd.8.gz\n        /usr/share/man/man8/exportfs.8.gz\n        ...\n3. To start and enable the NFS service, enter the following as root user on the \nNFS server:\n        # systemctl start nfs-server.service\n        # systemctl enable nfs-server.service\n4. To check the status of the NFS service that you just started on the NFS server, \nenter the following as root user:\n        # systemctl status nfs-server.service\n5. To share a directory /var/mystuff  from your NFS server as available to everyone, \nread-only, and with the root user on the client having root access to the share, first \ncreate the mount directory as follows:\n        # mkdir /var/mystuff\nThen create an entry in the /etc/exports  file that is similar to the following:\n        /var/mystuff   *(ro,no_root_squash,insecure)\nTo make the share available, enter the following:\n        # exportfs -v -a\n        exporting *:/var/mystuff", "doc_id": "73db8ea4-bb21-4dc5-ace9-a3c08a609c38", "embedding": null, "doc_hash": "2522ffcdee609f67b6ceb7520628cea1d0c672ebb82c9bfd570931e81fbe39f7", "extra_info": {"page_label": "856"}, "node_info": {"start": 0, "end": 1713}, "relationships": {"1": "dfdca133-c495-4853-afcb-ae76d10560b4"}}, "__type__": "1"}, "4394768a-88ef-43e9-83cc-071925735387": {"__data__": {"text": "Part VII: Appendixes8426. To make sure that the share you created is accessible to all hosts, first check that \nrpcbind  is not blocked by TCP wrappers by adding the following entry to the \nbeginning of the /etc/hosts.allow  file:\n        rpcbind: ALL\na. To open the firewall in systems that use firewalld  (RHEL 8 and recent Fedora \nsystems), install the firewall-config package. Then run firewall-config . \nFrom the Firewall Configuration window that appears, make sure that nfs and \nrpc-bind are checked to On for the Permanent firewall settings.\nb. To open the ports needed to allow clients to reach NFS through the iptables  \nfirewall (RHEL 6 and earlier Fedora systems without firewalld ), you need to \nopen at least TCP and UDP ports 111 ( rpcbind ), 20048 (mountd ), and 2049 \n(nfs) by adding the following rules to the /etc/sysconfig/iptables  file \nand starting the iptables  service:\n        -A INPUT -m state --state NEW -m tcp -p tcp --dport 111 -j ACCEPT\n        -A INPUT -m state --state NEW -m udp -p udp --dport 111 -j ACCEPT\n        -A INPUT -m state --state NEW -m tcp -p tcp --dport 2049 -j ACCEPT\n        -A INPUT -m state --state NEW -m udp -p udp --dport 2049 -j ACCEPT\n        -A INPUT -m state --state NEW -m tcp -p tcp --dport 20048 -j ACCEPT\n        -A INPUT -m state --state NEW -m udp -p udp --dport 20048 -j ACCEPT\nSELinux should be able to share NFS filesystems while in enforcing mode without \nany changes to file contexts or Booleans. To make sure that the share you created \ncan be shared read-only, run the following command as root user on the NFS server:\n        # setsebool -P nfs_export_all_ro on\n7. To view the shares available from the NFS server, assuming that the NFS server is \nnamed nfsserver , enter the following from the NFS client:\n        # showmount -e nfsserver\n        Export list for nfsserver:\n        /var/mystuff  *\n8. To create a directory called /var/remote  and temporarily mount the /var/\nmystuff  directory from the NFS server (named nfsserver  in this example) on \nthat mount point, enter the following as root user from the NFS client:\n        # mkdir /var/remote\n        # mount -t nfs nfsserver:/var/mystuff /var/remote\n9. To add an entry so that the same mount is done automatically when you reboot, \nfirst unmount /var/remote  as follows:\n        # umount /var/remote", "doc_id": "4394768a-88ef-43e9-83cc-071925735387", "embedding": null, "doc_hash": "cb075bb3d2bd9de739b023a3487972d893b57c0417edc4af40af4d8aff6d9cf2", "extra_info": {"page_label": "857"}, "node_info": {"start": 0, "end": 2335}, "relationships": {"1": "6ef00ac4-be9e-4560-94dc-c0f059986828"}}, "__type__": "1"}, "fac5edcf-4007-444a-9183-28fb4ae5cbf9": {"__data__": {"text": "Appendix B: Exercise Answers\nB843Then add an entry like the following to the /etc/fstab  on the client system:\n        /var/remote   nfsserver:/var/mystuff  nfs bg,ro 0 0\nTo test that the share is configured properly, enter the following on the NFS client \nas the root user:\n        # mount -a\n        # mount -t nfs4\n        nfsserver:/var/mystuff on /var/remote type nfs4\n         (ro,vers=4,rsize=524288...\n10. To copy some files to the /var/mystuff  directory, enter the following on the \nNFS server:\n        # cp /etc/hosts /etc/services /var/mystuff\nFrom the NFS client, to make sure that you can see the files just added to that \ndirectory, and to make sure that you can\u2019t write files to that directory from the \nclient, enter the following:\n        # ls /var/remote\n        hosts    services\n        # touch /var/remote/file1\n        touch: cannot touch '/var/remote/file1': Read-only file \nsystem\nChapter\u00a021: Troubleshooting Linux\n1. To go into Setup mode from the BIOS screen on your computer, do the following:\na. Reboot your computer.\nb. Within a few seconds, you should see the BIOS screen, with an indication of \nwhich function key to press to go into Setup mode. (On my Dell workstation, it\u2019s \nthe F2 function key.)\nc. The BIOS screen should appear. (If the system starts booting Linux, you didn\u2019t \npress the function key fast enough.)\n2. From the BIOS setup screen, do the following to determine whether your computer \nis 32-bit or 64-bit, whether it includes virtualization support, and whether your \nnetwork interface card is capable of PXE booting.\nYour experience may be a bit different from mine, depending on your computer \nand Linux system. The BIOS setup screen is different for different computers. In \ngeneral, however, you can use arrow keys and tab keys to move between different \ncolumns, and press Enter to select an entry.", "doc_id": "fac5edcf-4007-444a-9183-28fb4ae5cbf9", "embedding": null, "doc_hash": "d2ba3a9380960093480fb0ebc586038050b7c099d73e6286c7c1a83896dd06f9", "extra_info": {"page_label": "858"}, "node_info": {"start": 0, "end": 1853}, "relationships": {"1": "0323f4d5-e5ff-4f07-a733-97ca8f5587e1"}}, "__type__": "1"}, "383a043f-af27-482f-8897-dbebc5804f24": {"__data__": {"text": "Part VII: Appendixes844a. On my Dell workstation, under the System heading, I highlight Processor Info \nto see that mine is a 64-bit Technology computer. Look in the Processor Info \nsection, or a similar, section on your computer, to see the type of processor \nthat you have.\nb. On my Dell workstation, under the Onboard Devices heading, I highlight \nIntegrated NIC and press Enter. The Integrated NIC screen that appears to the \nright lets me choose to enable or disable the NIC (On or Off) or enable with PXE \nor RPL (if I intend to boot the computer over the network).\n3. To interrupt the boot process to get to the GRUB boot loader, do the following:\na. Reboot the computer.\nb. Just after the BIOS screen disappears, when you see the countdown to booting \nthe Linux system, press any key (perhaps the spacebar).\nc. The GRUB boot loader menu should appear, ready to allow you to select which \noperating system kernel to boot.\n4. To boot up your computer to runlevel 1 so that you can do some system mainte -\nnance, get to the GRUB boot screen (as described in the previous exercise), and \nthen do the following:\na. Use the arrow keys to highlight the operating system and kernel that you \nwant to boot.\nb. Type e to see the entries needed to boot the operating system.\nc. Move your cursor to the line that included the kernel. (It should include the \nword vmlinuz  somewhere on the line.)\nd. Move the cursor to the end of that line, add a space, and then type \ninit=bash .\ne. Follow the instructions to boot the new entry. You will probably either press \nCtrl+X or press Enter; if there is another screen, type b .\nIf it worked, your system should bypass the login prompt and boot up directly \nto a root user shell where you can do administrative tasks without providing a \npassword.\n5. To look at the messages that were produced in the kernel ring buffer (which shows \nthe activity of the kernel as it booted up), enter the following from the shell after \nthe system finishes booting:\n        # dmesg | less\n6. Or, on a system using systemd , enter the following:\n        # journalctl -k", "doc_id": "383a043f-af27-482f-8897-dbebc5804f24", "embedding": null, "doc_hash": "2bc03001f31b15c32e52c8050d36cebfa5ec94023cec2083d8d5fc6bb8fe4fa2", "extra_info": {"page_label": "859"}, "node_info": {"start": 0, "end": 2091}, "relationships": {"1": "96c02a1c-8c50-405b-a59a-fead0ef2f85f"}}, "__type__": "1"}, "8ca2685e-37c4-4e9d-becc-f919d796bcda": {"__data__": {"text": "Appendix B: Exercise Answers\nB8457. To run a trial yum update  from Fedora or RHEL and exclude any kernel package \nthat is available, enter the following (when prompted, type N to not actually go \nthrough with the update, if updates are available):\n        # yum update --exclude='kernel*'\n8. To check to see what processes are listening for incoming connections on your \nsystem, enter the following:\n        # netstat -tupln | less\n9. To check to see what ports are open on your external network interface, do the \nfollowing.\nIf possible, run the nmap  command from another Linux system on your network, \nreplacing yourhost  with the hostname or IP address of your system:\n        # nmap yourhost\n10. To clear your system\u2019s page cache and watch the effect it has on your memory \nusage, do the following:\na. Select Terminal from an application menu on your desktop (it is located on dif -\nferent menus for different systems).\nb. Run the top  command (to watch processes currently running on your \nsystem), and then type a capital M to sort processes by those consuming the \nmost memory.\nc. From the Terminal window, select File and Open Terminal to open a second Ter -\nminal window.\nd. From the second Terminal window, become root user ( su - ).\ne. While watching the Mem  line (used column) in the first Terminal window, enter \nthe following from the second Terminal window:\n        # echo 3 > /proc/sys/vm/drop_caches\nf. The used RES  memory should go down significantly on the Mem  line. The num-\nbers in the RES  column for each process should go down as well.\n11. To view memory and swap usage from Cockpit through your web browser, open your \nbrowser to Cockpit for your host ( https://hostname:9090 ). Then select System \n\u27aa Memory & Swap.\nChapter\u00a022: Understanding Basic Linux Security\n1. To check log messages from the systemd  journal for the NetworkManager.ser -\nvice , sshd.service , and auditd.service  services, enter the following:\n        # journalctl -u NetworkManager.service\n        ...", "doc_id": "8ca2685e-37c4-4e9d-becc-f919d796bcda", "embedding": null, "doc_hash": "a867cfeeacbe1ca39eaff388e75d616074c7f10aed8900675f2d37efad8736dc", "extra_info": {"page_label": "860"}, "node_info": {"start": 0, "end": 2004}, "relationships": {"1": "bd8d06d9-57fd-4124-95e2-00bc15eb87fb"}}, "__type__": "1"}, "ca8751b9-4577-4abf-b7cf-5d4fc77d6571": {"__data__": {"text": "Part VII: Appendixes846        # journalctl -u sshd.service\n        ...\n        # journalctl -u auditd.service\n        ...\n2. User passwords are stored in the /etc/shadow  file. To see its permissions, type  \nls -l /etc/shadow  at the command line. (If no shadow file exits, then you \nneed to run pwconv .)\nThe following are the appropriate settings:\n # ls -l /etc/shadow\n----------. 1 root root 1049 Feb  10 09:45 /etc/shadow\n3. To determine your account\u2019s password aging and whether it will expire using a \nsingle command, type chage -l  user _ name . For example:\n        # chage -l chris\n4. To start auditing writes to the /etc/shadow  with the auditd  daemon, enter the \nfollowing at the command line:\n        # auditctl -w /etc/shadow -p w\nTo check your audit settings, type in auditctl -l at the command line.\n5. To create a report from the auditd  daemon on the /etc/shadow  file, enter aus -\nearch -f /etc/shadow at the command line. To turn off the auditing on that \nfile, enter auditctl -W /etc/shadow -p w at the command line.\n6. To install the lemon package, damage the /usr/bin/lemon  file, verify that the \nfile has been tampered with, and remove the lemon package, enter the following:\n        # yum install -y lemon\n        # cp /etc/services /usr/bin/lemon\n        # rpm -V lemon\n        S.5....T.    /usr/bin/lemon\n        # yum erase lemon\nFrom the original lemon file, the file size (S), the md4sum (5), and the modifica -\ntion times (T) all differ. For Ubuntu, install the package with apt-get install \nlemon  and enter debsums lemon  to check it.\n7. If you suspect that you have had a malicious attack on your system today and \nimportant binary files have been modified, you can find these modified files by \nentering the following at the command line: find directory -mtime -1 for \nthe directories, /bin , /sbin , /usr/bin , and /usr/sbin .\n8. To install and run chkrootkit  to see if the malicious attack from the exercise \nabove installed a rootkit, choose your distribution and do the following:\na. To install on a Fedora or RHEL distribution, enter yum install chkrootkit \nat the command line.", "doc_id": "ca8751b9-4577-4abf-b7cf-5d4fc77d6571", "embedding": null, "doc_hash": "c7211316604d7d1d2b55268a6820f0411dd9ff95e6367dfaa8b0068a6ecb4c45", "extra_info": {"page_label": "861"}, "node_info": {"start": 0, "end": 2121}, "relationships": {"1": "d918ce06-130c-4f27-bcf5-eb9438e7783f"}}, "__type__": "1"}, "2d4b8818-69b1-4f61-8f82-fc4d8f7df54b": {"__data__": {"text": "Appendix B: Exercise Answers\nB847b. To install on an Ubuntu or Debian-based distribution, enter sudo apt-get \ninstall chkrootkit  at the command line.\nc. To run the check, enter chkrootkit  at the command line and review \nthe results.\n9. To find files anywhere in the system with the SUID  or SGID  permission set, enter \nfind / -perm /6000 -ls at the command line.\n10. To install the aide  package, run the aide  command to initialize the aide  data-\nbase, copy the database to the correct location, and run the aide  command to \ncheck whether any important files on your system have been modified, enter the \nfollowing.\n        # yum install aide\n        # aide -i\n        # cp /var/lib/aide/aide.db.new.gz /var/lib/aide/aide.db.gz\n        # aide -C\nTo make the output more interesting, you could install the lemon package \n(described in an earlier exercise) before you run aide -i,  and modify it before \nrunning aide -C  to see how a modified binary looks from aide .\nChapter\u00a023: Understanding Advanced Linux Security\nTo do the first few exercises, you must have the gnupg2  package installed. This is \nnot installed by default in Ubuntu, although it is installed for the latest Fedora and \nRHEL releases.\n1. To encrypt a file using the gpg2  utility and a symmetric key, enter the following \ncommand. (The gpg2  utility asks for a passphrase to protect the symmetric key.)\n        $ gpg2 -c filename\n2. To generate a key pair using the gpg2  utility, enter the following:\n $ gpg2 --gen-key\nYou must provide the following information:\na. Your real name and email address\nb. A passphrase for the private key\n3. To list out the keys you generated, enter the following:\n        $ gpg2 --list-keys\n4. To encrypt a file and add your digital signature using the gpg2  utility, do the \nfollowing:\na. You must have first generated a key ring (Exercise 2).\nb. After you have generated the key ring, enter\n        $ gpg2 --output EncryptedSignedFile --sign \nFiletoEncryptSign", "doc_id": "2d4b8818-69b1-4f61-8f82-fc4d8f7df54b", "embedding": null, "doc_hash": "dc69d6875dff1a6f6d44ece01adf8661934c1eb3cab9215f14aad9eb1c7a174d", "extra_info": {"page_label": "862"}, "node_info": {"start": 0, "end": 1969}, "relationships": {"1": "25a1cd45-cf98-4029-a208-34e8e873cba8"}}, "__type__": "1"}, "0a3f1463-b7d3-42b6-81f1-c19898984d97": {"__data__": {"text": "Part VII: Appendixes8485. From the getfedora.org  page, select one of the Fedora distributions to down -\nload. When the download is complete, select Verify your Download to see instruc -\ntions for verifying your image. For example, download the appropriate CHECKSUM \nfile for your image, then enter the following:\n        $ curl https://getfedora.org/static/fedora.gpg | gpg \n--import\n        $ gpg --verify-files *-CHECKSUM\n        $ sha256sum -c *-CHECKSUM\n6. To determine if the su  command on your Linux system is PAM-aware, enter the \nfollowing:\n        $ ldd $(which su) | grep pam\n        libpam.so.0 => /lib64/libpam.so.0 (0x00007fca14370000)\n        ibpam_misc.so.0 => /lib64/libpam_misc.so.0 \n(0x00007fca1416c000\nIf the su  command on your Linux system is PAM-aware, you should see a PAM \nlibrary name listed when you issue the ldd  command.\n7. To determine if the su  command has a PAM configuration file, type the following :\n        $ ls /etc/pam.d/su\n        /etc/pam.d/su\nIf the file exists, type the following at the command line to display its contents. \nThe PAM contexts it uses include any of the following: auth , account , pass-\nword , or session .\n        $ cat /etc/pam.d/su\n8. To list out the various PAM modules on your Fedora or RHEL system, enter the \nfollowing:\n        $ ls /usr/lib64/security/pam*.so\nTo list out the various PAM modules on your Ubuntu Linux system, enter the \nfollowing:\n        # find / -name pam*.so\n9. To find the PAM \u201cother\u201d configuration file on your system, enter ls /etc/pam.d/\nother  at the command line. An \u201cother\u201d configuration file that enforces Implicit \nDeny should look similar to the following code:\n        $ cat /etc/pam.d/other\n        #%PAM-1.0\n        auth     required       pam_deny.so\n        account  required       pam_deny.so\n        password required       pam_deny.so\n        session  required       pam_deny.so\n ", "doc_id": "0a3f1463-b7d3-42b6-81f1-c19898984d97", "embedding": null, "doc_hash": "d1af5738d65dc025ab28d8e8a680e4163cce611648d5d431e4237c4383d6ed55", "extra_info": {"page_label": "863"}, "node_info": {"start": 0, "end": 1888}, "relationships": {"1": "d07b97f8-de65-4617-936d-e8e49fecad27"}}, "__type__": "1"}, "99bba93b-91f2-4eee-94d0-c34af69ef966": {"__data__": {"text": "Appendix B: Exercise Answers\nB84910. To find the PAM limits configuration file, enter the following:\n        $ ls /etc/security/limits.conf\nDisplay the file\u2019s contents by entering the following:\n        $ cat /etc/security/limits.conf\nSettings in this file to prevent a fork bomb look like the following:\n@student     hard    nproc           50\n@student     -       maxlogins        4\nChapter\u00a024: Enhancing Linux Security with SELinux\n1. To set your system into the permissive mode for SELinux, enter setenforce \npermissive  at the command line. It would also be acceptable to enter seten -\nforce 0  at the command line.\n2. To set your system into the enforcing operating mode for SELinux without chang -\ning the SELinux primary configuration file, use caution. It is best not to run this \ncommand on your system for an exercise until you are ready for the SELinux \nto be enforced. Use the following command at the command line: seten -\nforce enforcing . It would also be acceptable to enter setenforce 1  at the \ncommand line.\n3. To find and view the permanent SELinux policy type (set at boot time), go to the \nmain SELinux configuration file, /etc/selinux/config . To view it, enter cat /\netc/selinux/config | grep SELINUX= at the command line. To be sure how \nit is currently set, enter the getenforce  command.\n4. To list the /etc/hosts  file security context and identify the different security \ncontext attributes, enter ls -Z /etc/hosts at the command line:\n        $ ls -Z /etc/hosts\n        -rw-r--r--. root root system_u:object_r:net_conf_t:s0  /\netc/hosts\na. The file\u2019s user context is system_u, indicating a system file.\nb. The file\u2019s role is object_r, indicating an object in the file system (a text file, \nin this case).\nc. The file\u2019s type is net_conf_t, because the file is a network configuration file.\nd. The file\u2019s sensitivity level is s0 , indicating the lowest security level. (This \nnumber may be listed in a range of numbers from s0-s3 .)\ne. The file\u2019s category level starts with a c and ends with a number. It may be \nlisted in a range of numbers, such as c0-c102 . This is not required except in \nhighly secure environments and is not set here.", "doc_id": "99bba93b-91f2-4eee-94d0-c34af69ef966", "embedding": null, "doc_hash": "e54ed11dd2738252fc5209c9ed6aecb3c9460286f3287096bcf87a6d8e620cb4", "extra_info": {"page_label": "864"}, "node_info": {"start": 0, "end": 2169}, "relationships": {"1": "9bf88343-040d-40ce-b3a5-a26e12a83f0d"}}, "__type__": "1"}, "bd30ed6f-df65-4405-a0fd-be06cab65757": {"__data__": {"text": "Part VII: Appendixes8505. To create a file called test.html  and assign its type as httpd_sys_content_t, \nenter the following:\n        $ touch test.html\n        $ chcon -t httpd_sys_content_t test.html\n        $ ls -Z test.html\n        -rw-rw-r--. chris chris unconfined_u:object_r:httpd_sys_\ncontent_t:s0 test.html\n6. To list the crond  process\u2019s security context and identify the different security \ncontext attributes, enter this at the command line:\n        $ ps -efZ | grep crond\n        system_u:system_r:crond_t:s0-s0:c0.c1023 root 665  1  0\n            Sep18 ?   00:00:00 /usr/sbin/crond -n\na. The process\u2019s user context is system_u, indicating a system process.\nb. The process\u2019s role is system_r, indicating a system role.\nc. The process\u2019s type or domain is crond_t.\nd. The process\u2019s sensitivity level starts s0-s0 , indicating that it is not highly sen -\nsitive. (It is secure by normal Linux standards, however, because the process is \nrun as the root user.)\ne. The process\u2019s category level is c0.c1023 , with the c0 , indicating that the cat -\negory is also not highly secure from an SELinux standpoint.\n7. To create an /etc/test.txt  file, change its file context to user_tmp_t, restore \nit to its proper content (the default context for the /etc  directory), and remove \nthe file, enter the following:\n        # touch /etc/test.txt\n        # ls -Z /etc/test.txt\n        -rw-r--r--. root root unconfined_u:object_r:etc_t:s0   /etc/\ntest.txt\n        # chcon -t user_tmp_t /etc/test.txt\n        # ls -Z /etc/test.txt\n        -rw-r--r--. root root unconfined_u:object_r:user_tmp_t:s0 /\netc/test.txt\n        # restorecon /etc/test.txt\n        #  ls -Z /etc/test.txt\n        -rw-r--r--. root root unconfined_u:object_r:etc_t:s0   /etc/\ntest.txt\n        # rm /etc/test.txt\n        rm: remove regular empty file `/etc/test.txt'? y\n8. To determine what Booleans allow anonymous writes and access to the tftp  ser-\nvice\u2019s home directory, then turn those Booleans on permanently, enter the follow -\ning commands:\n        # getsebool -a | grep tftp\n        tftp_home_dir --> off\n        tftpd_anon_write --> off", "doc_id": "bd30ed6f-df65-4405-a0fd-be06cab65757", "embedding": null, "doc_hash": "18bfe7dded33d18fc795a871006e913636899f7ced42c8ff76979d51afadd8ef", "extra_info": {"page_label": "865"}, "node_info": {"start": 0, "end": 2113}, "relationships": {"1": "27a08d37-f5c3-4f75-98a2-f9b088600912"}}, "__type__": "1"}, "5d28adf1-3889-400d-b715-9bf6a3066cd9": {"__data__": {"text": "Appendix B: Exercise Answers\nB851        ...\n        # setsebool -P tftp_home_dir=on\n        # setsebool -P tftp_anon_write=on\n        # getsebool tftp_home_dir tftp_anon_write\n        tftp_home_dir --> on\n        tftp_anon_write --> on\n9. To list all SELinux policy modules on your system, along with their version num-\nbers, enter semodule \u2013l .\nNote\nIf you wrote ls /etc/selinux/targeted/modules/active/modules/*.pp  as your answer, that is \nokay, but this command doesn\u2019t give you the version numbers of the policy modules. Only semodule -l gives the \nversion numbers.\n10. To tell SELinux to allow access to the sshd  service through TCP Port 54903, enter \nthe following:\n        # semanage port -a -t ssh_port_t -p tcp 54903\n        # semanage port -l | grep ssh\n        ssh_port_t                tcp             54903, 22\nChapter\u00a025: Securing Linux on a Network\n1. To install the Network Mapper (aka nmap ) utility on your local Linux system:\na. On Fedora or RHEL, enter yum install nmap at the command line.\nb. On Ubuntu, nmap  may come pre-installed. If not, enter sudo apt-get \ninstall nmap  at the command line.\n2. To run a TCP Connect scan on your local loopback address, enter nmap -sT \n127.0.0.1  at the command line. The ports you have running on your Linux server \nwill vary. However, they may look similar to the following:\n # nmap -sT 127.0.0.1\n        ...\n        PORT    STATE SERVICE\n        25/tcp  open  smtp\n        631/tcp open  ipp\n3. To run a UDP Connect scan on your Linux system from a remote system:\na. Determine your Linux server\u2019s IP address by entering ifconfig  at the \ncommand line. The output will look similar to the following, and your system\u2019s \nIP address follows inet addr:  in the ifconfig  command\u2019s output.\n        # ifconfig\n        ...\n        p2p1  Link encap:Ethernet  HWaddr 08:00:27:E5:89:5A\n              inet addr:10.140.67.23", "doc_id": "5d28adf1-3889-400d-b715-9bf6a3066cd9", "embedding": null, "doc_hash": "ecdd9e2a1e10c7dc9600c00d3bee8aca1ade722e79edb7b5e2ecf497a35b8284", "extra_info": {"page_label": "866"}, "node_info": {"start": 0, "end": 1875}, "relationships": {"1": "8c1c17c1-a651-4f44-af98-24b8f8b3eaba"}}, "__type__": "1"}, "58cf8e5b-b9a7-4ee8-abe6-a810fa730042": {"__data__": {"text": "Part VII: Appendixes852b. From a remote Linux system, enter the command nmap -sU IP address  \nat the command line, using the IP address  you obtained from above. \nFor example:\n        # nmap -sU 10.140.67.23\n4. To check to see if your system is running the firewalld  service, and then install \nand start it if it is not:\na. Enter systemctl status firewalld.service.\nb. If the firewalld  service is not running, on a Fedora or RHEL system, enter \nthe following:\n        # yum install firewalld firewall-config -y\n        # systemctl start firewalld\n        # systemctl enable firewalld\n5. To open ports in your firewall to allow remote access to your local web service, do \nthe following:\na. Start the Firewall Configuration window ( firewalld-config ).\nb. Make sure that Configuration: Runtime is selected.\nc. Select your current zone (for example, FedoraWorkstation).\nd. Under Services, select the http and https check boxes.\ne. Select Configuration: Permanent.\nf. Under Services, select the http and https check boxes.\n6. To determine your Linux system\u2019s current netfilter/iptables  firewall policies \nand rules, enter iptables -vnL  at the command line.\n7. To save, flush, and restore your Linux system\u2019s current firewall rules:\na. To save your current rules:\n        # iptables-save >/tmp/myiptables\nb. To flush your current rules:\n        # iptables -F\nc. To restore the firewall\u2019s rules, enter:\n        # iptables-restore < /tmp/myiptables\n8. To set your Linux system\u2019s firewall filter table for the input chain to a policy of \nDROP , enter iptables -P INPUT DROP at the command line.\n9. To change your Linux system firewall\u2019s filter table policy back to accept  for the \ninput chain, enter the following:\n        # iptables -P INPUT ACCEPT", "doc_id": "58cf8e5b-b9a7-4ee8-abe6-a810fa730042", "embedding": null, "doc_hash": "c46028e8418d85bc23bdfbf9c316ef04a7de0fbe184a1bfdf30a5e22ac0cdf56", "extra_info": {"page_label": "867"}, "node_info": {"start": 0, "end": 1747}, "relationships": {"1": "0e99c074-85df-4b0b-aa60-7cf8b7563037"}}, "__type__": "1"}, "1c3b41cd-0987-4cf2-b45f-40c4461e88ec": {"__data__": {"text": "Appendix B: Exercise Answers\nB853To add a rule to drop all network packets from the IP address 10.140.67.23, enter the \nfollowing:\n        # iptables -A INPUT -s 10.140.67.23 -j DROP\n10. To remove the rule that you just added, without flushing or restoring your Linux \nsystem firewall\u2019s rules, enter iptables -D INPUT 1 at the command line. This \nis assuming that the rule you added above is rule 1. If not, change the 1 to the \nappropriate rule number in your iptables  command.\nChapter\u00a026: Shifting to Clouds and Containers\n1. To install and start either podman  (for any RHEL or Fedora system) or \ndocker  (RHEL 7):\n        # yum install podman -y\n             or\n        # yum install docker -y\n        # systemctl start docker\n        # systemctl enable docker\n2. To use either docker  or podman  to pull this image to your host, registry.\naccess.redhat.com/ubi7/ubi :\n# podman pull registry.access.redhat.com/ubi7/ubi\n             or\n# docker pull registry.access.redhat.com/ubi7/ubi\n3. To run the ubi7/ubi  image to open a bash shell:\n        # podman run -it ubi7/ubi bash\n             or\n        # docker run -it ubi7/ubi bash\n4. To run commands to see the operating system on which the container is based, \ninstall the proc-ps  package, and run a command to see the processes running \ninside the container:\n        bash-4.4# cat /etc/os-release | grep ^NAME\n        NAME=\"Red Hat Enterprise Linux\"\n        bash-4.4# yum install procps -y\n        bash-4.4# ps -ef\n        UID        PID  PPID  C STIME TTY          TIME CMD\n        root         1     0  0 03:37 pts/0    00:00:00 bash\n        root        20     1  0 03:43 pts/0    00:00:00 ps -ef\n        bash-4.4# exit\n5. To restart and connect to the container that you just closed using an interactive \nshell, enter the following:\n        # podman ps -a\n        CONTAINER ID  IMAGE              COMMAND  CREATED", "doc_id": "1c3b41cd-0987-4cf2-b45f-40c4461e88ec", "embedding": null, "doc_hash": "66beaa995b9019b1238735761785fb717e3ef59ab2467c8fc6795db4784b42bd", "extra_info": {"page_label": "868"}, "node_info": {"start": 0, "end": 1874}, "relationships": {"1": "8fe6ea00-4b37-4016-a3b3-d5d33758bb58"}}, "__type__": "1"}, "e7d3effc-d9ad-4481-a1f1-0049d133a99d": {"__data__": {"text": "Part VII: Appendixes854             STATUS                    PORTS  NAMES\n        eabf1fb57a3a  ...ubi8/ubi:latest bash     7 minutes ago\n             Exited (0) 4 seconds ago         compassionate_hawking\n      # podman start -a eabf1fb57a3a\n      bash-4.4# exit\n6. To create a simple Dockerfile from a ubi7/ubi  base image, include a script named \ncworks.sh  that echoes \"The Container Works!\", and add that script to the image \nso that it runs, do the following:\na. Create and change to a new directory:\n   # mkdir project\n   # cd project\nb. Create a file named Dockerfile  with the following content:\n   FROM registry.access.redhat.com/ubi7/ubi-minimal\n   COPY ./cworks.sh /usr/local/bin/\n   CMD [\"/usr/local/bin/cworks.sh\"]\nc. Create a file named cworks.sh  with the following content:\n   #!/bin/bash\n   set -o errexit\n   set -o nounset\n   set -o pipefail\n   echo \"The Container Works!\"\n7. Use docker  or podman  to build an image named containerworks  from the \nDockerfile that you just created.\n      # podman build -t myproject .\n             or\n      # docker build -t myproject .\n8. To gain access to a container registry, either by installing the docker-distribution \npackage or getting an account on Quay.io or Docker Hub:\n      # yum install docker-distribution -y\n      # systemctl start docker-distribution\n      # systemctl enable docker-distribution\nor get an account from Quay.io ( https://quay.io/plans/ ) or Docker Hub, then:\n      # podman login quay.io\n      Username: <username>\n      Password: *********\n9. To tag and push a new image to a chosen container registry:\n      # podman tag aa0274872f23 \\\n      quay.io/<user>/<imagename>:v1.0\n      # podman push \\\n      quay.io/<user>/<imagename>:v1.0", "doc_id": "e7d3effc-d9ad-4481-a1f1-0049d133a99d", "embedding": null, "doc_hash": "d57ca0ba5a7bd32dcdf6c647b3eea9c13c4fe9d87bdf2209919f67fc510cbf48", "extra_info": {"page_label": "869"}, "node_info": {"start": 0, "end": 1723}, "relationships": {"1": "b514d198-1adc-46fa-b510-4ce177ed5285"}}, "__type__": "1"}, "049ff036-6e11-44e2-8095-39a025d686e1": {"__data__": {"text": "Appendix B: Exercise Answers\nB855Chapter\u00a027: Using Linux for Cloud Computing\n1. To check your computer to see if it can support KVM virtualization, enter the \nfollowing:\n        # cat /proc/cpuinfo | grep --color -E \"vmx|svm|lm\"\n        flags  : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr \npge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm \npbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs \nbts rep_good xtopology nonstop_tsc aperfmperf pni pclmulqdq dtes64 \nmonitor ds_cpl vmx smx es...\n        ...\nThe CPU must support either vmx  or svm . The lm  indicates that it is a \n64-bit computer.\n2. To install a Linux system along with the packages needed to use it as a KVM host \nand, to run the Virtual Machine Manager application, do the following:\na. Get a live or installation image from a Linux site (such as getfedora.org ), \nand burn it to a DVD (or otherwise make it available to install).\nb. Boot the installation image, and select to install it to a hard drive.\nc. For a Fedora Workstation, after the install is complete and you have rebooted, \ninstall the following package (for different Linux distributions, you might need \nto install a package that provides libvirtd  as well):\n        # yum install virt-manager libvirt-daemon-config-network\n3. To make sure that the sshd  and libvirtd  services are running on the system, \nenter the following:\n        # systemctl start sshd.service\n        # systemctl enable sshd.service\n        # systemctl start libvirtd.service\n        # systemctl enable libvirtd.service\n4. Get a Linux installation ISO image that is compatible with your hypervisor, and \ncopy it to the default directory used by Virtual Machine Manager to store images. \nFor example, if the Fedora Workstation DVD is in the current directory, you can \nenter the following:\n        # cp Fedora-Workstation-Live-x86_64-30-1.2.iso /var/lib/\nlibvirt/images/\n5. To check the settings on the default network bridge ( virbr0 ), enter the following:\n        # ip addr show virbr0\n        4: virbr0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc\n             noqueue state UP group default\n            link/ether de:21:23:0e:2b:c1 brd ff:ff:ff:ff:ff:ff\n            inet 192.168.122.1/24 brd 192.168.122.255 scope global virbr0\n               valid_lft forever preferred_lft forever6.", "doc_id": "049ff036-6e11-44e2-8095-39a025d686e1", "embedding": null, "doc_hash": "e9e8446380b24ea674f64e0d03fc87b02dd151f12b3eb2cd25c97332ce583a26", "extra_info": {"page_label": "870"}, "node_info": {"start": 0, "end": 2335}, "relationships": {"1": "b21de841-0ca2-4c0c-bcb7-499d8c3f59e2"}}, "__type__": "1"}, "db84f7dd-9a7b-403a-8a4b-6aeac7549916": {"__data__": {"text": "Part VII: Appendixes8566. To install a virtual machine using the ISO image you copied earlier, do the \nfollowing.\na. Enter this command:\n        # virt-manager &\nb. Select File and then select New Virtual Machine.\nc. Select Local Install Media and click Forward.\nd. Select Browse, choose the live or install ISO, click Choose Volume, and \nclick Forward.\ne. Select memory and CPUs and click Forward.\nf. Select the size of disk that you want to use and click Forward.\ng. Select \u201cVirtual network default: NAT\u201d (it may already be selected).\nh. If it all looks okay, click Finish.\ni. Follow the installation process indicated by the installation ISO.\n7. To make sure that you can log in to and use the virtual machine, do the following:\na. Double-click the entry for the new virtual machine.\nb. When the viewer window appears, log in as you would normally.\n8. To check that your virtual machine can connect to the Internet or other network \noutside of the hypervisor, do one of the following:\na. Open a web browser, and try to connect to a website on the Internet.\nb. Open a Terminal window, enter ping redhat.com , and then press \nCtrl+C to exit.\n9. To stop the virtual machine so that it is no longer running:\na. Right-click the entry for the VM in the virt-manager window.\nb. Select Shut Down, and then select Shut Down again.\nc. If the VM doesn\u2019t shut down immediately, you can select Force Off instead, but \nthat is like pulling the plug out and risks data loss.\n10. Start the virtual machine again so that it is running and available:\na. Right-click the entry for the VM in the virt-manager window.\nb. Click Run.", "doc_id": "db84f7dd-9a7b-403a-8a4b-6aeac7549916", "embedding": null, "doc_hash": "b04d33dc59476fe4586f63b201a798c35ce75d6ff1e4fae9893e7379a4b62c3c", "extra_info": {"page_label": "871"}, "node_info": {"start": 0, "end": 1613}, "relationships": {"1": "a9564b8f-602c-439c-a34b-d1a68328cf98"}}, "__type__": "1"}, "c6efae6b-f1f8-4dbe-ad3f-8cfde381eb01": {"__data__": {"text": "Appendix B: Exercise Answers\nB857Chapter\u00a028: Deploying Linux to the Cloud\n1. To install the genisoimage , cloud-init , qemu-img , and virt-viewer  pack -\nages, enter:\n        # dnf install genisoimage cloud-init qemu-img virt-viewer\n2. To obtain a Fedora cloud image, go to https://getfedora.org/en/cloud/\ndownload/ , and download a qcow2 image. There is one listed with OpenStack \nnamed Fedora-Cloud-Base-31-1.9.x86_64.qcow2 .\n3. To create a snapshot of that image in qcow2 format called myvm.qcow2 , enter the \nfollowing:\n # qemu-img create -f qcow2 \\\n-o backing_file=Fedora-Cloud-Base-31-1.9.x86_64.qcow2 \\\nmyvm.qcow2\n4. Create a cloud-init  meta data file named meta-data  that includes the follow -\ning content:\n        instance-id: myvm\n        local-hostname: myvm.example.com\n5. Create a cloud-init  user data file called user-data  that includes the follow -\ning content:\n        #cloud-config\n        password: test\n        chpasswd: {expire: False}\n6. Run the genisoimage  command to combine the meta-data  and user-data  \nfiles to create a mydata.iso  file:\n        # genisoimage -output mydata.iso -volid cidata \\\n            -joliet-long -rock user-data meta-data\n7. Use the virt-install  command to combine the myvm.qcow2  virtual machine \nimage with the mydata.iso  image to create a new virtual machine image named \nnewvm  that runs as a virtual machine on your hypervisor.\n        # virt-install --import --name newvm \\\n           --ram 4096 --vcpus 2 \\\n           --disk path=myvm.qcow2,format=qcow2,bus=virtio \\\n           --disk path=mydata.iso,device=cdrom \\\n           --network network=default &\n8. To open the newvm  virtual machine with virt-viewer , enter the following:\n # virt-viewer newvm\n9. Log into the newvm  virtual machine using the fedora  user and password test :\n        Login: fedora\n        Password: test", "doc_id": "c6efae6b-f1f8-4dbe-ad3f-8cfde381eb01", "embedding": null, "doc_hash": "82dc51301cb5a13c9a82ba4d6f2a7230b471cb8a19323b44c0a59e92565b1fbc", "extra_info": {"page_label": "872"}, "node_info": {"start": 0, "end": 1845}, "relationships": {"1": "44dbd0d3-627a-40c9-8eec-8d867cc87aba"}}, "__type__": "1"}, "4de1dfc3-2705-43a7-ab85-6b0b8e5ba4a7": {"__data__": {"text": "Part VII: Appendixes858Chapter\u00a029: Automating Apps and Infrastructure \nwith Ansible\n1. To install the ansible package, do the following:\nRHEL 8\n        # subscription-manager repos \\\n            --enable ansible-2.9-for-rhel-8-x86_64-rpms\n        # dnf install ansible -y\nFedora\n        # dnf install ansible -y\nUbuntu\n$ sudo apt update\n$ sudo apt install software-properties-common\n$ sudo apt-add-repository --yes --update ppa:ansible/ansible\n$ sudo apt install ansible\n2. To add sudo  privileges for the user running Ansible commands, run visudo  and \ncreate an entry similar to the following (changing joe to your user name):\n        joe   ALL=(ALL)       NOPASSWD: ALL\n3. Open a file named my_playbook.yaml , and add the following content:\n        ---\n        - name: Create web server\n          hosts: localhost\n          tasks:\n          - name: Install httpd\n            yum:\n              name: httpd\n              state: present\n4. To run the my_playbook.yaml playbook in check mode, do the following. (It \nshould fail because the user does not have privilege to install a package.)\n        $ ansible-playbook -C my_playbook.yaml\n        ...\n \n        TASK [Install httpd]  \n*************************************************************\n        fatal: [localhost]: FAILED! => {\"changed\": false, \"msg\": \n\"This\n             command has to be run under the root user.\", \n\"results\": []}\n        ...", "doc_id": "4de1dfc3-2705-43a7-ab85-6b0b8e5ba4a7", "embedding": null, "doc_hash": "a6d94ffa7c2d4225928c51db793cd4c09aaec2743d407a5e087a49c8be0565a8", "extra_info": {"page_label": "873"}, "node_info": {"start": 0, "end": 1403}, "relationships": {"1": "ca639341-cfa1-4ad6-9a7c-ede9950e46c6"}}, "__type__": "1"}, "e5126c1b-dc03-44f8-9299-a433ced905a1": {"__data__": {"text": "Appendix B: Exercise Answers\nB8595. Make the following changes to the my_playbook.yaml file:\n        ---\n        - name: Create web server\n          hosts: localhost\n          become: yes\n          become_method: sudo\n          become_user: root\n          tasks:\n          - name: Install httpd\n            yum:\n              name: httpd\n              state: present\n6. To run the my_playbook.yaml file again to install the httpd  package, enter the \nfollowing:\n        $ ansible-playbook my_playbook.yaml\n        ...\n        TASK [Install httpd] **************************************\n        changed: [localhost]\n        PLAY RECAP ************************************************\n        localhost: ok=2 changed=1 unreachable=0 failed=0 skipped=0 \nrescued=0 ignored=0\n7. Modify my_playbook.yaml as follows to start the httpd  service, and set it so \nthat it will start every time the system boots:\n        ---\n        - name: Create web server\n          hosts: localhost\n          become: yes\n          become_method: sudo\n          become_user: root\n          tasks:\n          - name: Install httpd\n            yum:\n              name: httpd\n              state: present\n          - name: start httpd\n            service:\n              name: httpd\n              state: started\n8. To run an ansible  command so that it checks whether or not the httpd  service is \nup on localhost , enter the following:\n        $ ansible localhost -m service \\\n              -a \"name=httpd state=started\" --check\n        localhost | SUCCESS => {", "doc_id": "e5126c1b-dc03-44f8-9299-a433ced905a1", "embedding": null, "doc_hash": "f6447480d55bfa4e8f3d2ae1e0af4cd5b65a0b704b6e99b37f0ccd67f7738f14", "extra_info": {"page_label": "874"}, "node_info": {"start": 0, "end": 1531}, "relationships": {"1": "fbc27a12-f526-4efe-94af-e825f8c29333"}}, "__type__": "1"}, "dfa079bd-3fd3-41f4-bb15-3dcd55bceaab": {"__data__": {"text": "Part VII: Appendixes860            \"changed\": false,\n            \"name\": \"httpd\",\n            \"state\": \"started\",\n            \"status\": { ...\n9. To create an index.html  file in the current directory that contains the text \"Web \nserver is up\" and runs the ansible  command to copy that file to the /var/www/\nhtml  directory on localhost , do the following (changing joe to your user name):\n        $ echo \"Web server is up\" > index.html\n        $ ansible localhost\n         -m copy -a \\\n            \"src=./index.html dest=/var/www/html/ \\\n            owner=apache group=apache mode=0644\" \\\n            -b --user joe --become-user root --become-method sudo\n        host01 | CHANGED => { ...\n10. To use the curl  command to view the contents of the file you just copied to the \nweb server, do the following:\n        $ curl localhost\n        Web server is up\nChapter\u00a030: Deploying Applications as Containers \nwith Kubernetes\n1. To gain access to a Minikube instance, either:\na. Install Minikube as described here: https://kubernetes.io/docs/tasks/\ntools/install-minikube , or\nb. Access an available remote Minikube instance, such as through the Kubernetes.\nio tutorials: https://kubernetes.io/docs/tutorials/\n2. To view the versions of your Minikube installation, kubectl  client, and Kuber -\nnetes service, enter the following:\n$ minikube version\n$ kubectl version \n3. To create a deployment that manages a pod running the hello-node  container \nimage, enter the following:\n$ kubectl create deployment hello-node \\\n    --image=gcr.io/hello-minikube-zero-install/hello-node\n4. To view the hello-node  deployment and describe the deployment in detail, enter \nthe following:\n        $ kubectl get deployment\n        $ kubectl describe deployment hello-node", "doc_id": "dfa079bd-3fd3-41f4-bb15-3dcd55bceaab", "embedding": null, "doc_hash": "6d2cb45713cfaf89036467aca3b22a3c3c60cd8735214e8ac61d0243ebff01f7", "extra_info": {"page_label": "875"}, "node_info": {"start": 0, "end": 1751}, "relationships": {"1": "5b6365a0-9a0e-423c-89df-5bf0ae10728b"}}, "__type__": "1"}, "b0c06f5d-0de4-4029-a0a0-65fdc2545907": {"__data__": {"text": "Appendix B: Exercise Answers\nB8615. To view the current replica set associated with your hello-node  deployment, \nenter the following:\n        $ kubectl get rs\n6. To scale up the hello-node  deployment to three (3) replicas, enter the following:\n        $ kubectl scale deployments/hello-node --replicas=3\n7. To expose the hello-node  deployment outside of the Kubernetes cluster using \nLoadBalancer , enter the following:\n        $ kubectl expose deployment hello-node \\\n             --type=LoadBalancer --port=8080\n8. To get the IP address of your Minikube instance and port number of the exposed \nhello-node  service, enter the following:\n        $ minikube ip\n        192.168.39.150\n        $ kubectl describe service hello-node | grep NodePort\n        NodePort:                 <unset>  31302/TCP\n9. Use the curl  command to query the hello-node  service, using the IP address \nand port number from the previous step. For example:\n        $ curl 192.168.39.105:31302\n        Hello World!\n10. To delete the hello-node  service and deployment and then stop the Minikube \nvirtual machine, enter the following:\n        $ kubectl delete service hello-node\n        $ kubectl delete deployment hello-node\n        $ minikube stop", "doc_id": "b0c06f5d-0de4-4029-a0a0-65fdc2545907", "embedding": null, "doc_hash": "3b922652cf522235df33df6ed788fbb6a8e7f944f69b13ce0dee491d9739d159", "extra_info": {"page_label": "876"}, "node_info": {"start": 0, "end": 1226}, "relationships": {"1": "16b9dee1-83f2-4077-b0c2-c105b5bc1089"}}, "__type__": "1"}, "e76ca2df-f6b1-4208-8742-3c7991d83141": {"__data__": {"text": "863Index\n( (left parenthesis), 78\n< (less than), 78\n\u2019 (backtick), 80\n? (question mark), 99\n& (ampersand character), 78\n; (semicolon), 78\n) (right parenthesis), 78\n| (pipe character), 78\u201379\n; (semicolon), 79\n{ } (curly braces), 101\n~ (tilde) in commands, 97\n# shell prompt, 63\n$ shell prompt, 63\n> (greater than), 78\n3D desktop effects, AIGLX, 54\u201357\nA\nabsolute path, 96\nACLs (Access Control Lists)\ndirectories, 267\nenabling, 265\u2013266\nrestricted deletion directory, 268\u2013269\nset GID directory, 267\u2013268\nsetfacl  command, 262\u2013264\nsetting, 262\u2013264\ndefault, 264\u2013265\nAD (Active Directory), 712\nad-hoc commands, Ansible, 760\u2013762\nadministrative commands\n/bin  directory, 179\n/sbin,  178\n/usr/bin  directory, 179\n/usr/sbin,  179\nadministrative privileges, 168\nadministrative utilities, 4\u20135\nAIGLX (Accelerated Indirect GLX), 54\u201357\nAlcatel-Lucent, 9\nalias  command, 81\u201383\naliases, 71\ncompletion, 75\ncreating, 81\u201383network interfaces, 360\u2013361\nusing, 81\u201383\naliases  file, 181\namanda,  566\nAmazon EC2, cloud images, 744\u2013746\nampersand character ( &), 78\nanaconda, Linux installation, 205\nAnaconda installer, 17\nanonymous FTP server, 456\nAnsible, 749\nad-hoc commands, 760\u2013762\napplications, deployment, 749\ncontainers, 749\u2013750\ndeployment\nprerequisites, 754\nSSH keys, 754\u2013755\nhost systems, configuring, 749\ninfrastructure, 749\ninstallation\nauthentication, 757\ninventories, 756\u2013757\nplaybook creation, 757\u2013758\nplaybook running, 758\u2013760\ninventories, 751\u2013752\noperators, 749\u2013750\nplaybooks, 749\nimports, 753\nincludes, 753\nmodules, 752\u2013753\nplays, 752\nroles, 753\ntasks, 752\nAnsible Tower, 762\u2013763\nantivirus software, 591\nApache HTTPD web server, 427\u2013428, 432\u2013433\naccess denied error, 452\nconfiguration files\ndefault settings, 438\u2013440\ndirectives, 435\u2013436, 435\u2013438\nhttpd  package, 428\u2013431\nindex not found error, 452\ninstalling, 431\nLinux\u00ae Bible , Tenth Edition. Christopher Negus. \n\u00a9 2020 John Wiley & Sons, Inc. Published 2020 by John Wiley & Sons, Inc.", "doc_id": "e76ca2df-f6b1-4208-8742-3c7991d83141", "embedding": null, "doc_hash": "30517150c5d7129cc03dd3b2621110e596f44e04c53d8c4ee9aa37bc3ba2b40b", "extra_info": {"page_label": "877"}, "node_info": {"start": 0, "end": 1923}, "relationships": {"1": "b0aa9b53-05a7-4e82-b2fa-e483014b4584"}}, "__type__": "1"}, "841821c6-f54d-4250-a40c-ea041358d2df": {"__data__": {"text": "Index\n864security\nfile ownership, 433\nfile permissions, 433\nfirewalls, 433\u2013434\nSELinux and, 434\u2013435\nSSL/TLS and, 443\u2013445\ncertificate signing request, 448\u2013449\nself-signed certificates, 447\u2013448\nSSL configuration, 445\u2013447\nSSL key generation, 447\u2013448\ntroubleshooting\nconfiguration errors, 449\u2013451\nerrors, accessing, 451\u2013452\nuser published content, 442\u2013443\nvirtual hosts, 440\u2013442\napplets, GNOME, 51\napplication-layer firewalls, 674\napplications\nAnsible, 749\u2013750\ndeploying as containers, 765\u2013783\naptitude  command, 226\narguments, commands, 67\u201368\narithmetic\nexpressions, expanding, 80\ninteger arithmetic, 152\u2013153\nshell scripts, 152\u2013153\nASF (Apache Software Foundation), 428\nash shell, 61\nAT&T, 8\naudits, 595\u2013596\nnetwork services, 663\u2013665\nnmap  utility, 665\u2013672\nports, 666\nauthentication, 4\ncloud, 712\nkey-based, Secure Shell tools, 324\u2013326\nPAM\ncontexts, 619\u2013620\ncontrol flags, 620\u2013621\nmodules, 621\u2013622\npublic key, 313\nauthor rights, GPL and, 12\nautofs\nhome directory automount, 518\u2013520\n/net  directory, 517\u2013518\nautomation, Ansible Tower and, 762\u2013763\nAWS (Amazon Web Services), 694B\nbackground commands, 79\nbackground processes, 137\u2013140\nbacktick ( \u2019 ), 80\nbackup script, 162\nbackup utilities, 566\nbase image, 696\ncontainer image, 694\nbash shell, 61, 148\nconfiguration files, 84\ncut command, 159\ngrep,  159\nprompt, characters, 86\nsed command, 160\ntext manipulation, 159\u2013161\ntr command, 160\nvariables, untyped, 152\u2013153\nbashrc  file, 181\nBell labs, 7\u20138\nBell-LaPadula Mandatory Access security model,  \n639\nBerkeley distribution, 9\u201310\nbigcommand  process, 141\n/bin  directory, 94\nBIOS (Basic Input Output System), 526\u2013528\nbond0  interface, 362\nbonded network interfaces, 362\nBooleans, SELinux, 653\u2013654\n/boot  directory, 94\nboot loaders\nGRUB (GRand Unified Bootloader), 528\u2013530\ninstallation, 217\u2013218\ntroubleshooting, 528\u2013530\nGRUB 2, 530\u2013531\ntroubleshooting, 530\u2013531\nboot options\nfeature disable, 210\nkickstarts, 211\u2013212\nmediacheck,  212\nrescue mode, 212\nspecial installation, 210\u2013211\nvideo problems, 210\nboot order, troubleshooting, 527\u2013528\nboot up, 523\u2013524\nfrom firmware, 526\u2013528\nGRUB 2 boot loader, 530\u2013531\nGRUB boot loader, 528\u2013530Apache HTTPD web server (continued)", "doc_id": "841821c6-f54d-4250-a40c-ea041358d2df", "embedding": null, "doc_hash": "d0a0d6b91a6b0462ff45e5cd304d9dda44395daa38d502944e0ae2379a14f930", "extra_info": {"page_label": "878"}, "node_info": {"start": 0, "end": 2156}, "relationships": {"1": "08697dc2-a7cd-4496-8e7d-c8f20224ca25"}}, "__type__": "1"}, "12fb9219-dbdf-48b4-9461-618bb847b98c": {"__data__": {"text": "Index\n865kernel startup, 532\u2013541\nstartup methods, 524\ninit  facility, 524\u2013525\nsystemd  facility, 525\nfrom USB drive, 791\u2013792\nbounties, software, 21\nBourne, Stephen, 61\nBourne shell, 61\nbrace expansion metacharacters, 101\nbrowser-based admin tools, 173\nBSD (Berkeley Software Distribution), 10, 12\u201313\nFreeBSD, 13\ninit  daemon, 371\u2013377\nNetBSD, 13\nOpenBSD, 13\nbuilt-in commands, 71\nC\nC programming language, 9\nCaesar Cipher, 602\ncase  command, 156\u2013157\ncd command, 96\u201397\nCDs/DVDs, burning, 792\u2013795\nCeph, 5\ncertification, 21\u201322\nRHCE (Red Hat Certified Engineer), 21, 22\ntopics, 23\u201325\nRHCSA (Red Hat Certified System \nAdministrator), 21, 22\ntopics, 22\u201323\ncgroups, 143\u2013144, 695\nchage  command, 72\nchkconfig  command, 385\u2013386\nchkrootkit,  592\nchmod  command, 100, 106\u2013108, 162\nchronyd  package, 309\nCIFS (Common Internet File System), 475\u2013476\nCISA (Cybersecurity and Infrastructure Security \nAgency), 596\nclasses\nimplicit, 404\nprinter classes, 404, 408\nclassification level, 639\ncloning, cloud instances, 734\u2013738\ncloud, 3\u20134\nhybrid, 731\nhypervisors, 710, 713configuring, 715\u2013718\nsetup, 714\nimages\nAmazon EC2, 744\u2013746\nOpenStack and, 739\u2013744\ninstances, 730\ncloning, 734\u2013738\ninvestigating, 733\u2013734\nnetworking, setup, 714\nplatforms, 712\nprivate, 730\npublic, 730\nstorage, 711\nconfiguring, 718\u2013720\nsetup, 714\nshared, 713\nvirtual machines, 713\ncreating, 720\u2013724\ncloud computing, 5\nauthentication, 712\nconfiguration, 712\ncontrollers, 711\ndeployment, 712\ncloud-based installations, 204\u2013205\ncloud-init,  730\nconfiguring, 731\u2013733\nenterprise computing, 738\nrunning, 731\u2013733\nclustering, 5\ncnegus-test-project,  739\nCockpit, 168, 169\u2013171, 249\u2013252\nfirewall rules, 677\u2013678\nstorage management and, 301\u2013303\ncommand languages, shell and, 62\ncommand-line\nargument, 148, 150\u2013151\ncompletion, 75\u201376\nediting, 73\u201375\nnetwork configuration, nmtui  command, 354\nNetworkManager TUI, editing connection, 354\u2013355\nrecall, 76\u201378\ncommands, 418\n\u2019 (backtick), 80\n~ (tilde), 97\nad-hoc (Ansible), 760\u2013762\nadministrative\n/sbin,  178\n/usr/sbin,  179", "doc_id": "12fb9219-dbdf-48b4-9461-618bb847b98c", "embedding": null, "doc_hash": "6173a2ec8b6dcb56a12f8d147762519aa8de636cfc5f0ccf74a55427e9147eac", "extra_info": {"page_label": "879"}, "node_info": {"start": 0, "end": 2000}, "relationships": {"1": "6cacc18f-9059-4dce-b72e-532d10024dda"}}, "__type__": "1"}, "2f4dbc75-c49d-4c21-b5d6-7d4ba1e10b1e": {"__data__": {"text": "Index\n866alias,  81\u201383\naliases, 71\naptitude,  226\narguments, 67\u201368\nbackground, 79\nbuilt-in, 71\ncase,  156\u2013157\ncd, 96\u201397\nchage,  72\nchkconfig,  385\u2013386\nchmod,  100, 106\u2013108, 162\ncompletion, 75\nconnecting, 78\u201381\ncp, 110\ncryptsetup,  612\ncut,  159\ndate,  66\ndf, 334\ndu, 334\u2013335\nexpanding, 78, 80\nexportfs,  507\nfiles, 96\u201398\nfilesystem, 71\nfind,  122\u2013128, 335\u2013336\nfirewall-config,  674\u2013675\nfunctions, 71\ngedit,  113\u2013114\ngrep,  128\u2013129\ngroupadd,  260\u2013261\nhelp,  88\nhere text, 100\nhistory, 72\u201378\nhistory,  72\u201378\nid, 69\ninfo,  89\ninformation about, 88\u201390\njournalctl,  184\nkill,  140\nkillall,  140, 141\u2013142\nlftp,  470\u2013472\nlocate,  72, 120\u2013122\nlocating, 70\u201372\nlp, 419\nlprm,  419\u2013420\nlpstat,  419\nls, 67\u201368, 101\u2013105\nman,  89\nmkfs,  300\nmount,  297\u2013298mv, 109\u2013110\nnice,  142\u2013143\nnmtui,  354\none-command actions, 156\noptions, 67\u201368\npath, 70\npipe ( | )metacharacter, 78\u201379\npodman,  694, 697\nps, 132\u2013134\npwd,  67\nrenice,  142\u2013143\nreserved words, 71\nrm, 110\nrpm,  241\u2013245\nrunning, 66\u201372\nsar,  332\u2013333\nsecon,  648\u2013649\nsed,  160\nsequential, 79\nsetfacl,  262\u2013264\nsftp,  324\nssh,  316\nsu, 168, 175\u2013176\nsudo,  168\nsyntax, 67\u201370\nsystemctl,  381\ntelinit,  374\ntext formatting, 79\ntop,  134\u2013135\ntouch,  98\u201399\ntr, 160\ntype,  71\numount,  299\nuseradd,  252\u2013255\nuserdel,  258\u2013259\nusermod,  257\u2013258\nvirsh,  711\nvirt-install,  720\u2013721\nvirt-manager,  714\nvirt-viewer,  714\nwho am i, 65\nyum,  229\u2013232, 233\u2013241\nCompiz, 55\ncompliance reviews, 595\u2013596\ncompute nodes, 710. See also  cloud hypervisors\nconfiguration\ncloud, 712\nhypervisors, 715\u2013718\nstorage, 718\u2013720\nfiles, 310commands (continued)", "doc_id": "2f4dbc75-c49d-4c21-b5d6-7d4ba1e10b1e", "embedding": null, "doc_hash": "db2c0f2474c1ac86a2374d627447012e856632be02c6219f9416009410f02717", "extra_info": {"page_label": "880"}, "node_info": {"start": 0, "end": 1559}, "relationships": {"1": "25e4d2b9-ee8d-4154-ad29-90ece83bf9f6"}}, "__type__": "1"}, "52b88dc7-18b3-416c-b38a-75f477c4b163": {"__data__": {"text": "Index\n867administrative, 179\u2013185\nplain-text files, 179\nsecurity, 314\nservers, 310\u2013311\nconfiguration files, 310\ndefault configuration, 310\u2013311\nconnecting commands, 78\u201381\nconnectionless protocols, UDP, 666\ncontainer registries, 694, 695\u2013696\nimages\npushing to, 705\u2013706\ntagging, 705\u2013706\ncontainers, 693\u2013694\nAnsible, 749\u2013750\nin enterprise, 706\nFTP, GitHub and, 703\u2013705\nimages, 694\nbase image, 694, 696\nbuilding, 702\u2013703\nRPM packages and, 246\nnamespaces, 694, 695\npulling, 697\u2013698\nrunning FTP servers, 699\u2013701\nrunning shells, 698\u2013699\nsidecar, 766\nstarting/stopping, 701\u2013702\ncontrol plane, 336\ncopying files, 110\ninteractive copying, 324\nscp command, 321\u2013324\ncopyrights, GPL and, 12\ncp command, 110\ncpio,  566\nCPU (computer processing unit), 273\ncracklib,  571\ncron,  software updates and, 545\ncrontab  file, 182\ncryptographic ciphers, 602\u2013603\ncryptography, 599\u2013600\nasymmetric keys, 604\u2013605\nblock ciphers, 600\ncipher keys, 603\u2013608\nciphers, 600\ndecryption, 600\ndigital signatures, 608\u2013610\nemail message encryption, 607\u2013608\nencryption/decryption\ncipher keys, 603\u2013608\nciphers, 602\u2013603\ndigital signatures, 608\u2013610hashing, 600\u2013601\nimplementing\ndirectories, 613\u2013615\nencryption from desktop, 617\u2013618\nfile encryption, 616\nfile integrity, 610\u2013611\nfilesystem encryption, installation, 611\u2013613\ntools, 616\u2013617\nkey pair generation, 605\u2013606\npublic key sharing, 607\nstream ciphers, 600\nsymmetric keys, 603\u2013604\ntar archive files, 604\ntools, 617\ncryptsetup  command, 612\ncsh (C shell), 61, 65\ncsh.cshrc  file, 182\nCUPS (Common UNIX Printing System), 403\u2013404\nconfiguring\nfrom a browser, 404\nmanual, 404, 417\u2013418\nprinter drivers, 404\nprinters, adding automatically, 405\u2013406\nprinting to from Windows, 405\nremote printers, 413\nserver\nconfiguring, 415\u2013416\nstarting, 417\nshared printers, 420\u2013422\nweb-based administration, 406\nautomatic detection, 407\u2013408\nremote administration, 406\u2013407\ncurly braces (), 101\ncut command, 159\ncutting text, 159\nCVE (Common Vulnerabilities and Exposures), 580\nD\nDAC (Discretionary Access Control), 635\u2013636\ndaemon processes, 5, 179, 307. See also  services\napache,  185\navahi,  185\nbin,  185\nchrony,  185\nconfiguration files, 311\nlp, 185\nnews,  186\npermissions and, 311\nport numbers, 311", "doc_id": "52b88dc7-18b3-416c-b38a-75f477c4b163", "embedding": null, "doc_hash": "d756674f63324d67bb886919b5ad8a0f68057b2f16b3629c23f029a8d359d2cb", "extra_info": {"page_label": "881"}, "node_info": {"start": 0, "end": 2186}, "relationships": {"1": "593d8f1e-9941-4dc9-886b-0eb9f2efe722"}}, "__type__": "1"}, "a036e6fa-8e38-4d88-9162-7dc63ee5e520": {"__data__": {"text": "Index\n868postfix,  185\nrpc,  186\nservices, 369\ndash  shell, 61, 65\ndatasources, 738\ndate  command, 66\nDEB packaging, 225\nUbuntu Software Center, 225\nDebian, 19\ndebugging, shell scripts, 148\ndependencies, 369\ndependent software, 224\ndeployment, automatic, 336\ndesktop. See also  GNOME; GNOME 2; GNOME 3; X \nWindow System\n3D effects, AIGLX, 54\u201357\nGNOME, 29, 30\nGNOME 3, 31\nKDE (K Desktop Environment), 29\nLXDE (Lightweight X11 Desktop Environment),  \n29\nwindow manager, 29\nXfce, 29\ndesktop networking\nconfiguring, NetworkManager, 340\u2013342\nNetworkManager, 340\u2013342\n/dev  directory, 94\ndf command, 334\nDHCP, 340\u2013341\ndigital signatures, 608\u2013610\ndirectories\n/bin,  94\n/boot,  94\n/dev,  94\nencrypting, 613\u2013615\n/etc,  94, 180\n/etc/cron,  180\n/etc/cups,  180, 405\n/etc/default,  180\n/etc/exports,  504, 505\n/etc/httpd,  181\n/etc/mail,  181\n/etc/postfix,  181\n/etc/ppp,  181\n/etc/rc?.d,  181\n/etc/security,  181\n/etc/skel,  181\n/etc/sysconfig,  181/etc/systemd,  181\n/etc/X11,  183\n/etc/xinetd.d,  181\nhard drive partitions, 216\nhierarchy, 94\n/home,  94\nidentifying, 104\n/lib,  94\nlisting, 101\u2013105\n/media,  94\n/misc,  94\n/mnt,  94\nnumber of characters, 103\n/opt,  94\npaths, 70\nabsolute path, 96\norder, 71\n/proc,  95\nrestricted deletion directory, 268\u2013269\nroot, 93\n/root,  95\n/sbin,  95\n/sys,  95\ntime and date column, 103\n/tmp,  95\n/usr,  95\n/var,  95\ndisaster recovery, security, 566\ndisk images, mounting in loopback, 298\u2013299\ndisk space, 197\ndisk storage, 273\ndistributions\ncomponents, 16\nDEB packaging, 225\nDebian, 19\nFedora, 18\u201319\nGPL and, 12\nRed Hat\nAnaconda installer, 17\ngraphical administration, 17\nRPM package management, 16\u201317\nRed Hat OpenShift, 18\nRed Hat OpenStack Platform, 18\nRHEL (Red Hat Enterprise Linux), 17\u201318\nRPM packaging, 225\nUbuntu, 19\nDNF (Dandified YUM), 229\nDocker, 697\ndocker  command, 694, 697daemon processes (continued)", "doc_id": "a036e6fa-8e38-4d88-9162-7dc63ee5e520", "embedding": null, "doc_hash": "27ed20cab14353c3c5bce10628f6266c2efe9055c242db5385b9d02baeb9904f", "extra_info": {"page_label": "882"}, "node_info": {"start": 0, "end": 1837}, "relationships": {"1": "c1e78ff3-2b09-4b18-b428-614d19edb7c6"}}, "__type__": "1"}, "43b06d07-9204-4c4b-a246-0b23c5af24ed": {"__data__": {"text": "Index\n869docker  daemon, 694\nDocker Desktop, 768\nDocker Hub, 696\nDocker project, 694\ndrivers, printer drivers, 404\ndu command, 334\u2013335\ndual booting, 208\u2013209\ndumb terminals, 137\ndump/restore, 566\nDVD, installing Linux, 196\nDVD drive, 197\nE\necho  statement, 148\necryptfs,  613\u2013615\nemacs  editor, 114\nemail, encrypting messages, 607\u2013608\nencryption/decryption\ncipher keys\nasymmetric keys, 604\u2013605\nemail message encryption, 607\u2013608\nkey pair generation, 605\u2013606\npublic key sharing, 607\nsymmetric keys, 603\u2013604\ntar archive files, 604\nciphers, 602\u2013603\ndigital signatures, 608\u2013610\nenterprise\ncloud-init,  738\ncontainers and, 706\ninstalling Linux, 196\nnetwork configuration\nLinux as DHCP server, 365\nLinux as DNS server, 365\u2013366\nLinux as proxy server, 366\nLinux as router, 364\nSamba and, 497\nserver management, 336\nsoftware management, 245\u2013246\nuser management, 261\nACLs (Access Control Lists), 262\u2013269\npermission setting, 262\u2013269\nenterprise networking, 340\nenvironment variables, 81, 82\u201383\nPATH, 70\nshell, adding, 87\nescaping shell characters, 149\n/etc  directory, 94aliases  file, 181\nbashrc  file, 181\ncrontab  file, 182\ncsh.cshrc  file, 182\nexports  file, 182\nfstab  file, 182\ngroup  file, 182\ngshadow  file, 182\nhost.conf  file, 182\nhostname  file, 182\nhosts  file, 182\ninittab  file, 182\nmtab  file, 182\nmtools.conf  file, 182\nnamed.conf  file, 182\nnsswitch.conf  file, 182\nntp.conf  file, 182\npasswd  file, 182\nprintcap  file, 183\nprofile  file, 183\nprotocols  file, 183\nrpc file, 183\nrsyslog.conf  file, 183\nservices  file, 183\nshadow  file, 183\nshells  file, 183\nsudoers  file, 183\nxinetd.conf  file, 183\n/etc/cron  directory, 180\n/etc/cups  directory, 180, 405\n/etc/default  directory, 180\n/etc/exports  file\nconfiguring, 504\nhostnames, 505\u2013506\nnfsnobody,  506\noptions, 506\nroot user, 506\nuser mapping options, 506\n/etc/fstab  file, mountable file systems, 295\u2013297\n/etc/hostname  file, 358\n/etc/hosts  file, 358\n/etc/httpd  directory, 181\n/etc/mail  directory, 181\n/etc/nsswitch.conf  file, 359\u2013360\n/etc/postfix  directory, 181\n/etc/ppp  directory, 181\n/etc/rc?.d  directory, 181\n/etc/rc.d/init.d  directory, 375\u2013376\n/etc/resolv.conf  file, 359", "doc_id": "43b06d07-9204-4c4b-a246-0b23c5af24ed", "embedding": null, "doc_hash": "3bfa12bca6ce3a601eb39c4b46f6963e22b395d774d77da318e555d355aa855a", "extra_info": {"page_label": "883"}, "node_info": {"start": 0, "end": 2143}, "relationships": {"1": "c585a92a-13ce-4d60-a974-f4345ab5224e"}}, "__type__": "1"}, "8a4b33d7-afa5-4875-849c-e4f8ec309402": {"__data__": {"text": "Index\n870/etc/samba/smb.conf  file\n[global],  486\u2013487\n[homes],  486, 487\u2013489\n[printers],  486, 489\u2013493\n/etc/security  directory, 181\n/etc/services  file, 663\u2013664\n/etc/skel  directory, 181\n/etc/sysconfig  directory, 181\n/etc/sysconfig/network  file, 358\n/etc/systemd  directory, 181\n/etc/X11  directory, 183\n/etc/xinetd.d  directory, 181\neth0  interface, 362\nEthernet, 339\nchannel bonding, 361\u2013362\nExecute permissions, 106\nexercise answers\nAnsible, 858\u2013860\napplication automation, 858\u2013860\ncloud computing, 855\u2013856\ndeploying to cloud, 857\nshifting to, 853\u2013854\ndesktop creation, 797\u2013800\ndisk management, 819\u2013821\nfile management, 819\u2013821\nfilesystem, 802\u2013803\nFTP server configuration,  \n835\u2013838\ninfrastructure automation, 858\u2013860\nKubernetes, 860\u2013861\nLinux installation, 812\u2013813\nnetwork administration, 825\u2013827\nNFS file server configuration, 841\u2013843\nprint server configuration, 829\u2013831\nprocesses, running, 805\u2013807\nSamba server configuration, 838\u2013841\nsecurity\nadvanced, 847\u2013849\nbasic, 845\u2013847\nnetwork security, 851\u2013853\nSELinux and, 849\u2013851\nserver administration, 822\u2013825\nservices, starting/stopping, 827\u2013829\nshell, 800\u2013802\nshell script writing, 807\u2013810\nsoftware acquisition, 814\u2013815\nsoftware management, 814\u2013815\nsystem administration, 810\u2013812\ntext files, 804\u2013805\ntroubleshooting, 843\u2013845user account management, 815\u2013819\nweb server configuration, 831\u2013835\nexiting shell, 83\u201384\nexpanding commands, 78, 80\nexpanding parameters, 151\u2013152\nexpanding variables, 80\u201381\nexportfs  command, 507\nexporting shared filesystems, 507\nexports  file, 182\nexports  man page, 504\nexpressions\narithmetic, expanding, 80\ntest expressions, 154\noperators, 155\u2013156\nextended memory, 4\nF\nFCoE (Fibre Channel over Ethernet Devices), 213\nFedora, 18\u201319, 27\ndownloading, 788\u2013789\ninstalling from Live media\nbare metal system, 198\nmulti-boot, 198\nsingle-boot, 198\nvirtual system, 198\nTerminal window, 64\nFibre Channel, 5\nfile-matching metacharacters, 98\u201399\nfilenames, shell scripts, 148\nfile-redirection metacharacters, 99\u2013100\nfiles\ncommands, 96\u201398\ncopying, 110\nscp command, 321\u2013324\nencrypting, 616\nlisting, 101\u2013105\nmoving, 109\u2013110\nNautilus, 42, 43\nfilesystem organization, 42\u201343\nownership\nApache web server, 433\nchanging, 109\npassword files, 574\u2013576\npermissions, 105\u2013106\nApache web server, 433\nchanging, chmod,  106\u2013108\ndefault, 108\u2013109\nerrors, 452\nExecute, 106", "doc_id": "8a4b33d7-afa5-4875-849c-e4f8ec309402", "embedding": null, "doc_hash": "0bcc51410aab2a6ce1780acb3828a8dacc77b93b8bf9586f99999206350a93f3", "extra_info": {"page_label": "884"}, "node_info": {"start": 0, "end": 2319}, "relationships": {"1": "1560dae4-3c1f-41ac-98a5-59587b8248d7"}}, "__type__": "1"}, "412e27e8-8143-45c8-89db-16268c269701": {"__data__": {"text": "Index\n871Read, 106\nvsftpd,  465\nWrite, 106\nremoving, 110\nsearching for\nby date and time, 125\u2013126\nfind  command, 122\u2013128\ngrep command, 128\u2013129\nlocate  command, 120\nby name, 123\u2013124\n-not,  126\u2013127\n-or,  126\u2013127\nby permission, 125\nby size, 124\nby user, 124\nfilesystems, 4, 93, 273, 275, 500\ncommands, 71, 96\u201398\ncreating, 300\ndirectories, 94\nencryption at installation, 611\u2013613\nLinux compared to Windows-based,  \n95\nmounting, 291\u2013293\nautofs,  on demand, 517\u2013520\ndefining mountable systems, 295\u2013297\n/etc/fstab  file, 295\u2013297\nmount  command, 297\u2013298\nNFS, 512\u2013520\noptions, 515\u2013517\nswap areas\ndisabling, 294\u2013295\nenabling, 293\u2013294\nNautilus organization, 42\u201343\nnoauto,  514\u2013515\npartitions, 273\nroot directory, 93\nsecurity\ndangerous permissions, 576\u2013577\nlockdown, 578\u2013579\nsecuring files, 577\u2013578\nshared, exporting, 507\nsystem administrator and, 168\nfilter  table, 678\nfind  command, 122\u2013128, 335\u2013336\nFirefox, FTP access, 470\nfirefox  package, 227\nFirewall Configuration window, 509, 674\u2013675\nfirewall-config  command, 674\u2013675\nfirewalld  service, 674\u2013675, 675\u2013677\nfirewalls, 313, 672\u2013674Apache web server, 433\u2013434\napplication-layer firewalls, 674\nimplementing, 674\u2013688\niptables, 673\niptables,  313\nnetwork-layer firewalls, 674\nrules, Cockpit and, 677\u2013678\nSamba, 482\u2013483\ntroubleshooting and, 552\u2013553\nfirmware\nRAID devices, 213\nstarting from, 526\u2013528\nfolders, Nautilus, 42, 43\ncreating, 43\nHome folder, 42\nfor...do  loop, 157\u2013158\nforeground processes, 137\u2013138\ncommands, 139\u2013140\nFOSS (Free and Open Source Software), 12, 666\nfree distribution, GPL and, 12\nfree software, 12\nFree Software Directory, 12\nFreeBSD, 13\nFSF (Free Software Foundation), 11\nfstab  file, 182\nFTP (File Transfer Protocol), 455\u2013456\nactive connection, 456\nclients, 469\u2013473\ncommand-oriented clients, 456\ncontainers, GitHub and, 703\u2013705\npassive connection, 456\nserver, 309\naccessing, 470\u2013472\nanonymous, 456\nfirewall, 461\u2013463\ngFTP client, 472\u2013473\ngraphical tools, 456\nSELinux, configuring, 463\u2013465\nuploading, allowing, 467\u2013468\nuser access, setup, 465\u2013466\nvsftpd,  457\u2013461\nservers, running from container, 699\u2013701\nfunctions, 71\ncompletion, 75\nG\ngconf-editor,  173\ngedit  command, 113\u2013114\ngeneral regular expression print. See  grep command", "doc_id": "412e27e8-8143-45c8-89db-16268c269701", "embedding": null, "doc_hash": "b50b6cb929df938a1a85c9d201801806c52ad957cf149dfc7f66b9413f621a4d", "extra_info": {"page_label": "885"}, "node_info": {"start": 0, "end": 2190}, "relationships": {"1": "1d8bffc0-70c5-4588-998b-7d76637ccb23"}}, "__type__": "1"}, "346383ba-907b-4272-af20-7f1121950fa8": {"__data__": {"text": "Index\n872Gentoo, 16, 207\ngFTP client, 472\u2013473\nGibson Research Corporation, 596\nGitHub, FTP containers, 703\u2013705\nGlusterFS, 5\nGNOME, 30\u201331\nGNOME 2\nAppearances Preference, 49\nCompiz, 46\nGNOME panels, 47\nMetacity, 46, 48\u201349\nNautilus, 46\npanels, 50\nadding, 52\napplets, 51\napplication launcher, 52\u201353\nApplications menu, 51\ndrawers, 53\nmoving items, 50\nproperties, 54\nresizing items, 51\nSystem menu, 51\nWindow list, 51\nPreferences, 47\nGNOME 3, 31\napplications, 41\nadditional, 34\nlaunching, 37\u201338\nopening, 32\nApplications view, 37\nBluetooth, 39\nbootup, 31\ncommands, launching, 37\u201338\ndash, 36\ndevices, 39\nkeyboard, Windows key, 36\nNautilus\nfiles, 42\u201343\nfolders, 42, 43\nFTP with login, 43\nPublic FTP, 43\nremote content, 43\nRhythmbox, 45\u201346\nSecure (HTTPS), 43\nsoftware, 43\u201345\nSSH and, 43\nWebDav (HTTP), 43\nWindows share, 43\nnavigation\nkeyboard, 36\u201338\nmouse, 32\u201335networking, 39\nsearches, 37\nset up, 38\u201339\nshell extensions, 39\u201340\nsound, 39\nstopping, 46\nSystem Settings window, 38\ntoggling, 32\ntop bar, 36\nTweak Tool, 40\u201341\nviews, 36\nwindow menu, 35\nwindows\nactive, 37\nminimized, 33\nopening, 32\nWindows view, 36\nworkspaces, multiple, 34\u201335\nGNOME Terminal, 64\ngnome-disks,  173\ngnome-utils,  173\nGNU (GNU is Not UNIX), 11\u201312\nBSD (Berkeley Software Distribution) License, 15\nLGPL (Lesser General Public License), 15\nMIT license, 15\nMozilla license, 15\u201316\nGNU Project page, 11\nGPL (GNU Public License), 12\ngraphical tools, 172\ngraphical windows, 168\ngraphics, Red Hat, 17\ngreater than (>), 78\ngrep command, 128\u2013129, 159\ngroup accounts, 259\u2013261\ngroup  file, 182\ngroupadd  command, 260\u2013261\ngroups, 249\nGRUB (GRand Unified Bootloader), 217\u2013218, 528\u2013530\ntroubleshooting, 528\u2013530\nGRUB 2 boot loader, 530\u2013531\ntroubleshooting, 530\u2013531\ngshadow  file, 182\nGUID (Globally Unique Identifier), partition tables, 276\nGUIs (graphical user interfaces), 61\nH\nhard drive, partitioning\nassigning to directory, 216\nfilesystem types, 214\nLinux partitions, 215", "doc_id": "346383ba-907b-4272-af20-7f1121950fa8", "embedding": null, "doc_hash": "54deb889d7fdca21044e67d2d8d2ab75d41de14d6404b03fb75ea98626831bef", "extra_info": {"page_label": "886"}, "node_info": {"start": 0, "end": 1923}, "relationships": {"1": "65bc225b-5c4a-4331-b7f0-fe48cb9bb13c"}}, "__type__": "1"}, "ea26042b-9503-41f1-82bb-f8337b2f96c8": {"__data__": {"text": "Index\n873LVM partitions, 215\nmultiple operating systems, 214\nmultiple-partition disks, 281\u2013285\npartition tables, 275\u2013276\nRAID partitions, 215\nsingle-partition disks, 277\u2013281\nswap partitions, 215\nviewing partitions, 276\u2013277\nhardware, 4\nchecking, 187\u2013189\nkernel and, 186\u2013193\nmodules, loadable, 191\u2013193\nremovable, 189\u2013191\nrequirements, 196\u2013197\nhashed passwords, 574\u2013576\nheaders, packet headers, 673\nhelp  command, 88\nhere text, 100\nhierarchy of directories, 94\nhistory  command, 72\u201378\n/home  directory, 94\nhost systems, generic, 336\nhost.conf  file, 182\nhostname\ncompletion, 75\n/etc/exports,  505\nhostname  file, 182\nhosts\nindividual, 505\nIP network, 505\nTCP/IP domain, 505\nhosts  file, 182\nhttpd  daemon, 442\u2013443\nhttpd  package, 310\nhybrid cloud, 731\nhypervisor, 709, 713\nconfiguring, 715\u2013718\nDNS, setup, 718\n/etc/hosts,  editing, 718\nLinux, installing, 716\u2013717\nnaming, 717\nservices, 717\u2013718\nsetup, 714\nI\nid command, 69\nIDS (Intrusion Detection System), 592\u2013595\nif...then  statements, 153\u2013154\nimages, 694\nbuilding, 702\u2013703cloud\nAmazon EC2, 744\u2013746\nOpenStack and, 739\u2013744\nfor clouds, 731\u2013733\ncontainer registries and, 705\u2013706\nvirtual machines, 721\nimplicit classes, 404\nInfiniband, 5\ninfo  command, 89\ninformation about commands, 88\u201390\ninit,  369, 370\u2013371, 371\u2013377, 524\u2013525\nrunlevels, 373\u2013374\nsystemd,  370\u2013371\nSysVinit,  370\ntroubleshooting, 533\ninittab  file, 182\ninput/output redirection, 8\ninstallation\nApache HTTPD web server, 431\nboot options\nfeature disable, 210\nkickstarts, 211\u2013212\nmediacheck,  212\nrescue mode, 212\nspecial installation, 210\u2013211\nvideo problems, 210\ndual booting\ndefragmenting, 209\nhard disk, adding, 208\nWindows partition resize, 208\nGRUB (GRand Unified Bootloader), 217\u2013218\nNFS server, 502\nnmap  utility, 665\u2013666\nSamba, 476\u2013478\nfrom scratch, 207\nservers, 308\u2013310\nsoftware, 221\u2013222\nstorage, specialized, 213\ninstallation server, 206\ninstalling Linux\ncloud based installations, 204\u2013205\nfrom DVD, 196\nRed Hat Enterprise, 201\u2013204\nin enterprise, 196, 205\u2013207\nGRUB (GRand Unified Bootloader), 217\u2013218\nhard drives, partitioning, 214\u2013217\nfrom Live media, 195\nFedora installation, 198\u2013201\nfrom scratch, 207\nvirtualization and, 209\ninteger arithmetic, 152\u2013153", "doc_id": "ea26042b-9503-41f1-82bb-f8337b2f96c8", "embedding": null, "doc_hash": "3307c65e248249bf2af004471836f23825f205f25452710e6623999f0fde77ea", "extra_info": {"page_label": "887"}, "node_info": {"start": 0, "end": 2172}, "relationships": {"1": "107e1562-7713-449e-84dd-fc3b40cb96e3"}}, "__type__": "1"}, "b285d8fc-579c-4be7-8c81-a69c19b9ee59": {"__data__": {"text": "Index\n874interactive copying, 324\ninterfaces, 4\ninterpreter, shell script, 148\nIP (Internet Protocol), 341\naddresses\naliases, setting, 350\u2013351\nmanually setting, 349\u2013350\nroutes, setting, 351\u2013352\nsource, blocking, 684\u2013685\nIP masquerading, 673\nIPC (interprocess communications), 695\nIPP (Internet Printing Protocol), 404\niptables  firewall, 313\niptables  utility, 673, 674, 680\nchains, 679\nconfiguration, saving, 687\u2013688\nDROP,  683\nfilter  table, 678\nmangle  table, 678\nnat table, 678\noptions, 683\npolicies, modifying, 680\u2013683\nport blocking, 685\u2013687\nprotocol blocking, 685\u2013687\nraw table, 678\nrules, modifying, 680\u2013683\nsecurity  table, 678\nsource IP address blocking, 684\u2013685\niSCSI, 5, 213\nISO images, 787\nJ\nJava, JBoss, 18\nJBoss, 18\njournalctl  command, 184\nK\nKali Linux, 595\nKDE (K Desktop Environment), 29\nKerberos, 309, 712\nkernel, 13, 16\nhardware and, 186\u2013193\nring buffer, 532\nstarting, 532\u2013541\nstartup, 532\u2013541\nKernighan, Brian, 9\nkey-based authentication, Secure Shell tools, 324\u2013326\nkeystrokescommand history, 77\u201378\ncommand-line editing, 74\nkickstart files, 206\nboot options and, 211\u2013212\nLinux installation, 205\nRPM packages and, 246\nkillall  command, 141\u2013142\nkilling processes\nkill  command, 140\nkillall  command, 140, 141\u2013142\nKNOPPIX, 16\nksh (Korn shell), 61, 65\nKubernetes, 5, 765\u2013766\naccessing, 769\u2013771\napplications, 767\u2013768\nclusters, 766\ncontainer engines, 767\ncontainers and, 694\nDocker Desktop, 768\ninterfaces, 768\nMinikube and, 766, 768\nstarting, 770\u2013771\nnodes\nmaster node, 766\u2013767\nworker node, 766, 767\nOpenShift and, 782\u2013783\npods, 766\nservices, 766\nsidecar containers, 766\nstorage, 766\ntutorials, 768\nKubernetes Basics Tutorial, 769\u2013770, 771\u2013772\napplication deployment, 772\u2013773\napplications\nexposing, 776\u2013777\nscaling down, 781\u2013782\nscaling up, 779\u2013780\nload balancer, 780\u2013781\npod information, 773\u2013776\nservices\ndeleting, 778\u2013779\nlabeling, 777\u2013778\nKVM (Kernel-based Virtual Machine), 5, 209, 710, 713\nL\nLAMP (Linux, Apache web server, MySQL database, PHP \nweb scripting language) stack, 3\nlaptops, networking, 340\nLDAP (Lightweight Directory Access Protocol), 270, 309", "doc_id": "b285d8fc-579c-4be7-8c81-a69c19b9ee59", "embedding": null, "doc_hash": "b1c43b2f94ea46973dc904342d0db6f2740293f8860879b301477a86a060f8b5", "extra_info": {"page_label": "888"}, "node_info": {"start": 0, "end": 2078}, "relationships": {"1": "67db3404-3718-4854-a347-f3da51c473ca"}}, "__type__": "1"}, "da10c766-d5a9-4ec3-95d5-f65432d136ae": {"__data__": {"text": "Index\n875LDP/LPR printers, 413\nleft parenthesis ( ( ), 78\nless than (<), 78\nlftp  command, 470\u2013472\n/lib  directory, 94\nLibvirt Service Daemon, 713\nlibvirtd  service, 713, 715\u2013718\nlibvirt-daemon-config-network  package,  \n717\nLinux\nbooting from USB drive, 791\u2013792\ncompared to other OSs, 6\nfeatures, 4\u20135\nhistory, 3\nBell labs, 7\u20138\nBSD, 12\u201313\ncommercial UNIX, 9\u201311\nGNU, 11\u201312\nOSI, 14\u201316\nUNIX, 7\u20138\nkernel, 13\nMinix, 7\nas open source UNIX-like OS, 14\nLinux Foundation, 14\nLinux partitions, 215\nlisting\ndirectories, 101\u2013105\nfiles, 101\u2013105\nLive media, installing Linux from, 195\nFedora, 198\u2013201\nlocate  command, 72, 120\u2013122\nlogwatch  service, 331\u2013332\nloopback, mounting disk image, 298\u2013299\nloops\nfor...do,  157\u2013158\nuntil...do,  158\u2013159\nwhile...do,  158\u2013159\nlp command, 419\nlprm  command, 419\u2013420\nlpstat  command, 419\nls command, 67\u201368, 101\u2013105\nLUKS (Linux Unified Key Setup), 612\nLVM (Logical Volume Manager), 273, 274,  \n538\npartitions, 215, 285\ncreating logical volumes, 289\u2013290\ndisplaying, 286\u2013288\nvolume growth, 290\u2013291\nphysical volumes, 273\nLXDE (Lightweight X11 Desktop Environment), 29M\nMAC addresses, 341\nmail server, 309\nman command, 89\nman pages, 502\nexports,  504\nsections, 89\nMandrake, 16\nMandriva, 16\nmangle  table, 678\nmangling packet headers, 673\nmaster nodes, 336\nMBR (Master Boot Record), 275\nMCS (Multi-Category Security), 638\n/media  directory, 94\nmediacheck, 212\nmemory, 4\nOOM condition, 556\npage caches, 558\nprocesses, killing, 558\ntroubleshooting, 553\u2013559\nmetacharacters, 78\nbrace expansion, 101\nfile-matching, 98\u201399\nfile-redirection, 99\u2013100\nmeta-data,  730\nMicrosoft Active Directory. See  AD (Active Directory)\nmigration, VMs, 725\u2013727\nMinikube, 766, 768\nstarting, 770\u2013771\nMinix, 7\n/misc  directory, 94\nmkfs  command, 300\nMLS (multi-level security), 638\u2013639\n/mnt  directory, 94\nmodules\nloaded, listing, 191\u2013192\nloading, 192\nremoving, 192\u2013193\nmonitoring servers\nCockpit, 314\ncrackers, 315\nlogging configuration, 314\nsoftware updates, 315\nsystem activity reports, 314\nmount  command, 297\u2013298\nmounting, 274\ndisk images, in loopback, 298\u2013299\nfilesystems, 291\u2013293", "doc_id": "da10c766-d5a9-4ec3-95d5-f65432d136ae", "embedding": null, "doc_hash": "3f11f8b37f13dd193c71e7ca8fc3b7d164e4a13aecfc59a793a24f4de8e26dca", "extra_info": {"page_label": "889"}, "node_info": {"start": 0, "end": 2073}, "relationships": {"1": "cbcc793c-7a18-4bf7-b7a4-62be1fefcbd4"}}, "__type__": "1"}, "33532678-816f-4ab1-a694-6ced2eb79788": {"__data__": {"text": "Index\n876defining mountable systems, 295\u2013297\n/etc/fstab  file, 295\u2013297\nmount  command, 297\u2013298\noptions, 515\u2013517\nswap areas, 293\u2013295\nunmounting NFS, 520\u2013521\nNFS\nautofs,  on demand mounting, 517\u2013520\nat boot time, 513\u2013517\nmanually, 512\u2013513\numount  command, 299\nmount-level security, 499\nmoving files, 109\u2013110\nMS-DOS filesystems, 95\nMTA (Mail Transport Agent) server, 309\nmtab  file, 182\nmtools.conf  file, 182\nMultics, 8\nmultipath devices, 213\nmultitasking, 167\nmultiuser features, 167\nmv command, 109\u2013110\nN\nnamed.conf  file, 182\nnamespaces, containers, 694, 695\nnano  editor, 114\nnat table, 678\nNautilus\nfiles, 42, 43\nfilesystem organization, 42\u201343\nfolders, 42, 43\ncreating, 43\nHome folder, 42\nFTP with login, 43\nPublic FTP, 43\nremote content, 43\nRhythmbox, 45\u201346\nSecure (HTTPS), 43\nsoftware\ninstalling, 43\u201345\nmanaging, 43\u201345\nSSH and, 43\nWebDav (HTTP), 43\nWindows share, 43\nNCSA (National Center for Supercomputing \nApplications), 428NetBEUI, 475\nNetBSD, 13\nnetfilter/iptables  tables, 678\u2013679\npolicies, 679\u2013680\nrules, 679\u2013680\ntargets, 679\u2013680\nnetwork bridge, VMs, 721\nnetwork cards, 197\nnetwork interfaces\naliases, 360\u2013361\nbonded, 362\nCockpit and, 343\u2013345\ncommand line and, 345\u2013349\nconfiguring\nIP address aliases, 350\u2013351\nIP address manual set, 349\u2013350\nroute setting, 351\u2013352\ndomain names, 349\nhost names, 349\nNetworkManager and, 342\u2013343\nrouting information, 347\u2013348\ntroubleshooting and, 547\u2013548\nviewing, from command line, 345\u2013347\nNetwork Mapper, 665\nnetwork services, auditing, 663\u2013665\nnmap  utility, 665\u2013672\nnetworking\ncloud, setup, 714\nconfiguration\ncommand line, 353\u2013364\nenterprise, 364\u2013366\nfiles, 355\u2013360\ncustom routes, 363\u2013364\ndesktop, 340\u2013353\nenterprise, 340\nEthernet channel bonding, 361\u2013362\nhostnames, troubleshooting and, 549\u2013550\nlaptop, 340\nphysical connections, troubleshooting and, 548\nproxy connections, configuring, 352\u2013353\nroutes\ncustom, 363\u2013364\ntroubleshooting and, 548\u2013549\nservers, 340\ntroubleshooting\nincoming connections, 550\u2013553\noutgoing connections, 547\u2013550\nnetwork-layer firewalls, 674\nNetworkManager, 340mounting (continued)", "doc_id": "33532678-816f-4ab1-a694-6ced2eb79788", "embedding": null, "doc_hash": "11b8b814b96b6f6e2db57dfed5fab6f7c8c510d419cb406b9198424f45ffb7ef", "extra_info": {"page_label": "890"}, "node_info": {"start": 0, "end": 2048}, "relationships": {"1": "7bf8a7c6-8046-4f4a-8850-c41f9a04a11e"}}, "__type__": "1"}, "6bf083d3-b00b-476a-9329-8d89242f7676": {"__data__": {"text": "Index\n877DHCP\nserver response, 340\nservice request, 340\ndomain name server, 341\ngateway, default, 341\nIP address, 341\nlease time, 341\nlocal settings, 342\nnetwork interfaces, activating, 340\nnetwork settings, 350\nsubnet mask, 341\nNetworkManager TUI, connection, editing,  \n354\u2013355\nNFS (Network File System) server, 309, 499\nfilesystems, sharing, 503\u2013507\ninstalling, 502\nmounting\nautofs,  on demand mounting, 517\u2013520\nat boot time, 513\u2013517\nclient, 500\nmanually, 512\u2013513\nsecurity, 508\nfilesystem structure exposure, 508\nfirewall, 508\u2013510\nroot  users, 508\nSELinux configuration, 511\u2013512\nTCP wrappers, 510\u2013511\nunencrypted communications, 508\nuser mapping, 508\nshares, viewing, 512\nunmounting, 520\u2013521\nnfs-server  service, starting, 502\u2013503\nnfs-utils  package, 502\nnice  command, 142\u2013143\nNIS (Network Information Service), 270\ngroups, 506\nnmap  utility\ninstalling, 665\u2013666\nport scans, 666\nport states, 667\nnmbd  service\nstarting, 480\u2013481\nstopping, 481\u2013482\nnmtui  command, 354\nnoauto  filesystem, 514\u2013515\nNokia, 9\nnsswitch.conf  file, 182\nntp.conf  file, 182\nntpd  package, 309O\nOEM (original equipment manufacture), 10\none-command actions, 156\nOOM condition, 556\nopen source, storage platforms\nCeph, 5\nGlusterFS, 5\nOpen Source Development Labs, 14\nopen source software, 12\nOpenBSD, 13\nOpenPGP, 616\nOpenShift, 173\nKubernetes and, 782\u2013783\nopenssh  package, 316\nopenssh-clients  package, 316\nopenssh-server  package, 316\u2013318\nOpenStack, 5\ncloud images, 739\u2013744\nremote access keys, 741\u2013742\nVM access via ssh, 743\u2013744\nVM launch, 742\u2013743\noperators\nAnsible, 749\u2013750\nexpressions, test expressions, 155\u2013156\n/opt  directory, 94\noptions, commands, 67\u201368\nOSI (Open Source Initiative), 14\u201316\nOSs (operating systems), Linux and, 6\noVirt project, 5\nownership of files, 109\nP\npackage collections, 308\npackages\nnfs-utils,  502\nopenssh,  316\nopenssh-clients,  316\nopenssh-server,  316\nservers\ndirectory server, 309\nDNS server, 309\nFTP server, 309\nmail server, 309\nNetwork Time Protocol server, 309\nNFS file server, 309\nprint server, 309\nrsyslog  service, 308\u2013309", "doc_id": "6bf083d3-b00b-476a-9329-8d89242f7676", "embedding": null, "doc_hash": "3fa306767fc5f8f4ba21b632b0c40d9b8990b530cda97b7437ec42a5a3890765", "extra_info": {"page_label": "891"}, "node_info": {"start": 0, "end": 2036}, "relationships": {"1": "8b5128bc-04b2-475d-b054-5c200a69628f"}}, "__type__": "1"}, "e2ba94bb-eda1-4b6f-b7dc-17701554a485": {"__data__": {"text": "Index\n878SQL server, 309\nsystem logging server, 308\u2013309\nweb server, 309\nWindows file server, 309\npacket filters, 674\npacket headers, mangling, 673\npackets, blocking/allowing, 673\nPAM (Pluggable Authentication Module), 312\nadministering\napplication configuring files, 622\u2013623\npassword enforcement, 628\u2013632\nsudo  and, 632\u2013633\nsystem event configuration files,  \n623\u2013626\ntime restrictions, 626\u2013627\nauthentication process, 619\ncontexts, 619\u2013620\ncontrol flags, 620\u2013621\nmodules, 621\u2013622\nresources, 633\nPAM facility, 312\npanels (GNOME), 50\nadding, 52\napplets, 51\napplication launcher, 52\u201353\nApplications menu, 51\ndrawers, 53\nmoving items, 50\nproperties, 54\nresizing items, 51\nSystem menu, 51\nWindow list, 51\nparameters, shell script\nexpanding, 151\u2013152\nreading in, 151\npartition tables, GUID, 276\npartitioning\nfilesystems, 273\nhard drives\nassigning to directory, 216\nfilesystem types, 214\nLinux partitions, 215\nLVM partitions, 215\nmultiple operating systems, 214\nRAID partitions, 215\nswap partitions, 215\nhypervisors and, 717\nLVM (Logical Volume Manager), 285creating volumes, 289\u2013290\ndisplaying, 286\u2013288\nvolume growth, 290\u2013291\nmultiple-partition disks, 281\u2013285\npartition tables, 275\u2013276\nsingle-partition disks, 277\u2013281\nviewing, 276\u2013277\npasswd  file, 182\npasswords, 312\u2013313\nchanging, 571\u2013572\nenforcing best practices, 572\u2013574\nfiles, 574\u2013576\nhashes, 574\u2013576\nPAM, 628\u2013632\npublic key authentication, 313\nselecting, 570\u2013571\nsetting, 571\u2013572\npath, 70\nabsolute, 96\norder, 71\nPATH environment variable, 70, 88\nPE (Physical Extent), 286\npenetration testing, 595\npermissions, 105\u2013106\nchanging, chmod,  106\u2013108\ndaemons and, 311\ndefault, umask  value, 108\u2013109\nerrors, 452\nExecute, 106\nRead, 106\nWrite, 106\npersistent services, enabling, 391\u2013394\nphysical security, 565\u2013566\nPID (process ID), 131, 370\npipe character ( | ), 78\nplain-text files, 179\nplaybooks (Ansible), 749\ncreating, 757\u2013758\nimports, 753\nincludes, 753\nmodules, 752\u2013753\nplays, 752\nroles, 753\nrunning, 758\u2013760\ntasks, 752\npodman  command, 694, 697\nport numbers, daemon processes, 311\nportability, 8\u20139\nports, 666packages (continued)", "doc_id": "e2ba94bb-eda1-4b6f-b7dc-17701554a485", "embedding": null, "doc_hash": "04f027ee1eef207fca140e805c5c9a5564eac8eb39c59a4a2029ab6f3979016d", "extra_info": {"page_label": "892"}, "node_info": {"start": 0, "end": 2073}, "relationships": {"1": "08326ecb-8555-47d4-8f1b-4d2743157c08"}}, "__type__": "1"}, "68c9d971-6d20-4286-be5f-1920ca1e4bc8": {"__data__": {"text": "Index\n879auditing, 666\nblocking, 685\u2013687\nscans\nTCP Connect, 666\nUDP, 666\nstates, 667\npositional parameters, 150\u2013151\nPOSIX (Portable Operating System Interface), 10\nPostgreSQL, 309\nprint server, 309\nconfiguring\nshared CUPS printer, 420\u2013422\nshared Samba printer, 422\u2013424\nPrint Settings window, 403\nlocal printers\nadding, 409\u2013411\nediting, 411\u2013412\nremote CUPS printers, 413\nremote LDP/LPR printers, 413\nremote printers, configuring, 412\u2013413\nremote UNIX printers, 413\nWindows (SMB) printer, 414\u2013415\nprintcap  file, 183\nprinter browsing, 404\nprinter classes, 404\nprinters, adding automatically, 405\u2013406\nprinting. See also  CUPS (Common UNIX Printing System)\ncanceling jobs, 408\ncommands, 418\nlp, 419\nlprm,  419\u2013420\nlpstat,  419\ndrivers, 404\n/etc/cups  directory, 405\nIPP (Internet Printing Protocol), 404\nlisting print jobs, 407\nmoving jobs, 408\nprinter classes, 408\nUNIX print commands, 404\nviewing printers, 408\nprivate cloud, 730\nprivate key cryptography, 603\n/proc  directory, 95\nprocesses, 4, 131\u2013132\nbackground, 137\u2013138\ncommands, 139\u2013140\nbigcommand,  141\ncgroups, 143\u2013144\nchanging, 134\u2013135daemon processes, 5, 179\nforeground, 137\u2013138\ncommands, 139\u2013140\nkillall  command, 141\u2013142\nkilling, 135, 558\nkill  command, 140\nkillall  command, 140\nlimiting, 143\u2013144\nlisting\nps command, 132\u2013134\nSystem Monitor, 136\u2013137\ntop command, 134\u2013135\n( | )piping, 133\npriorities, 142\u2013143\nrenicing, 135\nRSS (resident set size), 133\nVSZ (virtual set size), 133\nprocessors, 196\nprofessional opportunities, 19\u201321\nprofile  file, 183\nprogramming, utilities, 5\nprompt, setting, 85\u201387\nprotocols, blocking, 685\u2013687\nprotocols  file, 183\nproxy servers, configuring connections, 352\u2013353\nps command, 132\u2013134\npublic cloud, 730\npublic key authentication, 313\npulling containers, 697\u2013698\npwd command, 67\nPXE server, 206\nRPM packages and, 246\nQ\nQEMU, 713\nqemu  process, 713\nquestion mark (?), 99\nQwest, 9\nR\nRAID partitions, 215\nRAM (random access memory), 197, 273\u2013274\ntroubleshooting and, 554\u2013555\nraw table, 678\nRBAC (role-based access control), 635\nTE (type enforcement) and, 637\u2013638\nrc.sysinit,  troubleshooting, 533\u2013534", "doc_id": "68c9d971-6d20-4286-be5f-1920ca1e4bc8", "embedding": null, "doc_hash": "31f003572b4972bba29c776148c68bd2df2974d59b706f3b4aea35b37e7b769f", "extra_info": {"page_label": "893"}, "node_info": {"start": 0, "end": 2083}, "relationships": {"1": "854b1789-6709-42db-a512-74ef59dc1c0a"}}, "__type__": "1"}, "131e9ccf-945b-4914-8538-d96d062ada5f": {"__data__": {"text": "Index\n880Read permissions, 106\nreal-time computing, 5\nRed Hat\nAnaconda installer, 17\ngraphical administration, 17\nRPM package management, 16\u201317\nRed Hat Enterprise\ndownloading, 789\u2013790\ninstalling, from DVD, 201\u2013204\nRed Hat OpenShift, 18\nRed Hat OpenStack Platform, 18\nRed Hat Virtualization, 5\nremote access, 307. See also  Secure Shell tools\ninteractive copying, 324\nremovable hardware, 189\u2013191\nRemovable Media window, 189\u2013190\nrenice  command, 142\u2013143\nrepositories, software, 223\nrescue mode, 212\ntroubleshooting in, 559\u2013561\nreserved words, 71\nREST API, Ansible Tower and, 763\nrestricted deletion directory, 268\u2013269\nreviews\ncompliance, 595\u2013596\nsecurity, 596\nRHCE (Red Hat Certified Engineer), 21, 22\nnetwork services, 24\u201325\nsystem configuration and management, 24\ntopics, 23\u201325\nRHCSA (Red Hat Certified System Administrator), 21, 22\ntopics, 22\u201323\nRHEL (Red Hat Enterprise Linux), 17\u201318\nTerminal window, 64\nRHELOSP (Red Hat Enterprise Linux OpenStack \nPlatform), 173\nRHEV (Red Hat Virtualization), 173\nRhythmbox (Nautilus), 45\u201346\nright parenthesis ( ) ), 78\nRitchie, Dennis, 8, 9\nrlogin,  316\nrm command, 110\nroot directory, 93\n/root  directory, 95\nroot user, 174\nsudo  facility, 176\u2013178\nvia GUI, 176\nvia shell, 175\u2013176\nrootkits, 590\u2013595route-interface  file, 363\nrpc file, 183\nrpcbind  service, 503\nrpm command\npackage installation, 241\u2013242\npackage removal, 241\u2013242\nquerying information, 242\u2013244\nRPM package management, 16\u201317\nRPM (RPM Package Manager) packaging, 225, 226\u2013228\ncontainer images, 246\ndependencies, 228\ninstalling, 228\nkickstart files, 246\nlocation, 228\norigins, 227\u2013228\nPXE boot, 246\nsatellite server, 246\nSpacewalk, 246\nverifying packages, 244\u2013245\nYUM and, 229\u2013232\nthird-party software repositories, 233\ntransition to DNF, 229\nyum command, 233\u2013241\nRSS (resident set size), 133\nrsync  command, 322\u2013323, 566\nrsyslog  service, 308, 326\u2013331\nrsyslog.conf  file, 183, 327\u2013329\nrsyslogd  daemon, 326\u2013327\nrsyslogd  facility and, 184\u2013185\nrunlevels, 369, 373\u2013374\ndefault, 369\nconfiguring, 394\u2013395\ntroubleshooting, 534\u2013538\nS\nSamba, 475\u2013476\nenterprise, 497\n/etc/samba/smb.conf  file\n[global],  486\u2013487\n[homes],  486, 487\u2013489\n[printers],  486, 489\u2013493\nfirewalls, configuring, 482\u2013483\nfolders\nchecking share, 490\u2013493\nshared, 489\u2013490\nhost/user permissions, 486\ninstalling, 476\u2013478\nprinter configuration, 422\u2013424", "doc_id": "131e9ccf-945b-4914-8538-d96d062ada5f", "embedding": null, "doc_hash": "4659b369234871be0654aecf0ca294817e080802047e97116178ca7e0d45f268", "extra_info": {"page_label": "894"}, "node_info": {"start": 0, "end": 2310}, "relationships": {"1": "0e2763f5-8282-48c8-bdb5-c6858d809ef8"}}, "__type__": "1"}, "410d6767-b34f-44af-9056-bdb1ad2ddf87": {"__data__": {"text": "Index\n881SELinux, configuring, 484\u2013486\nshare access\nLinux file manager, 493\u2013495\nmounting from command line, 495\u2013496\nWindows, 496\u2013497\nstarting, 478\u2013480\nstopping, 481\u2013482\nsamba  package, 309, 476\u2013478\nsamba-client  package, 476\nsamba-common  packages, 476\nsamba-winbind  package, 476\nSAN devices, 213\nSANS institute, 596\nsar command, 332\u2013333\nsatellite server, RPM packages and, 246\n/sbin  directory, 95\nSCO (Santa Cruz Operation), 10\nscp command, file copy and, 321\u2013324\nscripts, backup script, 162\nsecon  command, 648\u2013649\nsecret key cryptography, 603\nSecure Shell tools, 316\nclient tools, 318\u2013324\nkey-based authentication, 324\u2013326\nsecurity, 307\nApache web server\nfile ownership, 433\nfile permissions, 433\nfirewalls, 433\u2013434\nSELinux and, 434\u2013435\nBell-LaPadula Mandatory Access model, 639\ncryptography, 599\u2013600\nblock ciphers, 600\nciphers, 600\ndecryption, 600\nencryption/decryption, 602\u2013610\nhashing, 600\u2013601\nimplementing, 610\u2013618\nstream ciphers, 600\ndisaster recovery, 566\nfilesystem, 576\u2013579\nfirewalls, 672\u2013674\napplication-layer firewalls, 674\nCockpit and, 677\u2013678\nimplementing, 674\u2013688\niptables, 673\nnetwork-layer firewalls, 674\nMCS (Multi-Category Security), 638\nMLS (multi-level security), 638\u2013639mount-level, 499\nnetwork services, auditing, 663\u2013665, 665\u2013672\nPAM (Pluggable Authentication Modules), 618\nadministering, 622\u2013633\nauthentication process, 619\u2013622\nresources, 633\npasswords, 570\u2013576\nphysical, 565\u2013566\nservers, 312\u2013314\nconfiguration file settings, 314\nfirewalls, 313\npasswords, 312\u2013313\nSELinux, 313\nTCP Wrappers, 313\nservices, 579\u2013580\nsoftware, 579\u2013580\nsystem administration and, 169\nsystems monitoring, 580\u2013581\nfilesystem, 587\u2013595\nlog files, 581\u2013584\nuser accounts, 584\u2013587\nuser accounts, 566\u2013569\nsecurity clearance, 639\nsecurity reviews, 596\nsecurity  table, 678\nsed command, 160\nSELinux (Security Enhanced Linux), 313\nbenefits of, 635\u2013636\nBooleans and, 653\u2013654\nBooleans for Samba, 484\u2013485\nconfiguration, NFS server, 511\u2013512\nerrors, 452\nfile contexts for Samba, 485\u2013486\nleast privilege access, 636\nmode, setting, 645\u2013647\nmonitoring, 654\u2013656\noperational modes\ndisabled mode, 639\u2013640\nenforcing mode, 640\npermissive mode, 640\npolicy rules, 644\u2013645\npackage management, 651\u2013653\npolicy types, 643\nminimum, 644\nMLS (Multi-Level Security), 644\nsetting, 647\u2013648\ntargeted, 644\nprocess sandboxing, 636\nRBAC, 636", "doc_id": "410d6767-b34f-44af-9056-bdb1ad2ddf87", "embedding": null, "doc_hash": "1332cb7d625bd7c4d4ea65eb3eb237c4a9669fbc003847d5707aea2f2d69a940", "extra_info": {"page_label": "895"}, "node_info": {"start": 0, "end": 2307}, "relationships": {"1": "9c6ac038-0c4f-4f96-9761-a7521cb18726"}}, "__type__": "1"}, "157bdee0-6094-4bc8-9a99-51b549305942": {"__data__": {"text": "Index\n882resources, 659\nsecurity contexts, 640\u2013641\nfile security, 650\u2013651\nfiles, 642\nlevel  attribute, 641\nprocesses, 642\u2013643\nrole  attribute, 641\nsecon  command, 648\u2013649\ntype  attribute, 641\nuser, 649\u2013650\nuser  attribute, 641\nusers, 641\u2013642\nsecurity models, implementing, 639\u2013645\nTE (type enforcement), 637\u2013638\ntesting, 636\ntroubleshooting\nBooleans set incorrectly, 658\u2013659\ncontext labels, lost, 658\nlogging, 656\u2013657\nnonstandard directory as service,  \n657\nnonstandard port as service, 658\nsemicolon character (;), 78, 79\nsequential commands, 79\nservers, 307\nchecking, 316\nconfiguring, 310\u2013311\nenterprise and, 336\ninstallation server, 206\ninstalling, 308\u2013310\nmonitoring, 314\u2013315\nCockpit, 314\ncrackers, 315\nlogging configuration, 314\nsoftware updates, 315\nsystem activity reports, 314\nnetwork, 340\npackages\ndirectory server, 309\nDNS server, 309\nFTP server, 309\nmail server, 309\nNetwork Time Protocol server, 309\nNFS file server, 309\nprint server, 309\nrsyslog  service, 308\u2013309\nSQL server, 309\nsystem logging server, 308\u2013309web server, 309\nWindows file server, 309\nPXE, 206\nsecuring, 312\u2013314\nconfiguration file settings, 314\nfirewalls, 313\npasswords, 312\u2013313\nSELinux, 313\nTCP Wrappers, 313\nsetting, 316\nstarting, 311\u2013312\nsystem administration and, 169\nservices\nfirewalld,  674\u2013675, 675\u2013677\npersistent, enabling, 391\u2013394\nreloading, 388\nsecurity, 579\u2013580\nstarting, 5\nstatus, checking, 384\u2013387\nsystemd,  new, 399\u2013401\nSysVinit\nnew, 396\u2013398\nstarting and stopping, 387\u2013391\nservices  file, 183\nset GID bit, 267\u2013268\nset UID bit, 268\nsetfacl  command, 262\u2013264\nsftp  command, 324\nsh shell, 65\nshadow  file, 183\nshared filesystems, exporting, 507\nshell, 4, 61\n# prompt, 63\n$ prompt, 63\naccessing, 62\u201363\nash, 61\nbash shell, 61\nconfiguration files, 84\nBourne shell, 61\ncommand languages and, 62\nconfiguring, 84\u201385\ncsh (C shell), 61, 65\ndash,  65\ndash shell, 61\nenvironment, 84\u201387\nenvironment variables, 87\nexiting, 83\u201384\nksh,  65\nmetacharacterspackages (continued)", "doc_id": "157bdee0-6094-4bc8-9a99-51b549305942", "embedding": null, "doc_hash": "2a8e326d2030f2e78b68cb2859f39b5c07a7d9d93d7479d450244fca86270bed", "extra_info": {"page_label": "896"}, "node_info": {"start": 0, "end": 1950}, "relationships": {"1": "18d7b87e-2110-4bf2-80e8-47ac8e602f47"}}, "__type__": "1"}, "5941d376-ff8b-415d-8a48-c526773c0ee3": {"__data__": {"text": "Index\n883brace expansion, 101\nfile-matching, 98\u201399\nfile-redirection, 99\u2013100\nprompt, 63\nsetting, 85\u201387\nreasons to learn, 62\nroot user, 175\u2013176\nrunning from container, 698\u2013699\nselecting, 65\u201366\nsh, 65\ntcsh,  61, 65\nvariables, 81\nshell history, 72\u201373\nshell script\narithmetic in, 152\u2013153\nbackup script, 162\ncase  command, 156\u2013157\nchmod  command, 162\ncommand-line argument, 148, 150\u2013151\ncut command, 159\nfor...do  loop, 157\u2013158\ngrep,  159\nif...then  statements, 153\u2013154\ninterpreter, 148\nparameters\nexpanding, 151\u2013152\nreading in, 151\npositional parameters, 150\u2013151\nprogramming constructs, 153\u2013159\nsed command, 160\nspecial characters, escaping, 149\ntelephone list example, 161\u2013162\ntext\ncutting, 159\u2013160\ndeleting, 160\ntranslating, 160\ntext manipulation, 159\u2013161\ntr command, 160\nuntil...do  loop, 158\u2013159\nvariables, 149\nwhile...do  loop, 158\u2013159\nshell scripts, 147\u2013148\nshells  file, 183\nsidecar containers, 766\nsignals, 141\nsingle-partition disks, 277\u2013281\nSlackware, 16\nSLES (SUSE Linux Enterprise Server), 730\nSMB (Server Message Block), 475smb.conf  file, 422\u2013423\nsoftware\nbounties, 21\ndependent software, 224\nfree software, 12\ninstallation, 221\u2013222\nsystem administrator and, 168\nNautilus, 43\u201345\nopen source software, 12\nrepositories, 223\nsecurity, 579\u2013580\nadvisories, 580\npackage updates, 579\u2013580\nsubscriptions, 20\u201321\nupstream software providers, 228\nSoftware window, 222\u2013223\nsource code, UNIX and, 10\nSpacewalk, RPM packages and, 246\nspecial characters, escaping, 149\nspecialized storage, 5\nSquid Proxy Server, 366\nSSH (Secure Shell), 307\nssh command, 316\nremote execution, 320\u2013321\nremote login, 318\u2013320\nsshd  service, 718\nstarting, 317\u2013318\nat boot, 318\nstatus, 317\nStallman, Richard M., 11\nstartup methods\ninit  facility, 524\u2013525\nsystemd  facility, 525\nstatements, echo,  148\nsticky bits, 103, 268\u2013269\nstorage\ncloud, 711, 713\nconfiguring, 718\u2013720\nsetup, 714\nCockpit, 301\u2013303\nspecialized, 5, 213\nvolume groups, 274\nstream editor (sed), 160\nsu command, 168, 175\u2013176\nsubscriptions, 20\u201321\nsudo  command, 168, 632\u2013633\nsudo  facility, 176\u2013178\nsudoers  file, 177, 183\nsuperuser, 167", "doc_id": "5941d376-ff8b-415d-8a48-c526773c0ee3", "embedding": null, "doc_hash": "5f6d9072cd7b63535a6def61c9ccff1227f9cd46720914785231a1ca0bf16c8a", "extra_info": {"page_label": "897"}, "node_info": {"start": 0, "end": 2070}, "relationships": {"1": "f14bf528-b3b1-4135-b175-1100d96baedd"}}, "__type__": "1"}, "2e1654cc-e559-43b5-aeb0-9e11286de456": {"__data__": {"text": "Index\n884SVID (System V Interface Definition), 10\nswap partitions, 215\nswap space, 4, 274\ntroubleshooting and, 554\u2013555\nSYN (synchronize packet), 666\nsyntax, commands, 67\u201368\n/sys  directory, 95\nsysstat  package, sar  command, 332\u2013333\nSystem Activity Reporter, 332\u2013333. See also  \nsar command\nsystem administration, 167\nbrowser-based tools, 173\nCockpit, 168, 169\u2013171\ncommands, 178\u2013179\nconfiguration files, 179\u2013185\ndaemon processes\napache,  185\navahi,  185\nbin,  185\nchrony,  185\nlp, 185\nnews,  186\npostfix,  185\nrpc,  186\nfilesystems and, 168\ngraphical tools, 172\nhardware\nchecking, 187\u2013189\nloadable modules, 191\u2013193\nremovable, 189\u2013191\nlog files, 183\u2013184\nrsyslogd  facility and, 184\u2013185\nnetwork interfaces, 169\nroot user, 174\nvia shell, 175\u2013176\nsecurity, 169\nservers, 169\nsoftware installation and, 168\nsystem-config*  tools, 171\u2013173\nsystemd  journal, 183\u2013184\nuser accounts and, 168\nsystem administrator, 167\nsystem logging\nenabling, 326\u2013331\nloghost, 330\u2013331\nlogwatch,  331\u2013332\nmessage log file, 329\nrsyslogd  daemon, 326\u2013327\nSystem Monitor, processesending, 136\nkilling, 136\nlisting, 136\u2013137\npriorities, 137\nstopping, 136\nsystem space\ndisk consumption, 335\u2013336\ndisk usage check, 334\u2013335\ndisplaying, 334\nSystem V, init  facility, 524\u2013525\ntroubleshooting, 533\nsystem-config*  tools, 171\nsystem-config-authentication,  172\nsystem-config-bind,  172\nsystem-config-date,  172\nsystem-config-firewall,  172\nsystem-config-httpd,  172\nsystem-config-kickstart,  173\nsystem-config-language,  172\nsystem-config-nfs,  172\nsystem-config-printer,  172\nsystem-config-rootpassword,  172\nsystem-config-samba,  172\nsystem-config-selinux,  172\nsystem-config-services,  172\nsystem-config-users,  172\nsystemctl  command, 381\nsystemd,  370\u2013371, 525\ninitialization, 377\u2013384\njournal, 183\u2013184\nservice units, 378\u2013380\nservices\nnew, 399\u2013401\nreloading, 390\u2013391\nrestarting, 389\u2013390\nstarting, 389\nstopping, 389\nSysVinit,  backward compatibility,  \n382\u2013384\ntarget units, 377, 378, 381\u2013382, 395\ntroubleshooting, 538\u2013541\nunits, 377\nsystems monitoring, 580\u2013581\nfilesystem, 587\nrootkits, 590\u2013595\nscanning, 589\u2013590\nsoftware package verification, 588\nvirus detection, 590\u2013595\nlog files, 581", "doc_id": "2e1654cc-e559-43b5-aeb0-9e11286de456", "embedding": null, "doc_hash": "057b4b293f8cc220e39567d683f7aa721d00f759f909801ac2cd25c83a93a652", "extra_info": {"page_label": "898"}, "node_info": {"start": 0, "end": 2149}, "relationships": {"1": "1cb0578c-0020-4679-9804-36abb1bab365"}}, "__type__": "1"}, "47295507-957a-4c4f-a0a6-baf566a5b854": {"__data__": {"text": "Index\n885special commands, 582\u2013583\n/var/log  directory, 581\u2013582\nuser accounts, 584\nbad passwords, 586\u2013587\ncounterfeit accounts and privileges, 584\u2013586\nSysVinit,  370, 372\nbackward compatibility, 382\u2013384\nrunlevels, default, 394\u2013395\nservices\nchecking, 385\u2013387\nnew, 396\u2013398\npersistent, 391\u2013394\nstarting/stopping, 387\u2013391\nT\ntar,  566\nencryption/decryption, 604\ntarballs, 16, 224\u2013225\ntarget units, 377, 395\ntargeted policy, 638\u2013639\ntargets, 369\nTCP Connect port scan, 666, 668\nTCP Wrappers, 313\nNFS access, 510\ntcsh  shell, 61, 65\nTE (type enforcement), 637\u2013638\ntelinit  command, 374\ntelnet, 316\nTerminal emulator, 63\u201364\nTerminal window, 63\nGNOME Terminal, 64\nlaunching, 64\nterminal windows, 62\u201363\ntest expressions, 154\u2013156\ntext\nadding, vi  editor, 115\u2013116\nchanging, vi  editor, 117\ncommands, 79\ncopying, vi  editor, 117\ncutting, 159\ndeleting, 160\nvi editor, 117\ngrep,  159\nhere text, 100\nmoving within, vi  editor, 116\u2013117\npasting, vi  editor, 118\nsearching for, vi  editor, 119\u2013120\ntranslating, 160text editors\nemacs,  114\njed,  114\njoe,  114\nkate,  114\nkedit,  114\nmcedit,  114\nnano,  114\nnedit,  114\nvi, 113\u2013119\narrow keys, 116\u2013117\ncommand mode, 115\ncommand repeat, 118\ncursor, 115\nex mode, 120\nexiting, 118\u2013119\ninput mode, 115\nmoving around in file, 119\ntext, 115\u2013120\nvim,  113\u2013114\nThompson, Ken, 8\ntilde (~), 97\n/tmp  directory, 95\ntop command, 134\u2013135\nTorvalds, Linus, 7, 13\u201314\ntouch  command, 98\u201399\ntr command, 160\ntraining, 21\ntranslating text, 160\ntroubleshooting\nBIOS (Basic Input Output System),  \n526\u2013527\nboot order, 527\u2013528\nboot up and, 523\u2013524\nfrom firmware, 526\u2013528\nkernel startup, 532\u2013541\nstartup methods, 524\u2013525\nGRUB 2 boot loader, 530\u2013531\nGRUB boot loader, 528\u2013530\ninit  system, 533\nmemory, 553\u2013554\nuncovering issues, 554\u2013559\nnetworking\nincoming connections, 550\u2013553\noutgoing connections, 547\u2013550\nRAM and, 554\u2013555\nrc.sysinit,  533\u2013534\nin rescue mode, 559\u2013561\nrunlevels, 534\u2013538", "doc_id": "47295507-957a-4c4f-a0a6-baf566a5b854", "embedding": null, "doc_hash": "f55c3be793ee153050bede144714d2ae9f7afc3a1c1382a66bc32c21a4803eaa", "extra_info": {"page_label": "899"}, "node_info": {"start": 0, "end": 1892}, "relationships": {"1": "e940afb5-1b99-4fec-b375-13e230e8fc17"}}, "__type__": "1"}, "1d8b7d68-8728-4102-a755-d576e2794e4a": {"__data__": {"text": "Index\n886software packages, 542\u2013545\nRPM databases and caches, 545\u2013546\nsystemd  initialization, 538\u2013541\ntype  command, 71\nU\nUbuntu, 19\ndownloading, 790\u2013791\nUbuntu Software Center, 225\nUDP port scan, 666\nUEFI (Unified Extensible Firmware Interface), 526\u2013528\numask  value, 108\u2013109\numount  command, 299\nunits, systemd,  377\nUNIX, 7\u20138\nassembler, 9\ncommercial, Berkeley distribution, 9\u201310\nfilesystem, 8\ninput/output redirection, 8\nlaboratory, 10\u201311\nportability, 8\u20139\nprint commands, 404\nprinters, remote, 413\npublished interfaces, 10\nsource code, 10\nUSL (UNIX System Laboratories), 10\nunmounting filesystems, 520\u2013521\nuntyped variables, 152\u2013153\nupdates, Gentoo, 207\nupgrades from scratch, 207\nupstream software providers, 228\nUSB drive, 197\nbooting Linux from, 791\u2013792\nuser accounts\ncentralizing, 269\u2013270\nCockpit, 249\u2013252\ncreating, 249\u2013250\ndefaults, 255\u2013257\ndeleting, 258\u2013259\nmodifying, 257\u2013258\nsecurity, 566\nnumber of users, 567\nroot, access, 567\ntemporary account expiration, 567\u2013568\nunused, 568\u2013569\nsystem administrator and, 168\nuseradd  command, 252\u2013255user interfaces, 4\nuseradd  command\nadding users, 252\u2013255\ndefaults, setting, 255\u2013257\nuserdel  command, 258\u2013259\nusermod  command, 257\u2013258\nusername, completion, 75\nUSL (UNIX System Laboratories), 10\n/usr  directory, 95\nutilities\nadministrative, 4\u20135\nbackup, 566\ncracklib,  571\niptables,  673\u2013674, 678\u2013688\nnmap,  665\u2013672\nprogramming, 5\nUTS namespace, 695\nV\n/var  directory, 95\nvariables\ncommand output, 149\ncompletion, 75\nenvironment variables, 81, 82\u201383\nadding to shell, 87\nPATH, 70\nexpanding, 80\u201381\nshell, 81\nshell scripts, 149\nuntyped, 152\u2013153\nVerizon, 9\nVery Secure FTP daemon, 309\nVFAT, 275\nvi editor, 85, 113\u2013114\narrow keys, 116\u2013117\ncommand mode, 115\ncommands, repeating, 118\ncursor, 115\nex mode, 120\nexiting, 118\u2013119\ninput mode, 115\nmoving around in file, 119\ntext\nadding, 115\u2013116\nchanging, 117\ncopying, 117\ndeleting, 117\nmoving in, 116\u2013117troubleshooting (continued)", "doc_id": "1d8b7d68-8728-4102-a755-d576e2794e4a", "embedding": null, "doc_hash": "12843f3a7741e8105048edc68a2d990ed8a15c5030c644ab9f27dbeb0a54293f", "extra_info": {"page_label": "900"}, "node_info": {"start": 0, "end": 1919}, "relationships": {"1": "4990288f-9a75-4a29-95ad-7ff392f458ec"}}, "__type__": "1"}, "1716a32b-b80f-4576-a281-67b8a4a9346e": {"__data__": {"text": "Index\n887pasting, 118\nsearching for, 119\u2013120\nvideo, boot options, 210\nvim editor, 113\u2013114\nvimtutor,  177\nvirsh  command, 711\nvirt-install  command, 720\u2013721\nvirt-manager,  711, 717, 720\u2013724,  \n722\nvirt-manager  command, 714\nvirtual consoles, 65\nVirtual Machine Manager, 711,  \n714\nstarting, 722\nvirtual memory, 556\nVirtualBox, 209\nvirtualization, 5, 709\nLinux installation, 209\nviewer, 714\nvirt-viewer  command, 714\nvirus detection, 590\nintrusion detection, 592\u2013595\nmonitoring for rootkits, 591\u2013592\nmonitoring for viruses, 591\nvirus signature, 591\nVMs (virtual machines), 693\u2013694, 709, 713. See also  \nhypervisor\nconnections, 722\ncreating, 720\u2013724\nimages, 721\ninstalling, 724\nmanaging, 724\u2013725\nmigrating, 725\u2013727\nnetwork bridge and, 721\nsystem, viewing, 724\u2013725\nVMware, 209\nVNC installations, boot options,  \n212\nvolume groups, 274\nVPN (virtual private network), 339\nvsftpd,  309, 458\u2013461\nfile permissions, 465\ninstalling, 457\u2013458\nsetup, 468\u2013469\nVSZ (virtual set size), 133W\nweb server, 309\nApache HTTPD, 427\u2013428\ninstalling, 431\nwho am i command, 65\nwildcards, 505\nWinbind, 270\nwindow manager, 29\nwindows\ngraphical, 168\nterminal windows, 62\u201363\nWindows (SMB) printer, 414\u2013415\nWindows-based filesystems, 95\nwired networks, 339\nwireless networks, 339\nworker nodes, 710\nWrite permissions, 106\nX\nX Window System, 28\nbackground, 28\nclients, 28\nservers, 28\nwindow manager, 29\nXen, 5, 209, 710\nXfce, 29\nxinetd.conf  file, 183\nY\u2013Z\nYUM (YellowDog Update Modified)\nDNF (Dandified YUM), 229\npackages\ngroups, updating, 239\u2013240\ninstalling, 236\u2013237\nmaintenance, 240\nremoving, 236\u2013237\nsearching for, 234\u2013235\nupdating, 238\nRPM download, 241\nthird-party software repositories, 233\nyum command, syntax, 229\u2013232\nyum cache, 546\nyum command, 229\u2013241", "doc_id": "1716a32b-b80f-4576-a281-67b8a4a9346e", "embedding": null, "doc_hash": "c8cb01c4e844f0a590aeae07631292bca2c52b66d6f01aa2edd63be164f0846d", "extra_info": {"page_label": "901"}, "node_info": {"start": 0, "end": 1726}, "relationships": {"1": "617fb5da-93b0-4a73-8d01-5d4df1e5b623"}}, "__type__": "1"}}}